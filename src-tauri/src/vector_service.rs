use crate::database::DatabaseManager;
use crate::types::*;
use anyhow::{Result, anyhow};
use tracing::info;
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;
use lru::LruCache;
use rayon::prelude::*;
use sqlx::Row;

// å‘é‡æœåŠ¡
pub struct VectorService {
    db: Arc<DatabaseManager>,
    embedding_cache: Arc<RwLock<LruCache<String, Vec<f32>>>>,
    model_cache: Arc<RwLock<HashMap<String, EmbeddingModel>>>,
}

impl VectorService {
    pub fn new(db: Arc<DatabaseManager>) -> Self {
        Self {
            db,
            embedding_cache: Arc::new(RwLock::new(LruCache::new(std::num::NonZeroUsize::new(10000).unwrap()))),
            model_cache: Arc::new(RwLock::new(HashMap::new())),
        }
    }

    // è·å–åµŒå…¥æ¨¡å‹é…ç½®
    pub async fn get_embedding_model(&self, model_id: &str) -> Result<EmbeddingModel> {
        // æ£€æŸ¥ç¼“å­˜
        {
            let cache = self.model_cache.read().await;
            if let Some(model) = cache.get(model_id) {
                return Ok(model.clone());
            }
        }

        // ä»æ•°æ®åº“è·å– - å°è¯•é€šè¿‡model_idæŸ¥æ‰¾ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™é€šè¿‡idæŸ¥æ‰¾
        let row = sqlx::query(
            "SELECT id, name, model_id, dimensions, language, enabled, max_tokens, created_at, updated_at
             FROM embedding_models WHERE model_id = ? AND enabled = 1"
        )
        .bind(model_id)
        .fetch_one(self.db.main_pool())
        .await?;

        let model = EmbeddingModel {
            id: row.get(0),
            name: row.get(1),
            model_id: row.get(2),
            dimensions: row.get(3),
            language: row.get(4),
            enabled: row.get(5),
            max_tokens: row.get(6),
            created_at: chrono::DateTime::from_timestamp(row.get(7), 0).unwrap_or_default(),
            updated_at: chrono::DateTime::from_timestamp(row.get(8), 0).unwrap_or_default(),
        };

        // æ›´æ–°ç¼“å­˜
        {
            let mut cache = self.model_cache.write().await;
            cache.insert(model_id.to_string(), model.clone());
        }

        Ok(model)
    }

    // è·å–æ‰€æœ‰å¯ç”¨çš„åµŒå…¥æ¨¡å‹
    pub async fn get_available_models(&self) -> Result<Vec<EmbeddingModel>> {
        let rows = sqlx::query(
            "SELECT id, name, model_id, dimensions, language, enabled, max_tokens, created_at, updated_at
             FROM embedding_models WHERE enabled = 1 ORDER BY language, name"
        )
        .fetch_all(self.db.main_pool())
        .await?;

        let mut models = Vec::new();
        for row in rows {
            models.push(EmbeddingModel {
                id: row.get(0),
                name: row.get(1),
                model_id: row.get(2),
                dimensions: row.get(3),
                language: row.get(4),
                enabled: row.get(5),
                max_tokens: row.get(6),
                created_at: chrono::DateTime::from_timestamp(row.get(7), 0).unwrap_or_default(),
                updated_at: chrono::DateTime::from_timestamp(row.get(8), 0).unwrap_or_default(),
            });
        }

        Ok(models)
    }

    // ç”Ÿæˆæ–‡æœ¬åµŒå…¥
    pub async fn generate_embedding(&self, text: &str, model_id: &str) -> Result<Vec<f32>> {
        // ç”Ÿæˆç¼“å­˜é”®
        let cache_key = format!("embedding:{}:{}", model_id, text);

        // æ£€æŸ¥ç¼“å­˜
        {
            let mut cache = self.embedding_cache.write().await;
            if let Some(cached_embedding) = cache.get(&cache_key) {
                return Ok(cached_embedding.clone());
            }
        }

        // è·å–æ¨¡å‹é…ç½®
        let model = self.get_embedding_model(model_id).await?;

        // è°ƒç”¨å®é™…çš„åµŒå…¥æœåŠ¡ï¼ˆä½¿ç”¨ç©ºAPIå¯†é’¥ï¼Œå°†è¿”å›é”™è¯¯è€Œä¸æ˜¯å›é€€åˆ°æ¨¡æ‹Ÿå®ç°ï¼‰
        let embedding = self.generate_real_embedding(text, &model, "").await?;

        // ç¼“å­˜ç»“æœ
        {
            let mut cache = self.embedding_cache.write().await;
            cache.put(cache_key, embedding.clone());
        }

        Ok(embedding)
    }

    // æ‰¹é‡ç”ŸæˆåµŒå…¥ï¼ˆä½¿ç”¨APIå¯†é’¥ï¼‰
    pub async fn generate_embeddings_with_api_key_batch(&self, texts: &[String], model: &EmbeddingModel, api_key: &str) -> Result<Vec<Vec<f32>>> {
        // è°ƒç”¨å®é™…çš„åµŒå…¥æœåŠ¡ï¼Œä½¿ç”¨æä¾›çš„APIå¯†é’¥
        let embeddings = self.generate_real_embeddings_batch(texts, model, api_key).await?;
        Ok(embeddings)
    }

    // æ‰¹é‡ç”ŸæˆåµŒå…¥
    pub async fn generate_embeddings_batch(&self, texts: &[String], model_id: &str) -> Result<Vec<Vec<f32>>> {
        let model = self.get_embedding_model(model_id).await?;

        // è°ƒç”¨å®é™…çš„åµŒå…¥æœåŠ¡ï¼ˆä½¿ç”¨ç©ºAPIå¯†é’¥ï¼Œå°†å›é€€åˆ°æ¨¡æ‹Ÿå®ç°ï¼‰
        let embeddings = self.generate_real_embeddings_batch(texts, &model, "").await?;

        Ok(embeddings)
    }

    // è°ƒç”¨å®é™…çš„åµŒå…¥æœåŠ¡
    async fn generate_real_embedding(&self, text: &str, model: &EmbeddingModel, api_key: &str) -> Result<Vec<f32>> {
        // è°ƒç”¨ SiliconFlow API æˆ–å…¶ä»–åµŒå…¥æœåŠ¡
        let result = crate::siliconflow_embedding::generate_siliconflow_embedding(
            api_key.to_string(),
            text.to_string(),
            model.model_id.clone()
        ).await;

        // è½¬æ¢ Result<Vec<f32>, String> ä¸º Result<Vec<f32>, anyhow::Error>
        result.map_err(|e| anyhow::anyhow!(e))
    }

    // æ‰¹é‡è°ƒç”¨å®é™…çš„åµŒå…¥æœåŠ¡
    async fn generate_real_embeddings_batch(&self, texts: &[String], model: &EmbeddingModel, api_key: &str) -> Result<Vec<Vec<f32>>> {
        const MAX_BATCH_SIZE: usize = 32; // SiliconFlow APIé™åˆ¶

        if texts.len() <= MAX_BATCH_SIZE {
            // å¦‚æœæ•°é‡åœ¨é™åˆ¶å†…ï¼Œç›´æ¥è°ƒç”¨
            let result = crate::siliconflow_embedding::generate_siliconflow_batch_embeddings(
                api_key.to_string(),
                texts.to_vec(),
                model.model_id.clone()
            ).await;
            return result.map_err(|e| anyhow::anyhow!(e));
        }

        // åˆ†æ‰¹å‘é€è¯·æ±‚
        println!("ğŸ“¦ æ–‡æœ¬æ•°é‡({})è¶…è¿‡APIé™åˆ¶({})ï¼Œå¼€å§‹åˆ†æ‰¹å‘é€...", texts.len(), MAX_BATCH_SIZE);
        let mut all_embeddings = Vec::new();

        for (batch_index, chunk) in texts.chunks(MAX_BATCH_SIZE).enumerate() {
            println!("ğŸ”„ å¤„ç†ç¬¬ {}/{} æ‰¹ ({} ä¸ªæ–‡æœ¬)", batch_index + 1, (texts.len() + MAX_BATCH_SIZE - 1) / MAX_BATCH_SIZE, chunk.len());

            let result = crate::siliconflow_embedding::generate_siliconflow_batch_embeddings(
                api_key.to_string(),
                chunk.to_vec(),
                model.model_id.clone()
            ).await;

            match result {
                Ok(batch_embeddings) => {
                    let count = batch_embeddings.len();
                    all_embeddings.extend(batch_embeddings);
                    println!("âœ… ç¬¬ {} æ‰¹å¤„ç†å®Œæˆï¼Œè·å¾— {} ä¸ªå‘é‡", batch_index + 1, count);
                },
                Err(e) => {
                    println!("âŒ ç¬¬ {} æ‰¹å¤„ç†å¤±è´¥: {}", batch_index + 1, e);
                    return Err(anyhow::anyhow!("æ‰¹é‡å¤„ç†ç¬¬ {} æ‰¹å¤±è´¥: {}", batch_index + 1, e));
                }
            }
        }

        println!("âœ… æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œæ€»å…±ç”Ÿæˆ {} ä¸ªå‘é‡", all_embeddings.len());
        Ok(all_embeddings)
    }
    async fn mock_generate_embedding(&self, text: &str, model: &EmbeddingModel) -> Result<Vec<f32>> {
        // ç®€å•çš„æ¨¡æ‹ŸåµŒå…¥ç”Ÿæˆ
        let dimensions = model.dimensions as usize;
        let mut embedding = vec![0.0; dimensions];

        // ä½¿ç”¨æ–‡æœ¬çš„ç®€å•å“ˆå¸Œæ¥ç”Ÿæˆä¼ªéšæœºå‘é‡
        let mut hash: i32 = 0;
        for byte in text.as_bytes() {
            hash = hash.wrapping_mul(31).wrapping_add(*byte as i32);
        }

        // å¡«å……å‘é‡
        for i in 0..dimensions {
            embedding[i] = ((hash.wrapping_mul(i as i32 + 1)) as f32 / 2147483647.0) * 2.0 - 1.0;
        }

        // å½’ä¸€åŒ–
        let norm: f32 = embedding.iter().map(|x| x * x).sum::<f32>().sqrt();
        if norm > 0.0 {
            for val in &mut embedding {
                *val /= norm;
            }
        }

        Ok(embedding)
    }

    // å‘é‡ç›¸ä¼¼åº¦è®¡ç®—
    pub fn cosine_similarity(&self, vec1: &[f32], vec2: &[f32]) -> Result<f32> {
        if vec1.len() != vec2.len() {
            return Err(anyhow!("Vector dimensions don't match"));
        }

        let dot_product: f32 = vec1.iter().zip(vec2.iter()).map(|(a, b)| a * b).sum();
        let norm1: f32 = vec1.iter().map(|x| x * x).sum::<f32>().sqrt();
        let norm2: f32 = vec2.iter().map(|x| x * x).sum::<f32>().sqrt();

        if norm1 == 0.0 || norm2 == 0.0 {
            return Ok(0.0);
        }

        Ok(dot_product / (norm1 * norm2))
    }

    // å‘é‡è·ç¦»è®¡ç®—ï¼ˆæ¬§å‡ é‡Œå¾—è·ç¦»ï¼‰
    pub fn euclidean_distance(&self, vec1: &[f32], vec2: &[f32]) -> Result<f32> {
        if vec1.len() != vec2.len() {
            return Err(anyhow!("Vector dimensions don't match"));
        }

        let sum_squares: f32 = vec1.iter().zip(vec2.iter())
            .map(|(a, b)| (a - b).powi(2))
            .sum();

        Ok(sum_squares.sqrt())
    }

    // æ‰¹é‡å‘é‡ç›¸ä¼¼åº¦è®¡ç®—
    pub fn batch_cosine_similarity(&self, query_vec: &[f32], vectors: &[Vec<f32>]) -> Result<Vec<f32>> {
        let similarities: Result<Vec<_>> = vectors
            .par_iter()
            .map(|vec| self.cosine_similarity(query_vec, vec))
            .collect();

        similarities
    }

    // å‘é‡èšç±»ï¼ˆç®€å•çš„K-meansï¼‰
    pub fn kmeans_clustering(&self, vectors: &[Vec<f32>], k: usize, max_iterations: usize) -> Result<(Vec<Vec<f32>>, Vec<usize>)> {
        if vectors.is_empty() || k == 0 {
            return Err(anyhow!("Invalid input for clustering"));
        }

        let _dimensions = vectors[0].len();
        let mut centroids = self.initialize_centroids(vectors, k)?;
        let mut assignments = vec![0; vectors.len()];

        for iteration in 0..max_iterations {
            let mut changed = false;

            // åˆ†é…æ¯ä¸ªå‘é‡åˆ°æœ€è¿‘çš„ä¸­å¿ƒç‚¹
            for (i, vector) in vectors.iter().enumerate() {
                let mut min_distance = f32::INFINITY;
                let mut closest_centroid = 0;

                for (j, centroid) in centroids.iter().enumerate() {
                    let distance = self.euclidean_distance(vector, centroid)?;
                    if distance < min_distance {
                        min_distance = distance;
                        closest_centroid = j;
                    }
                }

                if assignments[i] != closest_centroid {
                    assignments[i] = closest_centroid;
                    changed = true;
                }
            }

            // æ›´æ–°ä¸­å¿ƒç‚¹
            for j in 0..k {
                let cluster_vectors: Vec<&Vec<f32>> = vectors.iter()
                    .enumerate()
                    .filter(|&(i, _)| assignments[i] == j)
                    .map(|(_, v)| v)
                    .collect();

                if !cluster_vectors.is_empty() {
                    let new_centroid = self.calculate_centroid(&cluster_vectors)?;
                    centroids[j] = new_centroid;
                }
            }

            if !changed {
                break;
            }

            info!("K-means iteration {} completed", iteration + 1);
        }

        Ok((centroids, assignments))
    }

    // åˆå§‹åŒ–ä¸­å¿ƒç‚¹
    fn initialize_centroids(&self, vectors: &[Vec<f32>], k: usize) -> Result<Vec<Vec<f32>>> {
        if vectors.len() <= k {
            return Ok(vectors.to_vec());
        }

        let mut centroids = Vec::new();
        let mut used_indices = std::collections::HashSet::new();

        // éšæœºé€‰æ‹©kä¸ªä¸åŒçš„å‘é‡ä½œä¸ºåˆå§‹ä¸­å¿ƒç‚¹
        use rand::Rng;
        let mut rng = rand::thread_rng();

        while centroids.len() < k {
            let index = rng.gen_range(0..vectors.len());
            if !used_indices.contains(&index) {
                centroids.push(vectors[index].clone());
                used_indices.insert(index);
            }
        }

        Ok(centroids)
    }

    // è®¡ç®—ä¸­å¿ƒç‚¹
    fn calculate_centroid(&self, vectors: &[&Vec<f32>]) -> Result<Vec<f32>> {
        if vectors.is_empty() {
            return Err(anyhow!("Cannot calculate centroid of empty cluster"));
        }

        let dimensions = vectors[0].len();
        let mut centroid = vec![0.0; dimensions];

        for vector in vectors {
            for (i, &val) in vector.iter().enumerate() {
                centroid[i] += val;
            }
        }

        let count = vectors.len() as f32;
        for val in &mut centroid {
            *val /= count;
        }

        Ok(centroid)
    }

    // å‘é‡é™ç»´ï¼ˆPCAç®€åŒ–ç‰ˆï¼‰
    pub fn pca_reduce(&self, vectors: &[Vec<f32>], target_dim: usize) -> Result<Vec<Vec<f32>>> {
        if vectors.is_empty() || target_dim == 0 {
            return Err(anyhow!("Invalid input for PCA"));
        }

        let original_dim = vectors[0].len();
        if target_dim >= original_dim {
            return Ok(vectors.to_vec());
        }

        // ç®€åŒ–çš„PCAå®ç°
        // 1. è®¡ç®—å‡å€¼
        let mean = self.calculate_mean(vectors)?;

        // 2. ä¸­å¿ƒåŒ–æ•°æ®
        let centered: Vec<Vec<f32>> = vectors.iter()
            .map(|v| v.iter().zip(&mean).map(|(a, b)| a - b).collect())
            .collect();

        // 3. è®¡ç®—åæ–¹å·®çŸ©é˜µ
        let covariance = self.calculate_covariance(&centered)?;

        // 4. è®¡ç®—ç‰¹å¾å‘é‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
        let eigenvectors = self.simplify_eigenvectors(&covariance, target_dim)?;

        // 5. æŠ•å½±åˆ°æ–°çš„ç©ºé—´
        let reduced: Result<Vec<_>> = centered.iter()
            .map(|v| self.project_vector(v, &eigenvectors))
            .collect();

        reduced
    }

    // è®¡ç®—å‡å€¼å‘é‡
    fn calculate_mean(&self, vectors: &[Vec<f32>]) -> Result<Vec<f32>> {
        if vectors.is_empty() {
            return Err(anyhow!("Cannot calculate mean of empty vectors"));
        }

        let dimensions = vectors[0].len();
        let mut mean = vec![0.0; dimensions];

        for vector in vectors {
            for (i, &val) in vector.iter().enumerate() {
                mean[i] += val;
            }
        }

        let count = vectors.len() as f32;
        for val in &mut mean {
            *val /= count;
        }

        Ok(mean)
    }

    // è®¡ç®—åæ–¹å·®çŸ©é˜µ
    fn calculate_covariance(&self, vectors: &[Vec<f32>]) -> Result<Vec<Vec<f32>>> {
        if vectors.is_empty() {
            return Err(anyhow!("Cannot calculate covariance of empty vectors"));
        }

        let n = vectors.len();
        let dim = vectors[0].len();
        let mut covariance = vec![vec![0.0; dim]; dim];

        for i in 0..dim {
            for j in 0..dim {
                let sum: f32 = vectors.iter()
                    .map(|v| v[i] * v[j])
                    .sum();
                covariance[i][j] = sum / (n - 1) as f32;
            }
        }

        Ok(covariance)
    }

    // ç®€åŒ–çš„ç‰¹å¾å‘é‡è®¡ç®—
    fn simplify_eigenvectors(&self, matrix: &[Vec<f32>], target_dim: usize) -> Result<Vec<Vec<f32>>> {
        // ç®€åŒ–å®ç°ï¼šè¿”å›å‰target_dimä¸ªå•ä½å‘é‡
        let dim = matrix.len();
        let mut eigenvectors = Vec::new();

        for i in 0..target_dim.min(dim) {
            let mut vec = vec![0.0; dim];
            vec[i] = 1.0;
            eigenvectors.push(vec);
        }

        Ok(eigenvectors)
    }

    // å‘é‡æŠ•å½±
    fn project_vector(&self, vector: &[f32], eigenvectors: &[Vec<f32>]) -> Result<Vec<f32>> {
        let mut projected = Vec::new();

        for eigenvector in eigenvectors {
            let projection: f32 = vector.iter().zip(eigenvector.iter())
                .map(|(a, b)| a * b)
                .sum();
            projected.push(projection);
        }

        Ok(projected)
    }

    // æ¸…ç†ç¼“å­˜
    pub async fn clear_cache(&self) {
        let mut cache = self.embedding_cache.write().await;
        cache.clear();

        let mut model_cache = self.model_cache.write().await;
        model_cache.clear();
    }

    // è·å–ç¼“å­˜ç»Ÿè®¡
    pub async fn cache_stats(&self) -> (usize, usize, usize) {
        let embedding_cache = self.embedding_cache.read().await;
        let model_cache = self.model_cache.read().await;

        (embedding_cache.len(), embedding_cache.cap().into(), model_cache.len())
    }
}