use serde::{Deserialize, Serialize};
use tauri::{AppHandle, Emitter};
use std::sync::Arc;
use std::sync::atomic::{AtomicUsize, Ordering};

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct DocumentChunk {
    pub index: usize,
    pub text: String,
    pub start_pos: usize,
    pub end_pos: usize,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct EmbeddingResult {
    pub chunk_index: usize,
    pub chunk_text: String,
    pub embedding: Vec<f32>,
    pub model: String,
    pub dimensions: usize,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct DocumentProcessingRequest {
    pub content: String,
    pub model: String,
    pub chunk_size: Option<usize>,
    pub overlap: Option<usize>,
    pub batch_size: Option<usize>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct DocumentProcessingResponse {
    pub embeddings: Vec<EmbeddingResult>,
    pub total_chunks: usize,
    pub processing_time_ms: u64,
    pub model_used: String,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct ProcessingProgress {
    pub current: usize,
    pub total: usize,
    pub percentage: f32,
    pub stage: String,
    pub message: String,
}

pub struct DocumentProcessor {
    // å¯ä»¥æ·»åŠ æ¨¡å‹ç¼“å­˜ç­‰çŠ¶æ€
}

impl DocumentProcessor {
    pub fn new() -> Self {
        Self {}
    }

    /// æ™ºèƒ½æ–‡æœ¬åˆ†å—ï¼Œæ”¯æŒä¸­è‹±æ–‡
    pub fn chunk_text(&self, text: &str, chunk_size: usize, overlap: usize) -> Vec<DocumentChunk> {
        if text.is_empty() {
            return Vec::new();
        }

        let mut chunks = Vec::new();
        let mut start = 0;
        let max_chunks = 10000; // é˜²æ­¢æ— é™åˆ†å—
        let chars: Vec<char> = text.chars().collect();
        let total_chars = chars.len();

        while start < total_chars && chunks.len() < max_chunks {
            let end = std::cmp::min(start + chunk_size, total_chars);
            let chunk_chars = &chars[start..end];
            let mut chunk_text = chunk_chars.iter().collect::<String>();

            // å¦‚æœä¸æ˜¯æœ€åä¸€å—ï¼Œå°è¯•åœ¨å¥å­è¾¹ç•Œåˆ†å‰²
            if end < total_chars {
                if let Some(best_split) = self.find_best_split_point(&chunk_text, chunk_size) {
                    // ç¡®ä¿åˆ†å‰²ç‚¹åœ¨å­—ç¬¦è¾¹ç•Œï¼Œå¹¶ä¸”ä¸è¶…å‡ºå½“å‰å—çš„èŒƒå›´
                    let safe_split = std::cmp::min(best_split, chunk_text.chars().count());
                    let split_chars = &chars[start..start + safe_split];
                    chunk_text = split_chars.iter().collect::<String>();
                    start = start + safe_split - overlap;
                } else {
                    start = end - overlap;
                }
            } else {
                start = end;
            }

            if !chunk_text.trim().is_empty() {
                chunks.push(DocumentChunk {
                    index: chunks.len(),
                    text: chunk_text.trim().to_string(),
                    start_pos: start.saturating_sub(overlap),
                    end_pos: start + chunk_text.chars().count(),
                });
            }

            // é˜²æ­¢æ— é™å¾ªç¯
            if start <= 0 || start >= total_chars {
                start = end;
            }
            if start >= total_chars {
                break;
            }
        }

        if chunks.len() >= max_chunks {
            println!("âš ï¸ æ–‡æ¡£è¿‡å¤§ï¼Œå·²è¾¾åˆ°æœ€å¤§åˆ†å—é™åˆ¶ {}ï¼Œéƒ¨åˆ†å†…å®¹å¯èƒ½è¢«æˆªæ–­", max_chunks);
        }

        println!("ğŸ“„ æ–‡æ¡£åˆ†å—å®Œæˆ: {} ä¸ªå— (åŸå§‹é•¿åº¦: {} å­—ç¬¦)", chunks.len(), total_chars);
        chunks
    }

    /// æ‰¾åˆ°æœ€ä½³åˆ†å‰²ç‚¹ï¼ˆè¿”å›å­—ç¬¦ä½ç½®ï¼‰
    fn find_best_split_point(&self, chunk: &str, chunk_size: usize) -> Option<usize> {
        let min_split = chunk_size / 3; // æœ€å°åˆ†å‰²ç‚¹
        
        // æ£€æµ‹å¤šç§å¥å­ç»“æŸç¬¦
        let split_chars = ['ã€‚', '.', 'ï¼', '!', 'ï¼Ÿ', '?', '\n', 'ï¼›', ';'];
        let mut best_split = None;
        let mut best_score = 0;

        // å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºå­—ç¬¦å‘é‡ä»¥ä¾¿æŒ‰å­—ç¬¦ä½ç½®æ“ä½œ
        let chars: Vec<char> = chunk.chars().collect();
        
        for &char in &split_chars {
            // ä»åå¾€å‰æŸ¥æ‰¾å­—ç¬¦
            for (i, &c) in chars.iter().enumerate().rev() {
                if c == char {
                    if i > min_split && i > best_score {
                        best_split = Some(i + 1);
                        best_score = i;
                    }
                    break; // æ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…çš„å°±åœæ­¢
                }
            }
        }

        best_split
    }

    /// ç”Ÿæˆç®€å•åµŒå…¥å‘é‡ï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼Œåç»­å¯é›†æˆçœŸå®æ¨¡å‹ï¼‰
    fn generate_simple_embedding(&self, text: &str, dimensions: usize) -> Vec<f32> {
        let mut embedding = vec![0.0; dimensions];
        let mut hash = 0u64;
        
        for (_i, byte) in text.bytes().enumerate() {
            hash = hash.wrapping_mul(31).wrapping_add(byte as u64);
            let index = (hash as usize) % dimensions;
            embedding[index] = (hash % 1000) as f32 / 1000.0 - 0.5;
        }
        
        // å½’ä¸€åŒ–å‘é‡
        let norm: f32 = embedding.iter().map(|x| x * x).sum::<f32>().sqrt();
        if norm > 0.0 {
            for val in &mut embedding {
                *val /= norm;
            }
        }
        
        embedding
    }

    /// æ‰¹é‡å¤„ç†æ–‡æ¡£åµŒå…¥ï¼ˆé«˜æ•ˆç‰ˆæœ¬ï¼‰
    pub async fn process_document_embeddings(
        &self,
        request: DocumentProcessingRequest,
        app_handle: AppHandle,
    ) -> Result<DocumentProcessingResponse, String> {
        let start_time = std::time::Instant::now();
        
        // è®¾ç½®é»˜è®¤å‚æ•°
        let chunk_size = request.chunk_size.unwrap_or(800);
        let overlap = request.overlap.unwrap_or(100);
        let batch_size = request.batch_size.unwrap_or(50);

        println!("ğŸš€ å¼€å§‹å¤„ç†æ–‡æ¡£åµŒå…¥: å†…å®¹é•¿åº¦={}, åˆ†å—å¤§å°={}, é‡å ={}, æ‰¹æ¬¡å¤§å°={}", 
                 request.content.len(), chunk_size, overlap, batch_size);

        // å‘é€å¼€å§‹äº‹ä»¶
        let _ = app_handle.emit("document_processing_started", ProcessingProgress {
            current: 0,
            total: 0,
            percentage: 0.0,
            stage: "chunking".to_string(),
            message: "å¼€å§‹æ–‡æ¡£åˆ†å—...".to_string(),
        });

        // 1. æ–‡æœ¬åˆ†å—
        let chunks = self.chunk_text(&request.content, chunk_size, overlap);
        let total_chunks = chunks.len();

        if total_chunks == 0 {
            return Ok(DocumentProcessingResponse {
                embeddings: Vec::new(),
                total_chunks: 0,
                processing_time_ms: start_time.elapsed().as_millis() as u64,
                model_used: request.model.clone(),
            });
        }

        // å‘é€åˆ†å—å®Œæˆäº‹ä»¶
        let _ = app_handle.emit("document_chunking_completed", ProcessingProgress {
            current: total_chunks,
            total: total_chunks,
            percentage: 20.0,
            stage: "embedding".to_string(),
            message: format!("åˆ†å—å®Œæˆï¼Œå…± {} ä¸ªå—ï¼Œå¼€å§‹ç”ŸæˆåµŒå…¥...", total_chunks),
        });

        // 2. æ‰¹é‡ç”ŸæˆåµŒå…¥
        let embeddings = self.generate_embeddings_batch(
            &chunks,
            &request.model,
            batch_size,
            app_handle.clone(),
        ).await?;

        let processing_time = start_time.elapsed().as_millis() as u64;

        // å‘é€å®Œæˆäº‹ä»¶
        let _ = app_handle.emit("document_processing_completed", ProcessingProgress {
            current: embeddings.len(),
            total: embeddings.len(),
            percentage: 100.0,
            stage: "completed".to_string(),
            message: format!("å¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {} ä¸ªåµŒå…¥å‘é‡ï¼Œè€—æ—¶ {}ms", embeddings.len(), processing_time),
        });

        println!("ğŸ‰ æ–‡æ¡£å¤„ç†å®Œæˆ: {} ä¸ªåµŒå…¥å‘é‡ï¼Œè€—æ—¶ {}ms", embeddings.len(), processing_time);

        Ok(DocumentProcessingResponse {
            embeddings,
            total_chunks,
            processing_time_ms: processing_time,
            model_used: request.model,
        })
    }

    /// æ‰¹é‡ç”ŸæˆåµŒå…¥å‘é‡
    async fn generate_embeddings_batch(
        &self,
        chunks: &[DocumentChunk],
        model: &str,
        batch_size: usize,
        app_handle: AppHandle,
    ) -> Result<Vec<EmbeddingResult>, String> {
        let mut all_embeddings = Vec::new();
        let total_batches = (chunks.len() + batch_size - 1) / batch_size;
        let processed_count = Arc::new(AtomicUsize::new(0));

        for (batch_index, batch_chunks) in chunks.chunks(batch_size).enumerate() {
            let batch_num = batch_index + 1;
            println!("ğŸ“¦ å¤„ç†ç¬¬ {}/{} æ‰¹ ({} ä¸ªå—)", batch_num, total_batches, batch_chunks.len());

            // å‘é€æ‰¹æ¬¡å¼€å§‹äº‹ä»¶
            let _ = app_handle.emit("batch_processing_started", ProcessingProgress {
                current: batch_index * batch_size,
                total: chunks.len(),
                percentage: 20.0 + (batch_index as f32 / total_batches as f32) * 70.0,
                stage: "embedding".to_string(),
                message: format!("å¤„ç†ç¬¬ {} æ‰¹ï¼Œå…± {} ä¸ªå—", batch_num, batch_chunks.len()),
            });

            // å¤„ç†å½“å‰æ‰¹æ¬¡
            let batch_embeddings = self.process_batch(batch_chunks, model).await?;
            all_embeddings.extend(batch_embeddings);

            // æ›´æ–°è¿›åº¦
            let processed = processed_count.fetch_add(batch_chunks.len(), Ordering::Relaxed);
            let percentage = 20.0 + ((processed + batch_chunks.len()) as f32 / chunks.len() as f32) * 70.0;

            // å‘é€æ‰¹æ¬¡å®Œæˆäº‹ä»¶
            let _ = app_handle.emit("batch_processing_completed", ProcessingProgress {
                current: processed + batch_chunks.len(),
                total: chunks.len(),
                percentage,
                stage: "embedding".to_string(),
                message: format!("ç¬¬ {} æ‰¹å¤„ç†å®Œæˆï¼Œå·²å¤„ç† {}/{} ä¸ªå—", batch_num, processed + batch_chunks.len(), chunks.len()),
            });

            // æ·»åŠ å°å»¶è¿Ÿï¼Œé¿å…è¿‡åº¦å ç”¨èµ„æº
            if batch_num < total_batches {
                tokio::time::sleep(tokio::time::Duration::from_millis(50)).await;
            }
        }

        Ok(all_embeddings)
    }

    /// å¤„ç†å•ä¸ªæ‰¹æ¬¡
    async fn process_batch(
        &self,
        batch_chunks: &[DocumentChunk],
        model: &str,
    ) -> Result<Vec<EmbeddingResult>, String> {
        let mut batch_embeddings = Vec::new();

        for chunk in batch_chunks {
            let embedding = self.generate_simple_embedding(&chunk.text, 768);
            
            batch_embeddings.push(EmbeddingResult {
                chunk_index: chunk.index,
                chunk_text: chunk.text.clone(),
                embedding,
                model: model.to_string(),
                dimensions: 768,
            });
        }

        Ok(batch_embeddings)
    }
}

// Tauriå‘½ä»¤ï¼šå¤„ç†æ–‡æ¡£åµŒå…¥
#[tauri::command]
pub async fn process_document_embeddings(
    request: DocumentProcessingRequest,
    app_handle: AppHandle,
) -> Result<DocumentProcessingResponse, String> {
    let processor = DocumentProcessor::new();
    processor.process_document_embeddings(request, app_handle).await
}

// Tauriå‘½ä»¤ï¼šåªè¿›è¡Œæ–‡æœ¬åˆ†å—ï¼Œä¸ç”ŸæˆåµŒå…¥
#[tauri::command]
pub async fn chunk_document_text(
    content: String,
    chunk_size: Option<usize>,
    overlap: Option<usize>,
) -> Result<Vec<DocumentChunk>, String> {
    let processor = DocumentProcessor::new();
    let chunk_size = chunk_size.unwrap_or(800);
    let overlap = overlap.unwrap_or(100);
    
    println!("ğŸ“„ å¼€å§‹æ–‡æ¡£åˆ†å—: å†…å®¹é•¿åº¦={}, åˆ†å—å¤§å°={}, é‡å ={}", 
             content.len(), chunk_size, overlap);
    
    let chunks = processor.chunk_text(&content, chunk_size, overlap);
    
    println!("âœ… æ–‡æ¡£åˆ†å—å®Œæˆ: {} ä¸ªå—", chunks.len());
    
    Ok(chunks)
}

// Tauriå‘½ä»¤ï¼šè·å–å¤„ç†è¿›åº¦ï¼ˆå¯é€‰ï¼Œç”¨äºå‰ç«¯è½®è¯¢ï¼‰
#[tauri::command]
pub async fn get_processing_progress() -> Result<ProcessingProgress, String> {
    // è¿™é‡Œå¯ä»¥å®ç°è¿›åº¦çŠ¶æ€ç®¡ç†
    // ç›®å‰é€šè¿‡äº‹ä»¶ç³»ç»Ÿå®æ—¶æ¨é€ï¼Œä¸éœ€è¦è½®è¯¢
    Ok(ProcessingProgress {
        current: 0,
        total: 0,
        percentage: 0.0,
        stage: "idle".to_string(),
        message: "ç­‰å¾…å¤„ç†...".to_string(),
    })
}
