// ç§»é™¤databaseæ¨¡å—ï¼Œä½¿ç”¨tauri-plugin-sql

use serde::{Deserialize, Serialize};
use anyhow::Result;
use sqlx::{SqlitePool, Row};
use std::sync::Mutex;
use tauri::Manager;

mod embedding_service;
mod qdrant_manager;
mod qdrant_service;
use embedding_service::{EmbeddingService, generate_embedding, generate_batch_embeddings, calculate_similarity};
use qdrant_manager::{
    QdrantManager,
    compile_qdrant,
    start_qdrant,
    stop_qdrant,
    get_qdrant_status,
    is_qdrant_installed,
    get_qdrant_version
};
use qdrant_service::QdrantService;

#[cfg_attr(mobile, tauri::mobile_entry_point)]
pub fn run() {
  tauri::Builder::default()
    .plugin(tauri_plugin_fs::init())
    .plugin(tauri_plugin_shell::init())
    .plugin(tauri_plugin_sql::Builder::default().build())
    .manage(Mutex::new(EmbeddingService::new()))
    .manage(Mutex::new(QdrantManager::new()))
    .manage(Mutex::new(QdrantService::new()))
    .setup(|app| {
      if cfg!(debug_assertions) {
        app.handle().plugin(
          tauri_plugin_log::Builder::default()
            .level(log::LevelFilter::Info)
            .build(),
        )?;
      }
      
      // è‡ªåŠ¨å¯åŠ¨Qdrant (ä½¿ç”¨é¢„ç¼–è¯‘äºŒè¿›åˆ¶æ–‡ä»¶)
      let app_handle = app.handle().clone();
      std::thread::spawn(move || {
        let manager = app_handle.state::<Mutex<QdrantManager>>();
        let mut manager = manager.lock().unwrap();
        
        // æ£€æŸ¥é¢„ç¼–è¯‘çš„äºŒè¿›åˆ¶æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        let current_dir = std::env::current_dir().unwrap();
        println!("ğŸ” å½“å‰å·¥ä½œç›®å½•: {}", current_dir.display());
        println!("ğŸ” Qdrantæ–‡ä»¶æ˜¯å¦å­˜åœ¨: {}", manager.is_installed());
        
        if manager.is_installed() {
          println!("ğŸš€ å¯åŠ¨é¢„ç¼–è¯‘çš„QdrantæœåŠ¡...");
          match manager.start() {
            Ok(_) => println!("âœ… QdrantæœåŠ¡å·²è‡ªåŠ¨å¯åŠ¨"),
            Err(e) => println!("âŒ QdrantæœåŠ¡å¯åŠ¨å¤±è´¥: {}", e),
          }
        } else {
          println!("âš ï¸ æœªæ‰¾åˆ°é¢„ç¼–è¯‘çš„QdrantäºŒè¿›åˆ¶æ–‡ä»¶");
          println!("ğŸ’¡ è¯·å…ˆè¿è¡Œ: .\\compile_qdrant.bat æ¥ç¼–è¯‘Qdrant");
          println!("ğŸ’¡ æˆ–è€…æ‰‹åŠ¨å¯åŠ¨: .\\qdrant.exe");
        }
      });
      
      Ok(())
    })
    .invoke_handler(tauri::generate_handler![
      ensure_data_directory,
      get_file_size,
      init_knowledge_base,
      add_knowledge_document,
      add_knowledge_vector,
      search_knowledge_base,
      get_knowledge_documents,
      delete_knowledge_document,
      get_knowledge_statistics,
      generate_document_embeddings,
      generate_embedding,
      generate_batch_embeddings,
      calculate_similarity,
      compile_qdrant,
      start_qdrant,
      stop_qdrant,
      get_qdrant_status,
      is_qdrant_installed,
      get_qdrant_version
    ])
    .run(tauri::generate_context!())
    .expect("error while running tauri application");
}

#[tauri::command]
async fn ensure_data_directory() -> Result<String, String> {
  use std::fs;
  use std::path::Path;
  
  // ä½¿ç”¨ç”¨æˆ·æ•°æ®ç›®å½•ï¼Œé¿å…é‡æ–°æ„å»ºæ—¶æ•°æ®ä¸¢å¤±
  let data_dir = if cfg!(debug_assertions) {
    // å¼€å‘æ¨¡å¼ï¼šä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„dataæ–‡ä»¶å¤¹
    let mut project_root = std::env::current_dir().unwrap();
    project_root.push("data");
    project_root
  } else {
    // ç”Ÿäº§æ¨¡å¼ï¼šä½¿ç”¨ç”¨æˆ·æ•°æ®ç›®å½•
    let mut data_dir = dirs::data_dir().unwrap_or_else(|| std::env::current_dir().unwrap());
    data_dir.push("AI-Chat");
    data_dir
  };
  
  if !data_dir.exists() {
    fs::create_dir_all(&data_dir)
      .map_err(|e| format!("åˆ›å»ºæ•°æ®ç›®å½•å¤±è´¥: {}", e))?;
  }
  
  println!("æ•°æ®ç›®å½•: {}", data_dir.display());
  Ok(data_dir.to_string_lossy().to_string())
}

// ç§»é™¤è‡ªå®šä¹‰SQLiteå‘½ä»¤ï¼Œä½¿ç”¨tauri-plugin-sql

#[tauri::command]
async fn get_file_size(file_path: String) -> Result<u64, String> {
  use std::fs;
  
  let metadata = fs::metadata(&file_path)
    .map_err(|e| format!("è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {}", e))?;
  
  Ok(metadata.len())
}

// çŸ¥è¯†åº“ç›¸å…³æ•°æ®ç»“æ„
#[derive(Debug, Serialize, Deserialize)]
pub struct KnowledgeDocument {
    pub id: String,
    pub title: String,
    pub content: String,
    pub source_type: String,
    pub source_url: Option<String>,
    pub file_path: Option<String>,
    pub file_size: Option<i64>,
    pub mime_type: Option<String>,
    pub metadata: String, // JSONå­—ç¬¦ä¸²
    pub created_at: i64,
    pub updated_at: i64,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct KnowledgeVector {
    pub vector_id: String,
    pub document_id: String,
    pub chunk_index: i32,
    pub chunk_text: String,
    pub embedding: Vec<f32>,
    pub created_at: i64,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct SearchResult {
    pub document_id: String,
    pub title: String,
    pub content: String,
    pub similarity: f64,
    pub chunk_index: i32,
    pub source_type: String,
    pub source_url: Option<String>,
}

// çŸ¥è¯†åº“ç®¡ç†å‘½ä»¤
#[tauri::command]
async fn init_knowledge_base() -> Result<String, String> {
    // ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨å¹¶è·å–è·¯å¾„
    let data_dir = ensure_data_directory().await?;
    let db_path = format!("{}/ai_chat.db", data_dir);
    
    // åˆå§‹åŒ–SQLiteè¿æ¥
    let pool = SqlitePool::connect(&format!("sqlite://{}", db_path))
        .await
        .map_err(|e| format!("è¿æ¥æ•°æ®åº“å¤±è´¥: {}", e))?;
    
    // åˆ›å»ºçŸ¥è¯†åº“æ–‡æ¡£è¡¨
    sqlx::query(
        r#"
        CREATE TABLE IF NOT EXISTS knowledge_documents (
            id TEXT PRIMARY KEY,
            title TEXT NOT NULL,
            content TEXT NOT NULL,
            source_type TEXT NOT NULL DEFAULT 'text',
            source_url TEXT,
            file_path TEXT,
            file_size INTEGER,
            mime_type TEXT,
            metadata TEXT DEFAULT '{}',
            created_at INTEGER NOT NULL,
            updated_at INTEGER NOT NULL
        )
        "#
    )
    .execute(&pool)
    .await
    .map_err(|e| format!("åˆ›å»ºçŸ¥è¯†åº“æ–‡æ¡£è¡¨å¤±è´¥: {}", e))?;
    
    // åˆ›å»ºsqlite-vecè™šæ‹Ÿè¡¨ç”¨äºå‘é‡æœç´¢
    sqlx::query(
        r#"
        CREATE VIRTUAL TABLE IF NOT EXISTS knowledge_vectors USING vec0(
            embedding float[384]
        )
        "#
    )
    .execute(&pool)
    .await
    .map_err(|e| format!("åˆ›å»ºå‘é‡è™šæ‹Ÿè¡¨å¤±è´¥: {}", e))?;
    
    // åˆ›å»ºå‘é‡å…ƒæ•°æ®è¡¨
    sqlx::query(
        r#"
        CREATE TABLE IF NOT EXISTS vector_metadata (
            rowid INTEGER PRIMARY KEY,
            document_id TEXT NOT NULL,
            chunk_index INTEGER NOT NULL,
            chunk_text TEXT NOT NULL,
            created_at INTEGER NOT NULL,
            FOREIGN KEY (document_id) REFERENCES knowledge_documents(id) ON DELETE CASCADE
        )
        "#
    )
    .execute(&pool)
    .await
    .map_err(|e| format!("åˆ›å»ºå‘é‡å…ƒæ•°æ®è¡¨å¤±è´¥: {}", e))?;
    
    // åˆ›å»ºç´¢å¼•ä»¥æé«˜æœç´¢æ€§èƒ½
    sqlx::query("CREATE INDEX IF NOT EXISTS idx_knowledge_documents_title ON knowledge_documents(title)")
        .execute(&pool)
        .await
        .map_err(|e| format!("åˆ›å»ºæ ‡é¢˜ç´¢å¼•å¤±è´¥: {}", e))?;
    
    sqlx::query("CREATE INDEX IF NOT EXISTS idx_knowledge_documents_content ON knowledge_documents(content)")
        .execute(&pool)
        .await
        .map_err(|e| format!("åˆ›å»ºå†…å®¹ç´¢å¼•å¤±è´¥: {}", e))?;
    
    pool.close().await;
    
    Ok("çŸ¥è¯†åº“åˆå§‹åŒ–æˆåŠŸ".to_string())
}

#[tauri::command]
async fn add_knowledge_document(document: KnowledgeDocument) -> Result<String, String> {
    // ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨å¹¶è·å–è·¯å¾„
    let data_dir = ensure_data_directory().await?;
    let db_path = format!("{}/ai_chat.db", data_dir);
    let pool = SqlitePool::connect(&format!("sqlite://{}", db_path))
        .await
        .map_err(|e| format!("è¿æ¥æ•°æ®åº“å¤±è´¥: {}", e))?;
    
    sqlx::query(
        r#"
        INSERT OR REPLACE INTO knowledge_documents 
        (id, title, content, source_type, source_url, file_path, file_size, mime_type, metadata, created_at, updated_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        "#
    )
    .bind(&document.id)
    .bind(&document.title)
    .bind(&document.content)
    .bind(&document.source_type)
    .bind(&document.source_url)
    .bind(&document.file_path)
    .bind(&document.file_size)
    .bind(&document.mime_type)
    .bind(&document.metadata)
    .bind(document.created_at)
    .bind(document.updated_at)
    .execute(&pool)
    .await
    .map_err(|e| format!("æ·»åŠ çŸ¥è¯†åº“æ–‡æ¡£å¤±è´¥: {}", e))?;
    
    pool.close().await;
    Ok(document.id)
}

#[tauri::command]
async fn add_knowledge_vector(vector: KnowledgeVector) -> Result<String, String> {
    // ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨å¹¶è·å–è·¯å¾„
    let data_dir = ensure_data_directory().await?;
    let db_path = format!("{}/ai_chat.db", data_dir);
    let pool = SqlitePool::connect(&format!("sqlite://{}", db_path))
        .await
        .map_err(|e| format!("è¿æ¥æ•°æ®åº“å¤±è´¥: {}", e))?;
    
    // å°†å‘é‡è½¬æ¢ä¸ºJSONæ ¼å¼ï¼ˆsqlite-vecè¦æ±‚çš„æ ¼å¼ï¼‰
    let embedding_json = serde_json::to_string(&vector.embedding)
        .map_err(|e| format!("åºåˆ—åŒ–å‘é‡å¤±è´¥: {}", e))?;
    
    // æ’å…¥å‘é‡åˆ°è™šæ‹Ÿè¡¨
    let result = sqlx::query(
        r#"
        INSERT INTO knowledge_vectors (embedding)
        VALUES (?)
        "#
    )
    .bind(&embedding_json)
    .execute(&pool)
    .await
    .map_err(|e| format!("æ·»åŠ å‘é‡å¤±è´¥: {}", e))?;
    
    let rowid = result.last_insert_rowid();
    
    // æ’å…¥å…ƒæ•°æ®åˆ°å…ƒæ•°æ®è¡¨
    sqlx::query(
        r#"
        INSERT INTO vector_metadata (rowid, document_id, chunk_index, chunk_text, created_at)
        VALUES (?, ?, ?, ?, ?)
        "#
    )
    .bind(rowid)
    .bind(&vector.document_id)
    .bind(vector.chunk_index)
    .bind(&vector.chunk_text)
    .bind(vector.created_at)
    .execute(&pool)
    .await
    .map_err(|e| format!("æ·»åŠ å‘é‡å…ƒæ•°æ®å¤±è´¥: {}", e))?;
    
    pool.close().await;
    Ok(vector.vector_id)
}

#[tauri::command]
async fn search_knowledge_base(query: String, limit: i32) -> Result<Vec<SearchResult>, String> {
    // ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨å¹¶è·å–è·¯å¾„
    let data_dir = ensure_data_directory().await?;
    let db_path = format!("{}/ai_chat.db", data_dir);
    let pool = SqlitePool::connect(&format!("sqlite://{}", db_path))
        .await
        .map_err(|e| format!("è¿æ¥æ•°æ®åº“å¤±è´¥: {}", e))?;
    
    // ç”ŸæˆæŸ¥è¯¢å‘é‡ï¼ˆè¿™é‡Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…åº”è¯¥è°ƒç”¨åµŒå…¥APIï¼‰
    let query_embedding = generate_simple_embedding(&query);
    let query_embedding_json = serde_json::to_string(&query_embedding)
        .map_err(|e| format!("åºåˆ—åŒ–æŸ¥è¯¢å‘é‡å¤±è´¥: {}", e))?;
    
    // ä½¿ç”¨sqlite-vecè¿›è¡ŒKNNæœç´¢
    let results = sqlx::query(
        r#"
        SELECT 
            vm.document_id,
            vm.chunk_index,
            vm.chunk_text,
            kd.title,
            kd.source_type,
            kd.source_url,
            kv.distance
        FROM knowledge_vectors kv
        JOIN vector_metadata vm ON kv.rowid = vm.rowid
        JOIN knowledge_documents kd ON vm.document_id = kd.id
        WHERE kv.embedding MATCH ?
        ORDER BY kv.distance
        LIMIT ?
        "#
    )
    .bind(&query_embedding_json)
    .bind(limit)
    .fetch_all(&pool)
    .await
    .map_err(|e| format!("å‘é‡æœç´¢å¤±è´¥: {}", e))?;
    
    let search_results: Vec<SearchResult> = results
        .iter()
        .map(|row| {
            let distance: f64 = row.get("distance");
            // å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼ˆè·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜ï¼‰
            let similarity = 1.0 / (1.0 + distance);
            
            SearchResult {
                document_id: row.get("document_id"),
                title: row.get("title"),
                content: row.get("chunk_text"),
                similarity,
                chunk_index: row.get("chunk_index"),
                source_type: row.get("source_type"),
                source_url: row.get("source_url"),
            }
        })
        .collect();
    
    pool.close().await;
    Ok(search_results)
}

// ç®€åŒ–çš„å‘é‡ç”Ÿæˆå‡½æ•°ï¼ˆå®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨çœŸå®çš„åµŒå…¥APIï¼‰
fn generate_simple_embedding(text: &str) -> Vec<f32> {
    // ä½¿ç”¨ç®€å•çš„å“ˆå¸Œç®—æ³•ç”Ÿæˆ384ç»´å‘é‡
    let mut embedding = vec![0.0; 384];
    let mut hash = 0u64;
    
    for (_i, byte) in text.bytes().enumerate() {
        hash = hash.wrapping_mul(31).wrapping_add(byte as u64);
        let index = (hash as usize) % 384;
        embedding[index] = (hash % 1000) as f32 / 1000.0 - 0.5;
    }
    
    // å½’ä¸€åŒ–å‘é‡
    let norm: f32 = embedding.iter().map(|x| x * x).sum::<f32>().sqrt();
    if norm > 0.0 {
        for val in &mut embedding {
            *val /= norm;
        }
    }
    
    embedding
}

#[tauri::command]
async fn get_knowledge_documents() -> Result<Vec<KnowledgeDocument>, String> {
    // ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨å¹¶è·å–è·¯å¾„
    let data_dir = ensure_data_directory().await?;
    let db_path = format!("{}/ai_chat.db", data_dir);
    let pool = SqlitePool::connect(&format!("sqlite://{}", db_path))
        .await
        .map_err(|e| format!("è¿æ¥æ•°æ®åº“å¤±è´¥: {}", e))?;
    
    let results = sqlx::query(
        r#"
        SELECT * FROM knowledge_documents 
        ORDER BY updated_at DESC
        "#
    )
    .fetch_all(&pool)
    .await
    .map_err(|e| format!("è·å–çŸ¥è¯†åº“æ–‡æ¡£å¤±è´¥: {}", e))?;
    
    let documents: Vec<KnowledgeDocument> = results
        .iter()
        .map(|row| KnowledgeDocument {
            id: row.get("id"),
            title: row.get("title"),
            content: row.get("content"),
            source_type: row.get("source_type"),
            source_url: row.get("source_url"),
            file_path: row.get("file_path"),
            file_size: row.get("file_size"),
            mime_type: row.get("mime_type"),
            metadata: row.get("metadata"),
            created_at: row.get("created_at"),
            updated_at: row.get("updated_at"),
        })
        .collect();
    
    pool.close().await;
    Ok(documents)
}

#[tauri::command]
async fn delete_knowledge_document(document_id: String) -> Result<String, String> {
    // ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨å¹¶è·å–è·¯å¾„
    let data_dir = ensure_data_directory().await?;
    let db_path = format!("{}/ai_chat.db", data_dir);
    let pool = SqlitePool::connect(&format!("sqlite://{}", db_path))
        .await
        .map_err(|e| format!("è¿æ¥æ•°æ®åº“å¤±è´¥: {}", e))?;
    
    // è·å–è¦åˆ é™¤çš„å‘é‡rowid
    let vector_rowids: Vec<i64> = sqlx::query_scalar(
        "SELECT rowid FROM vector_metadata WHERE document_id = ?"
    )
    .bind(&document_id)
    .fetch_all(&pool)
    .await
    .map_err(|e| format!("è·å–å‘é‡rowidå¤±è´¥: {}", e))?;
    
    // åˆ é™¤å‘é‡æ•°æ®
    for rowid in vector_rowids {
        sqlx::query("DELETE FROM knowledge_vectors WHERE rowid = ?")
            .bind(rowid)
            .execute(&pool)
            .await
            .map_err(|e| format!("åˆ é™¤å‘é‡å¤±è´¥: {}", e))?;
    }
    
    // åˆ é™¤å‘é‡å…ƒæ•°æ®
    sqlx::query("DELETE FROM vector_metadata WHERE document_id = ?")
        .bind(&document_id)
        .execute(&pool)
        .await
        .map_err(|e| format!("åˆ é™¤å‘é‡å…ƒæ•°æ®å¤±è´¥: {}", e))?;
    
    // åˆ é™¤æ–‡æ¡£
    sqlx::query("DELETE FROM knowledge_documents WHERE id = ?")
        .bind(&document_id)
        .execute(&pool)
        .await
        .map_err(|e| format!("åˆ é™¤çŸ¥è¯†åº“æ–‡æ¡£å¤±è´¥: {}", e))?;
    
    pool.close().await;
    Ok("æ–‡æ¡£åˆ é™¤æˆåŠŸ".to_string())
}

#[tauri::command]
async fn get_knowledge_statistics() -> Result<serde_json::Value, String> {
    // ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨å¹¶è·å–è·¯å¾„
    let data_dir = ensure_data_directory().await?;
    let db_path = format!("{}/ai_chat.db", data_dir);
    let pool = SqlitePool::connect(&format!("sqlite://{}", db_path))
        .await
        .map_err(|e| format!("è¿æ¥æ•°æ®åº“å¤±è´¥: {}", e))?;
    
    let doc_count: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM knowledge_documents")
        .fetch_one(&pool)
        .await
        .map_err(|e| format!("è·å–æ–‡æ¡£æ•°é‡å¤±è´¥: {}", e))?;
    
    let vector_count: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM vector_metadata")
        .fetch_one(&pool)
        .await
        .map_err(|e| format!("è·å–å‘é‡æ•°é‡å¤±è´¥: {}", e))?;
    
    let total_size: i64 = sqlx::query_scalar("SELECT COALESCE(SUM(file_size), 0) FROM knowledge_documents")
        .fetch_one(&pool)
        .await
        .map_err(|e| format!("è·å–æ€»å¤§å°å¤±è´¥: {}", e))?;
    
    pool.close().await;
    
    Ok(serde_json::json!({
        "documentCount": doc_count,
        "vectorCount": vector_count,
        "totalSize": total_size
    }))
}

#[tauri::command]
async fn generate_document_embeddings(document_id: String) -> Result<String, String> {
    // ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨å¹¶è·å–è·¯å¾„
    let data_dir = ensure_data_directory().await?;
    let db_path = format!("{}/ai_chat.db", data_dir);
    let pool = SqlitePool::connect(&format!("sqlite://{}", db_path))
        .await
        .map_err(|e| format!("è¿æ¥æ•°æ®åº“å¤±è´¥: {}", e))?;
    
    // è·å–æ–‡æ¡£å†…å®¹
    let document: (String, String) = sqlx::query_as(
        "SELECT title, content FROM knowledge_documents WHERE id = ?"
    )
    .bind(&document_id)
    .fetch_one(&pool)
    .await
    .map_err(|e| format!("è·å–æ–‡æ¡£å¤±è´¥: {}", e))?;
    
    let (title, content) = document;
    
    // åˆ†å—å¤„ç†æ–‡æ¡£å†…å®¹
    let chunks = chunk_text(&content, 500, 100);
    let mut vector_count = 0;
    
    for (i, chunk) in chunks.iter().enumerate() {
        // ç”Ÿæˆå‘é‡åµŒå…¥
        let embedding = generate_simple_embedding(&format!("{} {}", title, chunk));
        
        // åˆ›å»ºå‘é‡æ•°æ®
        let vector = KnowledgeVector {
            vector_id: format!("{}_chunk_{}", document_id, i),
            document_id: document_id.clone(),
            chunk_index: i as i32,
            chunk_text: chunk.clone(),
            embedding,
            created_at: chrono::Utc::now().timestamp_millis(),
        };
        
        // æ·»åŠ å‘é‡åˆ°æ•°æ®åº“
        add_knowledge_vector_internal(&pool, vector).await?;
        vector_count += 1;
    }
    
    pool.close().await;
    Ok(format!("æˆåŠŸç”Ÿæˆ {} ä¸ªå‘é‡åµŒå…¥", vector_count))
}

// å†…éƒ¨å‡½æ•°ï¼šæ·»åŠ å‘é‡åˆ°æ•°æ®åº“
async fn add_knowledge_vector_internal(pool: &SqlitePool, vector: KnowledgeVector) -> Result<(), String> {
    // å°†å‘é‡è½¬æ¢ä¸ºJSONæ ¼å¼
    let embedding_json = serde_json::to_string(&vector.embedding)
        .map_err(|e| format!("åºåˆ—åŒ–å‘é‡å¤±è´¥: {}", e))?;
    
    // æ’å…¥å‘é‡åˆ°è™šæ‹Ÿè¡¨
    let result = sqlx::query(
        "INSERT INTO knowledge_vectors (embedding) VALUES (?)"
    )
    .bind(&embedding_json)
    .execute(pool)
    .await
    .map_err(|e| format!("æ·»åŠ å‘é‡å¤±è´¥: {}", e))?;
    
    let rowid = result.last_insert_rowid();
    
    // æ’å…¥å…ƒæ•°æ®åˆ°å…ƒæ•°æ®è¡¨
    sqlx::query(
        "INSERT INTO vector_metadata (rowid, document_id, chunk_index, chunk_text, created_at) VALUES (?, ?, ?, ?, ?)"
    )
    .bind(rowid)
    .bind(&vector.document_id)
    .bind(vector.chunk_index)
    .bind(&vector.chunk_text)
    .bind(vector.created_at)
    .execute(pool)
    .await
    .map_err(|e| format!("æ·»åŠ å‘é‡å…ƒæ•°æ®å¤±è´¥: {}", e))?;
    
    Ok(())
}

// æ–‡æœ¬åˆ†å—å‡½æ•°
fn chunk_text(text: &str, chunk_size: usize, overlap: usize) -> Vec<String> {
    let mut chunks = Vec::new();
    let mut start = 0;
    
    while start < text.len() {
        let end = std::cmp::min(start + chunk_size, text.len());
        let mut chunk = text[start..end].to_string();
        
        // å°è¯•åœ¨å¥å­è¾¹ç•Œåˆ†å‰²
        if end < text.len() {
            if let Some(last_sentence) = chunk.rfind('ã€‚') {
                if last_sentence > chunk_size / 2 {
                    chunk = chunk[..last_sentence + 1].to_string();
                    start = start + last_sentence + 1 - overlap;
                } else {
                    start = end - overlap;
                }
            } else {
                start = end - overlap;
            }
        } else {
            start = end;
        }
        
        if !chunk.trim().is_empty() {
            chunks.push(chunk.trim().to_string());
        }
    }
    
    chunks
}
