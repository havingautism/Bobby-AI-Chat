{"version":3,"file":"static/js/9276.26257ef1.chunk.js","mappings":"iLAiBIA,GAAmBC,EAAG,cAAcC,EAAAA,GAItCC,WAAAA,GACEC,MAAM,CAAC,WACT,IAJEC,EAAAA,EAAAA,IAAMJ,EAAO,uBAAsBA,GAQnCK,EAAgB,iDAChBC,GAAqBC,EAAG,cAAcC,EAAAA,GAIxCC,kBAAAA,CAAmBC,EAAMC,EAAOC,GAC9B,GAAkB,YAAdF,EAAKG,KACP,OAAOC,WAAWH,EAAMI,QAAQ,KAAM,KACjC,GAAkB,cAAdL,EAAKG,KACd,OAAOF,EAAMK,UAAU,EAAGL,EAAMM,OAAS,GACpC,GAAkB,YAAdP,EAAKG,KACd,OAAOF,EAAMK,UAAU,EAAGL,EAAMM,OAAS,GACpC,GAAkB,gBAAdP,EAAKG,KACd,OAAOF,EAAMM,OACR,GAAkB,aAAdP,EAAKG,KAAqB,CACnC,GAAqB,kBAAVF,EACT,OAAOA,EAET,MAAMO,EAAQb,EAAcc,KAAKR,GACjC,GAAIO,EACF,MAAO,CACLE,MAAO,oBACPC,UAAWH,EAAM,GACjBI,UAAWJ,EAAM,SAAM,EAG7B,CAEF,IAzBEd,EAAAA,EAAAA,IAAMG,EAAO,yBAAwBA,GA6BzC,SAASgB,EAAyBC,GAChC,MAAMC,EAAYD,EAASE,WAAWC,iBAChCC,EAAWJ,EAASE,WAAWG,mBACrC,GAAID,EAAU,CACZ,MAAME,EAAS,CACbC,QAASN,EAAUO,gBAAgBC,KAAKR,IAG1CG,EAASM,SAASJ,EAAQL,EAC5B,CACF,EACArB,EAAAA,EAAAA,IAAOmB,EAA0B,4BACjC,IAAII,GAAgBQ,EAAG,MAQrBH,eAAAA,CAAgBI,EAAKC,GACnB,IAAIC,EACJ,IAAK,MAAMC,KAAOH,EAAII,YACfD,EAAIE,YAGmB,IAAxBH,QACW,IAAfC,EAAIG,OACFJ,EAAsB,QACE,IAAfC,EAAIG,aAKoB,IAAxBJ,GAAkCA,GAAuBK,SAASJ,EAAIG,OAAQ,MAJvFL,EAAO,QAAS,oDAAqD,CACnEO,KAAML,EACNM,SAAU,SASlB,IA3BEzC,EAAAA,EAAAA,IAAM+B,EAAO,oBAAmBA,GA+BhCW,EAAgB,CAClBC,OAAQ,CACNC,cAA8B5C,EAAAA,EAAAA,IAAO,IAAM,IAAIL,EAAuB,gBACtEkD,gBAAgC7C,EAAAA,EAAAA,IAAO,IAAM,IAAIE,EAAyB,mBAE5EoB,WAAY,CACVC,kBAAkCvB,EAAAA,EAAAA,IAAO,IAAM,IAAIuB,EAAoB,sBAG3E,SAASuB,IAAiD,IAA3BC,EAAOC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGE,EAAAA,EACvC,MAAMC,GAASC,EAAAA,EAAAA,KACbC,EAAAA,EAAAA,GAA8BN,GAC9BO,EAAAA,IAEI3B,GAAUyB,EAAAA,EAAAA,KACdG,EAAAA,EAAAA,GAAwB,CAAEJ,WAC1BK,EAAAA,GACAd,GAIF,OAFAS,EAAOM,gBAAgB3B,SAASH,GAChCR,EAAyBQ,GAClB,CAAEwB,SAAQxB,UACnB,EACA3B,EAAAA,EAAAA,IAAO8C,EAAuB,wB,uEClG9B,QALA,SAAkBY,GAChB,MAAuB,iBAATA,KACVC,EAAAA,EAAAA,GAAQD,KAAUE,EAAAA,EAAAA,GAAaF,IArBrB,oBAqB+BG,EAAAA,EAAAA,GAAWH,EAC1D,C,iBCtBAI,OAAOC,eAAeC,EAAS,aAAc,CAAEN,OAAO,IACtDM,EAAQC,QAAUD,EAAQE,WAAQ,EAClC,MAAMC,EAAQC,EAAQ,OACtB,IAAIF,GACJ,SAAWA,GACP,MAAMG,EAAc,CAAEC,OAAAA,GAAY,GAClCJ,EAAMK,KAAO,WAAc,OAAOF,CAAa,CAClD,CAHD,CAGGH,IAAUF,EAAQE,MAAQA,EAAQ,CAAC,IACtC,MAAMM,EACFC,GAAAA,CAAIC,GAAkC,IAAxB3B,EAAOC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,KAAM2B,EAAM3B,UAAAnC,OAAA,EAAAmC,UAAA,QAAAC,EAC3B2B,KAAKC,aACND,KAAKC,WAAa,GAClBD,KAAKE,UAAY,IAErBF,KAAKC,WAAWE,KAAKL,GACrBE,KAAKE,UAAUC,KAAKhC,GAChBiC,MAAMrB,QAAQgB,IACdA,EAAOI,KAAK,CAAET,QAASA,IAAMM,KAAKK,OAAOP,EAAU3B,IAE3D,CACAkC,MAAAA,CAAOP,GAA0B,IAAhB3B,EAAOC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,KACvB,IAAK4B,KAAKC,WACN,OAEJ,IAAIK,GAAoC,EACxC,IAAK,IAAIC,EAAI,EAAGC,EAAMR,KAAKC,WAAWhE,OAAQsE,EAAIC,EAAKD,IACnD,GAAIP,KAAKC,WAAWM,KAAOT,EAAU,CACjC,GAAIE,KAAKE,UAAUK,KAAOpC,EAItB,OAFA6B,KAAKC,WAAWQ,OAAOF,EAAG,QAC1BP,KAAKE,UAAUO,OAAOF,EAAG,GAIzBD,GAAoC,CAE5C,CAEJ,GAAIA,EACA,MAAM,IAAII,MAAM,oFAExB,CACAC,MAAAA,GACI,IAAKX,KAAKC,WACN,MAAO,GAEX,MAAMW,EAAM,GAAIC,EAAYb,KAAKC,WAAWa,MAAM,GAAIC,EAAWf,KAAKE,UAAUY,MAAM,GAAG,QAAAE,EAAA5C,UAAAnC,OAJnFgF,EAAI,IAAAb,MAAAY,GAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAAJD,EAAIC,GAAA9C,UAAA8C,GAKV,IAAK,IAAIX,EAAI,EAAGC,EAAMK,EAAU5E,OAAQsE,EAAIC,EAAKD,IAC7C,IACIK,EAAIT,KAAKU,EAAUN,GAAGY,MAAMJ,EAASR,GAAIU,GAC7C,CACA,MAAOG,IAEH,EAAI7B,EAAM8B,WAAWC,QAAQC,MAAMH,EACvC,CAEJ,OAAOR,CACX,CACAY,OAAAA,GACI,OAAQxB,KAAKC,YAAyC,IAA3BD,KAAKC,WAAWhE,MAC/C,CACAyD,OAAAA,GACIM,KAAKC,gBAAa5B,EAClB2B,KAAKE,eAAY7B,CACrB,EAEJ,MAAMgB,EACFnE,WAAAA,CAAYuG,GACRzB,KAAKyB,SAAWA,CACpB,CAKA,SAAIC,GA6BA,OA5BK1B,KAAK2B,SACN3B,KAAK2B,OAAS,CAACC,EAAUC,EAAUC,KAC1B9B,KAAKC,aACND,KAAKC,WAAa,IAAIL,GAEtBI,KAAKyB,UAAYzB,KAAKyB,SAASM,oBAAsB/B,KAAKC,WAAWuB,WACrExB,KAAKyB,SAASM,mBAAmB/B,MAErCA,KAAKC,WAAWJ,IAAI+B,EAAUC,GAC9B,MAAMG,EAAS,CACXtC,QAASA,KACAM,KAAKC,aAIVD,KAAKC,WAAWI,OAAOuB,EAAUC,GACjCG,EAAOtC,QAAUL,EAAQ4C,MACrBjC,KAAKyB,UAAYzB,KAAKyB,SAASS,sBAAwBlC,KAAKC,WAAWuB,WACvExB,KAAKyB,SAASS,qBAAqBlC,SAO/C,OAHII,MAAMrB,QAAQ+C,IACdA,EAAY3B,KAAK6B,GAEdA,IAGRhC,KAAK2B,MAChB,CAKAQ,IAAAA,CAAKT,GACG1B,KAAKC,YACLD,KAAKC,WAAWU,OAAOyB,KAAKpC,KAAKC,WAAYyB,EAErD,CACAhC,OAAAA,GACQM,KAAKC,aACLD,KAAKC,WAAWP,UAChBM,KAAKC,gBAAa5B,EAE1B,EAEJe,EAAQC,QAAUA,EAClBA,EAAQ4C,MAAQ,WAAc,C,wECnG9B,QANA,SAAaI,GACX,OAAQA,GAASA,EAAMpG,QACnBqG,EAAAA,EAAAA,GAAaD,EAAOE,EAAAA,EAAUC,EAAAA,QAC9BnE,CACN,C,iFCAA,SAAS+C,EAAWqB,GAClB,GAAoB,iBAATA,EACT,MAAM,IAAIC,UAAU,mCAAqCC,KAAKC,UAAUH,GAE5E,CAGA,SAASI,EAAqBJ,EAAMrB,GAMlC,IALA,IAIIyB,EAJAC,EAAM,GACNvC,EAAoB,EACpBwC,GAAa,EACbC,EAAO,EAEFC,EAAI,EAAGA,GAAKR,EAAKxG,SAAUgH,EAAG,CACrC,GAAIA,EAAIR,EAAKxG,OACX4G,EAAOJ,EAAKS,WAAWD,OACpB,IAAa,KAATJ,EACP,MAEAA,EAAO,EAAQ,CACjB,GAAa,KAATA,EAAmB,CACrB,GAAIE,IAAcE,EAAI,GAAc,IAATD,QAEpB,GAAID,IAAcE,EAAI,GAAc,IAATD,EAAY,CAC5C,GAAIF,EAAI7G,OAAS,GAA2B,IAAtBsE,GAA8D,KAAnCuC,EAAII,WAAWJ,EAAI7G,OAAS,IAAsD,KAAnC6G,EAAII,WAAWJ,EAAI7G,OAAS,GAC1H,GAAI6G,EAAI7G,OAAS,EAAG,CAClB,IAAIkH,EAAiBL,EAAIM,YAAY,KACrC,GAAID,IAAmBL,EAAI7G,OAAS,EAAG,EACb,IAApBkH,GACFL,EAAM,GACNvC,EAAoB,GAGpBA,GADAuC,EAAMA,EAAIhC,MAAM,EAAGqC,IACKlH,OAAS,EAAI6G,EAAIM,YAAY,KAEvDL,EAAYE,EACZD,EAAO,EACP,QACF,CACF,MAAO,GAAmB,IAAfF,EAAI7G,QAA+B,IAAf6G,EAAI7G,OAAc,CAC/C6G,EAAM,GACNvC,EAAoB,EACpBwC,EAAYE,EACZD,EAAO,EACP,QACF,CAEE5B,IACE0B,EAAI7G,OAAS,EACf6G,GAAO,MAEPA,EAAM,KACRvC,EAAoB,EAExB,MACMuC,EAAI7G,OAAS,EACf6G,GAAO,IAAML,EAAK3B,MAAMiC,EAAY,EAAGE,GAEvCH,EAAML,EAAK3B,MAAMiC,EAAY,EAAGE,GAClC1C,EAAoB0C,EAAIF,EAAY,EAEtCA,EAAYE,EACZD,EAAO,CACT,MAAoB,KAATH,IAA+B,IAAVG,IAC5BA,EAEFA,GAAQ,CAEZ,CACA,OAAOF,CACT,CAcA,IAAIA,EAAQ,CAEVO,QAAS,WAKP,IAJA,IAEIZ,EAFAK,EAAe,GACfvC,GAAA,EAGKwC,EAAI3E,UAAUnC,OAAS,EAAG8G,IAAM,IAAMxC,EAAkBwC,IAAK,CACpE,IAAIC,EACAD,GAAK,EACPC,EAAO5E,UAAU2E,SAAA,IAEbN,IACFA,EAAMa,QAAQC,OAChBP,EAAOP,GAGTrB,EAAW4B,GAGS,IAAhBA,EAAK/G,SAIT6G,EAAeE,EAAO,IAAMF,EAC5BvC,EAA0C,KAAvByC,EAAKE,WAAW,GACrC,CAQA,OAFAJ,EAAeD,EAAqBC,GAAevC,GAE/CA,EACEuC,EAAa7G,OAAS,EACjB,IAAM6G,EAEN,IACAA,EAAa7G,OAAS,EACxB6G,EAEA,GAEX,EAEAU,UAAW,SAAmBf,GAG5B,GAFArB,EAAWqB,GAES,IAAhBA,EAAKxG,OAAc,MAAO,IAE9B,IAAI6G,EAAoC,KAAvBL,EAAKS,WAAW,GAC7B3C,EAAyD,KAArCkC,EAAKS,WAAWT,EAAKxG,OAAS,GAQtD,OAHoB,KAFpBwG,EAAOI,EAAqBJ,GAAOK,IAE1B7G,QAAiB6G,IAAYL,EAAO,KACzCA,EAAKxG,OAAS,GAAKsE,IAAmBkC,GAAQ,KAE9CK,EAAmB,IAAML,EACtBA,CACT,EAEAgB,WAAY,SAAoBhB,GAE9B,OADArB,EAAWqB,GACJA,EAAKxG,OAAS,GAA4B,KAAvBwG,EAAKS,WAAW,EAC5C,EAEAQ,KAAM,WACJ,GAAyB,IAArBtF,UAAUnC,OACZ,MAAO,IAET,IADA,IAAIwG,EACKI,EAAI,EAAGA,EAAIzE,UAAUnC,SAAU4G,EAAG,CACzC,IAAItC,EAAMnC,UAAUyE,GACpBzB,EAAWb,GACPA,EAAItE,OAAS,aACXwG,EACFA,EAASlC,EAETkC,GAAU,IAAMlC,EAEtB,CACA,gBAAIkC,EACK,IACFK,EAAMU,UAAUf,EACzB,EAEAkB,SAAU,SAAkBlB,EAAMI,GAIhC,GAHAzB,EAAWqB,GACXrB,EAAWyB,GAEPJ,IAASI,EAAI,MAAO,GAKxB,IAHAJ,EAAOK,EAAMO,QAAQZ,OACrBI,EAAKC,EAAMO,QAAQR,IAEF,MAAO,GAIxB,IADA,IAAItC,EAAY,EACTA,EAAYkC,EAAKxG,QACa,KAA/BwG,EAAKS,WAAW3C,KADYA,GASlC,IALA,IAAIwC,EAAUN,EAAKxG,OACf+G,EAAUD,EAAUxC,EAGpB0C,EAAU,EACPA,EAAUJ,EAAG5G,QACa,KAA3B4G,EAAGK,WAAWD,KADUA,GAW9B,IAPA,IACIE,EADQN,EAAG5G,OACKgH,EAGhBW,EAASZ,EAAUG,EAAQH,EAAUG,EACrCU,GAAiB,EACjBC,EAAI,EACDA,GAAKF,IAAUE,EAAG,CACvB,GAAIA,IAAMF,EAAQ,CAChB,GAAIT,EAAQS,EAAQ,CAClB,GAAmC,KAA/Bf,EAAGK,WAAWD,EAAUa,GAG1B,OAAOjB,EAAG/B,MAAMmC,EAAUa,EAAI,GACzB,GAAU,IAANA,EAGT,OAAOjB,EAAG/B,MAAMmC,EAAUa,EAE9B,MAAWd,EAAUY,IACoB,KAAnCnB,EAAKS,WAAW3C,EAAYuD,GAG9BD,EAAgBC,EACD,IAANA,IAGTD,EAAgB,IAGpB,KACF,CACA,IAAIE,EAAWtB,EAAKS,WAAW3C,EAAYuD,GAE3C,GAAIC,IADSlB,EAAGK,WAAWD,EAAUa,GAEnC,MACoB,KAAbC,IACPF,EAAgBC,EACpB,CAEA,IAAIE,EAAM,GAGV,IAAKF,EAAIvD,EAAYsD,EAAgB,EAAGC,GAAKf,IAAWe,EAClDA,IAAMf,GAAkC,KAAvBN,EAAKS,WAAWY,KAChB,IAAfE,EAAI/H,OACN+H,GAAO,KAEPA,GAAO,OAMb,OAAIA,EAAI/H,OAAS,EACR+H,EAAMnB,EAAG/B,MAAMmC,EAAUY,IAEhCZ,GAAWY,EACoB,KAA3BhB,EAAGK,WAAWD,MACdA,EACGJ,EAAG/B,MAAMmC,GAEpB,EAEAgB,UAAW,SAAmBxB,GAC5B,OAAOA,CACT,EAEAyB,QAAS,SAAiBzB,GAExB,GADArB,EAAWqB,GACS,IAAhBA,EAAKxG,OAAc,MAAO,IAK9B,IAJA,IAAI4G,EAAOJ,EAAKS,WAAW,GACvBJ,EAAmB,KAATD,EACVtC,GAAO,EACPwC,GAAA,EACKC,EAAIP,EAAKxG,OAAS,EAAG+G,GAAK,IAAKA,EAEtC,GAAa,MADbH,EAAOJ,EAAKS,WAAWF,KAEnB,IAAKD,EAAc,CACjBxC,EAAMyC,EACN,KACF,OAGFD,GAAA,EAIJ,OAAa,IAATxC,EAAmBuC,EAAU,IAAM,IACnCA,GAAmB,IAARvC,EAAkB,KAC1BkC,EAAK3B,MAAM,EAAGP,EACvB,EAEA4D,SAAU,SAAkB1B,EAAMI,GAChC,QAAI,IAAAA,GAAoC,iBAARA,EAAkB,MAAM,IAAIH,UAAU,mCACtEtB,EAAWqB,GAEX,IAGIK,EAHAvC,EAAQ,EACRwC,GAAO,EACPC,GAAA,EAGJ,QAAI,IAAAH,GAAqBA,EAAI5G,OAAS,GAAK4G,EAAI5G,QAAUwG,EAAKxG,OAAQ,CACpE,GAAI4G,EAAI5G,SAAWwG,EAAKxG,QAAU4G,IAAQJ,EAAM,MAAO,GACvD,IAAIQ,EAASJ,EAAI5G,OAAS,EACtBkH,GAAoB,EACxB,IAAKL,EAAIL,EAAKxG,OAAS,EAAG6G,GAAK,IAAKA,EAAG,CACrC,IAAIc,EAAOnB,EAAKS,WAAWJ,GAC3B,GAAa,KAATc,GAGA,IAAKZ,EAAc,CACjBzC,EAAQuC,EAAI,EACZ,KACF,OAEwB,IAAtBK,IAGFH,GAAA,EACAG,EAAmBL,EAAI,GAErBG,GAAU,IAERW,IAASf,EAAIK,WAAWD,IACR,KAAZA,IAGJF,EAAMD,IAKRG,GAAU,EACVF,EAAMI,GAId,CAGA,OADI5C,IAAUwC,EAAKA,EAAMI,GAAmC,IAATJ,IAAYA,EAAMN,EAAKxG,QACnEwG,EAAK3B,MAAMP,EAAOwC,EAC3B,CACE,IAAKD,EAAIL,EAAKxG,OAAS,EAAG6G,GAAK,IAAKA,EAClC,GAA2B,KAAvBL,EAAKS,WAAWJ,IAGhB,IAAKE,EAAc,CACjBzC,EAAQuC,EAAI,EACZ,KACF,OACkB,IAATC,IAGXC,GAAA,EACAD,EAAMD,EAAI,GAId,OAAa,IAATC,EAAmB,GAChBN,EAAK3B,MAAMP,EAAOwC,EAE7B,EAEAqB,QAAS,SAAiB3B,GACxBrB,EAAWqB,GAQX,IAPA,IAAII,GAAY,EACZC,EAAY,EACZvC,GAAO,EACPwC,GAAA,EAGAC,EAAc,EACTC,EAAIR,EAAKxG,OAAS,EAAGgH,GAAK,IAAKA,EAAG,CACzC,IAAIE,EAAOV,EAAKS,WAAWD,GAC3B,GAAa,KAATE,GASS,IAAT5C,IAGFwC,GAAA,EACAxC,EAAM0C,EAAI,GAEC,KAATE,GAEkB,IAAdN,EACFA,EAAWI,EACY,IAAhBD,IACPA,EAAc,IACK,IAAdH,IAGTG,GAAe,QArBb,IAAKD,EAAc,CACjBD,EAAYG,EAAI,EAChB,KACF,CAoBN,CAEA,OAAkB,IAAdJ,IAA4B,IAATtC,GAEH,IAAhByC,GAEgB,IAAhBA,GAAqBH,IAAatC,EAAM,GAAKsC,IAAaC,EAAY,EACjE,GAEFL,EAAK3B,MAAM+B,EAAUtC,EAC9B,EAEA8D,OAAQ,SAAgB5B,GACtB,GAAmB,OAAfA,GAA6C,iBAAfA,EAChC,MAAM,IAAIC,UAAU,0EAA4ED,GAElG,OAvVJ,SAAiBA,EAAKrB,GACpB,IAAIyB,EAAMzB,EAAWkD,KAAOlD,EAAWmD,KACnCzB,EAAO1B,EAAWoD,OAASpD,EAAWvF,MAAQ,KAAOuF,EAAWqD,KAAO,IAC3E,OAAK5B,EAGDA,IAAQzB,EAAWmD,KACd1B,EAAMC,EAERD,EA8UU,IA9UEC,EALVA,CAMX,CAVA,CAuVmB,EAAKL,EACtB,EAEAiC,MAAO,SAAejC,GACpBrB,EAAWqB,GAEX,IAAII,EAAM,CAAE0B,KAAM,GAAID,IAAK,GAAIE,KAAM,GAAIC,IAAK,GAAI5I,KAAM,IACxD,GAAoB,IAAhB4G,EAAKxG,OAAc,OAAO4G,EAC9B,IAEIC,EAFAvC,EAAOkC,EAAKS,WAAW,GACvBH,EAAsB,KAATxC,EAEbwC,GACFF,EAAI0B,KAAO,IACXzB,EAAQ,GAERA,EAAQ,EAaV,IAXA,IAAIE,GAAY,EACZC,EAAY,EACZE,GAAO,EACPS,GAAA,EACAC,EAAIpB,EAAKxG,OAAS,EAIlB6H,EAAc,EAGXD,GAAKf,IAASe,EAEnB,GAAa,MADbtD,EAAOkC,EAAKS,WAAWW,KAUV,IAATV,IAGFS,GAAA,EACAT,EAAMU,EAAI,GAEC,KAATtD,GAEkB,IAAdyC,EAAiBA,EAAWa,EAA2B,IAAhBC,IAAmBA,EAAc,IACrD,IAAdd,IAGXc,GAAe,QAlBb,IAAKF,EAAc,CACjBX,EAAYY,EAAI,EAChB,KACF,CAwCN,OArBkB,IAAdb,IAA4B,IAATG,GAEP,IAAhBW,GAEgB,IAAhBA,GAAqBd,IAAaG,EAAM,GAAKH,IAAaC,EAAY,GACvD,IAATE,IACiCN,EAAI2B,KAAO3B,EAAIhH,KAAhC,IAAdoH,GAAmBF,EAAkCN,EAAK3B,MAAM,EAAGqC,GAAgCV,EAAK3B,MAAMmC,EAAWE,KAG7G,IAAdF,GAAmBF,GACrBF,EAAIhH,KAAO4G,EAAK3B,MAAM,EAAGkC,GACzBH,EAAI2B,KAAO/B,EAAK3B,MAAM,EAAGqC,KAEzBN,EAAIhH,KAAO4G,EAAK3B,MAAMmC,EAAWD,GACjCH,EAAI2B,KAAO/B,EAAK3B,MAAMmC,EAAWE,IAEnCN,EAAI4B,IAAMhC,EAAK3B,MAAMkC,EAAUG,IAG7BF,EAAY,EAAGJ,EAAIyB,IAAM7B,EAAK3B,MAAM,EAAGmC,EAAY,GAAYF,IAAYF,EAAIyB,IAAM,KAElFzB,CACT,EAEA8B,IAAK,IACLC,UAAW,IACXC,MAAO,KACPC,MAAO,MAGThC,EAAMgC,MAAQhC,EAEdL,EAAOrD,QAAU0D,IC/gBb1B,EAA2B,CAAC,EAGhC,SAASyB,EAAoBC,GAE5B,IAAIvC,EAAea,EAAyB0B,GAC5C,QAAI,IAAAvC,EACH,OAAOA,EAAanB,QAGrB,IAAI2D,EAAS3B,EAAyB0B,GAAY,CAGjD1D,QAAS,CAAC,GAOX,OAHAqD,EAAoBK,GAAUC,EAAQA,EAAO3D,QAASyD,GAG/CE,EAAO3D,OACf,CCrBAyD,EAAoBkC,EAAI,CAACtC,EAASrB,KACjC,IAAI,IAAI0B,KAAO1B,EACXyB,EAAoBE,EAAE3B,EAAY0B,KAASD,EAAoBE,EAAEN,EAASK,IAC5E5D,OAAOC,eAAesD,EAASK,EAAK,CAAEkC,YAAA,EAAkBC,IAAK7D,EAAW0B,MCJ3ED,EAAoBE,EAAI,CAACN,EAAKrB,IAAUlC,OAAOgG,UAAUC,eAAe/C,KAAKK,EAAKrB,GCClFyB,EAAoBA,EAAKJ,IACH,oBAAX2C,QAA0BA,OAAOC,aAC1CnG,OAAOC,eAAesD,EAAS2C,OAAOC,YAAa,CAAEvG,MAAO,WAE7DI,OAAOC,eAAesD,EAAS,aAAc,CAAE3D,OAAA,K,eCQzC,IAAI2D,EAEX,G,sCAAuB,iBAAZa,QACVb,EAAiC,UAArBa,QAAQgC,cACd,GAAyB,iBAAdC,UAAwB,CACzC,IAAInE,EAAYmE,UAAUC,UAC1B/C,EAAYrB,EAAUqE,QAAQ,YAAc,C,CCV7C,MAAMrE,EAAiB,iBACjBb,EAAoB,MACpBwC,EAAoB,QAE1B,SAASC,EAAaP,EAAUI,GAG/B,IAAKJ,EAAIiD,QAAU7C,EAClB,MAAM,IAAInC,MAAA,2DAAAiF,OAAiElD,EAAImD,UAAA,cAAAD,OAAsBlD,EAAIoD,KAAA,eAAAF,OAAkBlD,EAAIqD,MAAA,kBAAAH,OAAsBlD,EAAIsD,SAAA,OAK1J,GAAItD,EAAIiD,SAAWtE,EAAe4E,KAAKvD,EAAIiD,QAC1C,MAAM,IAAIhF,MAAM,mDAQjB,GAAI+B,EAAIoD,KACP,GAAIpD,EAAImD,WACP,IAAKrF,EAAkByF,KAAKvD,EAAIoD,MAC/B,MAAM,IAAInF,MAAM,iJAGjB,GAAIqC,EAAkBiD,KAAKvD,EAAIoD,MAC9B,MAAM,IAAInF,MAAM,4HAIpB,CAkCA,MAAMuC,EAAS,GACTE,EAAS,IACTS,EAAU,+DAkBT,MAAMC,EAEZ,YAAAoC,CAAaxD,GACZ,OAAIA,aAAiBoB,KAGhBpB,GAGoC,iBAArBA,EAAOmD,WACU,iBAApBnD,EAAOsD,UACS,iBAAhBtD,EAAOoD,MACU,iBAAjBpD,EAAOqD,OACW,iBAAlBrD,EAAOiD,QACW,iBAAlBjD,EAAOyD,QACS,mBAAhBzD,EAAO0D,MACa,mBAApB1D,EAAO2D,QACzB,CA0CAlL,WAAAA,CAAsBuH,EAAsCrB,EAAoByB,EAAeC,EAAgBvC,GAAsC,IAAnBwC,EAAA3E,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,IAAmBiI,EAAAA,EAAAA,GAAA,uBAAAA,EAAAA,EAAAA,GAAA,0BAAAA,EAAAA,EAAAA,GAAA,qBAAAA,EAAAA,EAAAA,GAAA,sBAAAA,EAAAA,EAAAA,GAAA,wBAExH,iBAAjB5D,GACVzC,KAAK0F,OAASjD,EAAaiD,QAAUzC,EACrCjD,KAAK4F,UAAYnD,EAAamD,WAAa3C,EAC3CjD,KAAK6F,KAAOpD,EAAaoD,MAAQ5C,EACjCjD,KAAK8F,MAAQrD,EAAaqD,OAAS7C,EACnCjD,KAAK+F,SAAWtD,EAAasD,UAAY9C,IAKzCjD,KAAK0F,OAvHR,SAAoBjD,EAAgBrB,GACnC,OAAKqB,GAAWrB,EAGTqB,EAFC,MAGT,CALA,CAuH4BA,EAAcM,GACvC/C,KAAK4F,UAAYxE,GAAa6B,EAC9BjD,KAAK6F,KAjHR,SAA8BpD,EAAgBrB,GAM7C,OAAQqB,GACP,IAAK,QACL,IAAK,OACL,IAAK,OACCrB,EAEMA,EAAK,KAAO+B,IACtB/B,EAAO+B,EAAS/B,GAFhBA,EAAO+B,EAMV,OAAO/B,CACR,CAlBA,CAiHoCpB,KAAK0F,OAAQ7C,GAAQI,GACtDjD,KAAK8F,MAAQhD,GAASG,EACtBjD,KAAK+F,SAAWxF,GAAY0C,EAE5BD,EAAahD,KAAM+C,GAErB,CA4BA,UAAAmD,GAIC,OAAOI,EAAYtG,MAAM,EAC1B,CAIAmG,KAAK1D,GAEJ,IAAKA,EACJ,OAAOzC,KAGR,IAAI0F,OAAEtE,EAAMwE,UAAE/C,EAASgD,KAAE/C,EAAIgD,MAAEvF,EAAKwF,SAAEhD,GAAaN,EA2BnD,gBA1BIrB,EACHA,EAASpB,KAAK0F,OACO,OAAXtE,IACVA,EAAS6B,QAAA,IAENJ,EACHA,EAAY7C,KAAK4F,UACO,OAAd/C,IACVA,EAAYI,QAAA,IAETH,EACHA,EAAO9C,KAAK6F,KACO,OAAT/C,IACVA,EAAOG,QAAA,IAEJ1C,EACHA,EAAQP,KAAK8F,MACO,OAAVvF,IACVA,EAAQ0C,QAAA,IAELF,EACHA,EAAW/C,KAAK+F,SACO,OAAbhD,IACVA,EAAWE,GAGR7B,IAAWpB,KAAK0F,QAChB7C,IAAc7C,KAAK4F,WACnB9C,IAAS9C,KAAK6F,MACdtF,IAAUP,KAAK8F,OACf/C,IAAa/C,KAAK+F,SAEd/F,KAGD,IAAI+D,EAAI3C,EAAQyB,EAAWC,EAAMvC,EAAOwC,EAChD,CAUA,YAAA2B,CAAajC,GAAkC,IAAnBrB,EAAAhD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAC3B,MAAMyE,EAAQe,EAAQzH,KAAKsG,GAC3B,OAAKI,EAGE,IAAIkB,EACVlB,EAAM,IAAMI,EACZsD,EAAc1D,EAAM,IAAMI,GAC1BsD,EAAc1D,EAAM,IAAMI,GAC1BsD,EAAc1D,EAAM,IAAMI,GAC1BsD,EAAc1D,EAAM,IAAMI,GAC1B7B,GARO,IAAI2C,EAAId,EAAQA,EAAQA,EAAQA,EAAQA,EAUjD,CAuBA,WAAAuD,CAAYpF,GAEX,IAAIyB,EAAYI,EAWhB,GANIR,IACHrB,EAAOA,EAAKrF,QAAQ,MAAOoH,IAKxB/B,EAAK,KAAO+B,GAAU/B,EAAK,KAAO+B,EAAQ,CAC7C,MAAMV,EAAMrB,EAAKqE,QAAQtC,EAAQ,IACpB,IAATV,GACHI,EAAYzB,EAAKpF,UAAU,GAC3BoF,EAAO+B,IAEPN,EAAYzB,EAAKpF,UAAU,EAAGyG,GAC9BrB,EAAOA,EAAKpF,UAAUyG,IAAQU,E,CAIhC,OAAO,IAAIY,EAAI,OAAQlB,EAAWzB,EAAM6B,EAAQA,EACjD,CAEA,WAAAwD,CAAYhE,GACX,MAAMrB,EAAS,IAAI2C,EAClBtB,EAAWiD,OACXjD,EAAWmD,UACXnD,EAAWoD,KACXpD,EAAWqD,MACXrD,EAAWsD,UAGZ,OADA/C,EAAa5B,GAAA,GACNA,CACR,CAeAgF,QAAAA,GACC,OAAOM,EAAa1G,KADZ5B,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAET,CAEAuI,MAAAA,GACC,OAAO3G,IACR,CAMA,aAAA4G,CAAcnE,GACb,GAAKA,EAEE,IAAIA,aAAgBoB,EAC1B,OAAOpB,EACD,CACN,MAAMrB,EAAS,IAAI2C,EAAItB,GAGvB,OAFArB,EAAOyF,WAAwBpE,EAAMqE,SACrC1F,EAAO2F,QAAqBtE,EAAMuE,OAASlD,EAA4BrB,EAAMyD,OAAS,KAC/E9E,C,EAPP,OAAYqB,CASd,EAkBD,MAAMqB,EAAiBrB,EAAY,OAAI,EAGvC,MAAMsB,UAAYF,EAAA3I,WAAAA,GAAA,SAAAkD,YAAAiI,EAAAA,EAAAA,GAAA,kBAEW,OAAAA,EAAAA,EAAAA,GAAA,eACH,MAEzB,UAAAH,GAIC,OAHKlG,KAAK+G,UACT/G,KAAK+G,QAAUT,EAAYtG,MAAM,IAE3BA,KAAK+G,OACb,CAESX,QAAAA,GACR,OADiBhI,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAQTsI,EAAa1G,MAAM,IANrBA,KAAK6G,aACT7G,KAAK6G,WAAaH,EAAa1G,MAAM,IAE/BA,KAAK6G,WAKd,CAESF,MAAAA,GACR,MAAMlE,EAAgB,CACrBwE,KAAM,GA0BP,OAvBIjH,KAAK+G,UACRtE,EAAIyD,OAASlG,KAAK+G,QAClBtE,EAAIuE,KAAOlD,GAER9D,KAAK6G,aACRpE,EAAIqE,SAAW9G,KAAK6G,YAGjB7G,KAAK6F,OACRpD,EAAIoD,KAAO7F,KAAK6F,MAEb7F,KAAK0F,SACRjD,EAAIiD,OAAS1F,KAAK0F,QAEf1F,KAAK4F,YACRnD,EAAImD,UAAY5F,KAAK4F,WAElB5F,KAAK8F,QACRrD,EAAIqD,MAAQ9F,KAAK8F,OAEd9F,KAAK+F,WACRtD,EAAIsD,SAAW/F,KAAK+F,UAEdtD,CACR,EAID,MAAMuB,EAAwC,CAC7C,GAAkB,MAClB,GAAkB,MAClB,GAAyB,MACzB,GAAiB,MACjB,GAA8B,MAC9B,GAA+B,MAC/B,GAAmB,MAEnB,GAA4B,MAC5B,GAAuB,MACvB,GAAsB,MACtB,GAAwB,MACxB,GAAsB,MACtB,GAAuB,MACvB,GAAqB,MACrB,GAAiB,MACjB,GAAkB,MAClB,GAAsB,MACtB,GAAmB,MAEnB,GAAkB,OAGnB,SAASe,EAAuBtC,EAAsBrB,EAAiByB,GACtE,IAAIC,EACAvC,GAAmB,EAEvB,IAAK,IAAIwC,EAAM,EAAGA,EAAMN,EAAaxG,OAAQ8G,IAAO,CACnD,MAAMC,EAAOP,EAAaS,WAAWH,GAGrC,GACEC,GAAQ,IAAcA,GAAQ,KAC3BA,GAAQ,IAAcA,GAAQ,IAC9BA,GAAQ,IAAmBA,GAAQ,IAC3B,KAATA,GACS,KAATA,GACS,KAATA,GACS,MAATA,GACC5B,GAAmB,KAAT4B,GACVH,GAAwB,KAATG,GACfH,GAAwB,KAATG,GACfH,GAAwB,KAATG,GAGM,IAArBzC,IACHuC,GAAOoE,mBAAmBzE,EAAazG,UAAUuE,EAAiBwC,IAClExC,GAAmB,YAGhBuC,IACHA,GAAOL,EAAa0E,OAAOpE,QAGtB,UAEFD,IACHA,EAAML,EAAa2E,OAAO,EAAGrE,IAI9B,MAAM3B,EAAU4C,EAAYhB,QAAA,IACxB5B,IAGsB,IAArBb,IACHuC,GAAOoE,mBAAmBzE,EAAazG,UAAUuE,EAAiBwC,IAClExC,GAAmB,GAIpBuC,GAAO1B,IAEwB,IAArBb,IAEVA,EAAkBwC,E,EASrB,OAJyB,IAArBxC,IACHuC,GAAOoE,mBAAmBzE,EAAazG,UAAUuE,UAAA,IAG3CuC,EAAoBA,EAAML,CAClC,CAEA,SAAS4E,EAA0B5E,GAClC,IAAIrB,EACJ,IAAK,IAAIyB,EAAM,EAAGA,EAAMJ,EAAKxG,OAAQ4G,IAAO,CAC3C,MAAMC,EAAOL,EAAKS,WAAWL,GAChB,KAATC,GAAmC,KAATA,QAAA,IACzB1B,IACHA,EAAMqB,EAAK2E,OAAO,EAAGvE,IAEtBzB,GAAO4C,EAAYlB,SAAA,IAEf1B,IACHA,GAAOqB,EAAKI,G,CAIf,YAAO,IAAAzB,EAAoBA,EAAMqB,CAClC,CAKO,SAAS6D,EAAYlF,EAAUyB,GAErC,IAAIC,EAsBJ,OAnBCA,EAFG1B,EAAIwE,WAAaxE,EAAIyE,KAAK5J,OAAS,GAAoB,SAAfmF,EAAIsE,OAAA,KAAAC,OAElCvE,EAAIwE,WAAAD,OAAYvE,EAAIyE,MAEN,KAA3BzE,EAAIyE,KAAK3C,WAAW,KAChB9B,EAAIyE,KAAK3C,WAAW,IAAM,IAAc9B,EAAIyE,KAAK3C,WAAW,IAAM,IAAc9B,EAAIyE,KAAK3C,WAAW,IAAM,IAAc9B,EAAIyE,KAAK3C,WAAW,IAAM,MACxH,KAA3B9B,EAAIyE,KAAK3C,WAAW,GAElBL,EAIIzB,EAAIyE,KAAKuB,OAAO,GAFhBhG,EAAIyE,KAAK,GAAGyB,cAAgBlG,EAAIyE,KAAKuB,OAAO,GAM7ChG,EAAIyE,KAETpD,IACHK,EAAQA,EAAM/G,QAAQ,MAAO,OAEvB+G,CACR,CAKA,SAAS4D,EAAajE,EAAUrB,GAE/B,MAAMyB,EAAWzB,EAEdiG,EADAtC,EAGH,IAAIjC,EAAM,IACN4C,OAAEnF,EAAMqF,UAAE7C,EAAS8C,KAAE7C,EAAI8C,MAAE7C,EAAK8C,SAAEnC,GAAanB,EASnD,GARIlC,IACHuC,GAAOvC,EACPuC,GAAO,MAEJC,GAAwB,SAAXxC,KAChBuC,GAAOK,EACPL,GAAOK,GAEJJ,EAAW,CACd,IAAIN,EAAMM,EAAU0C,QAAQ,KAC5B,IAAa,IAAThD,EAAY,CAEf,MAAMrB,EAAW2B,EAAUqE,OAAO,EAAG3E,GACrCM,EAAYA,EAAUqE,OAAO3E,EAAM,GACnCA,EAAMrB,EAASgC,YAAY,MACd,IAATX,EACHK,GAAOD,EAAQzB,GAAA,GAAU,IAGzB0B,GAAOD,EAAQzB,EAASgG,OAAO,EAAG3E,IAAA,GAAM,GACxCK,GAAO,IACPA,GAAOD,EAAQzB,EAASgG,OAAO3E,EAAM,IAAI,OAE1CK,GAAO,G,CAERC,EAAYA,EAAUuE,cACtB7E,EAAMM,EAAUK,YAAY,MACf,IAATX,EACHK,GAAOD,EAAQE,GAAA,GAAW,IAG1BD,GAAOD,EAAQE,EAAUqE,OAAO,EAAG3E,IAAA,GAAM,GACzCK,GAAOC,EAAUqE,OAAO3E,G,CAG1B,GAAIO,EAAM,CAET,GAAIA,EAAK/G,QAAU,GAA4B,KAAvB+G,EAAKE,WAAW,IAAgD,KAAvBF,EAAKE,WAAW,GAAuB,CACvG,MAAMT,EAAOO,EAAKE,WAAW,GACzBT,GAAQ,IAAcA,GAAQ,KACjCO,EAAA,IAAA2C,OAAW4B,OAAOC,aAAa/E,EAAO,SAAAkD,OAAO3C,EAAKoE,OAAO,I,MAEpD,GAAIpE,EAAK/G,QAAU,GAA4B,KAAvB+G,EAAKE,WAAW,GAAuB,CACrE,MAAMT,EAAOO,EAAKE,WAAW,GACzBT,GAAQ,IAAcA,GAAQ,KACjCO,EAAA,GAAA2C,OAAU4B,OAAOC,aAAa/E,EAAO,SAAAkD,OAAO3C,EAAKoE,OAAO,I,CAI1DtE,GAAOD,EAAQG,GAAA,GAAM,E,CAUtB,OARIC,IACHH,GAAO,IACPA,GAAOD,EAAQI,GAAA,GAAO,IAEnBW,IACHd,GAAO,IACPA,GAAQ1B,EAAgEwC,EAAjDmB,EAAuBnB,GAAA,GAAU,IAElDd,CACR,CAIA,SAAS2E,EAA2BhF,GACnC,IACC,OAAOiF,mBAAmBjF,E,CACzB,MAAAkF,GACD,OAAIlF,EAAIxG,OAAS,EACTwG,EAAI2E,OAAO,EAAG,GAAKK,EAA2BhF,EAAI2E,OAAO,IAEzD3E,C,CAGV,CAEA,MAAMmF,EAAiB,8BAEvB,SAASrB,EAAc9D,GACtB,OAAKA,EAAIvG,MAAM0L,GAGRnF,EAAI1G,QAAQ6L,EAAiBnF,GAAUgF,EAA2BhF,IAFjEA,CAGT,C,aCjqBA,MAAMoF,EAAYC,EAAAhD,OAAkBgD,EAC9BC,EAAQ,IAEP,IAAUC,GAAjB,SAAiBvF,GAeGA,EAAAwF,SAAhB,SAAyBxF,GAAa,QAAAzB,EAAA5C,UAAAnC,OAAAmF,EAAA,IAAAhB,MAAAY,EAAA,EAAAA,EAAA,KAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAAAE,EAAAF,EAAA,GAAA9C,UAAA8C,GAClC,OAAOuB,EAAI0D,KAAK,CAAEN,KAAMgC,EAAUnE,KAAKjB,EAAIoD,QAASzE,IACxD,EAgBgBqB,EAAAyF,YAAhB,SAA4BzF,GACxB,IAAII,EAAOJ,EAAIoD,KACX/C,GAAA,EACAD,EAAK,KAAOkF,IACZlF,EAAOkF,EAAQlF,EACfC,GAAA,GAEJ,QAAAqF,EAAA/J,UAAAnC,OAPqCmF,EAAA,IAAAhB,MAAA+H,EAAA,EAAAA,EAAA,KAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAAhH,EAAAgH,EAAA,GAAAhK,UAAAgK,GAOrC,IAAI7H,EAAesH,EAAUxE,QAAQR,KAASzB,GAI9C,OAHI0B,GAAcvC,EAAa,KAAOwH,IAAUtF,EAAImD,YAChDrF,EAAeA,EAAavE,UAAU,IAEnCyG,EAAI0D,KAAK,CAAEN,KAAMtF,GAC5B,EAUgBkC,EAAAyB,QAAhB,SAAwBzB,GACpB,GAAwB,IAApBA,EAAIoD,KAAK5J,QAAgBwG,EAAIoD,OAASkC,EACtC,OAAOtF,EAEX,IAAIrB,EAAOyG,EAAU3D,QAAQzB,EAAIoD,MAIjC,OAHoB,IAAhBzE,EAAKnF,QAAuC,KAAvBmF,EAAK8B,WAAW,KACrC9B,EAAO,IAEJqB,EAAI0D,KAAK,CAAEN,KAAAzE,GACtB,EAUgBqB,EAAA0B,SAAhB,SAAyB1B,GACrB,OAAOoF,EAAU1D,SAAS1B,EAAIoD,KAClC,EAUgBpD,EAAA2B,QAAhB,SAAwB3B,GACpB,OAAOoF,EAAUzD,QAAQ3B,EAAIoD,KACjC,CACH,CAzFD,CAAiBmC,IAAAA,EAAK,I,+FCOtB,QAVA,SAAiBK,EAAYC,GAC3B,IAAIC,GAAS,EACTvG,GAASwG,EAAAA,EAAAA,GAAYH,GAAcjI,MAAMiI,EAAWpM,QAAU,GAKlE,OAHAwM,EAAAA,EAAAA,GAASJ,EAAY,SAASvJ,EAAO4J,EAAKL,GACxCrG,IAASuG,GAASD,EAASxJ,EAAO4J,EAAKL,EACzC,GACOrG,CACT,C,mCClBA,IAGImD,EAHcjG,OAAOgG,UAGQC,eAcjC,QAJA,SAAiBwD,EAAQD,GACvB,OAAiB,MAAVC,GAAkBxD,EAAe/C,KAAKuG,EAAQD,EACvD,E,eCkBA,QAJA,SAAaC,EAAQ9C,GACnB,OAAiB,MAAV8C,IAAkBC,EAAAA,EAAAA,GAAQD,EAAQ9C,EAAMgD,EACjD,C,gBC1BA,IAAIC,EACJ,SAASC,IACL,QAAa1K,IAATyK,EACA,MAAM,IAAIpI,MAAM,0CAEpB,OAAOoI,CACX,CAPA5J,OAAOC,eAAeC,EAAS,aAAc,CAAEN,OAAO,IAQtD,SAAWiK,GAOPA,EAAIC,QANJ,SAAiBC,GACb,QAAY5K,IAAR4K,EACA,MAAM,IAAIvI,MAAM,yCAEpBoI,EAAOG,CACX,CAEH,CARD,CAQGF,IAAQA,EAAM,CAAC,IAClB3J,EAAAA,QAAkB2J,C,iFChBdG,EAAchK,OAAOgG,UAGrBC,EAAiB+D,EAAY/D,eAsDjC,SA/BegE,EAAAA,EAAAA,GAAS,SAASR,EAAQS,GACvCT,EAASzJ,OAAOyJ,GAEhB,IAAIJ,GAAS,EACTtM,EAASmN,EAAQnN,OACjBoN,EAAQpN,EAAS,EAAImN,EAAQ,QAAK/K,EAMtC,IAJIgL,IAASC,EAAAA,EAAAA,GAAeF,EAAQ,GAAIA,EAAQ,GAAIC,KAClDpN,EAAS,KAGFsM,EAAQtM,GAMf,IALA,IAAIsN,EAASH,EAAQb,GACjBiB,GAAQC,EAAAA,EAAAA,GAAOF,GACfG,GAAc,EACdC,EAAcH,EAAMvN,SAEfyN,EAAaC,GAAa,CACjC,IAAIjB,EAAMc,EAAME,GACZ5K,EAAQ6J,EAAOD,SAELrK,IAAVS,IACC8K,EAAAA,EAAAA,GAAG9K,EAAOoK,EAAYR,MAAUvD,EAAe/C,KAAKuG,EAAQD,MAC/DC,EAAOD,GAAOa,EAAOb,GAEzB,CAGF,OAAOC,CACT,E,kDCxCA,QALA,SAAiBtG,GAEf,OADsB,MAATA,EAAgB,EAAIA,EAAMpG,SACvB4N,EAAAA,EAAAA,GAAYxH,EAAO,GAAK,EAC1C,C,qFCFIyH,GAAiB9O,EAAG,cAAcC,EAAAA,GAIpCC,WAAAA,GACEC,MAAM,CAAC,cACT,IAJEC,EAAAA,EAAAA,IAAMJ,EAAO,qBAAoBA,GAQjC+O,EAAc,CAChBhM,OAAQ,CACNC,cAA8B5C,EAAAA,EAAAA,IAAO,IAAM,IAAI0O,EAAqB,gBACpE7L,gBAAgC7C,EAAAA,EAAAA,IAAO,IAAM,IAAI4O,EAAAA,GAAwB,oBAG7E,SAASC,IAA+C,IAA3B9L,EAAOC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGE,EAAAA,EACrC,MAAMC,GAASC,EAAAA,EAAAA,KACbC,EAAAA,EAAAA,GAA8BN,GAC9BO,EAAAA,IAEIwL,GAAQ1L,EAAAA,EAAAA,KACZG,EAAAA,EAAAA,GAAwB,CAAEJ,WAC1B4L,EAAAA,GACAJ,GAGF,OADAxL,EAAOM,gBAAgB3B,SAASgN,GACzB,CAAE3L,SAAQ2L,QACnB,EACA9O,EAAAA,EAAAA,IAAO6O,EAAqB,sB,yGCI5B,QAlCA,SAAiBtB,EAAQ9C,EAAM/G,EAAOsL,GACpC,KAAKC,EAAAA,EAAAA,GAAS1B,GACZ,OAAOA,EAST,IALA,IAAIJ,GAAS,EACTtM,GAHJ4J,GAAOyE,EAAAA,EAAAA,GAASzE,EAAM8C,IAGJ1M,OACdsO,EAAYtO,EAAS,EACrBuO,EAAS7B,EAEI,MAAV6B,KAAoBjC,EAAQtM,GAAQ,CACzC,IAAIyM,GAAM+B,EAAAA,EAAAA,GAAM5E,EAAK0C,IACjBmC,EAAW5L,EAEf,GAAY,cAAR4J,GAA+B,gBAARA,GAAiC,cAARA,EAClD,OAAOC,EAGT,GAAIJ,GAASgC,EAAW,CACtB,IAAII,EAAWH,EAAO9B,QAELrK,KADjBqM,EAAWN,EAAaA,EAAWO,EAAUjC,EAAK8B,QAAUnM,KAE1DqM,GAAWL,EAAAA,EAAAA,GAASM,GAChBA,GACCC,EAAAA,EAAAA,GAAQ/E,EAAK0C,EAAQ,IAAM,GAAK,CAAC,EAE1C,EACAsC,EAAAA,EAAAA,GAAYL,EAAQ9B,EAAKgC,GACzBF,EAASA,EAAO9B,EAClB,CACA,OAAOC,CACT,ECnBA,QAhBA,SAAoBA,EAAQmC,EAAOC,GAKjC,IAJA,IAAIxC,GAAS,EACTtM,EAAS6O,EAAM7O,OACf+F,EAAS,CAAC,IAELuG,EAAQtM,GAAQ,CACvB,IAAI4J,EAAOiF,EAAMvC,GACbzJ,GAAQkM,EAAAA,EAAAA,GAAQrC,EAAQ9C,GAExBkF,EAAUjM,EAAO+G,IACnBoF,EAAQjJ,GAAQsI,EAAAA,EAAAA,GAASzE,EAAM8C,GAAS7J,EAE5C,CACA,OAAOkD,CACT,C,2CCnBM,MAAOkJ,UAA0BxK,MACnCxF,WAAAA,CAAY0C,EAA2BuN,GACnChQ,MAAMyC,EAAO,GAAH+H,OAAMwF,EAAO,QAAAxF,OAAO/H,EAAKwN,MAAMC,MAAMC,KAAI,KAAA3F,OAAI/H,EAAKwN,MAAMC,MAAME,WAAcJ,EAC1F,EAGE,SAAUK,EAAkBC,GAC9B,MAAM,IAAI/K,MAAM,0CACpB,C,iICSM,SAAUgL,EAAYhQ,EAAYiQ,EAA+BC,GACnE,MAAO,GAAPjG,OAAUjK,EAAKG,KAAI,KAAA8J,OAAIgG,EAAI,KAAAhG,OAAIiG,EACnC,CA6GM,MAAgBC,EAGlB3Q,WAAAA,CAAY4Q,GACR9L,KAAK8L,OAASA,CAClB,CAEAC,SAAAA,GACI,OAAO,CACX,EAGE,MAAOC,UAAuBH,EAGhC3Q,WAAAA,CAAY4Q,EAAkBG,GAC1B9Q,MAAM2Q,GACN9L,KAAKiM,UAAYA,CACrB,EAGE,MAAOC,UAA0BL,EACnC3Q,WAAAA,CAAY4Q,GACR3Q,MAAM2Q,EACV,CAEAC,SAAAA,GACI,OAAO,CACX,EAGE,MAAOI,UAAuBN,EAIhC3Q,WAAAA,CAAYkR,EAA2B1Q,EAAY2Q,GAC/ClR,MAAMiR,GACNpM,KAAKtE,KAAOA,EACZsE,KAAKqM,YAAcA,CACvB,CAEAN,SAAAA,GACI,OAAO,CACX,EAQE,SAAUO,EAAUC,GACtB,MAAMC,EAAW,CACbC,YAAa,CAAC,EACdC,eAAgB,GAChBC,iBAAkB,IAAIC,IACtBC,gBAAiB,IAAID,IACrBE,OAAQ,KAehB,SAAyCN,EAAUD,GAC/C,MAAMQ,EAAaR,EAAMtQ,OACzB,IAAK,IAAIsE,EAAI,EAAGA,EAAIwM,EAAYxM,IAAK,CACjC,MAAM7E,EAAO6Q,EAAMhM,GACb8K,EAAQ2B,EAAyBR,EAAK9Q,OAAM2C,EAAW,CACzDsN,KA9KkB,IAgLhBsB,EAAOD,EAAwBR,EAAK9Q,OAAM2C,EAAW,CACvDsN,KA5KiB,IA8KrBN,EAAM4B,KAAOA,EACbT,EAAIG,iBAAiBO,IAAIxR,EAAM2P,GAC/BmB,EAAIK,gBAAgBK,IAAIxR,EAAMuR,E,CAEtC,CA3BIE,CAAgCX,EAAKD,GACrC,MAAMQ,EAAaR,EAAMtQ,OACzB,IAAK,IAAIsE,EAAI,EAAGA,EAAIwM,EAAYxM,IAAK,CACjC,MAAM7E,EAAO6Q,EAAMhM,GACb6M,EAAYC,EAAMb,EAAK9Q,EAAMA,QACjB2C,IAAd+O,GAGJE,EAAgBd,EAAK9Q,EAAM0R,E,CAE/B,OAAOZ,CACX,CAkBA,SAASe,EACLf,EACA9Q,EACA8R,GAEA,OAAIA,aAAsBC,EAAAA,GACfC,EAASlB,EAAK9Q,EAAM8R,EAAWG,aAAcH,GAC7CA,aAAsBI,EAAAA,GAmVrC,SACIpB,EACAqB,EACAC,GAEA,MAAMpS,EAAOoS,EAAYC,eACnB1C,EAAQmB,EAAIG,iBAAiB1H,IAAIvJ,GACjCsS,EAAOhB,EAA+BR,EAAKqB,EAAaC,EAAa,CACvEnC,KA5hBiB,IA8hBfsC,EAAQjB,EAA+BR,EAAKqB,EAAaC,EAAa,CACxEnC,KA/hBiB,IAkiBfvJ,EAAO,IAAI+J,EAAed,EAAO3P,EAAMuS,GAG7C,OAFAC,EAAcF,EAAM5L,GAEb,CACH4L,OACAC,QAER,CAvWeE,CAAQ3B,EAAK9Q,EAAM8R,GACnBA,aAAsBY,EAAAA,GA2FrC,SACI5B,EACA9Q,EACA2S,GAEA,MAAMhD,EAAQ2B,EAA+BR,EAAK9Q,EAAM2S,EAAa,CACjE1C,KApSiB,IAsSrB2C,EAAoB9B,EAAKnB,GACzB,MAAMkD,GAAOC,EAAAA,EAAAA,GAAIH,EAAYI,WAAarN,GAAMmM,EAAKf,EAAK9Q,EAAM0F,IAC1DsN,EAASC,EAASnC,EAAK9Q,EAAM2P,EAAOgD,KAAgBE,GAC1D,OAAOG,CACX,CAtGeL,CAAY7B,EAAK9Q,EAAM8R,GACvBA,aAAsBoB,EAAAA,GAuGrC,SAAgBpC,EAAU9Q,EAAYmT,GAClC,MAAMxD,EAAQ2B,EAA+BR,EAAK9Q,EAAMmT,EAAQ,CAC5DlD,KA9SiB,IAgTrB2C,EAAoB9B,EAAKnB,GACzB,MAAMqD,EAASC,EAASnC,EAAK9Q,EAAM2P,EAAOwD,EAAQxB,EAAMb,EAAK9Q,EAAMmT,IACnE,OAwGJ,SAAkBrC,EAAU9Q,EAAYoT,EAAkBJ,GACtD,MAAMrD,EAAQqD,EAAOV,KACfe,EAAML,EAAOT,MAKnB,OAHAe,EAAQ3D,EAAO0D,GAEfvC,EAAIC,YAAYf,EAAYhQ,EAAM,SAAUoT,EAASG,MAAQ5D,EACtDqD,CACX,CAhHWI,CAAStC,EAAK9Q,EAAMmT,EAAQH,EACvC,CA7GeG,CAAOrC,EAAK9Q,EAAM8R,GAClBA,aAAsB0B,EAAAA,GAarC,SAAoB1C,EAAU9Q,EAAYyT,GACtC,MAAMC,EAAYpC,EAA8BR,EAAK9Q,EAAMyT,EAAY,CACnExD,KAnN4B,IAqNhC2C,EAAoB9B,EAAK4C,GACzB,MAAMV,EAASC,EACXnC,EACA9Q,EACA0T,EACAD,EACA9B,EAAMb,EAAK9Q,EAAMyT,IAErB,OAAOE,EAAK7C,EAAK9Q,EAAMyT,EAAYT,EACvC,CAzBeS,CAAW3C,EAAK9Q,EAAM8R,GACtBA,aAAsB8B,EAAAA,GA0BrC,SACI9C,EACA9Q,EACAyT,GAEA,MAAMC,EAAYpC,EAA8BR,EAAK9Q,EAAMyT,EAAY,CACnExD,KAtO4B,IAwOhC2C,EAAoB9B,EAAK4C,GACzB,MAAMV,EAASC,EACXnC,EACA9Q,EACA0T,EACAD,EACA9B,EAAMb,EAAK9Q,EAAMyT,IAEfxK,EAAM+I,EAASlB,EAAK9Q,EAAMyT,EAAWI,UAAWJ,GACtD,OAAOE,EAAK7C,EAAK9Q,EAAMyT,EAAYT,EAAQ/J,EAC/C,CA3Ce6K,CAAchD,EAAK9Q,EAAM8R,GACzBA,aAAsBiC,EAAAA,GA4CrC,SACIjD,EACA9Q,EACAyT,GAEA,MAAMO,EAAY1C,EAA8BR,EAAK9Q,EAAMyT,EAAY,CACnExD,KA3P4B,IA6PhC2C,EAAoB9B,EAAKkD,GACzB,MAAMhB,EAASC,EACXnC,EACA9Q,EACAgU,EACAP,EACA9B,EAAMb,EAAK9Q,EAAMyT,IAErB,OAAOQ,EAAKnD,EAAK9Q,EAAMyT,EAAYT,EACvC,CA5DekB,CAAoBpD,EAAK9Q,EAAM8R,GAC/BA,aAAsBqC,EAAAA,GA6DrC,SACIrD,EACA9Q,EACAyT,GAEA,MAAMO,EAAY1C,EAA8BR,EAAK9Q,EAAMyT,EAAY,CACnExD,KA9Q4B,IAgRhC2C,EAAoB9B,EAAKkD,GACzB,MAAMhB,EAASC,EACXnC,EACA9Q,EACAgU,EACAP,EACA9B,EAAMb,EAAK9Q,EAAMyT,IAEfxK,EAAM+I,EAASlB,EAAK9Q,EAAMyT,EAAWI,UAAWJ,GACtD,OAAOQ,EAAKnD,EAAK9Q,EAAMyT,EAAYT,EAAQ/J,EAC/C,CA9EemL,CAAuBtD,EAAK9Q,EAAM8R,GAElCH,EAAMb,EAAK9Q,EAAM8R,EAEhC,CAmGA,SAASH,EACLb,EACA9Q,EACA2R,GAEA,MAAM0C,GAAUC,EAAAA,EAAAA,IACZxB,EAAAA,EAAAA,GAAInB,EAAMoB,WAAarN,GAAMmM,EAAKf,EAAK9Q,EAAM0F,IAC5CA,QAAY/C,IAAN+C,GAEX,OAAuB,IAAnB2O,EAAQ9T,OACD8T,EAAQ,GACW,IAAnBA,EAAQ9T,YACf,EAyJR,SAAmBuQ,EAAU+B,GACzB,MAAM0B,EAAa1B,EAAKtS,OACxB,IAAK,IAAIsE,EAAI,EAAGA,EAAI0P,EAAa,EAAG1P,IAAK,CACrC,MAAMmO,EAASH,EAAKhO,GACpB,IAAI2P,EACmC,IAAnCxB,EAAOV,KAAKmC,YAAYlU,SACxBiU,EAAaxB,EAAOV,KAAKmC,YAAY,IAEzC,MAAMC,EAAmBF,aAAsB/D,EACzCkE,EAAiBH,EACjBI,EAAO/B,EAAKhO,EAAI,GAAGyN,KApeR,IAsebU,EAAOV,KAAKrC,MAteC,IAueb+C,EAAOT,MAAMtC,WACEtN,IAAf6R,IACEE,GAAoBC,EAAehE,cAAgBqC,EAAOT,OACxDiC,EAAWpE,SAAW4C,EAAOT,QAG7BmC,EACAC,EAAehE,YAAciE,EAE7BJ,EAAWpE,OAASwE,EAExBC,EAAY/D,EAAKkC,EAAOT,QAGxBe,EAAQN,EAAOT,MAAOqC,E,CAI9B,MAAME,EAAQjC,EAAK,GACbkC,EAAOlC,EAAK0B,EAAa,GAC/B,MAAO,CACHjC,KAAMwC,EAAMxC,KACZC,MAAOwC,EAAKxC,MAEpB,CA5LeyC,CAAUlE,EAAKuD,EAE9B,CAEA,SAASJ,EACLnD,EACA9Q,EACAiU,EACAjB,EACA/J,GAEA,MAAMgM,EAAWjC,EAAOV,KAClB4C,EAASlC,EAAOT,MAEhB4C,EAAO7D,EAA4BR,EAAK9Q,EAAMiU,EAAM,CACtDhE,KAxU0B,KA0U9B2C,EAAoB9B,EAAKqE,GACzB,MAAM9B,EAAM/B,EAAuBR,EAAK9Q,EAAMiU,EAAM,CAChDhE,KA3UoB,KA8VxB,OAjBAgF,EAASG,SAAWD,EACpB9B,EAAI+B,SAAWD,EACfrE,EAAIC,YAAYf,EAAYhQ,EAAMiJ,EAAM,mCAAqC,sBAAuBgL,EAAKV,MAAQ4B,EACjH7B,EAAQ4B,EAAQC,QAIJxS,IAARsG,GACAqK,EAAQ6B,EAAMF,GACd3B,EAAQ6B,EAAM9B,KAEdC,EAAQ6B,EAAM9B,GAEdC,EAAQ6B,EAAMlM,EAAIqJ,MAClBgB,EAAQrK,EAAIsJ,MAAO0C,IAGhB,CACH3C,KAAM2C,EACN1C,MAAOc,EAEf,CAEA,SAASM,EACL7C,EACA9Q,EACA2T,EACAX,EACA/J,GAEA,MAAM0G,EAAQqD,EAAOV,KACfe,EAAML,EAAOT,MAEb8C,EAAQ/D,EAA6BR,EAAK9Q,EAAM2T,EAAM,CACxD1D,KAjX2B,KAmX/B2C,EAAoB9B,EAAKuE,GACzB,MAAMC,EAAUhE,EAAuBR,EAAK9Q,EAAM2T,EAAM,CACpD1D,KAnXoB,KAqXlBkF,EAAO7D,EAA4BR,EAAK9Q,EAAM2T,EAAM,CACtD1D,KAzX0B,IA4Y9B,OAjBAoF,EAAMD,SAAWD,EACjBG,EAAQF,SAAWD,EAEnB7B,EAAQ+B,EAAO1F,GACf2D,EAAQ+B,EAAOC,GACfhC,EAAQD,EAAK8B,QAEDxS,IAARsG,GACAqK,EAAQ6B,EAAMG,GAEdhC,EAAQ6B,EAAMlM,EAAIqJ,MAClBgB,EAAQrK,EAAIsJ,MAAO5C,IAEnB2D,EAAQ6B,EAAME,GAGlBvE,EAAIC,YAAYf,EAAYhQ,EAAMiJ,EAAM,0BAA4B,aAAc0K,EAAKJ,MAAQ8B,EACxF,CACH/C,KAAM+C,EACN9C,MAAO+C,EAEf,CAYA,SAAS1C,EAAoB9B,EAAUyE,GAGnC,OAFAzE,EAAIE,eAAevM,KAAK8Q,GACxBA,EAAMC,SAAW1E,EAAIE,eAAezQ,OAAS,EACtCgV,EAAMC,QACjB,CAEA,SAASvC,EACLnC,EACA9Q,EACA2P,EACAmC,GAGA,MAAMuB,EAAM/B,EAAwBR,EAAK9Q,EAAM8R,EAAY,CACvD7B,KA3aqB,EA4arBN,UAEJA,EAAM0D,IAAMA,EAAG,QAAA/N,EAAA5C,UAAAnC,OANZsS,EAA+B,IAAAnO,MAAAY,EAAA,EAAAA,EAAA,KAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAA/BqN,EAA+BrN,EAAA,GAAA9C,UAAA8C,GAOlC,IAAK,MAAMiQ,KAAO5C,OACFlQ,IAAR8S,GAEAnC,EAAQ3D,EAAO8F,EAAInD,MACnBgB,EAAQmC,EAAIlD,MAAOc,IAEnBC,EAAQ3D,EAAO0D,GAIvB,MAAML,EAAoB,CACtBV,KAAM3C,EACN4C,MAAOc,GAGX,OADAvC,EAAIC,YAAYf,EAAYhQ,EAIhC,SAAqB8R,GACjB,GAAIA,aAAsBY,EAAAA,GACtB,MAAO,cACJ,GAAIZ,aAAsBoB,EAAAA,GAC7B,MAAO,SACJ,GAAIpB,aAAsB0B,EAAAA,GAC7B,MAAO,aACJ,GAAI1B,aAAsB8B,EAAAA,GAC7B,MAAO,0BACJ,GAAI9B,aAAsBiC,EAAAA,GAC7B,MAAO,sBACJ,GAAIjC,aAAsBqC,EAAAA,GAC7B,MAAO,mCAEP,MAAM,IAAInP,MAAM,sCAExB,CApBsC0Q,CAAY5D,GAAaA,EAAWyB,MAAQ5D,EACvEqD,CACX,CA2DA,SAAShB,EACLlB,EACA9Q,EACAuQ,EACAuB,GAEA,MAAMQ,EAAOhB,EAAqBR,EAAK9Q,EAAM8R,EAAY,CACrD7B,KAxgBiB,IA0gBfsC,EAAQjB,EAAqBR,EAAK9Q,EAAM8R,EAAY,CACtD7B,KA3gBiB,IA8gBrB,OADAuC,EAAcF,EAAM,IAAIhC,EAAeiC,EAAOhC,IACvC,CACH+B,OACAC,QAER,CAyBA,SAASX,EAAgBd,EAAU9Q,EAAY2R,GAC3C,MAAMhC,EAAQmB,EAAIG,iBAAiB1H,IAAIvJ,GACvCsT,EAAQ3D,EAAOgC,EAAMW,MACrB,MAAMf,EAAOT,EAAIK,gBAAgB5H,IAAIvJ,GACrCsT,EAAQ3B,EAAMY,MAAOhB,GAKrB,MAJ0B,CACtBe,KAAM3C,EACN4C,MAAOhB,EAGf,CAEA,SAAS+B,EAAQ7L,EAAiByE,GAE9BsG,EAAc/K,EADK,IAAI+I,EAAkBtE,GAE7C,CAEA,SAASoF,EACLR,EACA9Q,EACA8R,EACA6D,GAEA,MAAM5O,EAAOvD,OAAAoS,OAAA,CACT9E,MACAgB,aACA+D,wBAAwB,EACxB7V,OACAyU,YAAa,GACbqB,oBAAqB,GACrBC,YAAajF,EAAIM,OAAO7Q,QACrBoV,GAGP,OADA7E,EAAIM,OAAO3M,KAAKsC,GACTA,CACX,CAEA,SAASyL,EAAc+C,EAAqBf,GAGP,IAA7Be,EAAMd,YAAYlU,SAClBgV,EAAMM,uBAAyBrB,EAAWnE,aAE9CkF,EAAMd,YAAYhQ,KAAK+P,EAC3B,CAEA,SAASK,EAAY/D,EAAUyE,GAC3BzE,EAAIM,OAAOrM,OAAO+L,EAAIM,OAAOrH,QAAQwL,GAAQ,EACjD,CC1mBO,MAAMS,EAAY,CAAC,EAQpB,MAAOC,EAAbzW,WAAAA,GACU,KAAAsT,IAA8B,CAAC,EAC/B,KAAAoD,QAAuB,EAsCjC,CAlCE,QAAIC,GACF,OAAO7R,KAAK4R,QAAQ3V,MACtB,CAEA6V,QAAAA,GAEE9R,KAAKwO,IAAM,CAAC,CACd,CAEA3O,GAAAA,CAAIkS,GACF,MAAMrJ,EAAMsJ,EAAgBD,GAGtBrJ,KAAO1I,KAAKwO,MAChBxO,KAAKwO,IAAI9F,GAAO1I,KAAK4R,QAAQ3V,OAC7B+D,KAAK4R,QAAQzR,KAAK4R,GAEtB,CAEA,YAAIE,GACF,OAAOjS,KAAK4R,OACd,CAEA,QAAIrD,GACF,OAAOC,EAAAA,EAAAA,GAAIxO,KAAK4R,QAAUxQ,GAAMA,EAAE+P,IACpC,CAEA,OAAIzI,GACF,IAAI5J,EAAQ,GACZ,IAAK,MAAMoT,KAAKlS,KAAKwO,IACnB1P,GAASoT,EAAI,IAEf,OAAOpT,CACT,EAGI,SAAUkT,EAAgBD,GAC9B,MAAO,GAAPpM,SADoDvH,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,KAAAA,UAAA,GACpC,IAAHuH,OAAOoM,EAAOZ,KAAQ,GAAE,KAAAxL,OACnCoM,EAAOd,MAAMQ,YACf,KAAA9L,OAAIoM,EAAOI,MAAM3D,IAAKpN,GAAMA,EAAEqQ,YAAYrL,YAAY1C,KAAK,KAC7D,C,gDC/CA,QAJA,SAAgBrB,EAAOiG,GACrB,OAAQjG,GAASA,EAAMpG,QAAUmW,EAAAA,EAAAA,GAAS/P,GAAOgQ,EAAAA,EAAAA,GAAa/J,EAAU,IAAM,EAChF,E,gDCiCA,SAASgK,EAAeC,EAA2BrB,GAC/C,MAAM1C,EAAuC,CAAC,EAC9C,OAAQgE,IACJ,MAAM9J,EAAM8J,EAAapM,WACzB,IAAIqM,EAAWjE,EAAI9F,GACnB,YAAiBrK,IAAboU,IAGAA,EAAW,CACPC,cAAeH,EACfrB,WACApE,OAAQ,CAAC,GAEb0B,EAAI9F,GAAO+J,GAPJA,EAWnB,CAEA,MAAME,EAANzX,WAAAA,GACY,KAAA0X,WAAwB,EAkBpC,CAhBIC,EAAAA,CAAGtK,GACC,OAAOA,GAASvI,KAAK4S,WAAW3W,QAAU+D,KAAK4S,WAAWrK,EAC9D,CAEA2E,GAAAA,CAAI3E,EAAezJ,GACfkB,KAAK4S,WAAWrK,GAASzJ,CAC7B,CAEAsH,QAAAA,GACI,IAAItH,EAAQ,GACZ,MAAM+S,EAAO7R,KAAK4S,WAAW3W,OAC7B,IAAK,IAAIsE,EAAI,EAAGA,EAAIsR,EAAMtR,IACtBzB,IAAgC,IAAvBkB,KAAK4S,WAAWrS,GAAc,IAAM,IAEjD,OAAOzB,CACX,EASJ,MAAMgU,EAAmB,IAAIH,EAMvB,MAAOI,UAAgCC,EAAAA,GAMzC9X,WAAAA,CAAY+X,G,MACR9X,QACA6E,KAAKkT,QAA0B,QAAhBC,EAAO,OAAPF,QAAO,IAAPA,OAAO,EAAPA,EAASC,eAAO,IAAAC,EAAAA,EAAMhI,GAAY7J,QAAQ8R,IAAIjI,EACjE,CAESkI,UAAAA,CAAWJ,GAChBjT,KAAKwM,IAAMF,EAAU2G,EAAQ1G,OAC7BvM,KAAKsT,KA0Lb,SAA0B9G,GACtB,MAAM+G,EAAiB/G,EAAIE,eAAezQ,OACpCuX,EAA4BpT,MAAMmT,GACxC,IAAK,IAAIhT,EAAI,EAAGA,EAAIgT,EAAgBhT,IAChCiT,EAAcjT,GAAK+R,EAAe9F,EAAIE,eAAenM,GAAIA,GAE7D,OAAOiT,CACX,CAjMoBC,CAAiBzT,KAAKwM,IACtC,CAESkH,wCAAAA,GACL,MAAO,EACX,CAESC,2BAAAA,GACL,MAAO,EACX,CAESC,4BAAAA,CAA6BX,GAOlC,MAAM,eAAEY,EAAc,KAAEnY,EAAI,cAAEoY,EAAa,qBAAEC,GAAyBd,EAChEK,EAAOtT,KAAKsT,KACZJ,EAAUlT,KAAKkT,QACfxK,EAAMgD,EAAYhQ,EAAM,cAAemY,GAEvCG,EADgBhU,KAAKwM,IAAIC,YAAY/D,GACPwI,SAC9B+C,GAA2CzF,EAAAA,EAAAA,IAC7C0F,EAAAA,EAAAA,IAAkB,CACdC,aAAc,EACdvI,WAAYiI,EACZO,SAAU,cACV1Y,KAAMA,IAET2Y,IAAY7F,EAAAA,EAAAA,GAAI6F,EAAUxO,GAASA,EAAK,KAG7C,GAAIyO,EAAcL,GAAa,KAAWF,EAAsB,CAC5D,MAAMQ,GAAcC,EAAAA,EAAAA,GAChBP,EACA,CAACjS,EAAQqS,EAASpF,MACdwF,EAAAA,EAAAA,GAAQJ,EAAUK,IACVA,IACA1S,EAAO0S,EAAYC,cAAiB1F,GACpCwF,EAAAA,EAAAA,GAAQC,EAAYE,gBAAmBC,IACnC7S,EAAO6S,GAAqB5F,OAIjCjN,GAEX,CAAC,GAGL,OAAI8R,EACO,SAA4BgB,G,MAC/B,MAAMC,EAAY/U,KAAKgV,GAAG,GACpBC,EAAiCV,EAAYQ,EAAUJ,cAC7D,QAAetW,IAAXyW,QAAuCzW,IAAf4W,EAA0B,CAClD,MAAMC,EAAyB,QAAlB/B,EAAA2B,EAAOG,UAAW,IAAA9B,OAAA,EAAAA,EAAEgC,KACjC,QAAa9W,IAAT6W,IAA0C,IAApBA,EAAK9S,KAAKpC,MAChC,M,CAGR,OAAOiV,CACX,EAEO,WACH,MAAMF,EAAY/U,KAAKgV,GAAG,GAC1B,OAAOT,EAAYQ,EAAUJ,aACjC,C,CAED,OAAIb,EACA,SAA4BgB,GAC/B,MAAMlC,EAAa,IAAID,EACjB1W,OAAoBoC,IAAXyW,EAAuB,EAAIA,EAAO7Y,OACjD,IAAK,IAAIsE,EAAI,EAAGA,EAAItE,EAAQsE,IAAK,CAC7B,MAAM2U,EAAa,OAANJ,QAAM,IAANA,OAAM,EAANA,EAASvU,GAAG4U,KACzBvC,EAAW1F,IAAI3M,OAAYlC,IAAT6W,GAAsBA,EAAK9S,KAAKpC,M,CAEtD,MAAMgC,EAASoT,EAAgBhT,KAAKpC,KAAMsT,EAAMU,EAAepB,EAAYM,GAC3E,MAAyB,kBAAXlR,EAAsBA,OAAS3D,CACjD,EAEO,WACH,MAAM2D,EAASoT,EAAgBhT,KAAKpC,KAAMsT,EAAMU,EAAelB,EAAkBI,GACjF,MAAyB,kBAAXlR,EAAsBA,OAAS3D,CACjD,CAER,CAESgX,yBAAAA,CAA0BpC,GAO/B,MAAM,eAAEY,EAAc,KAAEnY,EAAI,SAAE0Y,EAAQ,qBAAEL,GAAyBd,EAC3DK,EAAOtT,KAAKsT,KACZJ,EAAUlT,KAAKkT,QACfxK,EAAMgD,EAAYhQ,EAAM0Y,EAAUP,GAElCG,EADgBhU,KAAKwM,IAAIC,YAAY/D,GACPwI,SAC9B3C,GAAOC,EAAAA,EAAAA,IACT0F,EAAAA,EAAAA,IAAkB,CACdC,aAAc,EACdvI,WAAYiI,EACZO,WACA1Y,SAEH0F,IACQoN,EAAAA,EAAAA,GAAIpN,EAAI4C,GAAMA,EAAE,KAI3B,GAAIsQ,EAAc/F,IAASA,EAAK,GAAG,KAAOwF,EAAsB,CAC9D,MAAM5C,EAAM5C,EAAK,GACX+G,GAAoBC,EAAAA,EAAAA,GAAQpE,GAElC,GAC+B,IAA7BmE,EAAkBrZ,SAClBuF,EAAAA,EAAAA,GAAQ8T,EAAkB,GAAGV,iBAC7B,CACA,MACMY,EADoBF,EAAkB,GACKX,aAEjD,OAAO,WACL,OAAO3U,KAAKgV,GAAG,GAAGL,eAAiBa,CACrC,C,CACK,CACL,MAAMjB,GAAcC,EAAAA,EAAAA,GAClBc,EACA,CAACtT,EAAQ0S,UACarW,IAAhBqW,IACF1S,EAAO0S,EAAYC,eAAiB,GACpCF,EAAAA,EAAAA,GAAQC,EAAYE,gBAAkBC,IACpC7S,EAAO6S,IAAqB,KAGzB7S,GAET,CAAC,GAGH,OAAO,WACL,MAAM+S,EAAY/U,KAAKgV,GAAG,GAC1B,OAA+C,IAAxCT,EAAYQ,EAAUJ,aAC/B,C,EAGJ,OAAO,WACL,MAAM3S,EAASoT,EAAgBhT,KAAKpC,KAAMsT,EAAMU,EAAelB,EAAkBI,GAC/E,MAAyB,kBAAXlR,GAAyC,IAAXA,CAChD,CACN,EAIJ,SAASsS,EAAcmB,GAAyD,IAAjBC,IAAUtX,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,KAAAA,UAAA,GACrE,MAAMuX,EAAU,IAAIC,IAEpB,IAAK,MAAMzE,KAAOsE,EAAW,CACzB,MAAMI,EAAS,IAAID,IACnB,IAAK,MAAME,KAAW3E,EAAK,CACvB,QAAgB9S,IAAZyX,EAAuB,CACvB,GAAIJ,EAEA,MAEA,OAAO,C,CAGf,MAAMK,EAAU,CAACD,EAAQnB,cAAehP,OAAOmQ,EAAQlB,iBACvD,IAAK,MAAMrM,KAASwN,EAChB,GAAIJ,EAAQK,IAAIzN,IACZ,IAAKsN,EAAOG,IAAIzN,GACZ,OAAO,OAGXoN,EAAQ9V,IAAI0I,GACZsN,EAAOhW,IAAI0I,E,EAK3B,OAAO,CACX,CAWA,SAAS6M,EAELa,EACA/E,EACAsB,EACAU,GAEA,MAAMgD,EAAMD,EAAU/E,GAAUsB,GAChC,IAAInH,EAAQ6K,EAAI7K,MAChB,QAAchN,IAAVgN,EAAqB,CAErBA,EAAQ8K,GAAYD,EAAKE,EADTC,GAAkBH,EAAIxD,iBAEtCwD,EAAI7K,MAAQA,C,CAIhB,OADYiL,EAAiBnV,MAAMnB,KAAM,CAACkW,EAAK7K,EAAOmH,EAAcU,GAExE,CAEA,SAASoD,EAELJ,EACAK,EACA/D,EACAU,GAEA,IAAIsD,EAAYD,EAEZhW,EAAI,EACR,MAAMsF,EAAiB,GACvB,IAAIpD,EAAIzC,KAAKgV,GAAGzU,KAEhB,OAAa,CACT,IAAIwE,EAAI0R,EAAuBD,EAAW/T,GAK1C,QAJUpE,IAAN0G,IACAA,EAAI2R,EAAuBvV,MAAMnB,KAAM,CAACkW,EAAKM,EAAW/T,EAAGlC,EAAGiS,EAAcU,KAG5EnO,IAAM2M,EACN,OAAOiF,EAA0B9Q,EAAM2Q,EAAW/T,GAGtD,IAAwB,IAApBsC,EAAE6R,cACF,OAAO7R,EAAEkQ,WAGbuB,EAAYzR,EACZc,EAAK1F,KAAKsC,GACVA,EAAIzC,KAAKgV,GAAGzU,I,CAEpB,CAEA,SAASmW,EAELR,EACAM,EACAK,EACAC,EACAtE,EACAU,GAEA,MAAM6D,EA4HV,SACInF,EACAiF,EACArE,GAEA,MAAMwE,EAAe,IAAIrF,EACnBsF,EAAiC,GAEvC,IAAK,MAAMrT,KAAKgO,EAAQK,SAAU,CAC9B,IAA+B,IAA3BO,EAAaK,GAAGjP,EAAEuN,KAClB,SAEJ,GH1dqB,IG0djBvN,EAAEqN,MAAMtF,KAAwB,CAChCsL,EAAkB9W,KAAKyD,GACvB,Q,CAEJ,MAAMsT,EAAmBtT,EAAEqN,MAAMd,YAAYlU,OAC7C,IAAK,IAAIsE,EAAI,EAAGA,EAAI2W,EAAkB3W,IAAK,CACvC,MACMuL,EAASqL,EADIvT,EAAEqN,MAAMd,YAAY5P,GACOsW,QAC/BxY,IAAXyN,GACAkL,EAAanX,IAAI,CACboR,MAAOnF,EACPqF,IAAKvN,EAAEuN,IACPgB,MAAOvO,EAAEuO,O,EAMzB,IAAI4E,EAE6B,IAA7BE,EAAkBhb,QAAsC,IAAtB+a,EAAanF,OAC/CkF,EAAQC,GAGZ,QAAc3Y,IAAV0Y,EAAqB,CACrBA,EAAQ,IAAIpF,EACZ,IAAK,MAAM/N,KAAKoT,EAAa/E,SACzBmF,GAAQxT,EAAGmT,E,CAInB,GAAIE,EAAkBhb,OAAS,IAqJnC,SAAkC2V,GAC9B,IAAK,MAAMhO,KAAKgO,EAAQK,SACpB,GHhpBqB,IGgpBjBrO,EAAEqN,MAAMtF,KACR,OAAO,EAGf,OAAO,CACX,CA5JyC0L,CAAyBN,GAC1D,IAAK,MAAMnT,KAAKqT,EACZF,EAAMlX,IAAI+D,GAIlB,OAAOmT,CACX,CA9KkBO,CAAgBd,EAAU5E,QAASiF,EAAOrE,GACxD,GAAmB,IAAfuE,EAAMlF,KAEN,OADA0F,EAAWrB,EAAKM,EAAWK,EAAOnF,GAC3BA,EAGX,IAAI1E,EAAWoJ,EAAYW,GAC3B,MAAMS,EAsLV,SACI5F,EACAY,GAEA,IAAIrB,EACJ,IAAK,MAAMvN,KAAKgO,EAAQK,SACpB,IAA+B,IAA3BO,EAAaK,GAAGjP,EAAEuN,KAClB,QAAY9S,IAAR8S,EACAA,EAAMvN,EAAEuN,SACL,GAAIA,IAAQvN,EAAEuN,IACjB,OAIZ,OAAOA,CACX,CArMyBsG,CAAaV,EAAOvE,GAEzC,QAAqBnU,IAAjBmZ,EACAxK,EAAS4J,eAAgB,EACzB5J,EAASiI,WAAauC,EACtBxK,EAAS4E,QAAQ8F,UAAYF,OAC1B,GAiUX,SAA0C5F,GACtC,GAVJ,SAAoCA,GAChC,IAAK,MAAMhO,KAAKgO,EAAQK,SACpB,GHzpBqB,IGypBjBrO,EAAEqN,MAAMtF,KACR,OAAO,EAGf,OAAO,CACX,CAGQgM,CAA2B/F,GAC3B,OAAO,EAEX,MAAMgG,EAMV,SACIhG,GAEA,MAAMiG,EAAe,IAAIjL,IACzB,IAAK,MAAMhJ,KAAKgO,EAAS,CACrB,MAAMlJ,EAAMsJ,EAAgBpO,GAAG,GAC/B,IAAI2K,EAAOsJ,EAAa5S,IAAIyD,QACfrK,IAATkQ,IACAA,EAAO,CAAC,EACRsJ,EAAa3K,IAAIxE,EAAK6F,IAE1BA,EAAK3K,EAAEuN,MAAO,C,CAElB,OAAO0G,CACX,CApBoBC,CAAsBlG,EAAQK,UAG9C,OAmBJ,SACI2F,GAEA,IAAK,MAAM9Y,KAASsB,MAAMqG,KAAKmR,EAAQG,UACnC,GAAI7Y,OAAO8Y,KAAKlZ,GAAO7C,OAAS,EAC5B,OAAO,EAGf,OAAO,CACX,CA7BQgc,CAAqBL,KA+B7B,SACIA,GAEA,IAAK,MAAM9Y,KAASsB,MAAMqG,KAAKmR,EAAQG,UACnC,GAAkC,IAA9B7Y,OAAO8Y,KAAKlZ,GAAO7C,OACnB,OAAO,EAGf,OAAO,CACX,CAxC0Cic,CAA6BN,EAEvE,CAzUeO,CAAiCpB,GAAQ,CAChD,MAAM9B,GAAamD,EAAAA,EAAAA,GAAIrB,EAAMxI,MAC7BvB,EAAS4J,eAAgB,EACzB5J,EAASiI,WAAaA,EACtBjI,EAAS4E,QAAQ8F,UAAYzC,EAC7BoD,EAAyBlX,MAAMnB,KAAM,CAACkW,EAAKY,EAAWC,EAAMxI,KAAM2E,G,CAItE,OADAlG,EAAWuK,EAAWrB,EAAKM,EAAWK,EAAO7J,GACtCA,CACX,CAEA,SAASqL,EAELnC,EACAY,EACAwB,EACApF,GAEA,MAAMqF,EAA0B,GAChC,IAAK,IAAIhY,EAAI,EAAGA,GAAKuW,EAAWvW,IAC5BgY,EAAWpY,KAAKH,KAAKgV,GAAGzU,GAAG0L,WAE/B,MAAMuM,EAAWtC,EAAIxD,cASrBQ,EAGJ,SAA6BD,GAMzB,MAAMwF,GAAUjK,EAAAA,EAAAA,GAAIyE,EAAQsF,WAAaG,IACrCC,EAAAA,EAAAA,IAAWD,IACbhV,KAAK,MACDkI,EACyB,IAA3BqH,EAAQzF,WAAWyB,IAAY,GAAKgE,EAAQzF,WAAWyB,IAC3D,IAAI2J,EACA,qCAAAjT,OAAqCsN,EAAQqF,iBAAiB5U,KAC1D,MACH,UAAAiC,OAWT,SAA8BkT,GAC1B,GAAIA,aAAgBjL,EAAAA,GAChB,MAAO,UACJ,GAAIiL,aAAgBjK,EAAAA,GACvB,MAAO,SACJ,GAAIiK,aAAgBzK,EAAAA,GACvB,MAAO,KACJ,GAAIyK,aAAgBpJ,EAAAA,GACvB,MAAO,eACJ,GAAIoJ,aAAgBhJ,EAAAA,GACvB,MAAO,mBACJ,GAAIgJ,aAAgBvJ,EAAAA,GACvB,MAAO,WACJ,GAAIuJ,aAAgB3J,EAAAA,GACvB,MAAO,OACJ,GAAI2J,aAAgBpL,EAAAA,GACvB,MAAO,UAEP,MAAM/M,MAAM,uBAEpB,CA/BkBoY,CAAqB7F,EAAQzF,aAAW7H,OAAGiG,EAAU,iBAAAjG,OACnDsN,EAAQ8F,aAAald,KAAI,aAAW,IAAA8J,OAC5C8S,EAAO,+DAMf,OAJAG,GACIA,mHAGGA,CACX,CAhCoBI,CAAoB,CAChCD,aAHiBP,EAAS9c,KAI1B4c,mBACA9K,WAJegL,EAAShL,WAKxB+K,eAGR,CAiDA,SAAS5B,EACL9Q,EACAoT,EACAC,GAEA,MAAMC,GAAkBC,EAAAA,EAAAA,GACpBH,EAASrH,QAAQK,SAChB7Q,GAAMA,EAAE6P,MAAMd,aAQnB,MAAO,CACHkJ,YAAaH,EACbI,mBARmBC,EACnBJ,EACKnJ,OAAQ5O,GAA2BA,aAAa4K,GAChDwC,IAAKpN,GAAMA,EAAE6K,WACjB7K,GAAMA,EAAEuT,cAKT6E,UAAW3T,EAEnB,CAEA,SAAS4Q,EACLxF,EACA4F,GAEA,OAAO5F,EAAMwI,MAAM5C,EAAMlC,aAC7B,CAsDA,SAASwC,EACLjH,EACA2G,GAEA,GACI3G,aAAsBlE,IACtB0N,EAAAA,EAAAA,GAAa7C,EAAO3G,EAAWjE,WAE/B,OAAOiE,EAAWpE,MAG1B,CAmBA,SAASsK,EAAYgB,GACjB,MAAO,CACHxF,QAASwF,EACTqC,MAAO,CAAC,EACR7C,eAAe,EACf3B,YAAa,EAErB,CAEA,SAASsC,EACLrB,EACAzP,EACAoQ,EACA8C,GAIA,OAFAA,EAAKxD,GAAYD,EAAKyD,GACtBlT,EAAKgT,MAAM5C,EAAMlC,cAAgBgF,EAC1BA,CACX,CAEA,SAASxD,GAAYD,EAAUjF,GAC3B,GAAIA,IAAUS,EACV,OAAOT,EAIX,MAAM2I,EAAS3I,EAAMW,QAAQlJ,IACvB+J,EAAWyD,EAAIpJ,OAAO8M,GAC5B,YAAiBvb,IAAboU,EACOA,GAEXxB,EAAMW,QAAQE,WACdoE,EAAIpJ,OAAO8M,GAAU3I,EACdA,EACX,CAEA,SAASoF,GAAkBmC,GACvB,MAAM5G,EAAU,IAAID,EAEdkI,EAAsBrB,EAASrI,YAAYlU,OACjD,IAAK,IAAIsE,EAAI,EAAGA,EAAIsZ,EAAqBtZ,IAAK,CAO1C6W,GAL0B,CACtBnG,MAFWuH,EAASrI,YAAY5P,GAAGuL,OAGnCqF,IAAK5Q,EACL4R,MAAO,IAEKP,E,CAGpB,OAAOA,CACX,CAEA,SAASwF,GAAQrF,EAAmBH,GAChC,MAAMvK,EAAI0K,EAAOd,MAEjB,GHxlByB,IGwlBrB5J,EAAEsE,KAAwB,CAC1B,GAAIoG,EAAOI,MAAMlW,OAAS,EAAG,CACzB,MAAM6d,EAAW,IAAI/H,EAAOI,OAO5BiF,GALgC,CAC5BnG,MAFgB6I,EAASC,MAGzB5I,IAAKY,EAAOZ,IACZgB,MAAO2H,GAEWlI,E,MAItBA,EAAQ/R,IAAIkS,GAEhB,M,CAGC1K,EAAEkK,wBACHK,EAAQ/R,IAAIkS,GAGhB,MAAMmF,EAAmB7P,EAAE8I,YAAYlU,OACvC,IAAK,IAAIsE,EAAI,EAAGA,EAAI2W,EAAkB3W,IAAK,CACvC,MACMqD,EAAIoW,GAAiBjI,EADR1K,EAAE8I,YAAY5P,SAGvBlC,IAANuF,GACAwT,GAAQxT,EAAGgO,E,CAGvB,CAEA,SAASoI,GACLjI,EACA7B,GAEA,GAAIA,aAAsBhE,EACtB,MAAO,CACH+E,MAAOf,EAAWpE,OAClBqF,IAAKY,EAAOZ,IACZgB,MAAOJ,EAAOI,OAEf,GAAIjC,aAAsB/D,EAAgB,CAC7C,MAAMgG,EAAQ,IAAIJ,EAAOI,MAAOjC,EAAW7D,aAC3C,MAAO,CACH4E,MAAOf,EAAWpE,OAClBqF,IAAKY,EAAOZ,IACZgB,Q,CAIZ,C,ICnrBW8H,GAOAC,GAOAC,GASAC,GAaAC,GA8BAC,GA2BAC,GAwBAC,GA4BAC,GA8BAC,GAyBAC,GA2BAC,GAmBAC,GAyCAC,GAwBAC,GAwBAC,GAqBAC,GAYAC,GA2CAC,GA0BAC,GAoCAC,GAqBAC,GAQAC,GA4CAC,GAiBAC,GAuBAC,GAwBAC,GAuBAC,GAuTAC,GAuBAC,GAwBAC,GAwBAC,GA6BAC,GAmBAC,GAcAC,GAgCAC,GAwBAC,GAYAC,GAwBAC,GAqBAC,GAaAC,GAeAC,GAaAC,GAoBAC,GAiBAC,GAiBAC,GAoBAC,GAmBAC,GAmBAC,GAkCAC,GAOAC,GAwBAC,GAkBAC,GA4CAC,GA2EAC,GAkBAC,GA2BAC,GAqCAC,GA0BAC,GAsBAC,GAsBAC,GAwBAC,GAwCAC,GAgBAC,GAcAC,GAoBAC,GAqBAC,GAsBAC,GAuBAC,GAeAC,GAeAC,GAsBAC,GAOAC,GAOAC,GAaAC,GAWAC,GAOAC,GAOAC,G,aA57DX,SAAW7E,GAIPA,EAAYpH,GAHZ,SAAY/T,GACR,MAAwB,kBAAVA,CAClB,CAEH,CALD,CAKGmb,KAAgBA,GAAc,CAAC,IAElC,SAAWC,GAIPA,EAAIrH,GAHJ,SAAY/T,GACR,MAAwB,kBAAVA,CAClB,CAEH,CALD,CAKGob,KAAQA,GAAM,CAAC,IAElB,SAAWC,GACPA,EAAQ4E,WAAa,WACrB5E,EAAQ6E,UAAY,WAIpB7E,EAAQtH,GAHR,SAAY/T,GACR,MAAwB,kBAAVA,GAAsBqb,EAAQ4E,WAAajgB,GAASA,GAASqb,EAAQ6E,SACvF,CAEH,CAPD,CAOG7E,KAAYA,GAAU,CAAC,IAE1B,SAAWC,GACPA,EAAS2E,UAAY,EACrB3E,EAAS4E,UAAY,WAIrB5E,EAASvH,GAHT,SAAY/T,GACR,MAAwB,kBAAVA,GAAsBsb,EAAS2E,WAAajgB,GAASA,GAASsb,EAAS4E,SACzF,CAEH,CAPD,CAOG5E,KAAaA,GAAW,CAAC,IAM5B,SAAWC,GAePA,EAAS4E,OATT,SAAgB3T,EAAMC,GAOlB,OANID,IAAS4T,OAAOF,YAChB1T,EAAO8O,GAAS4E,WAEhBzT,IAAc2T,OAAOF,YACrBzT,EAAY6O,GAAS4E,WAElB,CAAE1T,OAAMC,YACnB,EASA8O,EAASxH,GAJT,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOsgB,GAAGC,cAAcF,IAAcC,GAAGhF,SAAS+E,EAAU7T,OAAS8T,GAAGhF,SAAS+E,EAAU5T,UAC/F,CAEH,CAxBD,CAwBG8O,KAAaA,GAAW,CAAC,IAM5B,SAAWC,GAYPA,EAAM2E,OAXN,SAAgBK,EAAKC,EAAKC,EAAOC,GAC7B,GAAIL,GAAGhF,SAASkF,IAAQF,GAAGhF,SAASmF,IAAQH,GAAGhF,SAASoF,IAAUJ,GAAGhF,SAASqF,GAC1E,MAAO,CAAEpU,MAAOgP,GAAS4E,OAAOK,EAAKC,GAAMxQ,IAAKsL,GAAS4E,OAAOO,EAAOC,IAEtE,GAAIpF,GAASxH,GAAGyM,IAAQjF,GAASxH,GAAG0M,GACrC,MAAO,CAAElU,MAAOiU,EAAKvQ,IAAKwQ,GAG1B,MAAM,IAAI7e,MAAM,8CAADiF,OAA+C2Z,EAAG,MAAA3Z,OAAK4Z,EAAG,MAAA5Z,OAAK6Z,EAAK,MAAA7Z,OAAK8Z,EAAI,KAEpG,EASAnF,EAAMzH,GAJN,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOsgB,GAAGC,cAAcF,IAAc9E,GAASxH,GAAGsM,EAAU9T,QAAUgP,GAASxH,GAAGsM,EAAUpQ,IAChG,CAEH,CArBD,CAqBGuL,KAAUA,GAAQ,CAAC,IAMtB,SAAWC,GASPA,EAAS0E,OAHT,SAAgBS,EAAKtU,GACjB,MAAO,CAAEsU,MAAKtU,QAClB,EASAmP,EAAS1H,GAJT,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOsgB,GAAGC,cAAcF,IAAc7E,GAAMzH,GAAGsM,EAAU/T,SAAWgU,GAAGO,OAAOR,EAAUO,MAAQN,GAAG/gB,UAAU8gB,EAAUO,KAC3H,CAEH,CAlBD,CAkBGnF,KAAaA,GAAW,CAAC,IAM5B,SAAWC,GAWPA,EAAayE,OAHb,SAAgBW,EAAWC,EAAaC,EAAsBC,GAC1D,MAAO,CAAEH,YAAWC,cAAaC,uBAAsBC,uBAC3D,EAWAvF,EAAa3H,GANb,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOsgB,GAAGC,cAAcF,IAAc7E,GAAMzH,GAAGsM,EAAUU,cAAgBT,GAAGO,OAAOR,EAAUS,YACtFtF,GAAMzH,GAAGsM,EAAUW,wBAClBxF,GAAMzH,GAAGsM,EAAUY,uBAAyBX,GAAG/gB,UAAU8gB,EAAUY,sBAC/E,CAEH,CAtBD,CAsBGvF,KAAiBA,GAAe,CAAC,IAMpC,SAAWC,GAYPA,EAAMwE,OARN,SAAgBe,EAAKC,EAAOC,EAAMC,GAC9B,MAAO,CACHH,MACAC,QACAC,OACAC,QAER,EAYA1F,EAAM5H,GAPN,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOsgB,GAAGC,cAAcF,IAAcC,GAAGgB,YAAYjB,EAAUa,IAAK,EAAG,IAChEZ,GAAGgB,YAAYjB,EAAUc,MAAO,EAAG,IACnCb,GAAGgB,YAAYjB,EAAUe,KAAM,EAAG,IAClCd,GAAGgB,YAAYjB,EAAUgB,MAAO,EAAG,EAC9C,CAEH,CAxBD,CAwBG1F,KAAUA,GAAQ,CAAC,IAMtB,SAAWC,GAUPA,EAAiBuE,OANjB,SAAgB7T,EAAOiV,GACnB,MAAO,CACHjV,QACAiV,QAER,EASA3F,EAAiB7H,GAJjB,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOsgB,GAAGC,cAAcF,IAAc7E,GAAMzH,GAAGsM,EAAU/T,QAAUqP,GAAM5H,GAAGsM,EAAUkB,MAC1F,CAEH,CAnBD,CAmBG3F,KAAqBA,GAAmB,CAAC,IAM5C,SAAWC,GAWPA,EAAkBsE,OAPlB,SAAgBqB,EAAOC,EAAUC,GAC7B,MAAO,CACHF,QACAC,WACAC,sBAER,EAWA7F,EAAkB9H,GANlB,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOsgB,GAAGC,cAAcF,IAAcC,GAAGO,OAAOR,EAAUmB,SAClDlB,GAAG/gB,UAAU8gB,EAAUoB,WAAanF,GAASvI,GAAGsM,MAChDC,GAAG/gB,UAAU8gB,EAAUqB,sBAAwBpB,GAAGqB,WAAWtB,EAAUqB,oBAAqBpF,GAASvI,IACjH,CAEH,CAtBD,CAsBG8H,KAAsBA,GAAoB,CAAC,IAK9C,SAAWC,GAIPA,EAAiB8F,QAAU,UAI3B9F,EAAiB+F,QAAU,UAI3B/F,EAAiBgG,OAAS,QAC7B,CAbD,CAaGhG,KAAqBA,GAAmB,CAAC,IAM5C,SAAWC,GAuBPA,EAAaoE,OAnBb,SAAgB4B,EAAWC,EAASC,EAAgBC,EAAcC,EAAMC,GACpE,MAAMlf,EAAS,CACX6e,YACAC,WAcJ,OAZI1B,GAAG+B,QAAQJ,KACX/e,EAAO+e,eAAiBA,GAExB3B,GAAG+B,QAAQH,KACXhf,EAAOgf,aAAeA,GAEtB5B,GAAG+B,QAAQF,KACXjf,EAAOif,KAAOA,GAEd7B,GAAG+B,QAAQD,KACXlf,EAAOkf,cAAgBA,GAEpBlf,CACX,EAYA6Y,EAAahI,GAPb,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOsgB,GAAGC,cAAcF,IAAcC,GAAGhF,SAAS+E,EAAU0B,YAAczB,GAAGhF,SAAS+E,EAAU0B,aACxFzB,GAAG/gB,UAAU8gB,EAAU4B,iBAAmB3B,GAAGhF,SAAS+E,EAAU4B,mBAChE3B,GAAG/gB,UAAU8gB,EAAU6B,eAAiB5B,GAAGhF,SAAS+E,EAAU6B,iBAC9D5B,GAAG/gB,UAAU8gB,EAAU8B,OAAS7B,GAAGO,OAAOR,EAAU8B,MAChE,CAEH,CAnCD,CAmCGpG,KAAiBA,GAAe,CAAC,IAMpC,SAAWC,GAUPA,EAA6BmE,OAN7B,SAAgBmC,EAAUjW,GACtB,MAAO,CACHiW,WACAjW,UAER,EASA2P,EAA6BjI,GAJ7B,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOsgB,GAAG+B,QAAQhC,IAAc5E,GAAS1H,GAAGsM,EAAUiC,WAAahC,GAAGO,OAAOR,EAAUhU,QAC3F,CAEH,CAnBD,CAmBG2P,KAAiCA,GAA+B,CAAC,IAKpE,SAAWC,GAIPA,EAAmBra,MAAQ,EAI3Bqa,EAAmBsG,QAAU,EAI7BtG,EAAmBuG,YAAc,EAIjCvG,EAAmBwG,KAAO,CAC7B,CAjBD,CAiBGxG,KAAuBA,GAAqB,CAAC,IAOhD,SAAWC,GAOPA,EAAcwG,YAAc,EAM5BxG,EAAcyG,WAAa,CAC9B,CAdD,CAcGzG,KAAkBA,GAAgB,CAAC,IAOtC,SAAWC,GAKPA,EAAgBpI,GAJhB,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOsgB,GAAGC,cAAcF,IAAcC,GAAGO,OAAOR,EAAUuC,KAC9D,CAEH,CAND,CAMGzG,KAAoBA,GAAkB,CAAC,IAM1C,SAAWC,GAoBPA,EAAW+D,OAhBX,SAAgB7T,EAAOD,EAASwW,EAAUC,EAAMrY,EAAQsY,GACpD,IAAI7f,EAAS,CAAEoJ,QAAOD,WAatB,OAZIiU,GAAG+B,QAAQQ,KACX3f,EAAO2f,SAAWA,GAElBvC,GAAG+B,QAAQS,KACX5f,EAAO4f,KAAOA,GAEdxC,GAAG+B,QAAQ5X,KACXvH,EAAOuH,OAASA,GAEhB6V,GAAG+B,QAAQU,KACX7f,EAAO6f,mBAAqBA,GAEzB7f,CACX,EAiBAkZ,EAAWrI,GAZX,SAAY/T,GACR,IAAIqU,EACJ,IAAIgM,EAAYrgB,EAChB,OAAOsgB,GAAG+B,QAAQhC,IACX7E,GAAMzH,GAAGsM,EAAU/T,QACnBgU,GAAGO,OAAOR,EAAUhU,WACnBiU,GAAG0C,OAAO3C,EAAUwC,WAAavC,GAAG/gB,UAAU8gB,EAAUwC,aACxDvC,GAAGjF,QAAQgF,EAAUyC,OAASxC,GAAGO,OAAOR,EAAUyC,OAASxC,GAAG/gB,UAAU8gB,EAAUyC,SAClFxC,GAAG/gB,UAAU8gB,EAAU4C,kBAAqB3C,GAAGO,OAA4C,QAApCxM,EAAKgM,EAAU4C,uBAAoC,IAAP5O,OAAgB,EAASA,EAAGuO,SAC/HtC,GAAGO,OAAOR,EAAU5V,SAAW6V,GAAG/gB,UAAU8gB,EAAU5V,WACtD6V,GAAG/gB,UAAU8gB,EAAU0C,qBAAuBzC,GAAGqB,WAAWtB,EAAU0C,mBAAoB/G,GAA6BjI,IACnI,CAEH,CArCD,CAqCGqI,KAAeA,GAAa,CAAC,IAMhC,SAAWC,GAWPA,EAAQ8D,OAPR,SAAgB+C,EAAOC,GACnB,IAAIjgB,EAAS,CAAEggB,QAAOC,WAAU,QAAAjhB,EAAA5C,UAAAnC,OADDgF,EAAI,IAAAb,MAAAY,EAAA,EAAAA,EAAA,KAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAAJD,EAAIC,EAAA,GAAA9C,UAAA8C,GAKnC,OAHIke,GAAG+B,QAAQlgB,IAASA,EAAKhF,OAAS,IAClC+F,EAAO5D,UAAY6C,GAEhBe,CACX,EASAmZ,EAAQtI,GAJR,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOsgB,GAAG+B,QAAQhC,IAAcC,GAAGO,OAAOR,EAAU6C,QAAU5C,GAAGO,OAAOR,EAAU8C,QACtF,CAEH,CApBD,CAoBG9G,KAAYA,GAAU,CAAC,IAM1B,SAAWC,GASPA,EAASrf,QAHT,SAAiBqP,EAAO8W,GACpB,MAAO,CAAE9W,QAAO8W,UACpB,EAUA9G,EAAS+G,OAHT,SAAgBC,EAAUF,GACtB,MAAO,CAAE9W,MAAO,CAAEC,MAAO+W,EAAUrT,IAAKqT,GAAYF,UACxD,EASA9G,EAASiH,IAHT,SAAajX,GACT,MAAO,CAAEA,QAAO8W,QAAS,GAC7B,EAQA9G,EAASvI,GANT,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOsgB,GAAGC,cAAcF,IACjBC,GAAGO,OAAOR,EAAU+C,UACpB5H,GAAMzH,GAAGsM,EAAU/T,MAC9B,CAEH,CAlCD,CAkCGgQ,KAAaA,GAAW,CAAC,IAE5B,SAAWC,GAWPA,EAAiB4D,OAVjB,SAAgBqB,EAAOgC,EAAmBC,GACtC,MAAMvgB,EAAS,CAAEse,SAOjB,YAN0BjiB,IAAtBikB,IACAtgB,EAAOsgB,kBAAoBA,QAEXjkB,IAAhBkkB,IACAvgB,EAAOugB,YAAcA,GAElBvgB,CACX,EAQAqZ,EAAiBxI,GANjB,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOsgB,GAAGC,cAAcF,IAAcC,GAAGO,OAAOR,EAAUmB,SACrDlB,GAAGoD,QAAQrD,EAAUmD,yBAAsDjkB,IAAhC8gB,EAAUmD,qBACrDlD,GAAGO,OAAOR,EAAUoD,mBAA0ClkB,IAA1B8gB,EAAUoD,YACvD,CAEH,CAnBD,CAmBGlH,KAAqBA,GAAmB,CAAC,IAE5C,SAAWC,GAKPA,EAA2BzI,GAJ3B,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOsgB,GAAGO,OAAOR,EACrB,CAEH,CAND,CAMG7D,KAA+BA,GAA6B,CAAC,IAEhE,SAAWC,GAWPA,EAAkBxf,QAHlB,SAAiBqP,EAAO8W,EAASO,GAC7B,MAAO,CAAErX,QAAO8W,UAASQ,aAAcD,EAC3C,EAYAlH,EAAkB4G,OAHlB,SAAgBC,EAAUF,EAASO,GAC/B,MAAO,CAAErX,MAAO,CAAEC,MAAO+W,EAAUrT,IAAKqT,GAAYF,UAASQ,aAAcD,EAC/E,EAWAlH,EAAkB8G,IAHlB,SAAajX,EAAOqX,GAChB,MAAO,CAAErX,QAAO8W,QAAS,GAAIQ,aAAcD,EAC/C,EAMAlH,EAAkB1I,GAJlB,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOsc,GAASvI,GAAGsM,KAAe9D,GAAiBxI,GAAGsM,EAAUuD,eAAiBpH,GAA2BzI,GAAGsM,EAAUuD,cAC7H,CAEH,CAtCD,CAsCGnH,KAAsBA,GAAoB,CAAC,IAM9C,SAAWC,GAOPA,EAAiByD,OAHjB,SAAgB0D,EAAcC,GAC1B,MAAO,CAAED,eAAcC,QAC3B,EAQApH,EAAiB3I,GANjB,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOsgB,GAAG+B,QAAQhC,IACXpD,GAAwClJ,GAAGsM,EAAUwD,eACrDviB,MAAMrB,QAAQogB,EAAUyD,MACnC,CAEH,CAfD,CAeGpH,KAAqBA,GAAmB,CAAC,IAE5C,SAAWC,GAcPA,EAAWwD,OAbX,SAAgBS,EAAKzM,EAASwP,GAC1B,IAAIzgB,EAAS,CACTif,KAAM,SACNvB,OAQJ,YANgBrhB,IAAZ4U,QAAgD5U,IAAtB4U,EAAQ4P,gBAAsDxkB,IAA3B4U,EAAQ6P,iBACrE9gB,EAAOiR,QAAUA,QAEF5U,IAAfokB,IACAzgB,EAAO0gB,aAAeD,GAEnBzgB,CACX,EAOAyZ,EAAW5I,GALX,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOqgB,GAAgC,WAAnBA,EAAU8B,MAAqB7B,GAAGO,OAAOR,EAAUO,YAA+BrhB,IAAtB8gB,EAAUlM,eACpD5U,IAAhC8gB,EAAUlM,QAAQ4P,WAA2BzD,GAAGoD,QAAQrD,EAAUlM,QAAQ4P,mBAAqDxkB,IAArC8gB,EAAUlM,QAAQ6P,gBAAgC1D,GAAGoD,QAAQrD,EAAUlM,QAAQ6P,yBAAkDzkB,IAA3B8gB,EAAUuD,cAA8BpH,GAA2BzI,GAAGsM,EAAUuD,cAC1R,CAEH,CArBD,CAqBGjH,KAAeA,GAAa,CAAC,IAEhC,SAAWC,GAePA,EAAWuD,OAdX,SAAgB8D,EAAQC,EAAQ/P,EAASwP,GACrC,IAAIzgB,EAAS,CACTif,KAAM,SACN8B,SACAC,UAQJ,YANgB3kB,IAAZ4U,QAAgD5U,IAAtB4U,EAAQ4P,gBAAsDxkB,IAA3B4U,EAAQ6P,iBACrE9gB,EAAOiR,QAAUA,QAEF5U,IAAfokB,IACAzgB,EAAO0gB,aAAeD,GAEnBzgB,CACX,EAOA0Z,EAAW7I,GALX,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOqgB,GAAgC,WAAnBA,EAAU8B,MAAqB7B,GAAGO,OAAOR,EAAU4D,SAAW3D,GAAGO,OAAOR,EAAU6D,eAAkC3kB,IAAtB8gB,EAAUlM,eACtF5U,IAAhC8gB,EAAUlM,QAAQ4P,WAA2BzD,GAAGoD,QAAQrD,EAAUlM,QAAQ4P,mBAAqDxkB,IAArC8gB,EAAUlM,QAAQ6P,gBAAgC1D,GAAGoD,QAAQrD,EAAUlM,QAAQ6P,yBAAkDzkB,IAA3B8gB,EAAUuD,cAA8BpH,GAA2BzI,GAAGsM,EAAUuD,cAC1R,CAEH,CAtBD,CAsBGhH,KAAeA,GAAa,CAAC,IAEhC,SAAWC,GAcPA,EAAWsD,OAbX,SAAgBS,EAAKzM,EAASwP,GAC1B,IAAIzgB,EAAS,CACTif,KAAM,SACNvB,OAQJ,YANgBrhB,IAAZ4U,QAAgD5U,IAAtB4U,EAAQgQ,gBAAyD5kB,IAA9B4U,EAAQiQ,oBACrElhB,EAAOiR,QAAUA,QAEF5U,IAAfokB,IACAzgB,EAAO0gB,aAAeD,GAEnBzgB,CACX,EAOA2Z,EAAW9I,GALX,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOqgB,GAAgC,WAAnBA,EAAU8B,MAAqB7B,GAAGO,OAAOR,EAAUO,YAA+BrhB,IAAtB8gB,EAAUlM,eACpD5U,IAAhC8gB,EAAUlM,QAAQgQ,WAA2B7D,GAAGoD,QAAQrD,EAAUlM,QAAQgQ,mBAAwD5kB,IAAxC8gB,EAAUlM,QAAQiQ,mBAAmC9D,GAAGoD,QAAQrD,EAAUlM,QAAQiQ,4BAAqD7kB,IAA3B8gB,EAAUuD,cAA8BpH,GAA2BzI,GAAGsM,EAAUuD,cAChS,CAEH,CArBD,CAqBG/G,KAAeA,GAAa,CAAC,IAEhC,SAAWC,GAcPA,EAAc/I,GAbd,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOqgB,SACoB9gB,IAAtB8gB,EAAUgE,cAAuD9kB,IAA9B8gB,EAAUiE,wBACf/kB,IAA9B8gB,EAAUiE,iBAAiCjE,EAAUiE,gBAAgBC,MAAOC,GACrElE,GAAGO,OAAO2D,EAAOrC,MACVxF,GAAW5I,GAAGyQ,IAAW5H,GAAW7I,GAAGyQ,IAAW3H,GAAW9I,GAAGyQ,GAGhE9H,GAAiB3I,GAAGyQ,IAG3C,CAEH,CAfD,CAeG1H,KAAkBA,GAAgB,CAAC,KAwStC,SAAWC,GAQPA,EAAuBoD,OAHvB,SAAgBS,GACZ,MAAO,CAAEA,MACb,EASA7D,EAAuBhJ,GAJvB,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOsgB,GAAG+B,QAAQhC,IAAcC,GAAGO,OAAOR,EAAUO,IACxD,CAEH,CAjBD,CAiBG7D,KAA2BA,GAAyB,CAAC,IAMxD,SAAWC,GASPA,EAAgCmD,OAHhC,SAAgBS,EAAK6D,GACjB,MAAO,CAAE7D,MAAK6D,UAClB,EASAzH,EAAgCjJ,GAJhC,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOsgB,GAAG+B,QAAQhC,IAAcC,GAAGO,OAAOR,EAAUO,MAAQN,GAAGjF,QAAQgF,EAAUoE,QACrF,CAEH,CAlBD,CAkBGzH,KAAoCA,GAAkC,CAAC,IAM1E,SAAWC,GASPA,EAAwCkD,OAHxC,SAAgBS,EAAK6D,GACjB,MAAO,CAAE7D,MAAK6D,UAClB,EASAxH,EAAwClJ,GAJxC,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOsgB,GAAG+B,QAAQhC,IAAcC,GAAGO,OAAOR,EAAUO,OAA+B,OAAtBP,EAAUoE,SAAoBnE,GAAGjF,QAAQgF,EAAUoE,SACpH,CAEH,CAlBD,CAkBGxH,KAA4CA,GAA0C,CAAC,IAM1F,SAAWC,GAWPA,EAAiBiD,OAHjB,SAAgBS,EAAK8D,EAAYD,EAASE,GACtC,MAAO,CAAE/D,MAAK8D,aAAYD,UAASE,OACvC,EASAzH,EAAiBnJ,GAJjB,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOsgB,GAAG+B,QAAQhC,IAAcC,GAAGO,OAAOR,EAAUO,MAAQN,GAAGO,OAAOR,EAAUqE,aAAepE,GAAGjF,QAAQgF,EAAUoE,UAAYnE,GAAGO,OAAOR,EAAUsE,KACxJ,CAEH,CApBD,CAoBGzH,KAAqBA,GAAmB,CAAC,IAS5C,SAAWC,GAIPA,EAAWyH,UAAY,YAIvBzH,EAAW0H,SAAW,WAQtB1H,EAAWpJ,GAJX,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOqgB,IAAclD,EAAWyH,WAAavE,IAAclD,EAAW0H,QAC1E,CAEH,CAjBD,CAiBG1H,KAAeA,GAAa,CAAC,IAEhC,SAAWC,GAQPA,EAAcrJ,GAJd,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOsgB,GAAGC,cAAcvgB,IAAUmd,GAAWpJ,GAAGsM,EAAU8B,OAAS7B,GAAGO,OAAOR,EAAUrgB,MAC3F,CAEH,CATD,CASGod,KAAkBA,GAAgB,CAAC,IAKtC,SAAWC,GACPA,EAAmByH,KAAO,EAC1BzH,EAAmB0H,OAAS,EAC5B1H,EAAmB2H,SAAW,EAC9B3H,EAAmB4H,YAAc,EACjC5H,EAAmB6H,MAAQ,EAC3B7H,EAAmB8H,SAAW,EAC9B9H,EAAmB+H,MAAQ,EAC3B/H,EAAmBgI,UAAY,EAC/BhI,EAAmBiI,OAAS,EAC5BjI,EAAmBkI,SAAW,GAC9BlI,EAAmBmI,KAAO,GAC1BnI,EAAmBoI,MAAQ,GAC3BpI,EAAmBqI,KAAO,GAC1BrI,EAAmBsI,QAAU,GAC7BtI,EAAmBuI,QAAU,GAC7BvI,EAAmB1B,MAAQ,GAC3B0B,EAAmBwI,KAAO,GAC1BxI,EAAmByI,UAAY,GAC/BzI,EAAmB0I,OAAS,GAC5B1I,EAAmB2I,WAAa,GAChC3I,EAAmB4I,SAAW,GAC9B5I,EAAmB6I,OAAS,GAC5B7I,EAAmB7c,MAAQ,GAC3B6c,EAAmB8I,SAAW,GAC9B9I,EAAmB+I,cAAgB,EACtC,CA1BD,CA0BG/I,KAAuBA,GAAqB,CAAC,IAMhD,SAAWC,GAIPA,EAAiBsH,UAAY,EAW7BtH,EAAiBsI,QAAU,CAC9B,CAhBD,CAgBGtI,KAAqBA,GAAmB,CAAC,IAQ5C,SAAWC,GAIPA,EAAkBoF,WAAa,CAClC,CALD,CAKGpF,KAAsBA,GAAoB,CAAC,IAO9C,SAAWC,GAOPA,EAAkB2C,OAHlB,SAAgBiD,EAASC,EAAQpmB,GAC7B,MAAO,CAAEmmB,UAASC,SAAQpmB,UAC9B,EASAugB,EAAkBzJ,GAJlB,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOqgB,GAAaC,GAAGO,OAAOR,EAAU+C,UAAY5H,GAAMzH,GAAGsM,EAAUgD,SAAW7H,GAAMzH,GAAGsM,EAAUpjB,QACzG,CAEH,CAhBD,CAgBGugB,KAAsBA,GAAoB,CAAC,IAQ9C,SAAWC,GAQPA,EAAe4I,KAAO,EAUtB5I,EAAe6I,kBAAoB,CACtC,CAnBD,CAmBG7I,KAAmBA,GAAiB,CAAC,IAExC,SAAWC,GAMPA,EAA2B3J,GAL3B,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOqgB,IAAcC,GAAGO,OAAOR,EAAUkG,cAAgChnB,IAArB8gB,EAAUkG,UACzDjG,GAAGO,OAAOR,EAAUoD,mBAA0ClkB,IAA1B8gB,EAAUoD,YACvD,CAEH,CAPD,CAOG/F,KAA+BA,GAA6B,CAAC,IAMhE,SAAWC,GAQPA,EAAewC,OAHf,SAAgBqB,GACZ,MAAO,CAAEA,QACb,CAEH,CATD,CASG7D,KAAmBA,GAAiB,CAAC,IAMxC,SAAWC,GAUPA,EAAeuC,OAHf,SAAgBqG,EAAOC,GACnB,MAAO,CAAED,MAAOA,GAAgB,GAAIC,eAAgBA,EACxD,CAEH,CAXD,CAWG7I,KAAmBA,GAAiB,CAAC,IAExC,SAAWC,GASPA,EAAa6I,cAHb,SAAuBC,GACnB,OAAOA,EAAU1pB,QAAQ,wBAAyB,OACtD,EASA4gB,EAAa9J,GAJb,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOsgB,GAAGO,OAAOR,IAAeC,GAAGC,cAAcF,IAAcC,GAAGO,OAAOR,EAAUuG,WAAatG,GAAGO,OAAOR,EAAUrgB,MACxH,CAEH,CAlBD,CAkBG6d,KAAiBA,GAAe,CAAC,IAEpC,SAAWC,GAUPA,EAAM/J,GANN,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,QAASqgB,GAAaC,GAAGC,cAAcF,KAAejD,GAAcrJ,GAAGsM,EAAUwG,WAC7EhJ,GAAa9J,GAAGsM,EAAUwG,WAC1BvG,GAAGqB,WAAWtB,EAAUwG,SAAUhJ,GAAa9J,YAAyBxU,IAAhBS,EAAMsM,OAAuBkP,GAAMzH,GAAG/T,EAAMsM,OAC5G,CAEH,CAXD,CAWGwR,KAAUA,GAAQ,CAAC,IAMtB,SAAWC,GAUPA,EAAqBoC,OAHrB,SAAgBqB,EAAOsF,GACnB,OAAOA,EAAgB,CAAEtF,QAAOsF,iBAAkB,CAAEtF,QACxD,CAEH,CAXD,CAWGzD,KAAyBA,GAAuB,CAAC,IAMpD,SAAWC,GAcPA,EAAqBmC,OAbrB,SAAgBqB,EAAOsF,GACnB,IAAI5jB,EAAS,CAAEse,SACXlB,GAAG+B,QAAQyE,KACX5jB,EAAO4jB,cAAgBA,GAC1B,QAAAzd,EAAA/J,UAAAnC,OAJoC4pB,EAAU,IAAAzlB,MAAA+H,EAAA,EAAAA,EAAA,KAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAVyd,EAAUzd,EAAA,GAAAhK,UAAAgK,GAW/C,OANIgX,GAAG+B,QAAQ0E,GACX7jB,EAAO6jB,WAAaA,EAGpB7jB,EAAO6jB,WAAa,GAEjB7jB,CACX,CAEH,CAfD,CAeG8a,KAAyBA,GAAuB,CAAC,IAKpD,SAAWC,GAIPA,EAAsB6G,KAAO,EAI7B7G,EAAsB+I,KAAO,EAI7B/I,EAAsBgJ,MAAQ,CACjC,CAbD,CAaGhJ,KAA0BA,GAAwB,CAAC,IAMtD,SAAWC,GAaPA,EAAkBiC,OAPlB,SAAgB7T,EAAO6V,GACnB,IAAIjf,EAAS,CAAEoJ,SAIf,OAHIgU,GAAG0C,OAAOb,KACVjf,EAAOif,KAAOA,GAEXjf,CACX,CAEH,CAdD,CAcGgb,KAAsBA,GAAoB,CAAC,IAK9C,SAAWC,GACPA,EAAW0H,KAAO,EAClB1H,EAAWmH,OAAS,EACpBnH,EAAW+I,UAAY,EACvB/I,EAAWgJ,QAAU,EACrBhJ,EAAWiH,MAAQ,EACnBjH,EAAW4G,OAAS,EACpB5G,EAAWoH,SAAW,EACtBpH,EAAW+G,MAAQ,EACnB/G,EAAW8G,YAAc,EACzB9G,EAAWuH,KAAO,GAClBvH,EAAWkH,UAAY,GACvBlH,EAAW6G,SAAW,GACtB7G,EAAWgH,SAAW,GACtBhH,EAAW8H,SAAW,GACtB9H,EAAW1V,OAAS,GACpB0V,EAAWiC,OAAS,GACpBjC,EAAWiJ,QAAU,GACrBjJ,EAAW7c,MAAQ,GACnB6c,EAAW/d,OAAS,GACpB+d,EAAWkJ,IAAM,GACjBlJ,EAAWmJ,KAAO,GAClBnJ,EAAW6H,WAAa,GACxB7H,EAAW+H,OAAS,GACpB/H,EAAW3d,MAAQ,GACnB2d,EAAWgI,SAAW,GACtBhI,EAAWiI,cAAgB,EAC9B,CA3BD,CA2BGjI,KAAeA,GAAa,CAAC,IAOhC,SAAWC,GAIPA,EAAUuE,WAAa,CAC1B,CALD,CAKGvE,KAAcA,GAAY,CAAC,IAE9B,SAAWC,GAqBPA,EAAkB8B,OAXlB,SAAgBpjB,EAAMolB,EAAM7V,EAAOsU,EAAK2G,GACpC,IAAIrkB,EAAS,CACTnG,OACAolB,OACAG,SAAU,CAAE1B,MAAKtU,UAKrB,OAHIib,IACArkB,EAAOqkB,cAAgBA,GAEpBrkB,CACX,CAEH,CAtBD,CAsBGmb,KAAsBA,GAAoB,CAAC,IAE9C,SAAWC,GAePA,EAAgB6B,OALhB,SAAgBpjB,EAAMolB,EAAMvB,EAAKtU,GAC7B,YAAiB/M,IAAV+M,EACD,CAAEvP,OAAMolB,OAAMG,SAAU,CAAE1B,MAAKtU,UAC/B,CAAEvP,OAAMolB,OAAMG,SAAU,CAAE1B,OACpC,CAEH,CAhBD,CAgBGtC,KAAoBA,GAAkB,CAAC,IAE1C,SAAWC,GAwBPA,EAAe4B,OAbf,SAAgBpjB,EAAMwpB,EAAQpE,EAAM7V,EAAOkb,EAAgBC,GACvD,IAAIvkB,EAAS,CACTnG,OACAwpB,SACApE,OACA7V,QACAkb,kBAKJ,YAHiBjoB,IAAbkoB,IACAvkB,EAAOukB,SAAWA,GAEfvkB,CACX,EAeAqb,EAAexK,GAVf,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOqgB,GACHC,GAAGO,OAAOR,EAAUtjB,OAASujB,GAAG0C,OAAO3C,EAAU8B,OACjD3G,GAAMzH,GAAGsM,EAAU/T,QAAUkP,GAAMzH,GAAGsM,EAAUmH,uBAC1BjoB,IAArB8gB,EAAUkG,QAAwBjG,GAAGO,OAAOR,EAAUkG,gBAC7BhnB,IAAzB8gB,EAAUqH,YAA4BpH,GAAGoD,QAAQrD,EAAUqH,oBACpCnoB,IAAvB8gB,EAAUoH,UAA0BnmB,MAAMrB,QAAQogB,EAAUoH,kBACzCloB,IAAnB8gB,EAAUsH,MAAsBrmB,MAAMrB,QAAQogB,EAAUsH,MACjE,CAEH,CAvCD,CAuCGpJ,KAAmBA,GAAiB,CAAC,IAKxC,SAAWC,GAIPA,EAAeoJ,MAAQ,GAIvBpJ,EAAeqJ,SAAW,WAI1BrJ,EAAesJ,SAAW,WAY1BtJ,EAAeuJ,gBAAkB,mBAWjCvJ,EAAewJ,eAAiB,kBAahCxJ,EAAeyJ,gBAAkB,mBAMjCzJ,EAAe0J,OAAS,SAIxB1J,EAAe2J,sBAAwB,yBASvC3J,EAAe4J,aAAe,eACjC,CApED,CAoEG5J,KAAmBA,GAAiB,CAAC,IAOxC,SAAWC,GAIPA,EAAsB4J,QAAU,EAOhC5J,EAAsB6J,UAAY,CACrC,CAZD,CAYG7J,KAA0BA,GAAwB,CAAC,IAMtD,SAAWC,GAcPA,EAAkByB,OAVlB,SAAgBoI,EAAaC,EAAMC,GAC/B,IAAIvlB,EAAS,CAAEqlB,eAOf,YANahpB,IAATipB,GAA+B,OAATA,IACtBtlB,EAAOslB,KAAOA,QAEEjpB,IAAhBkpB,GAA6C,OAAhBA,IAC7BvlB,EAAOulB,YAAcA,GAElBvlB,CACX,EAWAwb,EAAkB3K,GANlB,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOsgB,GAAG+B,QAAQhC,IAAcC,GAAGqB,WAAWtB,EAAUkI,YAAanM,GAAWrI,WACrDxU,IAAnB8gB,EAAUmI,MAAsBlI,GAAGqB,WAAWtB,EAAUmI,KAAMlI,GAAGO,gBACvCthB,IAA1B8gB,EAAUoI,aAA6BpI,EAAUoI,cAAgBhK,GAAsB4J,SAAWhI,EAAUoI,cAAgBhK,GAAsB6J,UAC9J,CAEH,CAzBD,CAyBG5J,KAAsBA,GAAoB,CAAC,IAE9C,SAAWC,GAmBPA,EAAWwB,OAlBX,SAAgB+C,EAAOwF,EAAqBvG,GACxC,IAAIjf,EAAS,CAAEggB,SACXyF,GAAY,EAchB,MAbmC,kBAAxBD,GACPC,GAAY,EACZzlB,EAAOif,KAAOuG,GAETrM,GAAQtI,GAAG2U,GAChBxlB,EAAOigB,QAAUuF,EAGjBxlB,EAAO0lB,KAAOF,EAEdC,QAAsBppB,IAAT4iB,IACbjf,EAAOif,KAAOA,GAEXjf,CACX,EAYAyb,EAAW5K,GAVX,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOqgB,GAAaC,GAAGO,OAAOR,EAAU6C,cACT3jB,IAA1B8gB,EAAUkI,aAA6BjI,GAAGqB,WAAWtB,EAAUkI,YAAanM,GAAWrI,YACpExU,IAAnB8gB,EAAU8B,MAAsB7B,GAAGO,OAAOR,EAAU8B,cACjC5iB,IAAnB8gB,EAAUuI,WAA4CrpB,IAAtB8gB,EAAU8C,gBACpB5jB,IAAtB8gB,EAAU8C,SAAyB9G,GAAQtI,GAAGsM,EAAU8C,iBAC9B5jB,IAA1B8gB,EAAUwI,aAA6BvI,GAAGoD,QAAQrD,EAAUwI,qBACzCtpB,IAAnB8gB,EAAUuI,MAAsB9L,GAAc/I,GAAGsM,EAAUuI,MACpE,CAEH,CA/BD,CA+BGjK,KAAeA,GAAa,CAAC,IAMhC,SAAWC,GAWPA,EAASuB,OAPT,SAAgB7T,EAAOwc,GACnB,IAAI5lB,EAAS,CAAEoJ,SAIf,OAHIgU,GAAG+B,QAAQyG,KACX5lB,EAAO4lB,KAAOA,GAEX5lB,CACX,EASA0b,EAAS7K,GAJT,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOsgB,GAAG+B,QAAQhC,IAAc7E,GAAMzH,GAAGsM,EAAU/T,SAAWgU,GAAG/gB,UAAU8gB,EAAU8C,UAAY9G,GAAQtI,GAAGsM,EAAU8C,SAC1H,CAEH,CApBD,CAoBGvE,KAAaA,GAAW,CAAC,IAM5B,SAAWC,GAOPA,EAAkBsB,OAHlB,SAAgB4I,EAASC,GACrB,MAAO,CAAED,UAASC,eACtB,EASAnK,EAAkB9K,GAJlB,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOsgB,GAAG+B,QAAQhC,IAAcC,GAAGhF,SAAS+E,EAAU0I,UAAYzI,GAAGoD,QAAQrD,EAAU2I,aAC3F,CAEH,CAhBD,CAgBGnK,KAAsBA,GAAoB,CAAC,IAM9C,SAAWC,GAOPA,EAAaqB,OAHb,SAAgB7T,EAAOU,EAAQ8b,GAC3B,MAAO,CAAExc,QAAOU,SAAQ8b,OAC5B,EASAhK,EAAa/K,GAJb,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOsgB,GAAG+B,QAAQhC,IAAc7E,GAAMzH,GAAGsM,EAAU/T,SAAWgU,GAAG/gB,UAAU8gB,EAAUrT,SAAWsT,GAAGO,OAAOR,EAAUrT,QACxH,CAEH,CAhBD,CAgBG8R,KAAiBA,GAAe,CAAC,IAMpC,SAAWC,GASPA,EAAeoB,OAHf,SAAgB7T,EAAO2c,GACnB,MAAO,CAAE3c,QAAO2c,SACpB,EAMAlK,EAAehL,GAJf,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,OAAOsgB,GAAGC,cAAcF,IAAc7E,GAAMzH,GAAGsM,EAAU/T,cAAgC/M,IAArB8gB,EAAU4I,QAAwBlK,EAAehL,GAAGsM,EAAU4I,QACtI,CAEH,CAfD,CAeGlK,KAAmBA,GAAiB,CAAC,IASxC,SAAWC,GACPA,EAA8B,UAAI,YAKlCA,EAAyB,KAAI,OAC7BA,EAA0B,MAAI,QAC9BA,EAAyB,KAAI,OAC7BA,EAA8B,UAAI,YAClCA,EAA2B,OAAI,SAC/BA,EAAkC,cAAI,gBACtCA,EAA8B,UAAI,YAClCA,EAA6B,SAAI,WACjCA,EAA6B,SAAI,WACjCA,EAA+B,WAAI,aACnCA,EAA0B,MAAI,QAC9BA,EAA6B,SAAI,WACjCA,EAA2B,OAAI,SAC/BA,EAA0B,MAAI,QAC9BA,EAA4B,QAAI,UAChCA,EAA6B,SAAI,WACjCA,EAA4B,QAAI,UAChCA,EAA2B,OAAI,SAC/BA,EAA2B,OAAI,SAC/BA,EAA2B,OAAI,SAC/BA,EAA6B,SAAI,WAIjCA,EAA8B,UAAI,WACrC,CA/BD,CA+BGA,KAAuBA,GAAqB,CAAC,IAShD,SAAWC,GACPA,EAAoC,YAAI,cACxCA,EAAmC,WAAI,aACvCA,EAAiC,SAAI,WACrCA,EAA+B,OAAI,SACnCA,EAAmC,WAAI,aACvCA,EAAiC,SAAI,WACrCA,EAA8B,MAAI,QAClCA,EAAqC,aAAI,eACzCA,EAAsC,cAAI,gBAC1CA,EAAuC,eAAI,gBAC9C,CAXD,CAWGA,KAA2BA,GAAyB,CAAC,IAKxD,SAAWC,GAMPA,EAAenL,GALf,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOsgB,GAAGC,cAAcF,UAAsC9gB,IAAvB8gB,EAAU6I,UAAwD,kBAAvB7I,EAAU6I,WACxF5nB,MAAMrB,QAAQogB,EAAUyI,QAAoC,IAA1BzI,EAAUyI,KAAK3rB,QAA6C,kBAAtBkjB,EAAUyI,KAAK,GAC/F,CAEH,CAPD,CAOG5J,KAAmBA,GAAiB,CAAC,IAOxC,SAAWC,GAOPA,EAAgBgB,OAHhB,SAAgB7T,EAAOqY,GACnB,MAAO,CAAErY,QAAOqY,OACpB,EAMAxF,EAAgBpL,GAJhB,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,YAAqBT,IAAd8gB,GAAyC,OAAdA,GAAsB7E,GAAMzH,GAAGsM,EAAU/T,QAAUgU,GAAGO,OAAOR,EAAUsE,KAC7G,CAEH,CAbD,CAaGxF,KAAoBA,GAAkB,CAAC,IAO1C,SAAWC,GAOPA,EAA0Be,OAH1B,SAAgB7T,EAAO6c,EAAcC,GACjC,MAAO,CAAE9c,QAAO6c,eAAcC,sBAClC,EAOAhK,EAA0BrL,GAL1B,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,YAAqBT,IAAd8gB,GAAyC,OAAdA,GAAsB7E,GAAMzH,GAAGsM,EAAU/T,QAAUgU,GAAGoD,QAAQrD,EAAU+I,uBAClG9I,GAAGO,OAAOR,EAAU8I,oBAA4C5pB,IAA3B8gB,EAAU8I,aAC3D,CAEH,CAdD,CAcG/J,KAA8BA,GAA4B,CAAC,IAO9D,SAAWC,GAOPA,EAAiCc,OAHjC,SAAgB7T,EAAO+c,GACnB,MAAO,CAAE/c,QAAO+c,aACpB,EAOAhK,EAAiCtL,GALjC,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,YAAqBT,IAAd8gB,GAAyC,OAAdA,GAAsB7E,GAAMzH,GAAGsM,EAAU/T,SACnEgU,GAAGO,OAAOR,EAAUgJ,kBAAwC9pB,IAAzB8gB,EAAUgJ,WACzD,CAEH,CAdD,CAcGhK,KAAqCA,GAAmC,CAAC,IAQ5E,SAAWC,GAOPA,EAAmBa,OAHnB,SAAgBmJ,EAASC,GACrB,MAAO,CAAED,UAASC,kBACtB,EASAjK,EAAmBvL,GAJnB,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOsgB,GAAG+B,QAAQhC,IAAc7E,GAAMzH,GAAG/T,EAAMupB,gBACnD,CAEH,CAhBD,CAgBGjK,KAAuBA,GAAqB,CAAC,IAOhD,SAAWC,GAIPA,EAAciK,KAAO,EAIrBjK,EAAckK,UAAY,EAI1BlK,EAAcxL,GAHd,SAAY/T,GACR,OAAiB,IAAVA,GAAyB,IAAVA,CAC1B,CAEH,CAbD,CAaGuf,KAAkBA,GAAgB,CAAC,IAEtC,SAAWC,GAIPA,EAAmBW,OAHnB,SAAgBngB,GACZ,MAAO,CAAEA,QACb,EASAwf,EAAmBzL,GAPnB,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOsgB,GAAGC,cAAcF,UACM9gB,IAAtB8gB,EAAUqJ,SAAyBpJ,GAAGO,OAAOR,EAAUqJ,UAAYtM,GAAcrJ,GAAGsM,EAAUqJ,iBACvEnqB,IAAvB8gB,EAAUiC,UAA0B7G,GAAS1H,GAAGsM,EAAUiC,kBACpC/iB,IAAtB8gB,EAAU8C,SAAyB9G,GAAQtI,GAAGsM,EAAU8C,SACpE,CAEH,CAbD,CAaG3D,KAAuBA,GAAqB,CAAC,IAEhD,SAAWC,GAQPA,EAAUU,OAPV,SAAgBmD,EAAU9B,EAAOW,GAC7B,MAAMjf,EAAS,CAAEogB,WAAU9B,SAI3B,YAHajiB,IAAT4iB,IACAjf,EAAOif,KAAOA,GAEXjf,CACX,EAYAuc,EAAU1L,GAVV,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOsgB,GAAGC,cAAcF,IAAc9E,GAASxH,GAAGsM,EAAUiD,YACpDhD,GAAGO,OAAOR,EAAUmB,QAAUlB,GAAGqB,WAAWtB,EAAUmB,MAAOhC,GAAmBzL,YAC7DxU,IAAnB8gB,EAAU8B,MAAsB5C,GAAcxL,GAAGsM,EAAU8B,aACnC5iB,IAAxB8gB,EAAUsJ,WAA4BrJ,GAAGqB,WAAWtB,EAAUsJ,UAAWrN,GAASvI,WAC5DxU,IAAtB8gB,EAAUqJ,SAAyBpJ,GAAGO,OAAOR,EAAUqJ,UAAYtM,GAAcrJ,GAAGsM,EAAUqJ,iBACpEnqB,IAA1B8gB,EAAUuJ,aAA6BtJ,GAAGoD,QAAQrD,EAAUuJ,qBACjCrqB,IAA3B8gB,EAAUwJ,cAA8BvJ,GAAGoD,QAAQrD,EAAUwJ,cACzE,CAEH,CApBD,CAoBGpK,KAAcA,GAAY,CAAC,IAE9B,SAAWC,GAIPA,EAAYoK,cAHZ,SAAuB9pB,GACnB,MAAO,CAAEmiB,KAAM,UAAWniB,QAC9B,CAEH,CALD,CAKG0f,KAAgBA,GAAc,CAAC,IAElC,SAAWC,GAIPA,EAAqBQ,OAHrB,SAAgB4J,EAAYC,EAAY1d,EAAO6W,GAC3C,MAAO,CAAE4G,aAAYC,aAAY1d,QAAO6W,UAC5C,CAEH,CALD,CAKGxD,KAAyBA,GAAuB,CAAC,IAEpD,SAAWC,GAIPA,EAAqBO,OAHrB,SAAgBqG,GACZ,MAAO,CAAEA,QACb,CAEH,CALD,CAKG5G,KAAyBA,GAAuB,CAAC,IAQpD,SAAWC,GAIPA,EAA4BwI,QAAU,EAItCxI,EAA4ByI,UAAY,CAC3C,CATD,CASGzI,KAAgCA,GAA8B,CAAC,IAElE,SAAWC,GAIPA,EAAuBK,OAHvB,SAAgB7T,EAAOqY,GACnB,MAAO,CAAErY,QAAOqY,OACpB,CAEH,CALD,CAKG7E,KAA2BA,GAAyB,CAAC,IAExD,SAAWC,GAIPA,EAAwBI,OAHxB,SAAgBsI,EAAawB,GACzB,MAAO,CAAExB,cAAawB,yBAC1B,CAEH,CALD,CAKGlK,KAA4BA,GAA0B,CAAC,IAE1D,SAAWC,GAKPA,EAAgBjM,GAJhB,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOsgB,GAAGC,cAAcF,IAAcjF,GAAIrH,GAAGsM,EAAUO,MAAQN,GAAGO,OAAOR,EAAUtjB,KACvF,CAEH,CAND,CAMGijB,KAAoBA,GAAkB,CAAC,IAKnC,IAAIkK,GA6KP5J,IA5KJ,SAAW4J,GA8CP,SAASC,EAAUrB,EAAMsB,GACrB,GAAItB,EAAK3rB,QAAU,EAEf,OAAO2rB,EAEX,MAAMvgB,EAAKugB,EAAK3rB,OAAS,EAAK,EACxB+R,EAAO4Z,EAAK9mB,MAAM,EAAGuG,GACrB4G,EAAQ2Z,EAAK9mB,MAAMuG,GACzB4hB,EAAUjb,EAAMkb,GAChBD,EAAUhb,EAAOib,GACjB,IAAIC,EAAU,EACVC,EAAW,EACX7oB,EAAI,EACR,KAAO4oB,EAAUnb,EAAK/R,QAAUmtB,EAAWnb,EAAMhS,QAAQ,CACrD,IAAI2E,EAAMsoB,EAAQlb,EAAKmb,GAAUlb,EAAMmb,IAGnCxB,EAAKrnB,KAFLK,GAAO,EAEKoN,EAAKmb,KAILlb,EAAMmb,IAE1B,CACA,KAAOD,EAAUnb,EAAK/R,QAClB2rB,EAAKrnB,KAAOyN,EAAKmb,KAErB,KAAOC,EAAWnb,EAAMhS,QACpB2rB,EAAKrnB,KAAO0N,EAAMmb,KAEtB,OAAOxB,CACX,CAlEAoB,EAAa/J,OAHb,SAAgBS,EAAK8D,EAAYD,EAAS8F,GACtC,OAAO,IAAIC,GAAiB5J,EAAK8D,EAAYD,EAAS8F,EAC1D,EAUAL,EAAanW,GALb,SAAY/T,GACR,IAAIqgB,EAAYrgB,EAChB,SAAOsgB,GAAG+B,QAAQhC,IAAcC,GAAGO,OAAOR,EAAUO,OAASN,GAAG/gB,UAAU8gB,EAAUqE,aAAepE,GAAGO,OAAOR,EAAUqE,cAAgBpE,GAAGhF,SAAS+E,EAAUoK,YACtJnK,GAAGoK,KAAKrK,EAAUsK,UAAYrK,GAAGoK,KAAKrK,EAAUuK,aAAetK,GAAGoK,KAAKrK,EAAUwK,UAC5F,EA0BAX,EAAaY,WAxBb,SAAoBC,EAAUjH,GAC1B,IAAIa,EAAOoG,EAASJ,UAChBK,EAAcb,EAAUrG,EAAO,CAACzf,EAAGyE,KACnC,IAAImiB,EAAO5mB,EAAEiI,MAAMC,MAAMC,KAAO1D,EAAEwD,MAAMC,MAAMC,KAC9C,OAAa,IAATye,EACO5mB,EAAEiI,MAAMC,MAAME,UAAY3D,EAAEwD,MAAMC,MAAME,UAE5Cwe,IAEPC,EAAqBvG,EAAKxnB,OAC9B,IAAK,IAAIsE,EAAIupB,EAAY7tB,OAAS,EAAGsE,GAAK,EAAGA,IAAK,CAC9C,IAAIa,EAAI0oB,EAAYvpB,GAChB0pB,EAAcJ,EAASF,SAASvoB,EAAEgK,MAAMC,OACxC6e,EAAYL,EAASF,SAASvoB,EAAEgK,MAAM2D,KAC1C,KAAImb,GAAaF,GAIb,MAAM,IAAItpB,MAAM,oBAHhB+iB,EAAOA,EAAKznB,UAAU,EAAGiuB,GAAe7oB,EAAE8gB,QAAUuB,EAAKznB,UAAUkuB,EAAWzG,EAAKxnB,QAKvF+tB,EAAqBC,CACzB,CACA,OAAOxG,CACX,CAkCH,CA9ED,CA8EGuF,KAAiBA,GAAe,CAAC,IAIpC,MAAMM,GACFpuB,WAAAA,CAAYwkB,EAAK8D,EAAYD,EAAS8F,GAClCrpB,KAAKmqB,KAAOzK,EACZ1f,KAAKoqB,YAAc5G,EACnBxjB,KAAKqqB,SAAW9G,EAChBvjB,KAAKsqB,SAAWjB,EAChBrpB,KAAKuqB,kBAAelsB,CACxB,CACA,OAAIqhB,GACA,OAAO1f,KAAKmqB,IAChB,CACA,cAAI3G,GACA,OAAOxjB,KAAKoqB,WAChB,CACA,WAAI7G,GACA,OAAOvjB,KAAKqqB,QAChB,CACAZ,OAAAA,CAAQre,GACJ,GAAIA,EAAO,CACP,IAAIC,EAAQrL,KAAK2pB,SAASve,EAAMC,OAC5B0D,EAAM/O,KAAK2pB,SAASve,EAAM2D,KAC9B,OAAO/O,KAAKsqB,SAAStuB,UAAUqP,EAAO0D,EAC1C,CACA,OAAO/O,KAAKsqB,QAChB,CACAE,MAAAA,CAAO9oB,EAAO6hB,GACVvjB,KAAKsqB,SAAW5oB,EAAM+hB,KACtBzjB,KAAKqqB,SAAW9G,EAChBvjB,KAAKuqB,kBAAelsB,CACxB,CACAosB,cAAAA,GACI,QAA0BpsB,IAAtB2B,KAAKuqB,aAA4B,CACjC,IAAIG,EAAc,GACdjH,EAAOzjB,KAAKsqB,SACZK,GAAc,EAClB,IAAK,IAAIpqB,EAAI,EAAGA,EAAIkjB,EAAKxnB,OAAQsE,IAAK,CAC9BoqB,IACAD,EAAYvqB,KAAKI,GACjBoqB,GAAc,GAElB,IAAIC,EAAKnH,EAAKtc,OAAO5G,GACrBoqB,EAAsB,OAAPC,GAAsB,OAAPA,EACnB,OAAPA,GAAerqB,EAAI,EAAIkjB,EAAKxnB,QAAiC,OAAvBwnB,EAAKtc,OAAO5G,EAAI,IACtDA,GAER,CACIoqB,GAAelH,EAAKxnB,OAAS,GAC7ByuB,EAAYvqB,KAAKsjB,EAAKxnB,QAE1B+D,KAAKuqB,aAAeG,CACxB,CACA,OAAO1qB,KAAKuqB,YAChB,CACAb,UAAAA,CAAWmB,GACPA,EAASC,KAAKC,IAAID,KAAK1S,IAAIyS,EAAQ7qB,KAAKsqB,SAASruB,QAAS,GAC1D,IAAIyuB,EAAc1qB,KAAKyqB,iBACnBO,EAAM,EAAGC,EAAOP,EAAYzuB,OAChC,GAAa,IAATgvB,EACA,OAAO5Q,GAAS4E,OAAO,EAAG4L,GAE9B,KAAOG,EAAMC,GAAM,CACf,IAAIC,EAAMJ,KAAKK,OAAOH,EAAMC,GAAQ,GAChCP,EAAYQ,GAAOL,EACnBI,EAAOC,EAGPF,EAAME,EAAM,CAEpB,CAGA,IAAI5f,EAAO0f,EAAM,EACjB,OAAO3Q,GAAS4E,OAAO3T,EAAMuf,EAASH,EAAYpf,GACtD,CACAqe,QAAAA,CAASvH,GACL,IAAIsI,EAAc1qB,KAAKyqB,iBACvB,GAAIrI,EAAS9W,MAAQof,EAAYzuB,OAC7B,OAAO+D,KAAKsqB,SAASruB,OAEpB,GAAImmB,EAAS9W,KAAO,EACrB,OAAO,EAEX,IAAI8f,EAAaV,EAAYtI,EAAS9W,MAClC+f,EAAkBjJ,EAAS9W,KAAO,EAAIof,EAAYzuB,OAAUyuB,EAAYtI,EAAS9W,KAAO,GAAKtL,KAAKsqB,SAASruB,OAC/G,OAAO6uB,KAAKC,IAAID,KAAK1S,IAAIgT,EAAahJ,EAAS7W,UAAW8f,GAAiBD,EAC/E,CACA,aAAI7B,GACA,OAAOvpB,KAAKyqB,iBAAiBxuB,MACjC,GAGJ,SAAWmjB,GACP,MAAMhZ,EAAWlH,OAAOgG,UAAUkB,SAIlCgZ,EAAG+B,QAHH,SAAiBriB,GACb,MAAwB,qBAAVA,CAClB,EAKAsgB,EAAG/gB,UAHH,SAAmBS,GACf,MAAwB,qBAAVA,CAClB,EAKAsgB,EAAGoD,QAHH,SAAiB1jB,GACb,OAAiB,IAAVA,IAA4B,IAAVA,CAC7B,EAKAsgB,EAAGO,OAHH,SAAgB7gB,GACZ,MAAgC,oBAAzBsH,EAAShE,KAAKtD,EACzB,EAKAsgB,EAAG0C,OAHH,SAAgBhjB,GACZ,MAAgC,oBAAzBsH,EAAShE,KAAKtD,EACzB,EAKAsgB,EAAGgB,YAHH,SAAqBthB,EAAOsZ,EAAK2S,GAC7B,MAAgC,oBAAzB3kB,EAAShE,KAAKtD,IAAgCsZ,GAAOtZ,GAASA,GAASisB,CAClF,EAKA3L,EAAGjF,QAHH,SAAiBrb,GACb,MAAgC,oBAAzBsH,EAAShE,KAAKtD,KAAiC,YAAcA,GAASA,GAAS,UAC1F,EAKAsgB,EAAGhF,SAHH,SAAkBtb,GACd,MAAgC,oBAAzBsH,EAAShE,KAAKtD,IAAgC,GAAKA,GAASA,GAAS,UAChF,EAKAsgB,EAAGoK,KAHH,SAAc1qB,GACV,MAAgC,sBAAzBsH,EAAShE,KAAKtD,EACzB,EAQAsgB,EAAGC,cANH,SAAuBvgB,GAInB,OAAiB,OAAVA,GAAmC,kBAAVA,CACpC,EAKAsgB,EAAGqB,WAHH,SAAoB3hB,EAAOwsB,GACvB,OAAOlrB,MAAMrB,QAAQD,IAAUA,EAAMukB,MAAMiI,EAC/C,CAEH,CAjDD,CAiDGlM,KAAOA,GAAK,CAAC,IChqEV,MAAOmM,GAAbrwB,WAAAA,GAGY,KAAAswB,UAAoC,EAwFhD,CAtFI,WAAItS,G,MACA,OAAgD,QAAzC/F,EAAAnT,KAAKwrB,UAAUxrB,KAAKwrB,UAAUvvB,OAAS,UAAE,IAAAkX,EAAAA,EAAInT,KAAKyrB,QAC7D,CAEAC,aAAAA,CAAc/vB,GAIV,OAHAqE,KAAKyrB,SAAW,IAAIE,GAAgBhwB,GACpCqE,KAAKyrB,SAASlnB,KAAOvE,KAAKyrB,SAC1BzrB,KAAKwrB,UAAY,CAACxrB,KAAKyrB,UAChBzrB,KAAKyrB,QAChB,CAEAG,kBAAAA,CAAmBC,GACf,MAAMC,EAAgB,IAAIC,GAK1B,OAJAD,EAAcE,cAAgBH,EAC9BC,EAAcvnB,KAAOvE,KAAKyrB,SAC1BzrB,KAAKkZ,QAAQmQ,QAAQlpB,KAAK2rB,GAC1B9rB,KAAKwrB,UAAUrrB,KAAK2rB,GACbA,CACX,CAEAG,aAAAA,CAAcpV,EAAegV,GACzB,MAAMK,EAAW,IAAIC,GAAgBtV,EAAMoT,YAAapT,EAAMuV,MAAMnwB,QAAQowB,EAAAA,EAAAA,IAAaxV,GAAQA,EAAM5K,WAAY4f,GAInH,OAHAK,EAASF,cAAgBH,EACzBK,EAAS3nB,KAAOvE,KAAKyrB,SACrBzrB,KAAKkZ,QAAQmQ,QAAQlpB,KAAK+rB,GACnBA,CACX,CAEAI,UAAAA,CAAW1uB,GACP,MAAMmqB,EAASnqB,EAAK2uB,UACpB,GAAIxE,EAAQ,CACR,MAAMxf,EAAQwf,EAAOsB,QAAQ5jB,QAAQ7H,GACjC2K,GAAS,GACTwf,EAAOsB,QAAQ5oB,OAAO8H,EAAO,EAErC,CACJ,CAEAikB,cAAAA,CAAeC,GACX,MAAMC,EAAuB,GAC7B,IAAK,MAAM7V,KAAS4V,EAAQ,CACxB,MAAMP,EAAW,IAAIC,GAAgBtV,EAAMoT,YAAapT,EAAMuV,MAAMnwB,QAAQowB,EAAAA,EAAAA,IAAaxV,GAAQA,EAAM5K,WAAW,GAClHigB,EAAS3nB,KAAOvE,KAAKyrB,SACrBiB,EAAMvsB,KAAK+rB,EACf,CACA,IAAIhT,EAA4BlZ,KAAKkZ,QACjCyT,GAAQ,EAEZ,GAAIzT,EAAQmQ,QAAQptB,OAAS,EACzBid,EAAQmQ,QAAQlpB,QAAQusB,OAD5B,CAMA,KAAOxT,EAAQqT,WAAW,CACtB,MAAMhkB,EAAQ2Q,EAAQqT,UAAUlD,QAAQ5jB,QAAQyT,GAChD,GAAI3Q,EAAQ,EAAG,CAEX2Q,EAAQqT,UAAUlD,QAAQ5oB,OAAO8H,EAAO,KAAMmkB,GAC9CC,GAAQ,EACR,KACJ,CACAzT,EAAUA,EAAQqT,SACtB,CAGKI,GACD3sB,KAAKyrB,SAASpC,QAAQuD,WAAWF,EAhBrC,CAkBJ,CAEAG,SAAAA,CAAUpvB,GACN,MAAMyb,EAAmBlZ,KAAKkZ,QAGJ,kBAAfzb,EAAKrB,QACZ4D,KAAKkZ,QAAQ4T,QAAmBrvB,GAEpCA,EAAKsvB,SAAW7T,EAChB,MAAMtb,EAAOoC,KAAKwrB,UAAUzR,MAGC,KAArB,OAAJnc,QAAI,IAAJA,OAAI,EAAJA,EAAMyrB,QAAQptB,SACd+D,KAAKssB,WAAW1uB,EAExB,EAGE,MAAgBovB,GAYlB,UAAIjF,GACA,OAAO/nB,KAAKusB,SAChB,CAGA,WAAIV,GACA,OAAO7rB,KAAKgsB,aAChB,CAEA,UAAIiB,GACA,OAAO,CACX,CAEA,WAAIH,G,QACA,MAAMlvB,EAAuC,kBAAZ,QAAbuV,EAAAnT,KAAKktB,gBAAQ,IAAA/Z,OAAA,EAAAA,EAAE/W,OAAqB4D,KAAKktB,SAAyB,QAAdC,EAAAntB,KAAKusB,iBAAS,IAAAY,OAAA,EAAAA,EAAEL,QACxF,IAAKlvB,EACD,MAAM,IAAI8C,MAAM,2CAEpB,OAAO9C,CACX,CAEA,WAAIkvB,CAAQhuB,GACRkB,KAAKktB,SAAWpuB,CACpB,CAGA,WAAIsuB,GACA,OAAOptB,KAAK8sB,OAChB,CAEA,QAAIrJ,GACA,OAAOzjB,KAAKuE,KAAK8oB,SAASrxB,UAAUgE,KAAK6qB,OAAQ7qB,KAAK+O,IAC1D,EAGE,MAAOod,WAAwBa,GACjC,UAAInC,GACA,OAAO7qB,KAAKstB,OAChB,CAEA,UAAIrxB,GACA,OAAO+D,KAAKutB,OAChB,CAEA,OAAIxe,GACA,OAAO/O,KAAKstB,QAAUttB,KAAKutB,OAC/B,CAEA,UAAaN,GACT,OAAOjtB,KAAKwtB,OAChB,CAEA,aAAIvhB,GACA,OAAOjM,KAAKytB,UAChB,CAEA,SAAIriB,GACA,OAAOpL,KAAK0tB,MAChB,CAQAxyB,WAAAA,CAAY2vB,EAAgB5uB,EAAgBmP,EAAca,GAAoC,IAAdghB,EAAM7uB,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAClFjD,QACA6E,KAAKwtB,QAAUP,EACfjtB,KAAKstB,QAAUzC,EACf7qB,KAAKytB,WAAaxhB,EAClBjM,KAAKutB,QAAUtxB,EACf+D,KAAK0tB,OAAStiB,CAClB,EAGE,MAAO2gB,WAA6BiB,GAA1C9xB,WAAAA,G,oBACa,KAAAmuB,QAAqB,IAAIsE,GAAiB3tB,KAqDvD,CAjDI,YAAIumB,GACA,OAAOvmB,KAAKqpB,OAChB,CAEA,UAAIwB,G,QACA,OAAsC,QAA/BsC,EAAuB,QAAvBha,EAAAnT,KAAK4tB,0BAAkB,IAAAza,OAAA,EAAAA,EAAE0X,cAAM,IAAAsC,EAAAA,EAAI,CAC9C,CAEA,UAAIlxB,GACA,OAAO+D,KAAK+O,IAAM/O,KAAK6qB,MAC3B,CAEA,OAAI9b,G,QACA,OAAkC,QAA3Boe,EAAsB,QAAtBha,EAAAnT,KAAK6tB,yBAAiB,IAAA1a,OAAA,EAAAA,EAAEpE,WAAG,IAAAoe,EAAAA,EAAI,CAC1C,CAEA,SAAI/hB,GACA,MAAM0iB,EAAY9tB,KAAK4tB,mBACjBG,EAAW/tB,KAAK6tB,kBACtB,GAAIC,GAAaC,EAAU,CACvB,QAAyB1vB,IAArB2B,KAAKguB,YAA2B,CAChC,MAAQ5iB,MAAO6iB,GAAeH,GACtB1iB,MAAO8iB,GAAcH,EAC7B/tB,KAAKguB,YAAc,CAAE3iB,MAAO4iB,EAAW5iB,MAAO0D,IAAKmf,EAAUnf,IAAIzD,KAAO2iB,EAAW5iB,MAAMC,KAAO2iB,EAAW5iB,MAAQ6iB,EAAUnf,IACjI,CACA,OAAO/O,KAAKguB,WAChB,CACI,MAAO,CAAE3iB,MAAOgP,GAAS4E,OAAO,EAAG,GAAIlQ,IAAKsL,GAAS4E,OAAO,EAAG,GAEvE,CAEA,sBAAY2O,GACR,IAAK,MAAMO,KAASnuB,KAAKqpB,QACrB,IAAK8E,EAAMlB,OACP,OAAOkB,EAGf,OAAOnuB,KAAKqpB,QAAQ,EACxB,CAEA,qBAAYwE,GACR,IAAK,IAAIttB,EAAIP,KAAKqpB,QAAQptB,OAAS,EAAGsE,GAAK,EAAGA,IAAK,CAC/C,MAAM4tB,EAAQnuB,KAAKqpB,QAAQ9oB,GAC3B,IAAK4tB,EAAMlB,OACP,OAAOkB,CAEf,CACA,OAAOnuB,KAAKqpB,QAAQrpB,KAAKqpB,QAAQptB,OAAS,EAC9C,EAGJ,MAAM0xB,WAAyBvtB,MAG3BlF,WAAAA,CAAY6sB,GACR5sB,QACA6E,KAAK+nB,OAASA,EACd7oB,OAAOkvB,eAAepuB,KAAM2tB,GAAiBzoB,UACjD,CAES/E,IAAAA,GAAwB,QAAAa,EAAA5C,UAAAnC,OAAhBqpB,EAAgB,IAAAllB,MAAAY,GAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAAhBokB,EAAgBpkB,GAAA9C,UAAA8C,GAE7B,OADAlB,KAAKquB,WAAW/I,GACTnqB,MAAMgF,QAAQmlB,EACzB,CAESsH,OAAAA,GAA2B,QAAAzkB,EAAA/J,UAAAnC,OAAhBqpB,EAAgB,IAAAllB,MAAA+H,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAhBkd,EAAgBld,GAAAhK,UAAAgK,GAEhC,OADApI,KAAKquB,WAAW/I,GACTnqB,MAAMyxB,WAAWtH,EAC5B,CAES7kB,MAAAA,CAAO4K,EAAeijB,GAAkC,QAAAC,EAAAnwB,UAAAnC,OAAhBqpB,EAAgB,IAAAllB,MAAAmuB,EAAA,EAAAA,EAAA,KAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAhBlJ,EAAgBkJ,EAAA,GAAApwB,UAAAowB,GAE7D,OADAxuB,KAAKquB,WAAW/I,GACTnqB,MAAMsF,OAAO4K,EAAOijB,KAAUhJ,EACzC,CAEQ+I,UAAAA,CAAW/I,GACf,IAAK,MAAM7nB,KAAQ6nB,EACG7nB,EAAM8uB,UAAYvsB,KAAK+nB,MAEjD,EAGE,MAAO4D,WAAwBI,GAGjC,QAAatI,GACT,OAAOzjB,KAAKyuB,MAAMzyB,UAAUgE,KAAK6qB,OAAQ7qB,KAAK+O,IAClD,CAEA,YAAIse,GACA,OAAOrtB,KAAKyuB,KAChB,CAEAvzB,WAAAA,CAAYS,GACRR,QAXI,KAAAszB,MAAQ,GAYZzuB,KAAKyuB,MAAa,OAAL9yB,QAAK,IAALA,EAAAA,EAAS,EAC1B,ECzQG,MAAM+yB,GAAiBtpB,OAAO,YAUrC,SAASupB,GAAe/wB,GACpB,OAAOA,EAAKxB,QAAUsyB,EAC1B,CAgFA,MACME,GAAkB/yB,GAAyBA,EAAKgzB,SADnC,UAC0DhzB,EAAOA,EADjE,SAGb,MAAgBizB,GASlB5zB,WAAAA,CAAYsB,GALF,KAAAuyB,iBAA2C,IAAIniB,IAE/C,KAAAoiB,SAAW,IAAIpiB,IAIrB5M,KAAKivB,MAAQzyB,EAASuB,OAAOmxB,MAC7B,MAAMzC,EAASzsB,KAAKivB,MAAMxgB,WACpBjB,EAAgD,eAAnChR,EAAS2yB,iBAAiBC,KAC7CpvB,KAAKqvB,QAAU,IAAIC,GAAkB7C,EAAMvtB,OAAAoS,OAAApS,OAAAoS,OAAA,GACpC9U,EAASuB,OAAOwxB,cAAY,CAC/BC,gBAAiBhiB,EACjBiiB,qBAAsBjzB,EAASuB,OAAO2xB,6BAE9C,CAEAC,YAAAA,CAAa1gB,EAAa2gB,GACtB5vB,KAAKqvB,QAAQQ,OAAO5gB,EAAK2gB,EAC7B,CAEA9gB,QAAAA,CAASG,EAAanP,GAClBE,KAAKqvB,QAAQS,WAAW7gB,EAAKnP,EACjC,CAEAiwB,IAAAA,CAAK9gB,EAAanP,GACdE,KAAKqvB,QAAQW,SAAS/gB,EAAKnP,EAC/B,CAEAmwB,UAAAA,CAAWhhB,EAAanP,GACpBE,KAAKqvB,QAAQa,eAAejhB,EAAKnP,EACrC,CAQAqwB,OAAAA,CAAQt0B,GACJ,OAAOmE,KAAKgvB,SAAS/pB,IAAIpJ,EAC7B,CAEAu0B,WAAAA,GACI,OAAOpwB,KAAKqvB,QAAQgB,YACxB,CAEA,mBAAIC,GACA,OAAOtwB,KAAK+uB,gBAChB,CAEAwB,YAAAA,GACI,OAAQvwB,KAAKqvB,QAAgBmB,UACjC,CAEA1e,QAAAA,GACI9R,KAAKqvB,QAAQoB,kBACjB,EAOE,MAAOC,WAAsB5B,GAS/B,WAAY5V,GACR,OAAOlZ,KAAKmS,MAAMnS,KAAKmS,MAAMlW,OAAS,EAC1C,CAEAf,WAAAA,CAAYsB,GACRrB,MAAMqB,GAVO,KAAAm0B,YAAc,IAAIpF,GAE3B,KAAApZ,MAAe,GACf,KAAAye,cAAgB,IAAIhkB,IAQxB5M,KAAK6wB,OAASr0B,EAASs0B,WAAWC,OAClC/wB,KAAKgxB,UAAYx0B,EAASuB,OAAOE,eACjC+B,KAAKixB,cAAgBz0B,EAAS+B,OAAO2yB,aACzC,CAEAx1B,IAAAA,CAAKA,EAAkBy1B,GACnB,MAAMxlB,EAAO3L,KAAKoxB,gBAAgB11B,GAC5B21B,EAAarxB,KAAKqvB,QAAQiC,YAAY1C,GAAelzB,EAAKG,MAAOmE,KAAKuxB,oBAAoB5lB,EAAMwlB,GAAMl0B,KAAK+C,OAKjH,OAJAA,KAAKgvB,SAAS9hB,IAAIxR,EAAKG,KAAMw1B,GACzB31B,EAAKqV,QACL/Q,KAAKwxB,SAAWH,GAEbA,CACX,CAEQD,eAAAA,CAAgB11B,GACpB,IAAIA,EAAKqK,SAAT,CAEO,IAAI0rB,EAAAA,EAAAA,IAAe/1B,GACtB,OAAOgzB,GACJ,CACH,MAAMgD,GAAWC,EAAAA,EAAAA,IAAoBj2B,GACrC,OAAe,OAARg2B,QAAQ,IAARA,EAAAA,EAAYh2B,EAAKG,IAC5B,EACJ,CAEA6I,KAAAA,CAAmC/I,GAA0C,IAA3BsX,EAAA7U,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAyB,CAAC,EACxE4B,KAAK2wB,YAAYjF,cAAc/vB,GAC/B,MAAMi2B,EAAc5xB,KAAK4xB,YAAc5xB,KAAKivB,MAAM4C,SAASl2B,GAC3DqE,KAAKqvB,QAAQ1zB,MAAQi2B,EAAYnF,OACjC,MAAM4E,EAAape,EAAQvX,KAAOsE,KAAKgvB,SAAS/pB,IAAIgO,EAAQvX,MAAQsE,KAAKwxB,SACzE,IAAKH,EACD,MAAM,IAAI3wB,MAAMuS,EAAQvX,KAAO,4BAAHiK,OAA+BsN,EAAQvX,KAAI,KAAM,2BAEjF,MAAMsG,EAASqvB,EAAWjvB,KAAKpC,KAAKqvB,QAAS,CAAC,GAI9C,OAHArvB,KAAK2wB,YAAYnE,eAAeoF,EAAY3E,QAC5CjtB,KAAKswB,gBAAgBwB,QACrB9xB,KAAK4xB,iBAAcvzB,EACZ,CACHS,MAAOkD,EACP+vB,YAAaH,EAAYI,OACzBC,YAAaL,EAAYM,OACzBC,aAAcnyB,KAAKqvB,QAAQ2C,OAEnC,CAEQT,mBAAAA,CAAoBn1B,EAAoCg2B,GAC5D,OAAQnxB,IAEJ,MAAMoxB,GAAcryB,KAAKowB,oBAA2B/xB,IAAVjC,EAC1C,GAAIi2B,EAAY,CACZ,MAAMz0B,EAAY,CAAExB,SACpB4D,KAAKmS,MAAMhS,KAAKvC,GACZxB,IAAUsyB,KACV9wB,EAAKkB,MAAQ,GAErB,CACA,IAAIkD,EACJ,IACIA,EAASowB,EAAenxB,EAC5B,CAAE,MAAOqxB,GACLtwB,OAAS3D,CACb,CAIA,YAHeA,IAAX2D,GAAwBqwB,IACxBrwB,EAAShC,KAAK6sB,aAEX7qB,EAEf,CAEQuwB,mBAAAA,CAAoB1b,GACxB,MAAM2b,EAAexyB,KAAK4xB,YAAa3E,OACvC,IAAKuF,EAAav2B,OACd,MAAO,GAEX,MAAM4uB,EAAShU,EAAMoT,YACrB,IAAK,IAAI1pB,EAAI,EAAGA,EAAIiyB,EAAav2B,OAAQsE,IAAK,CAE1C,GADciyB,EAAajyB,GACjB0pB,YAAcY,EACpB,OAAO2H,EAAa/xB,OAAO,EAAGF,EAEtC,CACA,OAAOiyB,EAAa/xB,OAAO,EAAG+xB,EAAav2B,OAC/C,CAEAw2B,OAAAA,CAAQxjB,EAAahD,EAAsB4f,GACvC,MAAMhV,EAAQ7W,KAAKqvB,QAAQqD,YAAYzjB,EAAKhD,GAC5C,IAAKjM,KAAKowB,eAAiBpwB,KAAK2yB,aAAa9b,GAAQ,CACjD,MAAM2b,EAAexyB,KAAKuyB,oBAAoB1b,GAC9C7W,KAAK2wB,YAAYnE,eAAegG,GAChC,MAAMtG,EAAWlsB,KAAK2wB,YAAY1E,cAAcpV,EAAOgV,IACjD,WAAE+G,EAAU,WAAEC,GAAe7yB,KAAK8yB,cAAcjH,GAChD3S,EAAUlZ,KAAKkZ,QACrB,GAAI0Z,EAAY,CACZ,MAAMG,GAAiBC,EAAAA,EAAAA,IAAUnH,GAAWhV,EAAMuV,MAAQpsB,KAAKgxB,UAAUiC,QAAQpc,EAAMuV,MAAOF,GAC9FlsB,KAAKsR,OAAOshB,EAAWM,SAAUN,EAAW/G,QAASkH,EAAgB7G,EAAU2G,EACnF,MAAO,GAAIlE,GAAezV,GAAU,CAChC,IAAIuK,EAAO5M,EAAMuV,OACZ4G,EAAAA,EAAAA,IAAUnH,KACXpI,EAAOzjB,KAAKgxB,UAAUiC,QAAQxP,EAAMyI,GAAU9lB,YAElD8S,EAAQpa,OAAS2kB,CACrB,CACJ,CACJ,CAQQkP,YAAAA,CAAa9b,GACjB,OAAQA,EAAMsc,uBAAyBC,MAAMvc,EAAMoT,cAA2C,kBAApBpT,EAAMqT,YAA2BkJ,MAAMvc,EAAMqT,UAC3H,CAEAmJ,OAAAA,CAAQpkB,EAAavT,EAAkBqK,EAAmB8lB,EAA0B5qB,GAChF,IAAIqyB,EACCtzB,KAAKowB,eAAkBrqB,IAKxButB,EAAUtzB,KAAK2wB,YAAY/E,mBAAmBC,IAElD,MAAM0H,EAAgBvzB,KAAKqvB,QAAQmE,YAAYvkB,EAAKvT,EAAMuF,IACrDjB,KAAKowB,eAAiBkD,GAAWA,EAAQr3B,OAAS,GACnD+D,KAAKyzB,yBAAyBF,EAAe1H,EAASyH,EAE9D,CAEQG,wBAAAA,CAAyBzxB,EAAa6pB,EAA0ByH,GACpE,MAAM,WAAEV,EAAU,WAAEC,GAAe7yB,KAAK8yB,cAAcjH,GACtD,GAAI+G,EACA5yB,KAAKsR,OAAOshB,EAAWM,SAAUN,EAAW/G,QAAS7pB,EAAQsxB,EAAST,QACnE,IAAKD,EAAY,CAMpB,MAAM1Z,EAAUlZ,KAAKkZ,QACrB,GAAIyV,GAAezV,GACfA,EAAQpa,OAASkD,EAAOoE,gBACrB,GAAsB,kBAAXpE,GAAuBA,EAAQ,CAC7C,MACM0xB,EADS1zB,KAAK2zB,sBAAsB3xB,EAAQkX,GAElDlZ,KAAKmS,MAAM4H,MACX/Z,KAAKmS,MAAMhS,KAAKuzB,EACpB,CACJ,CACJ,CAEAE,MAAAA,CAAOx3B,EAAew3B,GAClB,IAAK5zB,KAAKowB,cAAe,CACrB,IAAI3f,EAAOzQ,KAAKkZ,QAChB,GAAI0a,EAAO/H,SAAW+H,EAAOV,SAAU,CACnCziB,EAAOzQ,KAAK6sB,YACZ7sB,KAAK2wB,YAAYrE,WAAW7b,EAAKsc,UACpB/sB,KAAK2wB,YAAY/E,mBAAmBgI,GAC5CvK,QAAQlpB,KAAKsQ,EAAKsc,UACvB,MAAM2G,EAAU,CAAEt3B,SAClB4D,KAAKmS,MAAMhS,KAAKuzB,GAChB1zB,KAAKsR,OAAOsiB,EAAOV,SAAUU,EAAO/H,QAASpb,EAAMA,EAAKsc,UAAU,EACtE,MACItc,EAAKrU,MAAQA,CAErB,CACJ,CAEAywB,SAAAA,GACI,GAAI7sB,KAAKowB,cACL,OAEJ,MAAMyD,EAAM7zB,KAAKkZ,QAIjB,OAHA4a,EAAAA,GAAAA,IAAuBD,GACvB7zB,KAAK2wB,YAAY9D,UAAUgH,GAC3B7zB,KAAKmS,MAAM4H,MACP4U,GAAekF,GACR7zB,KAAKgxB,UAAUiC,QAAQY,EAAI/0B,MAAO+0B,EAAI9G,YAE7CgH,EAAAA,GAAAA,IAA0B/zB,KAAKixB,cAAe4C,GAE3CA,EACX,CAEQf,aAAAA,CAAcjH,GAClB,IAAK7rB,KAAK4wB,cAAc5a,IAAI6V,GAAU,CAClC,MAAM+G,GAAaoB,EAAAA,GAAAA,IAAmBnI,EAASoI,EAAAA,IAC/Cj0B,KAAK4wB,cAAc1jB,IAAI2e,EAAS,CAC5B+G,WAAYA,EACZC,aAAYD,IAAasB,EAAAA,EAAAA,IAAiBtB,EAAWuB,WAE7D,CACA,OAAOn0B,KAAK4wB,cAAc3rB,IAAI4mB,EAClC,CAEQva,MAAAA,CAAO4hB,EAAkBrH,EAAiB/sB,EAAgBw0B,EAAkBT,GAChF,MAAMgB,EAAM7zB,KAAKkZ,QACjB,IAAIzb,EAMJ,OAJIA,EADAo1B,GAA+B,kBAAV/zB,EACdkB,KAAK6wB,OAAOuD,eAAeP,EAAKhI,EAASyH,EAASx0B,GAElDA,EAEHo0B,GACJ,IAAK,IACDW,EAAIhI,GAAWpuB,EACf,MAEJ,IAAK,KACDo2B,EAAIhI,IAAW,EACf,MAEJ,IAAK,KACIzrB,MAAMrB,QAAQ80B,EAAIhI,MACnBgI,EAAIhI,GAAW,IAEnBgI,EAAIhI,GAAS1rB,KAAK1C,GAG9B,CAEQk2B,qBAAAA,CAAsB7nB,EAAavC,GACvC,IAAK,MAAO1N,EAAMw4B,KAAkBn1B,OAAOo1B,QAAQ/qB,GAAS,CACxD,MAAMmB,EAAWoB,EAAOjQ,QACPwC,IAAbqM,EACAoB,EAAOjQ,GAAQw4B,EACRj0B,MAAMrB,QAAQ2L,IAAatK,MAAMrB,QAAQs1B,KAChDA,EAAcl0B,QAAQuK,GACtBoB,EAAOjQ,GAAQw4B,EAEvB,CAMA,MAAME,EAAgBzoB,EAAOihB,SAK7B,OAJIwH,IACAA,EAAczH,aAAUzuB,EACxByN,EAAOihB,cAAW1uB,GAEfyN,CACX,CAEA,oBAAI0oB,GACA,OAAOx0B,KAAKqvB,QAAQmF,gBACxB,EASE,MAAgBC,GAElBC,yBAAAA,CAA0BzhB,GAMtB,OAAO0hB,EAAAA,GAA2BD,0BAA0BzhB,EAChE,CAEA2hB,6BAAAA,CAA8B3hB,GAI1B,OAAO0hB,EAAAA,GAA2BC,8BAA8B3hB,EACpE,CAEA4hB,uBAAAA,CAAwB5hB,GAOpB,OAAO0hB,EAAAA,GAA2BE,wBAAwB5hB,EAC9D,CAEA6hB,qBAAAA,CAAsB7hB,GAOlB,OAAO0hB,EAAAA,GAA2BG,sBAAsB7hB,EAC5D,EAIE,MAAO8hB,WAA0CN,GAE1CC,yBAAAA,CAAyBM,GAKjC,IALkC,SAAEC,EAAQ,OAAEC,GAK9CF,EACG,MAAMG,EAAcF,EAASG,MACvB,IAAMH,EAASG,MAAQ,IACvBH,EAASp5B,KAAKgzB,SAAS,OAAM,YAAAlpB,OACbsvB,EAASp5B,KAAKG,UAAU,EAAGi5B,EAASp5B,KAAKI,OAAS,GAAE,uBAAA0J,OAC9CsvB,EAASp5B,KAAI,KACzC,MAAO,aAAP8J,OAAoBwvB,EAAW,gBAAAxvB,OAAgBuvB,EAAO9I,MAAK,KAC/D,CAESwI,6BAAAA,CAA6BS,GAGrC,IAHsC,eAAEC,GAGxCD,EACG,MAAO,oCAAP1vB,OAA4C2vB,EAAelJ,MAAK,KACpE,EASE,MAAOmJ,WAAgCzG,GAA7C5zB,WAAAA,G,oBACY,KAAAuxB,OAAmB,GAEnB,KAAA+I,aAAkC,GAClC,KAAAC,iBAAsC,GACtC,KAAAC,eAAiB,EACjB,KAAAC,UAAY,CAmGxB,CAjGI/B,MAAAA,GACI,CAGJ/G,SAAAA,GAGA,CAEAnoB,KAAAA,CAAM/I,GACFqE,KAAK41B,aACL,MAAMnJ,EAASzsB,KAAKivB,MAAM4C,SAASl2B,EAAO,CAAEyzB,KAAM,YAKlD,OAJApvB,KAAKysB,OAASA,EAAOA,OACrBzsB,KAAKqvB,QAAQ1zB,MAAQ,IAAIqE,KAAKysB,QAC9BzsB,KAAKwxB,SAASpvB,KAAKpC,KAAKqvB,QAAS,CAAC,GAClCrvB,KAAKswB,gBAAgBwB,QACd,CACHrF,OAAQzsB,KAAKysB,OACb+I,aAAc,IAAIx1B,KAAKy1B,kBACvBI,WAAY71B,KAAK01B,eAEzB,CAEAh6B,IAAAA,CAAKA,EAAkBy1B,GACnB,MAAME,EAAarxB,KAAKqvB,QAAQiC,YAAY1C,GAAelzB,EAAKG,MAAOmE,KAAKuxB,oBAAoBJ,GAAMl0B,KAAK+C,OAK3G,OAJAA,KAAKgvB,SAAS9hB,IAAIxR,EAAKG,KAAMw1B,GACzB31B,EAAKqV,QACL/Q,KAAKwxB,SAAWH,GAEbA,CACX,CAEQuE,UAAAA,GACJ51B,KAAKw1B,aAAe,GACpBx1B,KAAKy1B,iBAAmB,GACxBz1B,KAAK01B,eAAiB,EACtB11B,KAAK21B,UAAY,CACrB,CAEQpE,mBAAAA,CAAoBa,GACxB,OAAQnxB,IACJ,MAAM4Q,EAAO7R,KAAK81B,gBAClB,IACI1D,EAAenxB,EACnB,CAAE,QACEjB,KAAK+1B,eAAelkB,EACxB,EAER,CAEQmkB,wBAAAA,GACJh2B,KAAKw1B,aAAa/0B,OAAOT,KAAK21B,UAClC,CAEAG,aAAAA,GACI,MAAMjkB,EAAO7R,KAAKw1B,aAAav5B,OAE/B,OADA+D,KAAK21B,UAAY9jB,EACVA,CACX,CAEAkkB,cAAAA,CAAelkB,GACX7R,KAAKg2B,2BACLh2B,KAAK21B,UAAY9jB,CACrB,CAEA4gB,OAAAA,CAAQxjB,EAAahD,EAAsB4f,GACvC7rB,KAAKqvB,QAAQqD,YAAYzjB,EAAKhD,GACzBjM,KAAKowB,gBACNpwB,KAAKy1B,iBAAmB,IAAIz1B,KAAKw1B,aAAc3J,GAC/C7rB,KAAK01B,eAAiB11B,KAAKi2B,QAAU,EAE7C,CAEA5C,OAAAA,CAAQpkB,EAAavT,EAAkBqK,EAAmB8lB,EAA0B5qB,GAChFjB,KAAKk2B,OAAOrK,GACZ7rB,KAAKqvB,QAAQmE,YAAYvkB,EAAKvT,EAAMuF,GACpCjB,KAAKm2B,MAAMtK,EACf,CAEAqK,MAAAA,CAAO9I,GACEptB,KAAKowB,eACNpwB,KAAKw1B,aAAar1B,KAAKitB,EAE/B,CAEA+I,KAAAA,CAAM/I,GACF,IAAKptB,KAAKowB,cAAe,CACrB,MAAM7nB,EAAQvI,KAAKw1B,aAAapyB,YAAYgqB,GACxC7kB,GAAS,GACTvI,KAAKw1B,aAAa/0B,OAAO8H,EAEjC,CACJ,CAEA,WAAI0tB,GACA,OAAQj2B,KAAKqvB,QAAgB4G,OACjC,EAGJ,MAAMG,GAA+B,CACjCC,iBAAiB,EACjBC,qBAAsB,OACtB9G,iBAAiB,EACjBC,qBAAsB,IAAIsF,IAO9B,MAAMzF,WAA0BiH,EAAAA,GAK5Br7B,WAAAA,CAAYuxB,EAAyB1a,GACjC,MAAMykB,EAAsBzkB,GAAU,iBAAkBA,EACxD5W,MAAMsxB,EAAMvtB,OAAAoS,OAAApS,OAAAoS,OAAApS,OAAAoS,OAAA,GACL8kB,IAAa,CAChBK,kBAAmBD,EACb,IAAIxjB,EAAAA,GAAqB,CAAEmB,aAAcpC,EAAOoC,eAChD,IAAIpB,EAAwB,CAE1BG,QAASnB,EAAOyd,gBAAkB,YAAYnxB,MAEnD0T,GAEX,CAEA,gBAAIse,GACA,OAAOrwB,KAAK02B,eAChB,CAEApF,WAAAA,CAAYz1B,EAAcs1B,GACtB,OAAOnxB,KAAK22B,KAAK96B,EAAMs1B,EAC3B,CAEAV,gBAAAA,GACIzwB,KAAK42B,qBACT,CAEAlE,WAAAA,CAAYzjB,EAAahD,GACrB,OAAOjM,KAAKyyB,QAAQxjB,EAAKhD,EAC7B,CAEAunB,WAAAA,CAAYvkB,EAAavT,EAAkBuF,GACvC,OAAOjB,KAAKqzB,QAAQpkB,EAAKvT,EAAM,CAC3Bm7B,KAAM,CAAC51B,IAEf,CAEA4uB,MAAAA,CAAO5gB,EAAa2gB,GAChB5vB,KAAK82B,GAAG7nB,EAAK2gB,EACjB,CAEAE,UAAAA,CAAW7gB,EAAanP,GACpBE,KAAK6O,OAAOI,EAAKnP,EACrB,CAEAkwB,QAAAA,CAAS/gB,EAAanP,GAClBE,KAAK+vB,KAAK9gB,EAAKnP,EACnB,CAEAowB,cAAAA,CAAejhB,EAAanP,GACxBE,KAAKiwB,WAAWhhB,EAAKnP,EACzB,E,4BC5pBE,SAAUi3B,GAAmCC,EAAkBj5B,EAAW0uB,GAO5E,OAGJ,SAAoBwK,EAA8BD,GAC9C,MAAME,GAAYC,EAAAA,EAAAA,IAAqBH,GAAS,GAC1CI,GAAcC,EAAAA,GAAAA,IAAOL,EAAQzqB,OAAOyD,OAAOsnB,EAAAA,IAActnB,OAAOtU,GAAQw7B,EAAUlhB,IAAIta,IAC5F,IAAK,MAAMA,KAAQ07B,EAAa,CAC5B,MAAMG,EAAGr4B,OAAAoS,OAAApS,OAAAoS,OAAA,GACF2lB,GAAa,CAChBxE,QAAS,EACT3jB,SAAU,EACVukB,QAAS,EACTtD,KAAM,EACN+G,GAAI,IAERG,EAAcl5B,OAAOrC,KAAKA,EAAM87B,GAAaD,EAAK77B,EAAK+S,YAC3D,CACJ,CAlBIgpB,CALqC,CACjC15B,SACA0uB,SACAiL,UAAW,IAAI9qB,KAEOoqB,GACnBj5B,CACX,CAkBA,SAASy5B,GAAaD,EAAkBnK,GAA6C,IAC7EuK,EAD0DC,EAAWx5B,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAEzE,IAAI40B,EAAAA,EAAAA,IAAU5F,GACVuK,EAkOR,SAAsBJ,EAAkBM,GACpC,MAAM5oB,EAAMsoB,EAAI9E,UACV5b,EAAQ0gB,EAAI9K,OAAOoL,EAAQ/4B,OACjC,IAAK+X,EACD,MAAM,IAAInW,MAAM,qCAAuCm3B,EAAQ/4B,OAEnE,MAAO,IAAMy4B,EAAIx5B,OAAO00B,QAAQxjB,EAAK4H,EAAOghB,EAChD,CAzOiBC,CAAaP,EAAKnK,QACxB,IAAI2K,EAAAA,EAAAA,IAAS3K,GAChBuK,EAsBR,SAAqBJ,EAAkB3D,GACnC,MAAMoE,GAAaC,EAAAA,EAAAA,IAAYrE,GAC/B,MAAO,IAAM2D,EAAIx5B,OAAO61B,OAAOoE,EAAYpE,EAC/C,CAzBiBsE,CAAYX,EAAKnK,QACvB,IAAI6G,EAAAA,EAAAA,IAAa7G,GACpBuK,EAASH,GAAaD,EAAKnK,EAAQ+G,eAChC,IAAID,EAAAA,EAAAA,IAAiB9G,GACxBuK,EAASQ,GAAoBZ,EAAKnK,QAC/B,IAAIgL,EAAAA,EAAAA,IAAWhL,GAClBuK,EAqBR,SAAuBJ,EAAkBc,GACrC,MAAM38B,EAAO28B,EAAS38B,KAAK48B,IAC3B,IAAIhB,EAAAA,EAAAA,IAAa57B,GAAO,CACpB,MAAMuT,EAAMsoB,EAAIlE,UACVttB,EAAWrK,EAAKqK,SAChBgF,EAAYstB,EAASj6B,UAAUnC,OAAS,EAatD,SAAgCP,EAAkB68B,GAC9C,MAAM3lB,EAAa2lB,EAAU/pB,IAAIpN,GAAKo3B,GAAep3B,EAAEtC,QACvD,OAAQmC,IACJ,MAAMw3B,EAAiB,CAAC,EACxB,IAAK,IAAIl4B,EAAI,EAAGA,EAAIqS,EAAW3W,OAAQsE,IAAK,CACxC,MAAMm4B,EAAah9B,EAAKmqB,WAAWtlB,GAC7BwK,EAAY6H,EAAWrS,GAC7Bk4B,EAASC,EAAW78B,MAAQkP,EAAU9J,EAC1C,CACA,OAAOw3B,EAEf,CAxB0DE,CAAuBj9B,EAAM28B,EAASj6B,WAAa,KAAM,CAAG,GAC9G,OAAQ6C,GAASs2B,EAAIx5B,OAAOs1B,QAAQpkB,EAAKkhB,GAAQoH,EAAK77B,GAAOqK,EAAUsyB,EAAUttB,EAAU9J,GAC/F,CAAO,IAAI23B,EAAAA,EAAAA,IAAel9B,GAAO,CAC7B,MAAMuT,EAAMsoB,EAAI9E,UACVkF,EAASkB,GAAStB,EAAK77B,EAAKG,MAClC,MAAO,IAAM07B,EAAIx5B,OAAO00B,QAAQxjB,EAAK0oB,EAAQU,EACjD,CAAO,IAAK38B,EACR,MAAM,IAAIwP,GAAAA,EAAkBmtB,EAAStL,SAAU,mBAAFpnB,OAAqB0yB,EAAS38B,KAAKo9B,YAEhFttB,EAAAA,GAAAA,GAAkB9P,EAE1B,CArCiBq9B,CAAcxB,EAAKnK,QACzB,IAAI4L,EAAAA,EAAAA,IAAe5L,GACtBuK,EA6ER,SAA2BJ,EAAkB5H,GACzC,GAAqC,IAAjCA,EAAa1d,SAAShW,OACtB,OAAOu7B,GAAaD,EAAK5H,EAAa1d,SAAS,IAC5C,CACH,MAAMgnB,EAA8B,GAEpC,IAAK,MAAM7L,KAAWuC,EAAa1d,SAAU,CACzC,MAAMinB,EAAqC,CAGvCC,IAAK3B,GAAaD,EAAKnK,GAAS,IAE9B/jB,EAAQ+vB,GAAkBhM,GAC5B/jB,IACA6vB,EAAiB/jB,KAAOqjB,GAAenvB,IAE3C4vB,EAAQ94B,KAAK+4B,EACjB,CAEA,MAAMjqB,EAAMsoB,EAAIT,KAChB,OAAQ71B,GAASs2B,EAAIx5B,OAAO4xB,aAAa1gB,EAAKgqB,EAAQzqB,IAAImpB,IACtD,MAAMxmB,EAAuB,CACzBgoB,IAAKA,IAAMxB,EAAOwB,IAAIl4B,IAEpBiU,EAAOyiB,EAAOxiB,KAIpB,OAHID,IACA/D,EAAIgE,KAAO,IAAMD,EAAKjU,IAEnBkQ,IAEf,CACJ,CA5GiBkoB,CAAkB9B,EAAKnK,QAC7B,IAAIkM,EAAAA,EAAAA,IAAiBlM,GACxBuK,EA4GR,SAA6BJ,EAAkBgC,GAC3C,GAA8B,IAA1BA,EAAMtnB,SAAShW,OACf,OAAOu7B,GAAaD,EAAKgC,EAAMtnB,SAAS,IAE5C,MAAMgnB,EAA8B,GAEpC,IAAK,MAAM7L,KAAWmM,EAAMtnB,SAAU,CAClC,MAAMinB,EAAqC,CAGvCC,IAAK3B,GAAaD,EAAKnK,GAAS,IAE9B/jB,EAAQ+vB,GAAkBhM,GAC5B/jB,IACA6vB,EAAiB/jB,KAAOqjB,GAAenvB,IAE3C4vB,EAAQ94B,KAAK+4B,EACjB,CAEA,MAAMM,EAAQjC,EAAIT,KAEZ2C,EAASA,CAACC,EAAkBC,KAC9B,MAAMC,EAAUD,EAAQpJ,eAAe7sB,KAAK,KAC5C,MAAO,UAAPiC,OAAiB+zB,EAAQ,KAAA/zB,OAAIi0B,IAE3BjK,EAAwB1uB,GAASs2B,EAAIx5B,OAAO4xB,aAAa6J,EAAOP,EAAQzqB,IAAI,CAACmpB,EAAQ1oB,KACvF,MAAMkC,EAAuB,CAAEgoB,IAAKA,KAAM,GACpCp7B,EAASw5B,EAAIx5B,OACnBoT,EAAIgoB,IAAM,KAEN,GADAxB,EAAOwB,IAAIl4B,IACNlD,EAAOqyB,cAAe,CACvB,MAAM1nB,EAAM+wB,EAAOD,EAAOz7B,GACrBA,EAAOuyB,gBAAgBrrB,IAAIyD,IAE5B3K,EAAOuyB,gBAAgBpjB,IAAIxE,EAAK,IAEpC,MAAMmxB,EAAa97B,EAAOuyB,gBAAgBrrB,IAAIyD,GACb,qBAAZ,OAAVmxB,QAAU,IAAVA,OAAU,EAAVA,EAAa5qB,MAEpB4qB,EAAW5qB,IAAO,EAE1B,GAEJ,MAAMiG,EAAOyiB,EAAOxiB,KAUpB,OARIhE,EAAIgE,KADJD,EACW,IAAMA,EAAKjU,GAEX,KACP,MAAM64B,EAAsB/7B,EAAOuyB,gBAAgBrrB,IAAIw0B,EAAOD,EAAOz7B,IAErE,QADkC,OAAnB+7B,QAAmB,IAAnBA,OAAmB,EAAnBA,EAAsB7qB,KAItCkC,KAEL4oB,EAAUC,GAAKzC,EAAK6B,GAAkBG,GAAQ5J,EAAc,KAClE,OAAQ1uB,IACJ84B,EAAQ94B,GACHs2B,EAAIx5B,OAAOqyB,eACZmH,EAAIx5B,OAAOuyB,gBAAgB2J,OAAOR,EAAOD,EAAOjC,EAAIx5B,SAGhE,CA1KiBm8B,CAAoB3C,EAAKnK,QAC/B,IAAI+M,EAAAA,EAAAA,IAAQ/M,GACfuK,EA0KR,SAAoBJ,EAAkBgC,GAClC,MAAMN,EAAUM,EAAMtnB,SAASzD,IAAIpN,GAAKo2B,GAAaD,EAAKn2B,IAC1D,OAAQH,GAASg4B,EAAQxkB,QAAQkjB,GAAUA,EAAO12B,GACtD,CA7KiBm5B,CAAW7C,EAAKnK,OACtB,MAAGiN,EAAAA,EAAAA,IAAYjN,GAIlB,MAAM,IAAIliB,GAAAA,EAAkBkiB,EAAQL,SAAU,4BAAFpnB,OAA8BynB,EAAQhxB,QAJtD,CAC5B,MAAM6S,EAAMsoB,EAAI9E,UAChBkF,EAASA,IAAMJ,EAAIx5B,OAAO00B,QAAQxjB,EAAKqrB,EAAAA,GAAKlN,EAChD,CAEA,CACA,OAAO4M,GAAKzC,EAAKK,OAAcv5B,EAAY+6B,GAAkBhM,GAAUuK,EAAQvK,EAAQmN,YAC3F,CA2CA,SAAS/B,GAAegC,GACpB,IAAIC,EAAAA,EAAAA,IAAcD,GAAY,CAC1B,MAAMxsB,EAAOwqB,GAAegC,EAAUxsB,MAChCC,EAAQuqB,GAAegC,EAAUvsB,OACvC,OAAQhN,GAAU+M,EAAK/M,IAASgN,EAAMhN,EAC1C,CAAO,IAAIy5B,EAAAA,EAAAA,IAAcF,GAAY,CACjC,MAAMxsB,EAAOwqB,GAAegC,EAAUxsB,MAChCC,EAAQuqB,GAAegC,EAAUvsB,OACvC,OAAQhN,GAAU+M,EAAK/M,IAASgN,EAAMhN,EAC1C,CAAO,IAAI05B,EAAAA,EAAAA,IAAWH,GAAY,CAC9B,MAAM17B,EAAQ05B,GAAegC,EAAU17B,OACvC,OAAQmC,IAAUnC,EAAMmC,EAC5B,CAAO,IAAI25B,EAAAA,EAAAA,IAAqBJ,GAAY,CACxC,MAAM3+B,EAAO2+B,EAAUK,UAAUvC,IAAKz8B,KACtC,OAAQoF,QAAkB5C,IAAT4C,IAAqC,IAAfA,EAAKpF,EAChD,CAAO,IAAIi/B,EAAAA,EAAAA,IAAiBN,GAAY,CACpC,MAAM17B,EAAQonB,QAAQsU,EAAUO,MAChC,MAAO,IAAMj8B,CACjB,EACA0M,EAAAA,GAAAA,GAAkBgvB,EACtB,CAwGA,SAASpB,GAAkBhM,GACvB,IAAI+M,EAAAA,EAAAA,IAAQ/M,GACR,OAAOA,EAAQ4N,cAGvB,CAEA,SAAS7C,GAAoBZ,EAAkB0D,GAAsD,IAA5B9G,EAAQ/1B,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG68B,EAAS9G,SACzF,GAAKA,EAUE,KAAIiE,EAAAA,EAAAA,IAAWjE,KAAamD,EAAAA,EAAAA,IAAanD,EAASz4B,KAAK48B,KAAM,CAEhE,MAAM58B,EAAOy4B,EAASz4B,KAAK48B,IACrBrpB,EAAMsoB,EAAIlE,UAChB,OAAQpyB,GAASs2B,EAAIx5B,OAAOs1B,QAAQpkB,EAAKkhB,GAAQoH,EAAK77B,IAAO,EAAOu/B,EAAUh6B,EAClF,CAAO,IAAIm3B,EAAAA,EAAAA,IAAWjE,KAAayE,EAAAA,EAAAA,IAAezE,EAASz4B,KAAK48B,KAAM,CAClE,MAAMrpB,EAAMsoB,EAAI9E,UACVyI,EAAerC,GAAStB,EAAKpD,EAASz4B,KAAK48B,IAAIz8B,MACrD,MAAO,IAAM07B,EAAIx5B,OAAO00B,QAAQxjB,EAAKisB,EAAcD,EACvD,CAAO,IAAIjI,EAAAA,EAAAA,IAAUmB,GAAW,CAC5B,MAAMllB,EAAMsoB,EAAI9E,UACVoF,EAAUgB,GAAStB,EAAKpD,EAASr1B,OACvC,MAAO,IAAMy4B,EAAIx5B,OAAO00B,QAAQxjB,EAAK4oB,EAASoD,EAClD,CAEI,MAAM,IAAIv6B,MAAM,yCACpB,CA1Be,CACX,IAAKu6B,EAAStvB,KAAK2sB,IACf,MAAM,IAAI53B,MAAM,wCAA0Cu6B,EAAStvB,KAAKmtB,UAE5E,MAAMlG,GAAauI,EAAAA,EAAAA,IAAmBF,EAAStvB,KAAK2sB,KAC9C8C,EAA2B,OAAVxI,QAAU,IAAVA,OAAU,EAAVA,EAAYuB,SACnC,IAAKiH,EACD,MAAM,IAAI16B,MAAM,6CAA8Cu3B,EAAAA,EAAAA,IAAYgD,EAAStvB,KAAK2sB,MAE5F,OAAOH,GAAoBZ,EAAK0D,EAAUG,EAC9C,CAiBJ,CAWA,SAASpB,GAAKzC,EAAkBluB,EAA8BsuB,EAAgB4C,GAC1E,MAAMrlB,EAAO7L,GAASmvB,GAAenvB,GAErC,IAAKkxB,EAAa,CACd,GAAIrlB,EAAM,CACN,MAAMjG,EAAMsoB,EAAIT,KAChB,OAAQ71B,GAASs2B,EAAIx5B,OAAO4xB,aAAa1gB,EAAK,CAC1C,CACIkqB,IAAKA,IAAMxB,EAAO12B,GAClBkU,KAAMA,IAAMD,EAAKjU,IAErB,CACIk4B,KAAKkC,EAAAA,EAAAA,MACLlmB,KAAMA,KAAOD,EAAKjU,KAG9B,CACI,OAAO02B,CAEf,CAEA,GAAoB,MAAhB4C,EAAqB,CACrB,MAAMtrB,EAAMsoB,EAAIxH,OAChB,OAAQ9uB,GAASs2B,EAAIx5B,OAAOgyB,KAAK9gB,EAAK,CAClCqsB,IAAKA,IAAM3D,EAAO12B,GAClBkU,KAAMD,EAAO,IAAMA,EAAKjU,QAAQ5C,GAExC,CAAO,GAAoB,MAAhBk8B,EAAqB,CAC5B,MAAMtrB,EAAMsoB,EAAIxH,OAChB,GAAI7a,EAAM,CACN,MAAMskB,EAAQjC,EAAIT,KAKlB,OAAQ71B,GAASs2B,EAAIx5B,OAAO4xB,aAAa6J,EAAO,CAC5C,CACIL,IAAKA,IAAM5B,EAAIx5B,OAAOkyB,WAAWhhB,EAAK,CAClCqsB,IAAKA,IAAM3D,EAAO12B,KAEtBkU,KAAMA,IAAMD,EAAKjU,IAErB,CACIk4B,KAAKkC,EAAAA,EAAAA,MACLlmB,KAAMA,KAAOD,EAAKjU,KAG9B,CACI,OAAQA,GAASs2B,EAAIx5B,OAAOkyB,WAAWhhB,EAAK,CACxCqsB,IAAKA,IAAM3D,EAAO12B,IAG9B,CAAO,GAAoB,MAAhBs5B,EAAqB,CAC5B,MAAMtrB,EAAMsoB,EAAIzoB,WAChB,OAAQ7N,GAASs2B,EAAIx5B,OAAO+Q,SAASG,EAAK,CACtCqsB,IAAKA,IAAM3D,EAAO12B,GAClBkU,KAAMD,EAAO,IAAMA,EAAKjU,QAAQ5C,GAExC,EACImN,EAAAA,GAAAA,GAAkB+uB,EAE1B,CAEA,SAASpK,GAAQoH,EAAoBnK,GACjC,MAAMvxB,EAMV,SAAqB07B,EAAoBnK,GACrC,IAAIkK,EAAAA,EAAAA,IAAalK,GACb,OAAOA,EAAQvxB,KACZ,GAAI07B,EAAIG,UAAU1hB,IAAIoX,GACzB,OAAOmK,EAAIG,UAAUzyB,IAAImoB,GACtB,CACH,IAAI3vB,EAAgB2vB,EAChBrF,EAAkBtqB,EAAK89B,WACvBC,EAAmBpO,EAAQhxB,MAC/B,OAAQk7B,EAAAA,EAAAA,IAAavP,IAAS,CAC1B,IAAIoS,EAAAA,EAAAA,IAAQpS,KAAWiR,EAAAA,EAAAA,IAAejR,KAAWuR,EAAAA,EAAAA,IAAiBvR,GAAS,CAEvEyT,EADczT,EAAO9V,SAASxM,QAAQhI,GACrB2I,WAAa,IAAMo1B,CACxC,CACA/9B,EAAOsqB,EACPA,EAASA,EAAOwT,UACpB,CAIA,OAFAC,EADazT,EACGlsB,KAAO,IAAM2/B,EAC7BjE,EAAIG,UAAUxqB,IAAIkgB,EAASoO,GACpBA,CACX,CACJ,CA5BiBC,CAAYlE,EAAKnK,GACxB1xB,EAAO67B,EAAIx5B,OAAOoyB,QAAQt0B,GAChC,IAAKH,EAAM,MAAM,IAAIgF,MAAM,SAADiF,OAAU9J,EAAI,kBACxC,OAAOH,CACX,CA0BA,SAASm9B,GAAStB,EAAoB17B,GAClC,MAAMgb,EAAQ0gB,EAAI9K,OAAO5wB,GACzB,IAAKgb,EAAO,MAAM,IAAInW,MAAM,UAADiF,OAAW9J,EAAI,kBAC1C,OAAOgb,CACX,CCnYM,SAAU6kB,GAAoBl/B,GAChC,MAAMuB,EASJ,SAA+BvB,GACjC,MAAMw6B,EAAUx6B,EAASm/B,QACnB1M,EAAQzyB,EAASuB,OAAOmxB,MACxBnxB,EAAS,IAAI2yB,GAAcl0B,GACjC,OAAOu6B,GAAaC,EAASj5B,EAAQkxB,EAAMxgB,WAC/C,CAdmBmtB,CAAqBp/B,GAEpC,OADAuB,EAAO+T,WACA/T,CACX,C,oDCQA,IAAI89B,GAAW,EACXC,GAA2B,GAuBxB,MAAMC,GAAqB32B,OAAO,sBAMnC,SAAU42B,GAAqB1J,GACjC,OAAOA,IAAQyJ,EACnB,CAaOE,eAAeC,GAAkBrlB,GACpC,GAAIA,IAAUslB,GAAAA,GAAkBx8B,KAE5B,OAEJ,MAAMuZ,EAAUkjB,YAAYC,MAS5B,GARInjB,EAAU2iB,IAAYC,KACtBD,GAAW3iB,QA/DR,IAAIojB,QAAQj5B,IAGa,qBAAjBk5B,aACPC,WAAWn5B,EAAS,GAEpBk5B,aAAal5B,KA8DjBw4B,GAAWO,YAAYC,OAEvBxlB,EAAM4lB,wBACN,MAAMV,EAEd,CAMM,MAAOW,GAAbxhC,WAAAA,GAII,KAAAyhC,QAAU,IAAIL,QAAW,CAACj5B,EAASu5B,KAC/B58B,KAAKqD,QAAWw5B,IACZx5B,EAAQw5B,GACD78B,MAEXA,KAAK48B,OAAUtK,IACXsK,EAAOtK,GACAtyB,OAGnB,ECvGA,MAAMspB,GACFpuB,WAAAA,CAAYwkB,EAAK8D,EAAYD,EAAS8F,GAClCrpB,KAAKmqB,KAAOzK,EACZ1f,KAAKoqB,YAAc5G,EACnBxjB,KAAKqqB,SAAW9G,EAChBvjB,KAAKsqB,SAAWjB,EAChBrpB,KAAKuqB,kBAAelsB,CACxB,CACA,OAAIqhB,GACA,OAAO1f,KAAKmqB,IAChB,CACA,cAAI3G,GACA,OAAOxjB,KAAKoqB,WAChB,CACA,WAAI7G,GACA,OAAOvjB,KAAKqqB,QAChB,CACAZ,OAAAA,CAAQre,GACJ,GAAIA,EAAO,CACP,MAAMC,EAAQrL,KAAK2pB,SAASve,EAAMC,OAC5B0D,EAAM/O,KAAK2pB,SAASve,EAAM2D,KAChC,OAAO/O,KAAKsqB,SAAStuB,UAAUqP,EAAO0D,EAC1C,CACA,OAAO/O,KAAKsqB,QAChB,CACAE,MAAAA,CAAOrH,EAASI,GACZ,IAAK,MAAMD,KAAUH,EACjB,GAAImG,GAAiBwT,cAAcxZ,GAAS,CAExC,MAAMlY,EAAQ2xB,GAAmBzZ,EAAOlY,OAElC6e,EAAcjqB,KAAK2pB,SAASve,EAAMC,OAClC6e,EAAYlqB,KAAK2pB,SAASve,EAAM2D,KACtC/O,KAAKsqB,SAAWtqB,KAAKsqB,SAAStuB,UAAU,EAAGiuB,GAAe3G,EAAOG,KAAOzjB,KAAKsqB,SAAStuB,UAAUkuB,EAAWlqB,KAAKsqB,SAASruB,QAEzH,MAAM4kB,EAAYiK,KAAKC,IAAI3f,EAAMC,MAAMC,KAAM,GACvCwV,EAAUgK,KAAKC,IAAI3f,EAAM2D,IAAIzD,KAAM,GACzC,IAAIof,EAAc1qB,KAAKuqB,aACvB,MAAMyS,EAAmBC,GAAmB3Z,EAAOG,MAAM,EAAOwG,GAChE,GAAInJ,EAAUD,IAAcmc,EAAiB/gC,OACzC,IAAK,IAAIsE,EAAI,EAAGC,EAAMw8B,EAAiB/gC,OAAQsE,EAAIC,EAAKD,IACpDmqB,EAAYnqB,EAAIsgB,EAAY,GAAKmc,EAAiBz8B,QAIlDy8B,EAAiB/gC,OAAS,IAC1ByuB,EAAYjqB,OAAOogB,EAAY,EAAGC,EAAUD,KAAcmc,GAG1Dh9B,KAAKuqB,aAAeG,EAAcA,EAAY5pB,MAAM,EAAG+f,EAAY,GAAGlb,OAAOq3B,EAAkBtS,EAAY5pB,MAAMggB,EAAU,IAGnI,MAAMiJ,EAAOzG,EAAOG,KAAKxnB,QAAUiuB,EAAYD,GAC/C,GAAa,IAATF,EACA,IAAK,IAAIxpB,EAAIsgB,EAAY,EAAImc,EAAiB/gC,OAAQuE,EAAMkqB,EAAYzuB,OAAQsE,EAAIC,EAAKD,IACrFmqB,EAAYnqB,GAAKmqB,EAAYnqB,GAAKwpB,CAG9C,KACK,KAAIT,GAAiB4T,OAAO5Z,GAK7B,MAAM,IAAI5iB,MAAM,iCAJhBV,KAAKsqB,SAAWhH,EAAOG,KACvBzjB,KAAKuqB,kBAAelsB,CAIxB,CAEJ2B,KAAKqqB,SAAW9G,CACpB,CACAkH,cAAAA,GAII,YAH0BpsB,IAAtB2B,KAAKuqB,eACLvqB,KAAKuqB,aAAe0S,GAAmBj9B,KAAKsqB,UAAU,IAEnDtqB,KAAKuqB,YAChB,CACAb,UAAAA,CAAWmB,GACPA,EAASC,KAAKC,IAAID,KAAK1S,IAAIyS,EAAQ7qB,KAAKsqB,SAASruB,QAAS,GAC1D,MAAMyuB,EAAc1qB,KAAKyqB,iBACzB,IAAIO,EAAM,EAAGC,EAAOP,EAAYzuB,OAChC,GAAa,IAATgvB,EACA,MAAO,CAAE3f,KAAM,EAAGC,UAAWsf,GAEjC,KAAOG,EAAMC,GAAM,CACf,MAAMC,EAAMJ,KAAKK,OAAOH,EAAMC,GAAQ,GAClCP,EAAYQ,GAAOL,EACnBI,EAAOC,EAGPF,EAAME,EAAM,CAEpB,CAGA,MAAM5f,EAAO0f,EAAM,EAEnB,MAAO,CAAE1f,OAAMC,WADfsf,EAAS7qB,KAAKm9B,gBAAgBtS,EAAQH,EAAYpf,KACfof,EAAYpf,GACnD,CACAqe,QAAAA,CAASvH,GACL,MAAMsI,EAAc1qB,KAAKyqB,iBACzB,GAAIrI,EAAS9W,MAAQof,EAAYzuB,OAC7B,OAAO+D,KAAKsqB,SAASruB,OAEpB,GAAImmB,EAAS9W,KAAO,EACrB,OAAO,EAEX,MAAM8f,EAAaV,EAAYtI,EAAS9W,MACxC,GAAI8W,EAAS7W,WAAa,EACtB,OAAO6f,EAEX,MAAMC,EAAkBjJ,EAAS9W,KAAO,EAAIof,EAAYzuB,OAAUyuB,EAAYtI,EAAS9W,KAAO,GAAKtL,KAAKsqB,SAASruB,OAC3G4uB,EAASC,KAAK1S,IAAIgT,EAAahJ,EAAS7W,UAAW8f,GACzD,OAAOrrB,KAAKm9B,gBAAgBtS,EAAQO,EACxC,CACA+R,eAAAA,CAAgBtS,EAAQO,GACpB,KAAOP,EAASO,GAAcgS,GAAMp9B,KAAKsqB,SAASpnB,WAAW2nB,EAAS,KAClEA,IAEJ,OAAOA,CACX,CACA,aAAItB,GACA,OAAOvpB,KAAKyqB,iBAAiBxuB,MACjC,CACA,oBAAO6gC,CAAcp7B,GACjB,MAAMyd,EAAYzd,EAClB,YAAqBrD,IAAd8gB,GAAyC,OAAdA,GACJ,kBAAnBA,EAAUsE,WAAyCplB,IAApB8gB,EAAU/T,aACrB/M,IAA1B8gB,EAAUke,aAA8D,kBAA1Ble,EAAUke,YACjE,CACA,aAAOH,CAAOx7B,GACV,MAAMyd,EAAYzd,EAClB,YAAqBrD,IAAd8gB,GAAyC,OAAdA,GACJ,kBAAnBA,EAAUsE,WAAyCplB,IAApB8gB,EAAU/T,YAAiD/M,IAA1B8gB,EAAUke,WACzF,EAEG,IAAIrU,GA8DX,SAASC,GAAUrB,EAAMsB,GACrB,GAAItB,EAAK3rB,QAAU,EAEf,OAAO2rB,EAEX,MAAMvgB,EAAKugB,EAAK3rB,OAAS,EAAK,EACxB+R,EAAO4Z,EAAK9mB,MAAM,EAAGuG,GACrB4G,EAAQ2Z,EAAK9mB,MAAMuG,GACzB4hB,GAAUjb,EAAMkb,GAChBD,GAAUhb,EAAOib,GACjB,IAAIC,EAAU,EACVC,EAAW,EACX7oB,EAAI,EACR,KAAO4oB,EAAUnb,EAAK/R,QAAUmtB,EAAWnb,EAAMhS,QAAQ,CACrD,MAAM2E,EAAMsoB,EAAQlb,EAAKmb,GAAUlb,EAAMmb,IAGrCxB,EAAKrnB,KAFLK,GAAO,EAEKoN,EAAKmb,KAILlb,EAAMmb,IAE1B,CACA,KAAOD,EAAUnb,EAAK/R,QAClB2rB,EAAKrnB,KAAOyN,EAAKmb,KAErB,KAAOC,EAAWnb,EAAMhS,QACpB2rB,EAAKrnB,KAAO0N,EAAMmb,KAEtB,OAAOxB,CACX,CACA,SAASqV,GAAmBxZ,EAAM6Z,GAA+B,IAAhBC,EAAUn/B,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAC1D,MAAM4D,EAASs7B,EAAgB,CAACC,GAAc,GAC9C,IAAK,IAAIh9B,EAAI,EAAGA,EAAIkjB,EAAKxnB,OAAQsE,IAAK,CAClC,MAAMqqB,EAAKnH,EAAKvgB,WAAW3C,GACvB68B,GAAMxS,KACK,KAAPA,GAA2CrqB,EAAI,EAAIkjB,EAAKxnB,QAAqC,KAA3BwnB,EAAKvgB,WAAW3C,EAAI,IACtFA,IAEJyB,EAAO7B,KAAKo9B,EAAah9B,EAAI,GAErC,CACA,OAAOyB,CACX,CACA,SAASo7B,GAAMI,GACX,OAAgB,KAATA,GAAsD,KAATA,CACxD,CACA,SAAST,GAAmB3xB,GACxB,MAAMC,EAAQD,EAAMC,MACd0D,EAAM3D,EAAM2D,IAClB,OAAI1D,EAAMC,KAAOyD,EAAIzD,MAASD,EAAMC,OAASyD,EAAIzD,MAAQD,EAAME,UAAYwD,EAAIxD,UACpE,CAAEF,MAAO0D,EAAKA,IAAK1D,GAEvBD,CACX,CACA,SAASqyB,GAAkBld,GACvB,MAAMnV,EAAQ2xB,GAAmBxc,EAASnV,OAC1C,OAAIA,IAAUmV,EAASnV,MACZ,CAAE8W,QAAS3B,EAAS2B,QAAS9W,SAEjCmV,CACX,EA3HA,SAAWyI,GAYPA,EAAa/J,OAHb,SAAgBS,EAAK8D,EAAYD,EAAS8F,GACtC,OAAO,IAAIC,GAAiB5J,EAAK8D,EAAYD,EAAS8F,EAC1D,EAoBAL,EAAawB,OATb,SAAgBX,EAAU1G,EAASI,GAC/B,GAAIsG,aAAoBP,GAEpB,OADAO,EAASW,OAAOrH,EAASI,GAClBsG,EAGP,MAAM,IAAInpB,MAAM,uEAExB,EA6BAsoB,EAAaY,WA3Bb,SAAoBC,EAAUjH,GAC1B,MAAMa,EAAOoG,EAASJ,UAChBK,EAAcb,GAAUrG,EAAMpU,IAAIivB,IAAoB,CAACt6B,EAAGyE,KAC5D,MAAMmiB,EAAO5mB,EAAEiI,MAAMC,MAAMC,KAAO1D,EAAEwD,MAAMC,MAAMC,KAChD,OAAa,IAATye,EACO5mB,EAAEiI,MAAMC,MAAME,UAAY3D,EAAEwD,MAAMC,MAAME,UAE5Cwe,IAEX,IAAIC,EAAqB,EACzB,MAAM0T,EAAQ,GACd,IAAK,MAAMt8B,KAAK0oB,EAAa,CACzB,MAAMG,EAAcJ,EAASF,SAASvoB,EAAEgK,MAAMC,OAC9C,GAAI4e,EAAcD,EACd,MAAM,IAAItpB,MAAM,oBAEXupB,EAAcD,GACnB0T,EAAMv9B,KAAKsjB,EAAKznB,UAAUguB,EAAoBC,IAE9C7oB,EAAE8gB,QAAQjmB,QACVyhC,EAAMv9B,KAAKiB,EAAE8gB,SAEjB8H,EAAqBH,EAASF,SAASvoB,EAAEgK,MAAM2D,IACnD,CAEA,OADA2uB,EAAMv9B,KAAKsjB,EAAKrc,OAAO4iB,IAChB0T,EAAMh6B,KAAK,GACtB,CAEH,CA5DD,CA4DGslB,KAAiBA,GAAe,CAAC,I,ICnJxB2U,G,aAAZ,SAAYA,GAKRA,EAAAA,EAAA,qBAMAA,EAAAA,EAAA,mBAKAA,EAAAA,EAAA,mCAQAA,EAAAA,EAAA,mCAKAA,EAAAA,EAAA,mBAMAA,EAAAA,EAAA,yCAKAA,EAAAA,EAAA,wBACH,CAzCD,CAAYA,KAAAA,GAAa,KA8GnB,MAAOC,GAMT1iC,WAAAA,CAAYsB,GACRwD,KAAK69B,gBAAkBrhC,EAASqC,gBAChCmB,KAAK89B,cAAgBthC,EAASuhC,UAAUC,cACxCh+B,KAAKi+B,mBAAqBzhC,EAASuhC,UAAUG,kBACjD,CAEA,aAAMC,CAAqCze,GAAoD,IAA1C0e,EAAiBhgC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG+9B,GAAAA,GAAkBx8B,KACvF,MAAM0pB,QAAgBrpB,KAAKi+B,mBAAmBI,SAAS3e,GACvD,OAAO1f,KAAKs+B,YAAe5e,EAAK2J,EAAS+U,EAC7C,CAIAG,gBAAAA,CAA8C5b,EAA4BjD,EAAW7I,GAEjF,OADA6I,EAAS,OAAHA,QAAG,IAAHA,EAAAA,EAAOxF,GAAAA,EAAIxV,MAAMie,EAAajD,KAChCyc,GAAAA,GAAkBtpB,GAAGgE,GACd7W,KAAKs+B,YAAe5e,EAAKiD,EAAc9L,GAEvC7W,KAAKif,OAAUS,EAAKiD,EAAc9L,EAEjD,CAIA2nB,UAAAA,CAAwC/a,EAAc/D,EAAU7I,GAC5D,OAAIslB,GAAAA,GAAkBtpB,GAAGgE,GACd7W,KAAKs+B,YAAe5e,EAAK+D,EAAM5M,GAE/B7W,KAAKif,OAAUS,EAAK+D,EAAM5M,EAEzC,CAEA4nB,SAAAA,CAAuCC,EAAUhf,GAC7C,OAAO1f,KAAKif,OAAUS,EAAK,CAAEif,OAAQD,GACzC,CAEUzf,MAAAA,CAAoCS,EAAU2J,EAAgDpW,GACpG,GAAuB,kBAAZoW,EAAsB,CAC7B,MAAMuV,EAAc5+B,KAAK0E,MAASgb,EAAK2J,EAASpW,GAChD,OAAOjT,KAAK6+B,sBAAyBD,EAAalf,OAAKrhB,EAAWgrB,EAEtE,CAAO,GAAI,WAAYA,EAAS,CAC5B,MAAMuV,EAAc,CAAE9/B,MAAOuqB,EAAQsV,OAAQxM,aAAc,GAAIJ,YAAa,IAC5E,OAAO/xB,KAAK6+B,sBAAyBD,EAAalf,EAEtD,CAAO,CACH,MAAMkf,EAAc5+B,KAAK0E,MAASgb,EAAK2J,EAAQI,UAAWxW,GAC1D,OAAOjT,KAAK6+B,sBAAsBD,EAAalf,EAAK2J,EACxD,CACJ,CAEU,iBAAMiV,CAAyC5e,EAAU2J,EAAgCyV,GAC/F,GAAuB,kBAAZzV,EAAsB,CAC7B,MAAMuV,QAAoB5+B,KAAK++B,WAAcrf,EAAK2J,EAASyV,GAC3D,OAAO9+B,KAAK6+B,sBAAyBD,EAAalf,OAAKrhB,EAAWgrB,EACtE,CAAO,CACH,MAAMuV,QAAoB5+B,KAAK++B,WAAcrf,EAAK2J,EAAQI,UAAWqV,GACrE,OAAO9+B,KAAK6+B,sBAAsBD,EAAalf,EAAK2J,EACxD,CACJ,CAaUwV,qBAAAA,CAAmDD,EAA6Blf,EAAUiD,EAA6Bc,GAC7H,IAAIoG,EACJ,GAAIlH,EACAkH,EAAW,CACP+U,cACAlf,MACAzO,MAAO0sB,GAAcqB,OACrBlO,WAAY,GACZnO,oBAED,CACH,MAAMsc,EAAqBj/B,KAAKk/B,yBAAyBxf,EAAK+D,GAC9DoG,EAAW,CACP+U,cACAlf,MACAzO,MAAO0sB,GAAcqB,OACrBlO,WAAY,GACZ,gBAAInO,GACA,OAAOsc,GACX,EAER,CAEA,OADCL,EAAY9/B,MAA2BqgC,UAAYtV,EAC7CA,CACX,CAEA,YAAMW,CAAoCX,EAAuCuU,G,QAE7E,MAAMgB,EAA6C,QAAnCjsB,EAAA0W,EAAS+U,YAAY9/B,MAAMiuB,gBAAQ,IAAA5Z,OAAA,EAAAA,EAAE5O,KAAK8oB,SACpD1K,EAAiC,QAAlBwK,EAAAntB,KAAK89B,qBAAa,IAAA3Q,OAAA,EAAAA,EAAEloB,IAAI4kB,EAASnK,IAAItZ,YACpDqd,EAAOd,EAAeA,EAAa8G,gBAAkBzpB,KAAKi+B,mBAAmBI,SAASxU,EAASnK,KAErG,GAAIiD,EACAzjB,OAAOC,eACH0qB,EACA,eACA,CACI/qB,MAAO6jB,QAGZ,CACH,MAAMsc,EAAqBj/B,KAAKk/B,yBAAyBrV,EAASnK,IAAK+D,GACvEvkB,OAAOC,eACH0qB,EACA,eACA,CACI5kB,IAAKg6B,GAGjB,CASA,OALIG,IAAY3b,IACZoG,EAAS+U,kBAAoB5+B,KAAK++B,WAAWlV,EAASnK,IAAK+D,EAAM2a,GAChEvU,EAAS+U,YAAY9/B,MAA2BqgC,UAAYtV,GAEjEA,EAAS5Y,MAAQ0sB,GAAcqB,OACxBnV,CACX,CAEUnlB,KAAAA,CAAyBgb,EAAU+D,EAAcxQ,GAEvD,OADiBjT,KAAK69B,gBAAgBwB,YAAY3f,GAClC3hB,OAAO2yB,cAAchsB,MAAS+e,EAAMxQ,EACxD,CAEU8rB,UAAAA,CAA8Brf,EAAU+D,EAAc2a,GAE5D,OADiBp+B,KAAK69B,gBAAgBwB,YAAY3f,GAClC3hB,OAAOuhC,YAAY56B,MAAS+e,EAAM2a,EACtD,CAEUc,wBAAAA,CAAyBxf,EAAU+D,GACzC,MAAMoa,EAAkB79B,KAAK69B,gBAC7B,IAAI0B,EACJ,MAAO,IACW,OAAPA,QAAO,IAAPA,EAAAA,EAAAA,EAAYvW,GAAa/J,OAC5BS,EAAItZ,WAAYy3B,EAAgBwB,YAAY3f,GAAKyP,iBAAiB3L,WAAY,EAAO,OAAJC,QAAI,IAAJA,EAAAA,EAAQ,GAGrG,EAuEE,MAAO+b,GAOTtkC,WAAAA,CAAYsB,GAFO,KAAAijC,YAA4C,IAAI7yB,IAG/D5M,KAAK0/B,uBAAyBljC,EAASuhC,UAAU4B,uBACjD3/B,KAAK69B,gBAAkBrhC,EAASqC,eACpC,CAEA,OAAI+gC,GACA,OAAOvI,EAAAA,GAAAA,IAAOr3B,KAAKy/B,YAAY1nB,SACnC,CAEA8nB,WAAAA,CAAYhW,GACR,MAAMiW,EAAYjW,EAASnK,IAAItZ,WAC/B,GAAIpG,KAAKy/B,YAAYzpB,IAAI8pB,GACrB,MAAM,IAAIp/B,MAAM,4BAADiF,OAA6Bm6B,EAAS,0BAEzD9/B,KAAKy/B,YAAYvyB,IAAI4yB,EAAWjW,EACpC,CAEAkW,WAAAA,CAAYrgB,GACR,MAAMogB,EAAYpgB,EAAItZ,WACtB,OAAOpG,KAAKy/B,YAAYx6B,IAAI66B,EAChC,CAEA,yBAAME,CAAoBtgB,EAAU0e,GAChC,IAAIvU,EAAW7pB,KAAK+/B,YAAYrgB,GAChC,OAAImK,IAGJA,QAAiB7pB,KAAK0/B,uBAAuBvB,QAAQze,EAAK0e,GAC1Dp+B,KAAK6/B,YAAYhW,GACVA,EACX,CAIAoW,cAAAA,CAAevgB,EAAU+D,EAAc2a,GACnC,GAAIA,EACA,OAAOp+B,KAAK0/B,uBAAuBlB,WAAW/a,EAAM/D,EAAK0e,GAAmB8B,KAAKrW,IAC7E7pB,KAAK6/B,YAAYhW,GACVA,IAER,CACH,MAAMA,EAAW7pB,KAAK0/B,uBAAuBlB,WAAW/a,EAAM/D,GAE9D,OADA1f,KAAK6/B,YAAYhW,GACVA,CACX,CACJ,CAEAsW,WAAAA,CAAYzgB,GACR,OAAO1f,KAAKy/B,YAAYzpB,IAAI0J,EAAItZ,WACpC,CAEAg6B,kBAAAA,CAAmB1gB,GACf,MAAMogB,EAAYpgB,EAAItZ,WAChBi6B,EAAargC,KAAKy/B,YAAYx6B,IAAI66B,GACxC,GAAIO,EAAY,CACGrgC,KAAK69B,gBAAgBwB,YAAY3f,GAAKoR,WAAWC,OACzDuP,OAAOD,GACdA,EAAWpvB,MAAQ0sB,GAAc4C,QACjCF,EAAWG,uBAAoBniC,EAC/BgiC,EAAWhZ,iBAAchpB,CAC7B,CACA,OAAOgiC,CACX,CAEAI,cAAAA,CAAe/gB,GACX,MAAMogB,EAAYpgB,EAAItZ,WAChBi6B,EAAargC,KAAKy/B,YAAYx6B,IAAI66B,GAKxC,OAJIO,IACAA,EAAWpvB,MAAQ0sB,GAAc4C,QACjCvgC,KAAKy/B,YAAYxF,OAAO6F,IAErBO,CACX,ECjZJ,MAAMK,GAAgBt7B,OAAO,iBAOvB,MAAOu7B,GAMTzlC,WAAAA,CAAYsB,GACRwD,KAAK4gC,WAAapkC,EAAS+B,OAAO2yB,cAClClxB,KAAK6gC,iBAAmB,IAAMrkC,EAAS+B,OAAOw/B,UAAU+C,iBACxD9gC,KAAK+gC,cAAgBvkC,EAASs0B,WAAWkQ,cACzChhC,KAAKihC,eAAiBzkC,EAASuhC,UAAUmD,cAC7C,CAEA,UAAMC,CAAKtX,GAA+D,IAApCiV,EAAW1gC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG+9B,GAAAA,GAAkBx8B,KAClE,IAAK,MAAM/B,KAAQwjC,EAAAA,GAAAA,IAAUvX,EAAS+U,YAAY9/B,aACxCo9B,GAAkB4C,IACxBuC,EAAAA,GAAAA,IAAiBzjC,GAAM6W,QAAQ6jB,GAAOt4B,KAAKshC,OAAOhJ,EAAKzO,GAE/D,CAEUyX,MAAAA,CAAOC,EAAwB1X,G,MACrC,MAAMyO,EAAMiJ,EAAQC,UAEpB,QAAiBnjC,IAAbi6B,EAAItD,KAAoB,CACxBsD,EAAItD,KAAO0L,GACX,IACI,MAAMne,EAAcviB,KAAKyhC,aAAaF,GACtC,IAAIG,EAAAA,GAAAA,IAAenf,GACf+V,EAAItD,KAAOzS,OAGX,GADA+V,EAAIqJ,iBAAmBpf,EACnBviB,KAAK6gC,mBAAmBV,YAAY5d,EAAYqf,aAAc,CAE9D,MAAMC,EAAa7hC,KAAK8hC,YAAYvf,GACpC+V,EAAItD,KAAiB,OAAV6M,QAAU,IAAVA,EAAAA,EAAc7hC,KAAK+hC,mBAAmBR,EAAShf,EAC9D,MAEI+V,EAAItD,UAAO32B,CAGvB,CAAE,MAAOi0B,GACLhxB,QAAQC,MAAM,mDAADoE,OAAoD2yB,EAAIQ,SAAQ,MAAMxG,GACnF,MAAM0P,EAAqC,QAAtB7uB,EAACmf,EAAcnnB,eAAO,IAAAgI,EAAAA,EAAI5L,OAAO+qB,GACtDgG,EAAItD,KAAI91B,OAAAoS,OAAApS,OAAAoS,OAAA,GACDiwB,GAAO,CACVp2B,QAAS,mDAAFxF,OAAqD2yB,EAAIQ,SAAQ,OAAAnzB,OAAMq8B,IAEtF,CAKAnY,EAASiH,WAAW3wB,KAAKm4B,EAC7B,CACJ,CAEAgI,MAAAA,CAAOzW,GACH,IAAK,MAAMyO,KAAOzO,EAASiH,kBACfwH,EAAyBtD,YACzBsD,EAAyBqJ,iBAErC9X,EAASiH,WAAa,EAC1B,CAEA2Q,YAAAA,CAAaF,GACT,MACMhf,EADQviB,KAAK+gC,cAAckB,SAASV,GAChBW,WAAWX,EAAQC,UAAU1I,UACvD,OAAkB,OAAXvW,QAAW,IAAXA,EAAAA,EAAeviB,KAAK+hC,mBAAmBR,EAClD,CAEAnN,cAAAA,CAAex2B,EAAeC,EAAkBskC,EAA8BC,GAG1E,MAAMvR,EAAS7wB,KACTwhC,EAA8B,CAChCa,SAAUF,EACVrJ,SAAUsJ,EAEV,OAAI9J,G,MACA,IAAIgK,EAAAA,GAAAA,IAAUtiC,KAAKg1B,MAEf,OAAOh1B,KAAKg1B,KACT,IAAIuN,EAAAA,GAAAA,IAAqBviC,KAAK2hC,kBAAmB,CAEpD,MAAME,EAAahR,EAAOiR,YAAY9hC,KAAK2hC,kBAC3C3hC,KAAKg1B,KAAiB,OAAV6M,QAAU,IAAVA,EAAAA,EACRhR,EAAOkR,mBAAmB,CAAEP,YAAWjV,UAAW3uB,EAAMC,YAAYmC,KAAK2hC,iBACjF,MAAO,QAAkBtjC,IAAd2B,KAAKg1B,KAAoB,CAEhCh1B,KAAKg1B,KAAO0L,GACZ,MAAM7W,GAAW2Y,EAAAA,GAAAA,IAAa5kC,GAAMuhC,UAC9BsD,EAAU5R,EAAO6R,cAAc,CAAElB,YAAWjV,UAAW3uB,EAAMC,aACnE,GAAI4kC,EAAQlhC,OAASsoB,GAAYA,EAAS5Y,MAAQ0sB,GAAcgF,eAE5D,OAAO3iC,KAAKg1B,UAAO32B,EAEvB2B,KAAKg1B,KAAmB,QAAZ7hB,EAAAsvB,EAAQ7kC,YAAI,IAAAuV,EAAAA,EAAIsvB,EAAQlhC,MACpCvB,KAAK2hC,iBAAmBc,EAAQG,MACxB,OAAR/Y,QAAQ,IAARA,GAAAA,EAAUiH,WAAW3wB,KAAKH,KAC9B,MAAO,GAAIA,KAAKg1B,OAAS0L,GACrB,MAAM,IAAIhgC,MAAM,yCAADiF,OAA0CkrB,EAAOoQ,eAAe4B,eAAejlC,GAAK,KAAA+H,OAAI9H,EAAQ,cAAA8H,OAAay8B,EAAO,OAEvI,OAAOE,EAAAA,GAAAA,IAAUtiC,KAAKg1B,MAAQh1B,KAAKg1B,UAAO32B,CAC9C,EACA,oBAAIykC,GACA,OAAO9iC,KAAK2hC,gBAChB,EACA,SAAIpgC,GACA,OAAOmgC,EAAAA,GAAAA,IAAe1hC,KAAKg1B,MAAQh1B,KAAKg1B,UAAO32B,CACnD,GAEJ,OAAOmjC,CACX,CAEUkB,aAAAA,CAAcnB,G,MACpB,IACI,MAAMhf,EAAcviB,KAAKyhC,aAAaF,GACtC,IAAIG,EAAAA,GAAAA,IAAenf,GACf,MAAO,CAAEhhB,MAAOghB,GAEpB,MAAMsf,EAAa7hC,KAAK8hC,YAAYvf,GACpC,OAAIsf,EACO,CAAEjkC,KAAMikC,EAAYe,MAAOrgB,GAG3B,CACHqgB,MAAOrgB,EACPhhB,MACIvB,KAAK+hC,mBAAmBR,EAAShf,GAGjD,CAAE,MAAO+P,GACLhxB,QAAQC,MAAM,mDAADoE,OAAoD47B,EAAQC,UAAU1I,SAAQ,MAAMxG,GACjG,MAAM0P,EAAqC,QAAtB7uB,EAACmf,EAAcnnB,eAAO,IAAAgI,EAAAA,EAAI5L,OAAO+qB,GACtD,MAAO,CACH/wB,MAAKrC,OAAAoS,OAAApS,OAAAoS,OAAA,GACEiwB,GAAO,CACVp2B,QAAS,mDAAFxF,OAAqD47B,EAAQC,UAAU1I,SAAQ,OAAAnzB,OAAMq8B,KAGxG,CACJ,CAEUF,WAAAA,CAAYiB,GAClB,GAAIA,EAAgBnlC,KAChB,OAAOmlC,EAAgBnlC,KAE3B,MAAMR,EAAM4C,KAAK6gC,mBAAmBd,YAAYgD,EAAgBnB,aAChE,OAAKxkC,EAGE4C,KAAKihC,eAAe+B,WAAW5lC,EAAIwhC,YAAY9/B,MAAOikC,EAAgBl9B,WAH7E,CAIJ,CAEUk8B,kBAAAA,CAAmBR,EAAwB0B,GAGjD,MAAMpZ,GAAW2Y,EAAAA,GAAAA,IAAajB,EAAQhV,WAAW4S,UAC7CtV,GAAYA,EAAS5Y,MAAQ0sB,GAAcgF,gBAC3CrhC,QAAQ4hC,KAAK,gFAADv9B,OAAiFkkB,EAASnK,IAAG,OAE7G,MAAMyjB,EAAgBnjC,KAAK4gC,WAAWwC,iBAAiB7B,GACvD,OAAAriC,OAAAoS,OAAApS,OAAAoS,OAAA,GACOiwB,GAAO,CACVp2B,QAAS,kCAAFxF,OAAoCw9B,EAAa,YAAAx9B,OAAW47B,EAAQC,UAAU1I,SAAQ,MAC7FmK,qBAER,EClNE,MAAOI,GACTC,OAAAA,CAAQ1lC,GACJ,GAtBF,SAAkBA,GACpB,MAA8C,kBAA/BA,EAAsB/B,IACzC,CAoBY0nC,CAAQ3lC,GACR,OAAOA,EAAK/B,IAGpB,CAEA2nC,WAAAA,CAAY5lC,GACR,OAAO6lC,EAAAA,EAAAA,IAAoB7lC,EAAKmvB,SAAU,OAC9C,ECjCE,IAAW2W,IAAjB,SAAiBA,GAEAA,EAAAv/B,SAAWw/B,GAAAA,EAAMx/B,SACjBu/B,EAAAx/B,QAAUy/B,GAAAA,EAAMz/B,QAChBw/B,EAAAt/B,QAAUu/B,GAAAA,EAAMv/B,QAChBs/B,EAAAz7B,SAAW07B,GAAAA,EAAM17B,SACjBy7B,EAAAx7B,YAAcy7B,GAAAA,EAAMz7B,YAEjBw7B,EAAAE,OAAhB,SAAuBzgC,EAAkByE,GACrC,OAAQ,OAADzE,QAAC,IAADA,OAAC,EAADA,EAAGiD,eAAgB,OAADwB,QAAC,IAADA,OAAC,EAADA,EAAGxB,WAChC,EAEgBs9B,EAAA//B,SAAhB,SAAyB8C,EAAoBkT,GACzC,MAAMkqB,EAA2B,kBAATp9B,EAAoBA,EAAOA,EAAKZ,KAClDi+B,EAAuB,kBAAPnqB,EAAkBA,EAAKA,EAAG9T,KAC1Ck+B,EAAYF,EAASG,MAAM,KAAKh0B,OAAO5O,GAAKA,EAAEnF,OAAS,GACvDgoC,EAAUH,EAAOE,MAAM,KAAKh0B,OAAO5O,GAAKA,EAAEnF,OAAS,GACzD,IAAIsE,EAAI,EACR,KAAOA,EAAIwjC,EAAU9nC,QACb8nC,EAAUxjC,KAAO0jC,EAAQ1jC,GADJA,KAO7B,MAFiB,MAAM2jC,OAAOH,EAAU9nC,OAASsE,GAClC0jC,EAAQnjC,MAAMP,GAAGmD,KAAK,IAEzC,EAEgBggC,EAAAlgC,UAAhB,SAA0Bkc,GACtB,OAAOxF,GAAAA,EAAIxV,MAAMgb,EAAItZ,YAAYA,UACrC,CAEH,CAhCD,CAAiBs9B,KAAAA,GAAQ,KCuDnB,MAAOS,GAKTjpC,WAAAA,CAAYsB,GACRwD,KAAKokC,aAAe5nC,EAASs0B,WAAWuT,aACxCrkC,KAAKuI,MAAQ/L,EAAS+B,OAAOw/B,UAAUuG,aACvCtkC,KAAKukC,YAAc/nC,EAASuhC,UAAUmD,cAC1C,CAEAsD,eAAAA,CAAgBC,GACZ,GAAIA,EAAe,CACf,MAAM7R,GAAa8R,EAAAA,EAAAA,IAAeD,GAC5BE,EAAWF,EAAc3X,QAC/B,GAAI8F,GAAc+R,EAAU,CACxB,MAAMnD,EAAamD,EAA4B/R,EAAW/G,SAE1D,IAAI+Y,EAAAA,GAAAA,IAAYpD,GACZ,OAAOA,EAAUlJ,IACd,GAAIl4B,MAAMrB,QAAQyiC,GACrB,IAAK,MAAMlJ,KAAOkJ,EACd,IAAIoD,EAAAA,GAAAA,IAAYtM,IAAQA,EAAI+J,UACrB/J,EAAI+J,SAASxX,QAAU4Z,EAAc5Z,QACrCyN,EAAI+J,SAAStzB,KAAO01B,EAAc11B,IACrC,OAAOupB,EAAIA,GAI3B,CACA,GAAIqM,EAAU,CACV,MAAME,EAAW7kC,KAAKokC,aAAaZ,YAAYmB,GAE/C,GAAIE,IAAaA,IAAaJ,IAAiBK,EAAAA,EAAAA,IAAYL,EAAeI,IACtE,OAAOF,CAEf,CACJ,CAEJ,CAEAI,mBAAAA,CAAoBN,GAChB,MAAM3X,EAAU9sB,KAAKwkC,gBAAgBC,GACrC,GAAW,OAAP3X,QAAO,IAAPA,OAAO,EAAPA,EAASC,SAAU,CACnB,MAAMiY,EAAahlC,KAAKokC,aAAaZ,YAAY1W,GACjD,OAAiB,OAAVkY,QAAU,IAAVA,EAAAA,EAAclY,EAAQC,QACjC,CAEJ,CAEAkY,cAAAA,CAAeD,EAAqB/xB,GAChC,MAAMiyB,EAA+B,GACrC,GAAIjyB,EAAQkyB,mBAAoB,CAC5B,MAAM7M,EAAMt4B,KAAKolC,mBAAmBJ,GAChC1M,GACA4M,EAAK/kC,KAAKm4B,EAElB,CACA,IAAI+M,EAAkBrlC,KAAKuI,MAAM+8B,kBAAkBN,EAAYhlC,KAAKukC,YAAY1B,eAAemC,IAK/F,OAJI/xB,EAAQ2uB,cACRyD,EAAkBA,EAAgBr1B,OAAOsoB,GAAOoL,GAASE,OAAOtL,EAAIiN,UAAWtyB,EAAQ2uB,eAE3FsD,EAAK/kC,QAAQklC,IACNhO,EAAAA,GAAAA,IAAO6N,EAClB,CAEUE,kBAAAA,CAAmBJ,GACzB,MAAMH,EAAW7kC,KAAKokC,aAAaZ,YAAYwB,GAC/C,GAAIH,EAAU,CACV,MAAMznC,GAAM2iC,EAAAA,GAAAA,IAAYiF,GAClBn/B,EAAO7F,KAAKukC,YAAY1B,eAAemC,GAC7C,MAAO,CACHO,UAAWnoC,EAAIsiB,IACf8lB,WAAY3/B,EACZ+Z,UAAWxiB,EAAIsiB,IACf+lB,WAAY5/B,EACZ6/B,SAASC,EAAAA,EAAAA,IAAkBd,GAC3Be,OAAO,EAEf,CAEJ,ECtIE,MAAOC,GAMT3qC,WAAAA,CAAY+W,GACR,GALI,KAAAzD,IAAM,IAAI5B,IAKVqF,EACA,IAAK,MAAOvJ,EAAK5J,KAAUmT,EACvBjS,KAAKH,IAAI6I,EAAK5J,EAG1B,CAKA,QAAI+S,GACA,OAAOi0B,GAAAA,GAAUC,KAAI1O,EAAAA,GAAAA,IAAOr3B,KAAKwO,IAAIuJ,UAAUvJ,IAAIrL,GAAKA,EAAElH,QAC9D,CAKA61B,KAAAA,GACI9xB,KAAKwO,IAAIsjB,OACb,CAUAmI,OAAOvxB,EAAQ5J,GACX,QAAcT,IAAVS,EACA,OAAOkB,KAAKwO,IAAIyrB,OAAOvxB,GACpB,CACH,MAAMqP,EAAS/X,KAAKwO,IAAIvJ,IAAIyD,GAC5B,GAAIqP,EAAQ,CACR,MAAMxP,EAAQwP,EAAOtS,QAAQ3G,GAC7B,GAAIyJ,GAAS,EAMT,OALsB,IAAlBwP,EAAO9b,OACP+D,KAAKwO,IAAIyrB,OAAOvxB,GAEhBqP,EAAOtX,OAAO8H,EAAO,IAElB,CAEf,CACA,OAAO,CACX,CACJ,CASAtD,GAAAA,CAAIyD,G,MACA,OAAwB,QAAjByK,EAAAnT,KAAKwO,IAAIvJ,IAAIyD,UAAI,IAAAyK,EAAAA,EAAI,EAChC,CAOA6C,GAAAA,CAAItN,EAAQ5J,GACR,QAAcT,IAAVS,EACA,OAAOkB,KAAKwO,IAAIwH,IAAItN,GACjB,CACH,MAAMqP,EAAS/X,KAAKwO,IAAIvJ,IAAIyD,GAC5B,QAAIqP,GACOA,EAAOtS,QAAQ3G,IAAU,CAGxC,CACJ,CAKAe,GAAAA,CAAI6I,EAAQ5J,GAMR,OALIkB,KAAKwO,IAAIwH,IAAItN,GACb1I,KAAKwO,IAAIvJ,IAAIyD,GAAMvI,KAAKrB,GAExBkB,KAAKwO,IAAItB,IAAIxE,EAAK,CAAC5J,IAEhBkB,IACX,CAKAgmC,MAAAA,CAAOt9B,EAAQqP,GAMX,OALI/X,KAAKwO,IAAIwH,IAAItN,GACb1I,KAAKwO,IAAIvJ,IAAIyD,GAAMvI,QAAQ4X,GAE3B/X,KAAKwO,IAAItB,IAAIxE,EAAKtI,MAAMqG,KAAKsR,IAE1B/X,IACX,CAKAyU,OAAAA,CAAQwxB,GACJjmC,KAAKwO,IAAIiG,QAAQ,CAACpS,EAAOqG,IACrBrG,EAAMoS,QAAQ3V,GAASmnC,EAAWnnC,EAAO4J,EAAK1I,OAEtD,CAKA,CAACoF,OAAO8gC,YACJ,OAAOlmC,KAAKs0B,UAAU4R,UAC1B,CAKA5R,OAAAA,GACI,OAAO+C,EAAAA,GAAAA,IAAOr3B,KAAKwO,IAAI8lB,WAClBlb,QAAQ4b,IAAA,IAAEtsB,EAAKrG,GAAM2yB,EAAA,OAAK3yB,EAAMmM,IAAI1P,GAAS,CAAC4J,EAAK5J,KAC5D,CAKAkZ,IAAAA,GACI,OAAOqf,EAAAA,GAAAA,IAAOr3B,KAAKwO,IAAIwJ,OAC3B,CAKAD,MAAAA,GACI,OAAOsf,EAAAA,GAAAA,IAAOr3B,KAAKwO,IAAIuJ,UAAUouB,MACrC,CAKAC,mBAAAA,GACI,OAAO/O,EAAAA,GAAAA,IAAOr3B,KAAKwO,IAAI8lB,UAC3B,EAIE,MAAO+R,GAKT,QAAIx0B,GACA,OAAO7R,KAAKwO,IAAIqD,IACpB,CAIA3W,WAAAA,CAAY+W,GACR,GAVI,KAAAzD,IAAM,IAAI5B,IACV,KAAA05B,QAAU,IAAI15B,IASdqF,EACA,IAAK,MAAOvJ,EAAK5J,KAAUmT,EACvBjS,KAAKkN,IAAIxE,EAAK5J,EAG1B,CAEAgzB,KAAAA,GACI9xB,KAAKwO,IAAIsjB,QACT9xB,KAAKsmC,QAAQxU,OACjB,CAEA5kB,GAAAA,CAAIxE,EAAQ5J,GAGR,OAFAkB,KAAKwO,IAAItB,IAAIxE,EAAK5J,GAClBkB,KAAKsmC,QAAQp5B,IAAIpO,EAAO4J,GACjB1I,IACX,CAEAiF,GAAAA,CAAIyD,GACA,OAAO1I,KAAKwO,IAAIvJ,IAAIyD,EACxB,CAEA69B,MAAAA,CAAOznC,GACH,OAAOkB,KAAKsmC,QAAQrhC,IAAInG,EAC5B,CAEAm7B,OAAOvxB,GACH,MAAM5J,EAAQkB,KAAKwO,IAAIvJ,IAAIyD,GAC3B,YAAcrK,IAAVS,IACAkB,KAAKwO,IAAIyrB,OAAOvxB,GAChB1I,KAAKsmC,QAAQrM,OAAOn7B,IACb,EAGf,ECpJE,MAAO0nC,GAKTtrC,WAAAA,CAAYsB,GACRwD,KAAKokC,aAAe5nC,EAASs0B,WAAWuT,aACxCrkC,KAAKymC,aAAejqC,EAASuhC,UAAU2I,0BAC3C,CAEA,oBAAMC,CAAe9c,GAA+D,IAApCiV,EAAW1gC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG+9B,GAAAA,GAAkBx8B,KAC5E,OAAOK,KAAK4mC,sBAAsB/c,EAAS+U,YAAY9/B,MAAO+qB,OAAUxrB,EAAWygC,EACvF,CAcA,2BAAM8H,CAAsBC,EAAqBhd,GAA4J,IAAxHtD,EAAAnoB,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAiD0oC,GAAAA,GAAgBhI,EAAA1gC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAiC+9B,GAAAA,GAAkBx8B,KACrM,MAAMP,EAAgC,GAEtCY,KAAK+mC,WAAWF,EAAYznC,EAASyqB,GACrC,IAAK,MAAMjsB,KAAQ2oB,EAASsgB,SAClB3K,GAAkB4C,GACxB9+B,KAAK+mC,WAAWnpC,EAAMwB,EAASyqB,GAEnC,OAAOzqB,CACX,CAMU2nC,UAAAA,CAAWnpC,EAAewB,EAA+ByqB,GAC/D,MAAMhuB,EAAOmE,KAAKokC,aAAad,QAAQ1lC,GACnC/B,GACAuD,EAAQe,KAAKH,KAAKymC,aAAaO,kBAAkBppC,EAAM/B,EAAMguB,GAErE,CAEA,wBAAMod,CAAmBpd,GAA+D,IAApCiV,EAAW1gC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG+9B,GAAAA,GAAkBx8B,KAChF,MAAM8rB,EAAW5B,EAAS+U,YAAY9/B,MAChCooC,EAAS,IAAIrB,GAEnB,IAAK,MAAMjoC,KAAQupC,EAAAA,GAAAA,IAAkB1b,SAC3ByQ,GAAkB4C,GACxB9+B,KAAKonC,YAAYxpC,EAAMisB,EAAUqd,GAErC,OAAOA,CACX,CAOUE,WAAAA,CAAYxpC,EAAeisB,EAA2Bqd,GAC5D,MAAM3a,EAAY3uB,EAAK29B,WACvB,GAAIhP,EAAW,CACX,MAAM1wB,EAAOmE,KAAKokC,aAAad,QAAQ1lC,GACnC/B,GACAqrC,EAAOrnC,IAAI0sB,EAAWvsB,KAAKymC,aAAaO,kBAAkBppC,EAAM/B,EAAMguB,GAE9E,CACJ,EChGE,MAAOwd,GAKTnsC,WAAAA,CAAY+W,EAAsCq1B,EAAoBr0B,G,MAClEjT,KAAKiS,SAAWA,EAChBjS,KAAKsnC,WAAaA,EAClBtnC,KAAKunC,gBAA0C,QAAxBp0B,EAAO,OAAPF,QAAO,IAAPA,OAAO,EAAPA,EAASs0B,uBAAe,IAAAp0B,GAAAA,CACnD,CAEAq0B,cAAAA,GACI,OAAIxnC,KAAKsnC,WACEtnC,KAAKiS,SAAStM,OAAO3F,KAAKsnC,WAAWE,kBAErCxnC,KAAKiS,QAEpB,CAEAiwB,UAAAA,CAAWrmC,GACP,MAAM+pC,EAAQ5lC,KAAKunC,gBACbvnC,KAAKiS,SAASw1B,KAAKrmC,GAAKA,EAAEvF,KAAKyL,gBAAkBzL,EAAKyL,eACtDtH,KAAKiS,SAASw1B,KAAKrmC,GAAKA,EAAEvF,OAASA,GACzC,OAAI+pC,IAGA5lC,KAAKsnC,WACEtnC,KAAKsnC,WAAWpF,WAAWrmC,QADtC,EAIJ,EAGE,MAAO6rC,GAKTxsC,WAAAA,CAAY+W,EAAwCq1B,EAAoBr0B,G,MACpEjT,KAAKiS,SAAW,IAAIrF,IACpB5M,KAAKunC,gBAA0C,QAAxBp0B,EAAO,OAAPF,QAAO,IAAPA,OAAO,EAAPA,EAASs0B,uBAAe,IAAAp0B,GAAAA,EAC/C,IAAK,MAAMia,KAAWnb,EAAU,CAC5B,MAAMpW,EAAOmE,KAAKunC,gBACZna,EAAQvxB,KAAKyL,cACb8lB,EAAQvxB,KACdmE,KAAKiS,SAAS/E,IAAIrR,EAAMuxB,EAC5B,CACAptB,KAAKsnC,WAAaA,CACtB,CAEApF,UAAAA,CAAWrmC,GACP,MAAM8rC,EAAY3nC,KAAKunC,gBAAkB1rC,EAAKyL,cAAgBzL,EACxD+pC,EAAQ5lC,KAAKiS,SAAShN,IAAI0iC,GAChC,OAAI/B,IAGA5lC,KAAKsnC,WACEtnC,KAAKsnC,WAAWpF,WAAWrmC,QADtC,EAIJ,CAEA2rC,cAAAA,GACI,IAAII,GAAgBvQ,EAAAA,GAAAA,IAAOr3B,KAAKiS,SAAS8F,UAIzC,OAHI/X,KAAKsnC,aACLM,EAAgBA,EAAcjiC,OAAO3F,KAAKsnC,WAAWE,mBAElDI,CACX,EClGE,MAAgBC,GAAtB3sC,WAAAA,GAEc,KAAA4sC,UAA0B,GAC1B,KAAAC,YAAa,CAoB3B,CAlBIC,SAAAA,CAAUC,GACNjoC,KAAK8nC,UAAU3nC,KAAK8nC,EACxB,CAEAvoC,OAAAA,GACIM,KAAKkoC,kBACLloC,KAAK8xB,QACL9xB,KAAK+nC,YAAa,EAClB/nC,KAAK8nC,UAAUrzB,QAAQwzB,GAAcA,EAAWvoC,UACpD,CAEUwoC,eAAAA,GACN,GAAIloC,KAAK+nC,WACL,MAAM,IAAIrnC,MAAM,uCAExB,EAKE,MAAOynC,WAA0BN,GAAvC3sC,WAAAA,G,oBACuB,KAAAktC,MAAQ,IAAIx7B,GAoCnC,CAlCIoJ,GAAAA,CAAItN,GAEA,OADA1I,KAAKkoC,kBACEloC,KAAKooC,MAAMpyB,IAAItN,EAC1B,CAEAwE,GAAAA,CAAIxE,EAAQ5J,GACRkB,KAAKkoC,kBACLloC,KAAKooC,MAAMl7B,IAAIxE,EAAK5J,EACxB,CAIAmG,GAAAA,CAAIyD,EAAQ2/B,GAER,GADAroC,KAAKkoC,kBACDloC,KAAKooC,MAAMpyB,IAAItN,GACf,OAAO1I,KAAKooC,MAAMnjC,IAAIyD,GACnB,GAAI2/B,EAAU,CACjB,MAAMvpC,EAAQupC,IAEd,OADAroC,KAAKooC,MAAMl7B,IAAIxE,EAAK5J,GACbA,CACX,CAGJ,CAEAm7B,OAAOvxB,GAEH,OADA1I,KAAKkoC,kBACEloC,KAAKooC,MAAMnO,OAAOvxB,EAC7B,CAEAopB,KAAAA,GACI9xB,KAAKkoC,kBACLloC,KAAKooC,MAAMtW,OACf,EAGE,MAAOwW,WAAgET,GAKzE3sC,WAAAA,CAAY81B,GACR71B,QAJa,KAAAitC,MAAQ,IAAIx7B,IAKzB5M,KAAKgxB,UAAqB,OAATA,QAAS,IAATA,EAAAA,EAAclyB,GAASA,CAC5C,CAEAkX,GAAAA,CAAIuyB,EAAqB7/B,GAErB,OADA1I,KAAKkoC,kBACEloC,KAAKwoC,gBAAgBD,GAAYvyB,IAAItN,EAChD,CAEAwE,GAAAA,CAAIq7B,EAAqB7/B,EAAU5J,GAC/BkB,KAAKkoC,kBACLloC,KAAKwoC,gBAAgBD,GAAYr7B,IAAIxE,EAAK5J,EAC9C,CAIAmG,GAAAA,CAAIsjC,EAAqB7/B,EAAU2/B,GAC/BroC,KAAKkoC,kBACL,MAAMO,EAAezoC,KAAKwoC,gBAAgBD,GAC1C,GAAIE,EAAazyB,IAAItN,GACjB,OAAO+/B,EAAaxjC,IAAIyD,GACrB,GAAI2/B,EAAU,CACjB,MAAMvpC,EAAQupC,IAEd,OADAI,EAAav7B,IAAIxE,EAAK5J,GACfA,CACX,CAGJ,CAEAm7B,OAAOsO,EAAqB7/B,GAExB,OADA1I,KAAKkoC,kBACEloC,KAAKwoC,gBAAgBD,GAAYtO,OAAOvxB,EACnD,CAIAopB,KAAAA,CAAMyW,GAEF,GADAvoC,KAAKkoC,kBACDK,EAAY,CACZ,MAAM3uB,EAAS5Z,KAAKgxB,UAAUuX,GAC9BvoC,KAAKooC,MAAMnO,OAAOrgB,EACtB,MACI5Z,KAAKooC,MAAMtW,OAEnB,CAEU0W,eAAAA,CAAgBD,GACtB,MAAM3uB,EAAS5Z,KAAKgxB,UAAUuX,GAC9B,IAAIG,EAAgB1oC,KAAKooC,MAAMnjC,IAAI2U,GAKnC,OAJK8uB,IACDA,EAAgB,IAAI97B,IACpB5M,KAAKooC,MAAMl7B,IAAI0M,EAAQ8uB,IAEpBA,CACX,EA+CE,MAAOC,WAA6BR,GAUtCjtC,WAAAA,CAAY0tC,EAA2C33B,GACnD9V,QACI8V,GACAjR,KAAK8nC,UAAU3nC,KAAKyoC,EAAe7K,UAAU8K,gBAAgBC,aAAa73B,EAAO,KAC7EjR,KAAK8xB,WAET9xB,KAAK8nC,UAAU3nC,KAAKyoC,EAAe7K,UAAU8K,gBAAgBE,SAAS,CAACC,EAAUC,KACzEA,EAAQhtC,OAAS,GACjB+D,KAAK8xB,YAIb9xB,KAAK8nC,UAAU3nC,KAAKyoC,EAAe7K,UAAU8K,gBAAgBE,SAAS,KAClE/oC,KAAK8xB,UAGjB,EChLE,MAAOoX,GASThuC,WAAAA,CAAYsB,GACRwD,KAAK4gC,WAAapkC,EAAS+B,OAAO2yB,cAClClxB,KAAKokC,aAAe5nC,EAASs0B,WAAWuT,aACxCrkC,KAAKymC,aAAejqC,EAASuhC,UAAU2I,2BACvC1mC,KAAKmpC,aAAe3sC,EAAS+B,OAAOw/B,UAAUuG,aAC9CtkC,KAAKopC,iBAAmB,IAAIT,GAA8BnsC,EAAS+B,OACvE,CAEA0jC,QAAAA,CAAS9jC,GACL,MAAM+oC,EAA4C,GAC5C/D,EAAgBnjC,KAAK4gC,WAAWwC,iBAAiBjlC,GAEjDkrC,GAActJ,EAAAA,GAAAA,IAAY5hC,EAAQouB,WAAWiU,kBACnD,GAAI6I,EAAa,CACb,IAAIC,EAAmCnrC,EAAQouB,UAC/C,EAAG,CACC,MAAMgd,EAAkBF,EAAYpkC,IAAIqkC,GACpCC,EAAgBttC,OAAS,GACzBirC,EAAO/mC,MAAKk3B,EAAAA,GAAAA,IAAOkS,GAAiBv5B,OAChCw5B,GAAQxpC,KAAK4gC,WAAW6I,UAAUD,EAAK79B,KAAMw3B,KAErDmG,EAAcA,EAAY/N,UAC9B,OAAS+N,EACb,CAEA,IAAItnC,EAAgBhC,KAAK0pC,eAAevG,EAAehlC,GACvD,IAAK,IAAIoC,EAAI2mC,EAAOjrC,OAAS,EAAGsE,GAAK,EAAGA,IACpCyB,EAAShC,KAAK2pC,YAAYzC,EAAO3mC,GAAIyB,GAEzC,OAAOA,CACX,CAKU2nC,WAAAA,CAAY13B,EAAwCq1B,EAAoBr0B,GAC9E,OAAO,IAAIo0B,IAAYhQ,EAAAA,GAAAA,IAAOplB,GAAWq1B,EAAYr0B,EACzD,CAMU22B,mBAAAA,CAAoB33B,EAA6Bq1B,EAAoBr0B,GAC3E,MAAMjQ,GAAIq0B,EAAAA,GAAAA,IAAOplB,GAAUzD,IAAIpN,IAC3B,MAAMvF,EAAOmE,KAAKokC,aAAad,QAAQliC,GACvC,GAAIvF,EACA,OAAOmE,KAAKymC,aAAaO,kBAAkB5lC,EAAGvF,KAGnDguC,cACH,OAAO,IAAIxC,GAAYrkC,EAAGskC,EAAYr0B,EAC1C,CAKUy2B,cAAAA,CAAevG,EAAuB2G,GAC5C,OAAO9pC,KAAKopC,iBAAiBnkC,IAAIk+B,EAAe,IAAM,IAAIuE,GAAS1nC,KAAKmpC,aAAaY,YAAY5G,IACrG,ECGJ,SAAS6G,GAAwBnW,GAC7B,MAAsB,kBAARA,KAAsBA,IAAQ,SAAUA,GAAO,WAAYA,EAC7E,CAEM,MAAOoW,GAaT/uC,WAAAA,CAAYsB,GAVZ,KAAA0tC,iBAAmB,IAAIt0B,IAAI,CAAC,aAAc,qBAAsB,kBAAmB,YAAa,aAW5F5V,KAAK6gC,iBAAmBrkC,EAAS+B,OAAOw/B,UAAU+C,iBAClD9gC,KAAKihC,eAAiBzkC,EAASuhC,UAAUmD,eACzClhC,KAAKokC,aAAe5nC,EAASs0B,WAAWuT,aACxCrkC,KAAKmqC,gBAAkB3tC,EAASopB,cAAcwkB,eAClD,CAEAC,SAAAA,CAAUzsC,EAAeqV,GACrB,MAAMq3B,EAA0B,OAAPr3B,QAAO,IAAPA,EAAAA,EAAW,CAAC,EAC/Bs3B,EAA0B,OAAPt3B,QAAO,IAAPA,OAAO,EAAPA,EAASu3B,SAC5BC,EAAkBA,CAAC/hC,EAAa5J,IAAmBkB,KAAKwqC,SAAS9hC,EAAK5J,EAAOwrC,GAC7EE,EAAWD,EAAmB,CAAC7hC,EAAa5J,IAAmByrC,EAAiB7hC,EAAK5J,EAAO2rC,GAAmBA,EAErH,IAEI,OADAzqC,KAAK0qC,iBAAkB3K,EAAAA,GAAAA,IAAYniC,GAC5B+E,KAAKC,UAAUhF,EAAM4sC,EAAiB,OAAPv3B,QAAO,IAAPA,OAAO,EAAPA,EAAS03B,MACnD,CAAE,QACE3qC,KAAK0qC,qBAAkBrsC,CAC3B,CACJ,CAEAusC,WAAAA,CAAyCvhB,EAAiBpW,GACtD,MAAM43B,EAA4B,OAAP53B,QAAO,IAAPA,EAAAA,EAAW,CAAC,EACjC1O,EAAO5B,KAAK+B,MAAM2kB,GAExB,OADArpB,KAAK8qC,SAASvmC,EAAMA,EAAMsmC,GACnBtmC,CACX,CAEUimC,QAAAA,CAAS9hC,EAAa5J,EAAck2B,GAAoF,IAAlF,QAAEoN,EAAO,WAAE2I,EAAU,YAAEC,EAAW,SAAEC,EAAQ,aAAEC,GAAoClW,E,YAC9H,IAAIh1B,KAAKkqC,iBAAiBl0B,IAAItN,GAA9B,CAEO,IAAIk8B,EAAAA,GAAAA,IAAY9lC,GAAQ,CAC3B,MAAMqsC,EAAWrsC,EAAMw5B,IACjBQ,EAAWsJ,EAAUtjC,EAAMg6B,cAAWz6B,EAC5C,GAAI8sC,EAAU,CACV,MAAMC,GAAiBrL,EAAAA,GAAAA,IAAYoL,GACnC,IAAIvrB,EAAY,GACZ5f,KAAK0qC,iBAAmB1qC,KAAK0qC,kBAAoBU,IAE7CxrB,EADAsrB,EACYA,EAAaE,EAAe1rB,IAAK5gB,GAEjCssC,EAAe1rB,IAAItZ,YAGvC,MAAMq/B,EAAazlC,KAAKihC,eAAe4B,eAAesI,GACtD,MAAO,CACHE,KAAM,GAAF1lC,OAAKia,EAAS,KAAAja,OAAI8/B,GACtB3M,WAER,CACI,MAAO,CACHwS,OAA4B,QAApBne,EAAW,QAAXha,EAAArU,EAAMyC,aAAK,IAAA4R,OAAA,EAAAA,EAAEhI,eAAO,IAAAgiB,EAAAA,EAAI,8BAChC2L,WAGZ,CAAO,IAAIwJ,EAAAA,GAAAA,IAAUxjC,GAAQ,CACzB,IAAIguB,EAYJ,GAXIke,IACAle,EAAU9sB,KAAKurC,kCAAiCrsC,OAAAoS,OAAC,CAAC,EAAIxS,IAChD4J,IAAO5J,EAAMqgC,aAAqB,OAAPrS,QAAO,IAAPA,OAAO,EAAPA,EAAS0e,eAEtC1e,EAAQ0e,YAAYC,YAAkC,QAApBC,EAAA1rC,KAAK0qC,uBAAe,IAAAgB,OAAA,EAAAA,EAAEhsB,IAAItZ,aAGhE2kC,IAAeriC,IACR,OAAPokB,QAAO,IAAPA,IAAAA,EAAO5tB,OAAAoS,OAAA,GAAUxS,IACjBguB,EAAQ6e,YAA4B,QAAdC,EAAA9sC,EAAMiuB,gBAAQ,IAAA6e,OAAA,EAAAA,EAAEnoB,MAEtCwnB,EAAU,CACH,OAAPne,QAAO,IAAPA,IAAAA,EAAO5tB,OAAAoS,OAAA,GAAUxS,IACjB,MAAM+sC,EAAU7rC,KAAKmqC,gBAAgB2B,WAAWhtC,GAC5C+sC,IACC/e,EAA+Bif,SAAWF,EAAQ9vC,QAAQ,MAAO,IAE1E,CACA,OAAc,OAAP+wB,QAAO,IAAPA,EAAAA,EAAWhuB,CACtB,CACI,OAAOA,CACX,CACJ,CAEUysC,iCAAAA,CAAkC3tC,GACxC,MAAMouC,EAA4E1Y,IAAW,CACzFzI,OAAQyI,EAAQzI,OAChB9b,IAAKukB,EAAQvkB,IACb9S,OAAQq3B,EAAQr3B,OAChBmP,MAAOkoB,EAAQloB,QAGnB,GAAIxN,EAAKmvB,SAAU,CACf,MACMkf,GADaruC,EAAK4tC,YAAcQ,EAAsBpuC,EAAKmvB,WACCkf,YAAc,CAAC,EASjF,OAPA/sC,OAAO8Y,KAAKpa,GAAMoS,OAAOtH,IAAQA,EAAIwjC,WAAW,MAAMz3B,QAAQ/L,IAC1D,MAAMyjC,GAAsBC,EAAAA,EAAAA,IAAqBxuC,EAAKmvB,SAAUrkB,GAAK8F,IAAIw9B,GACtC,IAA/BG,EAAoBlwC,SACpBgwC,EAAYvjC,GAAOyjC,KAIpBvuC,CACX,CAEJ,CAEUktC,QAAAA,CAASltC,EAAsB2G,EAAe0O,EAAiCsZ,EAAqB8f,EAA4BC,GACtI,IAAK,MAAOC,EAAc9uC,KAASyB,OAAOo1B,QAAQ12B,GAC9C,GAAIwC,MAAMrB,QAAQtB,GACd,IAAK,IAAI8K,EAAQ,EAAGA,EAAQ9K,EAAKxB,OAAQsM,IAAS,CAC9C,MAAM6kB,EAAU3vB,EAAK8K,GACjByhC,GAAwB5c,GACxB3vB,EAAK8K,GAASvI,KAAKwsC,gBAAgB5uC,EAAM2uC,EAAchoC,EAAM6oB,EAASna,IAC/DqvB,EAAAA,GAAAA,IAAUlV,IACjBptB,KAAK8qC,SAAS1d,EAA2B7oB,EAAM0O,EAASrV,EAAM2uC,EAAchkC,EAEpF,MACOyhC,GAAwBvsC,GAC/BG,EAAK2uC,GAAgBvsC,KAAKwsC,gBAAgB5uC,EAAM2uC,EAAchoC,EAAM9G,EAAMwV,IACnEqvB,EAAAA,GAAAA,IAAU7kC,IACjBuC,KAAK8qC,SAASrtC,EAAwB8G,EAAM0O,EAASrV,EAAM2uC,GAGnE,MAAME,EAAU7uC,EAChB6uC,EAAQlR,WAAahP,EACrBkgB,EAAQC,mBAAqBL,EAC7BI,EAAQE,gBAAkBL,CAC9B,CAEUE,eAAAA,CAAgBjgB,EAAoB1uB,EAAkB0G,EAAei9B,EAAkCvuB,GAC7G,IAAImvB,EAAUZ,EAAU1I,SACpBv3B,EAAQigC,EAAU8J,OACtB,GAAI9J,EAAU6J,KAAM,CAChB,MAAM/S,EAAMt4B,KAAK4sC,WAAWroC,EAAMi9B,EAAU6J,KAAMp4B,EAAQi4B,cAC1D,IAAI5I,EAAAA,GAAAA,IAAUhK,GAIV,OAHK8J,IACDA,EAAUpiC,KAAKokC,aAAad,QAAQhL,IAEjC,CACHQ,SAAiB,OAAPsJ,QAAO,IAAPA,EAAAA,EAAW,GACrB9J,OAGJ/2B,EAAQ+2B,CAEhB,CACA,GAAI/2B,EAAO,CACP,MAAM+2B,EAA0B,CAC5BQ,SAAiB,OAAPsJ,QAAO,IAAPA,EAAAA,EAAW,IAQzB,OANA9J,EAAI/2B,MAAQ,CACRgrB,YACA1uB,WACAsN,QAAS5J,EACTigC,UAAWlJ,GAERA,CACX,CAGJ,CAEUsU,UAAAA,CAAWroC,EAAemb,EAAawrB,GAC7C,IACI,MAAM2B,EAAgBntB,EAAIja,QAAQ,KAClC,GAAsB,IAAlBonC,EAAqB,CACrB,MAAMjvC,EAAOoC,KAAKihC,eAAe+B,WAAWz+B,EAAMmb,EAAI1jB,UAAU,IAChE,OAAK4B,GACM,2BAA6B8hB,CAG5C,CACA,GAAImtB,EAAgB,EAAG,CACnB,MAAMjL,EAAcsJ,EAAeA,EAAaxrB,GAAOxF,GAAAA,EAAIxV,MAAMgb,GAC3DmK,EAAW7pB,KAAK6gC,iBAAiBd,YAAY6B,GACnD,OAAK/X,EAGEA,EAAS+U,YAAY9/B,MAFjB,oCAAsC4gB,CAGrD,CACA,MAAMkiB,EAAcsJ,EAAeA,EAAaxrB,EAAI1jB,UAAU,EAAG6wC,IAAkB3yB,GAAAA,EAAIxV,MAAMgb,EAAI1jB,UAAU,EAAG6wC,IACxGhjB,EAAW7pB,KAAK6gC,iBAAiBd,YAAY6B,GACnD,IAAK/X,EACD,MAAO,oCAAsCnK,EAEjD,GAAImtB,IAAkBntB,EAAIzjB,OAAS,EAC/B,OAAO4tB,EAAS+U,YAAY9/B,MAEhC,MAAMlB,EAAOoC,KAAKihC,eAAe+B,WAAWnZ,EAAS+U,YAAY9/B,MAAO4gB,EAAI1jB,UAAU6wC,EAAgB,IACtG,OAAKjvC,GACM,0BAA4B8hB,CAG3C,CAAE,MAAO4S,GACL,OAAO/qB,OAAO+qB,EAClB,CACJ,ECnRE,MAAOwa,GAST,OAAct+B,GACV,OAAOxO,KAAK+sC,gBAChB,CAIA7xC,WAAAA,CAAYsB,GAZO,KAAAwwC,cAAgB,IAAIpgC,IACpB,KAAAmgC,iBAAmB,IAAIngC,IAYtC5M,KAAK89B,cAAwB,OAARthC,QAAQ,IAARA,OAAQ,EAARA,EAAUuhC,UAAUC,aAC7C,CAEA9gC,QAAAA,CAASwoB,GACL,MAAMkC,EAAOlC,EAASyJ,iBACtB,IAAK,MAAM1qB,KAAOmjB,EAAKqlB,eACfjtC,KAAK+sC,iBAAiB/2B,IAAIvR,IAC1BnD,QAAQ4hC,KAAK,sBAADv9B,OAAuBlB,EAAG,2DAAAkB,OAA0DiiB,EAAKpE,WAAU,OAEnHxjB,KAAK+sC,iBAAiB7/B,IAAIzI,EAAKihB,GAEnC1lB,KAAKgtC,cAAc9/B,IAAI0a,EAAKpE,WAAYkC,GACR,IAA5B1lB,KAAKgtC,cAAcn7B,KACnB7R,KAAKktC,UAAYxnB,EAEjB1lB,KAAKktC,eAAY7uC,CAEzB,CAEAghC,WAAAA,CAAY3f,G,QACR,QAAuBrhB,IAAnB2B,KAAKktC,UACL,OAAOltC,KAAKktC,UAEhB,GAAgC,IAA5BltC,KAAKgtC,cAAcn7B,KACnB,MAAM,IAAInR,MAAM,yFAEpB,MAAM8iB,EAAyC,QAA5B2J,EAAkB,QAAlBha,EAAAnT,KAAK89B,qBAAa,IAAA3qB,OAAA,EAAAA,EAAElO,IAAIya,UAAI,IAAAyN,OAAA,EAAAA,EAAE3J,WACjD,QAAmBnlB,IAAfmlB,EAA0B,CAC1B,MAAMhnB,EAAWwD,KAAKgtC,cAAc/nC,IAAIue,GACxC,GAAIhnB,EACA,OAAOA,CAEf,CACA,MAAMiI,EAAMi/B,GAASt/B,QAAQsb,GACvBljB,EAAWwD,KAAK+sC,iBAAiB9nC,IAAIR,GAC3C,IAAKjI,EACD,MAAIgnB,EACM,IAAI9iB,MAAM,gEAADiF,OAAiElB,EAAG,oBAAAkB,OAAmB6d,EAAU,OAE1G,IAAI9iB,MAAM,gEAADiF,OAAiElB,EAAG,OAG3F,OAAOjI,CACX,CAEA2wC,WAAAA,CAAYztB,GACR,IAEI,OADA1f,KAAKq/B,YAAY3f,IACV,CACX,CAAE,MAAAvM,GACE,OAAO,CACX,CACJ,CAEA,OAAIysB,GACA,OAAOx/B,MAAMqG,KAAKzG,KAAKgtC,cAAcj1B,SACzC,ECzDE,SAAUq1B,GAAexrB,GAC3B,MAAO,CAAEA,OACb,CAqDM,IAAWyrB,GCuLAC,IDvLjB,SAAiBD,GACAA,EAAAzN,IAAqC,CAAC,OAAQ,OAAQ,WACtE,CAFD,CAAiByN,KAAAA,GAAkB,KAY7B,MAAOxwC,GAOT3B,WAAAA,CAAYsB,GANK,KAAA83B,QAAU,IAAIuR,GAGvB,KAAA0H,cAAyC,GACzC,KAAAC,aAAwC,GAG5CxtC,KAAK4gC,WAAapkC,EAAS+B,OAAO2yB,aACtC,CAUAh0B,QAAAA,CAAYuwC,GAAoH,IAAjFC,EAAAtvC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAsC4B,KAAM2tC,EAAAvvC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA+B,OACtH,GAAiB,aAAbuvC,EACA,MAAM,IAAIjtC,MAAM,6EAEpB,IAAK,MAAOiL,EAAMif,KAAO1rB,OAAOo1B,QAAQmZ,GAAe,CACnD,MAAM5sC,EAAY+pB,EAClB,GAAIxqB,MAAMrB,QAAQ8B,GACd,IAAK,MAAMyqB,KAASzqB,EAAW,CAC3B,MAAMkQ,EAA8B,CAChCua,MAAOtrB,KAAK4tC,wBAAwBtiB,EAAOoiB,GAC3CC,YAEJ3tC,KAAK6tC,SAASliC,EAAMoF,EACxB,MACG,GAAyB,oBAAdlQ,EAA0B,CACxC,MAAMkQ,EAA8B,CAChCua,MAAOtrB,KAAK4tC,wBAAwB/sC,EAAW6sC,GAC/CC,YAEJ3tC,KAAK6tC,SAASliC,EAAMoF,EACxB,MACIvF,EAAAA,GAAAA,GAAkB3K,EAE1B,CACJ,CAEU+sC,uBAAAA,CAAwBtiB,EAAwBoiB,GACtD,OAAOzR,MAAOr+B,EAAMP,EAAQyhC,WAClB9+B,KAAK8tC,gBAAgB,IAAMxiB,EAAMlpB,KAAKsrC,EAAS9vC,EAAMP,EAAQyhC,GAAc,sCAAuCzhC,EAAQO,GAExI,CAEU,qBAAMkwC,CAAgBC,EAAyCC,EAAwB3wC,EAA4BO,GACzH,UACUmwC,GACV,CAAE,MAAOzb,GACL,GAAI0J,GAAqB1J,GACrB,MAAMA,EAEVhxB,QAAQC,MAAM,GAADoE,OAAIqoC,EAAc,KAAK1b,GAChCA,aAAe5xB,OAAS4xB,EAAIngB,OAC5B7Q,QAAQC,MAAM+wB,EAAIngB,OAEtB,MAAM87B,EAAiB3b,aAAe5xB,MAAQ4xB,EAAInnB,QAAU5D,OAAO+qB,GACnEj1B,EAAO,QAAS,GAAFsI,OAAKqoC,EAAc,MAAAroC,OAAKsoC,GAAkB,CAAErwC,QAC9D,CACJ,CAEUiwC,QAAAA,CAASliC,EAAcoF,GAC7B,GAAa,YAATpF,EAIJ,IAAK,MAAMuiC,KAAWluC,KAAK4gC,WAAWuN,eAAexiC,GACjD3L,KAAKs0B,QAAQz0B,IAAIquC,EAASn9B,QAJ1B/Q,KAAKs0B,QAAQz0B,IAAI,UAAWkR,EAMpC,CAEAq9B,SAAAA,CAAUziC,EAAc0iC,GACpB,IAAIvxC,GAASu6B,EAAAA,GAAAA,IAAOr3B,KAAKs0B,QAAQrvB,IAAI0G,IAChChG,OAAO3F,KAAKs0B,QAAQrvB,IAAI,YAI7B,OAHIopC,IACAvxC,EAASA,EAAOkT,OAAOe,GAASs9B,EAAWC,SAASv9B,EAAM48B,YAEvD7wC,EAAO0R,IAAIuC,GAASA,EAAMua,MACrC,CAkBAijB,sBAAAA,CAAuBC,GAA8E,IAA1Cd,EAAAtvC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAsC4B,KAC7FA,KAAKutC,cAAcptC,KAAKH,KAAKyuC,yBAAyBD,EAAa,oDAAqDd,GAC5H,CAkBAgB,qBAAAA,CAAsBC,GAA6E,IAA1CjB,EAAAtvC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAsC4B,KAC3FA,KAAKwtC,aAAartC,KAAKH,KAAKyuC,yBAAyBE,EAAY,uDAAwDjB,GAC7H,CAEUe,wBAAAA,CAAyBnjB,EAA8B0iB,EAAwBN,GACrF,OAAOzR,MAAOxQ,EAAUpuB,EAAQgxC,EAAYvP,WAClC9+B,KAAK8tC,gBAAgB,IAAMxiB,EAAMlpB,KAAKsrC,EAASjiB,EAAUpuB,EAAQgxC,EAAYvP,GAAckP,EAAgB3wC,EAAQouB,GAEjI,CAEA,gBAAImjB,GACA,OAAO5uC,KAAKutC,aAChB,CAEA,eAAIsB,GACA,OAAO7uC,KAAKwtC,YAChB,EClNE,MAAOsB,GAKT5zC,WAAAA,CAAYsB,GACRwD,KAAK+uC,mBAAqBvyC,EAASE,WAAWG,mBAC9CmD,KAAKgvC,SAAWxyC,EAAS2yB,gBAC7B,CAEA,sBAAM8f,CAAiBplB,GAAgG,IAArE5W,EAAA7U,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA6B,CAAC,EAAG0gC,EAAW1gC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG+9B,GAAAA,GAAkBx8B,KAC/G,MAAMi/B,EAAc/U,EAAS+U,YACvBvX,EAA4B,GAIlC,SAFM6U,GAAkB4C,IAEnB7rB,EAAQo7B,YAAcp7B,EAAQo7B,WAAWC,SAAS,YAAa,CAEhE,GADAtuC,KAAKkvC,oBAAoBtQ,EAAavX,EAAapU,GAC/CA,EAAQk8B,uBAAyB9nB,EAAY+nB,KAAKrqC,IAAI,IAAAoO,EAAC,OAAM,QAANA,EAAApO,EAAE6iB,YAAI,IAAAzU,OAAA,EAAAA,EAAEyO,QAAS0rB,GAAkB+B,cAC1F,OAAOhoB,EAIX,GADArnB,KAAKsvC,qBAAqB1Q,EAAavX,EAAapU,GAChDA,EAAQs8B,wBAA0BloB,EAAY+nB,KAAKrqC,IAAI,IAAAoO,EAAC,OAAM,QAANA,EAAApO,EAAE6iB,YAAI,IAAAzU,OAAA,EAAAA,EAAEyO,QAAS0rB,GAAkBkC,eAC3F,OAAOnoB,EAIX,GADArnB,KAAKyvC,qBAAqB5lB,EAAUxC,EAAapU,GAC7CA,EAAQy8B,wBAA0BroB,EAAY+nB,KAAKrqC,IAAI,IAAAoO,EAAC,OAAM,QAANA,EAAApO,EAAE6iB,YAAI,IAAAzU,OAAA,EAAAA,EAAEyO,QAAS0rB,GAAkBqC,eAC3F,OAAOtoB,CAEf,CAGA,IACIA,EAAYlnB,cAAcH,KAAK4vC,YAAYhR,EAAY9/B,MAAOmU,EAAS6rB,GAC3E,CAAE,MAAOxM,GACL,GAAI0J,GAAqB1J,GACrB,MAAMA,EAEVhxB,QAAQC,MAAM,uCAAwC+wB,EAC1D,CAIA,aAFM4J,GAAkB4C,GAEjBzX,CACX,CAEU6nB,mBAAAA,CAAoBtQ,EAA0BvX,EAA2B5lB,G,UAC/E,MAAMouC,EAAmB,IAAIjR,EAAY7M,eAAoD,QAApC5E,EAAuB,QAAvBha,EAAAyrB,EAAY3M,mBAAW,IAAA9e,OAAA,EAAAA,EAAEkU,mBAAW,IAAA8F,EAAAA,EAAI,IACjG,IAAK,MAAM2iB,KAAmBD,EAAkB,CAC5C,MAAMluB,EAAmC,QAAxB+pB,EAAAoE,EAAgBnuB,gBAAQ,IAAA+pB,EAAAA,EAAI,QACvCqE,EAAyB,CAC3BpuB,SAAUquB,GAAqBruB,GAC/BvW,MAAO,CACHC,MAAO,CACHC,KAAMwkC,EAAgBxkC,KAAQ,EAC9BC,UAAWukC,EAAgBG,OAAU,GAEzClhC,IAAK,CACDzD,KAAMwkC,EAAgBxkC,KAAQ,EAC9BC,UAAWukC,EAAgBG,OAAUH,EAAgB7zC,OAAS,IAGtEkP,QAAS2kC,EAAgB3kC,QACzByc,KAAMsoB,GAAiBvuB,GACvBpY,OAAQvJ,KAAKmwC,aAEjB9oB,EAAYlnB,KAAK4vC,EACrB,CACJ,CAEUT,oBAAAA,CAAqB1Q,EAA0BvX,EAA2B5lB,GAChF,IAAK,MAAM2uC,KAAexR,EAAYzM,aAAc,CAChD,IAAI/mB,EAIJ,GAAIgoB,MAAMgd,EAAYv5B,MAAMoT,cAGxB,GAAI,kBAAmBmmB,EAAa,CAChC,MAAMv5B,EAASu5B,EAAyCC,cACxD,GAAKjd,MAAMvc,EAAMoT,aAGV,CAGH,MAAM7H,EAAqB,CAAE9W,KAAM,EAAGC,UAAW,GACjDH,EAAQ,CAAEC,MAAO+W,EAAUrT,IAAKqT,EACpC,KAR+B,CAC3B,MAAMA,EAAqB,CAAE9W,KAAMuL,EAAMiK,QAAW,EAAGvV,UAAWsL,EAAMy5B,WACxEllC,EAAQ,CAAEC,MAAO+W,EAAUrT,IAAKqT,EACpC,CAMJ,OAEAhX,GAAQihB,EAAAA,EAAAA,IAAa+jB,EAAYv5B,OAErC,GAAIzL,EAAO,CACP,MAAM2kC,EAAyB,CAC3BpuB,SAAUquB,GAAqB,SAC/B5kC,QACAD,QAASilC,EAAYjlC,QACrByc,KAAMwlB,GAAeE,GAAkBkC,cACvCjmC,OAAQvJ,KAAKmwC,aAEjB9oB,EAAYlnB,KAAK4vC,EACrB,CACJ,CACJ,CAEUN,oBAAAA,CAAqB5lB,EAA2BxC,EAA2B5lB,GACjF,IAAK,MAAM+/B,KAAa3X,EAASiH,WAAY,CACzC,MAAMyf,EAAe/O,EAAUjgC,MAC/B,GAAIgvC,EAAc,CACd,MAAMC,EAAwC,CAC1C5yC,KAAM2yC,EAAahkB,UACnB1uB,SAAU0yC,EAAa1yC,SACvB0K,MAAOgoC,EAAahoC,MACpBqf,KAAM,CACFhG,KAAM0rB,GAAkBqC,aACxBc,cAAeF,EAAahkB,UAAUnwB,MACtCyB,SAAU0yC,EAAa1yC,SACvBukC,QAASmO,EAAa/O,UAAU1I,WAGxCzR,EAAYlnB,KAAKH,KAAK0wC,aAAa,QAASH,EAAaplC,QAASqlC,GACtE,CACJ,CACJ,CAEU,iBAAMZ,CAAYnkB,EAAmBxY,GAAgE,IAApC6rB,EAAW1gC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG+9B,GAAAA,GAAkBx8B,KACvG,MAAMgxC,EAAgC,GAChCC,EAA+BA,CAAoBjvB,EAA8BxW,EAAiBqlC,KACpGG,EAAgBxwC,KAAKH,KAAK0wC,aAAa/uB,EAAUxW,EAASqlC,KAO9D,aAJMxwC,KAAK6wC,kBAAkBplB,EAAUxY,EAAS29B,EAAU9R,SACpD9+B,KAAK8wC,iBAAiBrlB,EAAUxY,EAAS29B,EAAU9R,SACnD9+B,KAAK+wC,iBAAiBtlB,EAAUxY,EAAS29B,EAAU9R,GAElD6R,CACX,CAEU,uBAAME,CAAkBplB,EAAmBxY,EAA4B29B,GAAkE,IAApC9R,EAAW1gC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG+9B,GAAAA,GAAkBx8B,K,MAC3I,MAAMivC,EAAe5uC,KAAK+uC,mBAAmBH,aAC7C,IAAK,MAAMJ,KAAeI,QAChB1S,GAAkB4C,SAClB0P,EAAY/iB,EAAUmlB,EAA4B,QAAlBz9B,EAAAF,EAAQo7B,kBAAU,IAAAl7B,EAAAA,EAAI,GAAI2rB,EAExE,CAEU,sBAAMgS,CAAiBrlB,EAAmBxY,EAA4B29B,GAAkE,IAApC9R,EAAW1gC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG+9B,GAAAA,GAAkBx8B,WACpI28B,QAAQsD,KAAIwB,EAAAA,GAAAA,IAAU3V,GAAUjd,IAAIytB,gBAChCC,GAAkB4C,GACxB,MAAMhiC,EAASkD,KAAK+uC,mBAAmBX,UAAUxwC,EAAKxB,MAAO6W,EAAQo7B,YACrE,IAAK,MAAM/iB,KAASxuB,QACVwuB,EAAM1tB,EAAMgzC,EAAU9R,KAGxC,CAEU,sBAAMiS,CAAiBtlB,EAAmBxY,EAA4B29B,GAAkE,IAApC9R,EAAW1gC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG+9B,GAAAA,GAAkBx8B,K,MAC1I,MAAMkvC,EAAc7uC,KAAK+uC,mBAAmBF,YAC5C,IAAK,MAAMF,KAAcE,QACf3S,GAAkB4C,SAClB6P,EAAWljB,EAAUmlB,EAA4B,QAAlBz9B,EAAAF,EAAQo7B,kBAAU,IAAAl7B,EAAAA,EAAI,GAAI2rB,EAEvE,CAEU4R,YAAAA,CAAgC/uB,EAA8BxW,EAAiBqlC,GACrF,MAAO,CACHrlC,UACAC,MAAO4lC,GAAmBR,GAC1B7uB,SAAUquB,GAAqBruB,GAC/BC,KAAM4uB,EAAK5uB,KACXG,gBAAiByuB,EAAKzuB,gBACtB0E,KAAM+pB,EAAK/pB,KACX5E,mBAAoB2uB,EAAK3uB,mBACzB+F,KAAM4oB,EAAK5oB,KACXre,OAAQvJ,KAAKmwC,YAErB,CAEUA,SAAAA,GACN,OAAOnwC,KAAKgvC,SAASxrB,UACzB,EAGE,SAAUwtB,GAAsCR,GAClD,GAAIA,EAAKplC,MACL,OAAOolC,EAAKplC,MAEhB,IAAIkoB,EAOJ,MAN6B,kBAAlBkd,EAAK3yC,SACZy1B,GAAUmQ,EAAAA,EAAAA,IAAoB+M,EAAK5yC,KAAKmvB,SAAUyjB,EAAK3yC,SAAU2yC,EAAKjoC,OACvC,kBAAjBioC,EAAK3Y,UACnBvE,GAAU2d,EAAAA,EAAAA,IAAmBT,EAAK5yC,KAAKmvB,SAAUyjB,EAAK3Y,QAAS2Y,EAAKjoC,QAEjE,OAAP+qB,QAAO,IAAPA,IAAAA,EAAYkd,EAAK5yC,KAAKmvB,UACjBuG,EAMEA,EAAQloB,MALJ,CACHC,MAAO,CAAEC,KAAM,EAAGC,UAAW,GAC7BwD,IAAK,CAAEzD,KAAM,EAAGC,UAAW,GAIvC,CAQM,SAAUykC,GAAqBruB,GACjC,OAAQA,GACJ,IAAK,QACD,OAAO,EACX,IAAK,UACD,OAAO,EACX,IAAK,OACD,OAAO,EACX,IAAK,OACD,OAAO,EACX,QACI,MAAM,IAAIjhB,MAAM,gCAAkCihB,GAE9D,CAEM,SAAUuuB,GAAiBvuB,GAC7B,OAAQA,GACJ,IAAK,QACD,OAAOyrB,GAAeE,GAAkB+B,aAC5C,IAAK,UACD,OAAOjC,GAAeE,GAAkB4D,eAC5C,IAAK,OACD,OAAO9D,GAAeE,GAAkB6D,YAC5C,IAAK,OACD,OAAO/D,GAAeE,GAAkB8D,YAC5C,QACI,MAAM,IAAI1wC,MAAM,gCAAkCihB,GAE9D,EAEA,SAAiB2rB,GACAA,EAAA+B,YAAc,eACd/B,EAAA4D,cAAgB,iBAChB5D,EAAA6D,WAAa,cACb7D,EAAA8D,WAAa,cACb9D,EAAAkC,aAAe,gBACflC,EAAAqC,aAAe,eAC/B,CAPD,CAAiBrC,KAAAA,GAAiB,KChQ5B,MAAO+D,GAKTn2C,WAAAA,CAAYsB,GACRwD,KAAKihC,eAAiBzkC,EAASuhC,UAAUmD,eACzClhC,KAAKokC,aAAe5nC,EAASs0B,WAAWuT,YAC5C,CAEA2C,iBAAAA,CAAkBppC,EAAe/B,EAA0BguB,GACvD,MAAMzsB,EAAc,OAARysB,QAAQ,IAARA,EAAAA,GAAYkW,EAAAA,GAAAA,IAAYniC,GAChC,OAAJ/B,QAAI,IAAJA,IAAAA,EAASmE,KAAKokC,aAAad,QAAQ1lC,IACnC,MAAMiI,EAAO7F,KAAKihC,eAAe4B,eAAejlC,GAChD,IAAK/B,EACD,MAAM,IAAI6E,MAAM,gBAADiF,OAAiBE,EAAI,kBAExC,IAAIyrC,EACJ,MAAMC,EAAoBA,KAAK,IAAAp+B,EAAA,OAAgB,OAAfm+B,QAAe,IAAfA,EAAAA,EAAAA,GAAoB3L,EAAAA,EAAAA,IAAqD,QAAnCxyB,EAAAnT,KAAKokC,aAAaZ,YAAY5lC,UAAK,IAAAuV,EAAAA,EAAIvV,EAAKmvB,WAClH,MAAO,CACHnvB,OACA/B,OACA,eAAI21C,GACA,OAAOD,GACX,EACAE,kBAAkB9L,EAAAA,EAAAA,IAAkB/nC,EAAKmvB,UACzCphB,KAAM/N,EAAKxB,MACXwlC,YAAaxkC,EAAIsiB,IACjB7Z,OAER,EAuCE,MAAO6rC,GAITx2C,WAAAA,CAAYsB,GACRwD,KAAKukC,YAAc/nC,EAASuhC,UAAUmD,cAC1C,CAEA,wBAAMyQ,CAAmB9nB,GAA+D,IAApCiV,EAAW1gC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG+9B,GAAAA,GAAkBx8B,KAChF,MAAMijC,EAAgC,GAChCnX,EAAW5B,EAAS+U,YAAY9/B,MACtC,IAAK,MAAMguB,KAAWsU,EAAAA,GAAAA,IAAU3V,SACtByQ,GAAkB4C,IACxBuC,EAAAA,GAAAA,IAAiBvU,GAAS9c,OAAOuxB,KAAYG,EAAAA,GAAAA,IAAeH,IAAU9sB,QAAQ8sB,IAE1E,MAAMhf,EAAcviB,KAAKgnC,kBAAkBzF,GACvChf,GACAqgB,EAAMziC,KAAKoiB,KAIvB,OAAOqgB,CACX,CAEUoE,iBAAAA,CAAkBzF,GACxB,MAAMqQ,EAAkBrQ,EAAQC,UAAUsB,iBACpC+O,EAAatQ,EAAQC,UAAUa,SACrC,IAAKuP,IAAoBC,EACrB,OAEJ,MAAMC,GAAS/R,EAAAA,GAAAA,IAAYwB,EAAQhV,WAAW7M,IAC9C,MAAO,CACH6lB,UAAWuM,EACXtM,WAAYxlC,KAAKukC,YAAY1B,eAAetB,EAAQhV,WACpD3M,UAAWgyB,EAAgBhQ,YAC3B6D,WAAYmM,EAAgB/rC,KAC5B6/B,SAASC,EAAAA,EAAAA,IAAkBkM,GAC3BjM,MAAOlC,GAASE,OAAOgO,EAAgBhQ,YAAakQ,GAE5D,EC/GE,MAAOC,GAAb72C,WAAAA,GACc,KAAA82C,iBAAmB,IACnB,KAAAC,eAAiB,GAuC/B,CArCIpP,cAAAA,CAAejlC,GACX,GAAIA,EAAK29B,WAAY,CACjB,MAAM2W,EAAgBlyC,KAAK6iC,eAAejlC,EAAK29B,YACzC4W,EAAanyC,KAAKoyC,eAAex0C,GAEvC,OADiBs0C,EAAgBlyC,KAAKgyC,iBAAmBG,CAE7D,CACA,MAAO,EACX,CAEUC,cAAAA,CAAcpd,GAAiD,IAAhD,mBAAE0X,EAAkB,gBAAEC,GAA0B3X,EACrE,IAAK0X,EACD,MAAM,IAAIhsC,MAAM,6CAEpB,YAAwBrC,IAApBsuC,EACOD,EAAqB1sC,KAAKiyC,eAAiBtF,EAE/CD,CACX,CAEA1J,UAAAA,CAAwCplC,EAAeiI,GAEnD,OADiBA,EAAKm+B,MAAMhkC,KAAKgyC,kBACjBx9B,OAAO,CAAC69B,EAAeC,KACnC,IAAKD,GAAyC,IAAxBC,EAAar2C,OAC/B,OAAOo2C,EAEX,MAAME,EAAgBD,EAAa7sC,QAAQzF,KAAKiyC,gBAChD,GAAIM,EAAgB,EAAG,CACnB,MAAM10C,EAAWy0C,EAAat2C,UAAU,EAAGu2C,GACrCC,EAAa70C,SAAS20C,EAAat2C,UAAUu2C,EAAgB,IAC7DlwC,EAASgwC,EAAuDx0C,GACtE,OAAY,OAALwE,QAAK,IAALA,OAAK,EAALA,EAAQmwC,EACnB,CACA,OAAQH,EAAqDC,IAC9D10C,EACP,E,ICtDa60C,G,WCiEX,MAAOC,GAQTx3C,WAAAA,CAAYsB,GALO,KAAAm2C,OAAS,IAAIjW,GACtB,KAAAkW,SAAgD,CAAC,EACjD,KAAAC,iBAAkB,EAClB,KAAAC,oCAAsC,IAAIzzC,GAAAA,QAGhDW,KAAK69B,gBAAkBrhC,EAASqC,eACpC,CAEA,SAAIk0C,GACA,OAAO/yC,KAAK2yC,OAAOhW,OACvB,CAEAtpB,UAAAA,CAAW2/B,G,QACPhzC,KAAK6yC,gBAA8D,QAA5C1lB,EAA6B,QAA7Bha,EAAA6/B,EAAOC,aAAalV,iBAAS,IAAA5qB,OAAA,EAAAA,EAAE+/B,qBAAa,IAAA/lB,GAAAA,CACvE,CAEA,iBAAMgmB,CAAYH,GACd,GAAIhzC,KAAK6yC,gBAAiB,CACtB,GAAIG,EAAO91C,SAAU,CAIjB,MAAMk2C,EAAYpzC,KAAK69B,gBAAgB+B,IACvCoT,EAAO91C,SAAS,CAEZm2C,QAASD,EAAU5kC,IAAI8kC,GAAQtzC,KAAKuzC,cAAcD,EAAKnkB,iBAAiB3L,cAEhF,CAEA,GAAIwvB,EAAOQ,mBAAoB,CAG3B,MAAMC,EAAiBzzC,KAAK69B,gBAAgB+B,IAAIpxB,IAAI8kC,IAAQ,CAExDD,QAASrzC,KAAKuzC,cAAcD,EAAKnkB,iBAAiB3L,eAIhD5R,QAAgBohC,EAAOQ,mBAAmBC,GAChDA,EAAeh/B,QAAQ,CAACi/B,EAAMzkC,KAC1BjP,KAAK2zC,2BAA2BD,EAAKL,QAAUzhC,EAAQ3C,KAE/D,CACJ,CACAjP,KAAK2yC,OAAOtvC,SAChB,CAQAuwC,mBAAAA,CAAoBtwB,GACXA,EAAOsvB,UAGZ1zC,OAAO8Y,KAAKsL,EAAOsvB,UAAUn+B,QAAQ4+B,IACjC,MAAMH,EAAgB5vB,EAAOsvB,SAASS,GACtCrzC,KAAK2zC,2BAA2BN,EAASH,GACzClzC,KAAK8yC,oCAAoC3wC,KAAK,CAAEkxC,UAASH,mBAEjE,CAEUS,0BAAAA,CAA2BN,EAAiBH,GAClDlzC,KAAK4yC,SAASS,GAAWH,CAC7B,CAQA,sBAAMW,CAAiBnuB,EAAkBwtB,SAC/BlzC,KAAK+yC,MAEX,MAAMe,EAAc9zC,KAAKuzC,cAAc7tB,GACvC,GAAI1lB,KAAK4yC,SAASkB,GACd,OAAO9zC,KAAK4yC,SAASkB,GAAaZ,EAE1C,CAEUK,aAAAA,CAAc/vB,GACpB,MAAO,GAAP7d,OAAU6d,EACd,CAEA,gCAAIuwB,GACA,OAAO/zC,KAAK8yC,oCAAoCpxC,KACpD,GD9JJ,SAAiB+wC,GAGGA,EAAAxzB,OAAhB,SAAuBnf,GACnB,MAAO,CACHJ,QAASu8B,eAAkBn8B,IAEnC,CACH,CARD,CAAiB2yC,KAAAA,GAAU,KEoGrB,MAAOuB,GAqBT94C,WAAAA,CAAYsB,GAnBZ,KAAAy3C,mBAAmC,CAE/Bv3C,WAAY,CACR2xC,WAAY,CAAC,WAAY,UASd,KAAA6F,gBAA4C,GAC5C,KAAAC,oBAAsB,IAAItO,GAC1B,KAAAuO,uBAAyB,IAAIvO,GAC7B,KAAAwO,WAAa,IAAIznC,IACjB,KAAA0nC,qBAAuB,IAAI1nC,IACpC,KAAA2nC,aAAe5W,GAAc4C,QAGnCvgC,KAAK6gC,iBAAmBrkC,EAASuhC,UAAU+C,iBAC3C9gC,KAAK0/B,uBAAyBljC,EAASuhC,UAAU4B,uBACjD3/B,KAAK89B,cAAgBthC,EAASuhC,UAAUC,cACxCh+B,KAAKmpC,aAAe3sC,EAASuhC,UAAUuG,aACvCtkC,KAAK69B,gBAAkBrhC,EAASqC,eACpC,CAEA,WAAM21C,CAAyBC,GAAsG,IAAhExhC,EAAA7U,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAwB,CAAC,EAAG0gC,EAAW1gC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG+9B,GAAAA,GAAkBx8B,K,QAC7H,IAAK,MAAMkqB,KAAY4qB,EAAW,CAC9B,MAAM/rC,EAAMmhB,EAASnK,IAAItZ,WACzB,GAAIyjB,EAAS5Y,QAAU0sB,GAAc+W,WACjC,GAAkC,mBAAvBzhC,EAAQvW,YAA4BuW,EAAQvW,WAEnDmtB,EAAS5Y,MAAQ0sB,GAAcgX,kBAC/B9qB,EAASxC,iBAAchpB,EACvB2B,KAAKq0C,WAAWpa,OAAOvxB,QACpB,GAAkC,kBAAvBuK,EAAQvW,WAAyB,CAC/C,MAAM23C,EAAar0C,KAAKq0C,WAAWpvC,IAAIyD,GACjCksC,EAAuC,QAAlBzhC,EAAU,OAAVkhC,QAAU,IAAVA,OAAU,EAAVA,EAAYryC,cAAM,IAAAmR,OAAA,EAAAA,EAAE0hC,iBAC/C,GAAID,EAAoB,CAGpB,MACMvG,GAD6C,QAA7BlhB,EAAAla,EAAQvW,WAAW2xC,kBAAU,IAAAlhB,EAAAA,EAAIkgB,GAAmBzN,KACzC5vB,OAAOpM,IAAMgxC,EAAmBtG,SAAS1qC,IACtEyqC,EAAWpyC,OAAS,IACpB+D,KAAKq0C,WAAWnnC,IAAIxE,EAAK,CACrBosC,WAAW,EACX7hC,QAAS,CACLvW,WAAUwC,OAAAoS,OAAApS,OAAAoS,OAAA,GACH2B,EAAQvW,YAAU,CACrB2xC,gBAGRrsC,OAAQqyC,EAAWryC,SAEvB6nB,EAAS5Y,MAAQ0sB,GAAcgX,kBAEvC,CACJ,OAGA30C,KAAKq0C,WAAWpa,OAAOvxB,EAE/B,CACA1I,KAAKu0C,aAAe5W,GAAc4C,cAC5BvgC,KAAK+0C,WAAWN,EAAUjmC,IAAIpN,GAAKA,EAAEse,KAAM,UAC3C1f,KAAKg1C,eAAeP,EAAWxhC,EAAS6rB,EAClD,CAEA,YAAMtU,CAAOyqB,EAAgBhM,GAAoD,IAApCnK,EAAW1gC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG+9B,GAAAA,GAAkBx8B,KACzEK,KAAKu0C,aAAe5W,GAAc4C,QAElC,IAAK,MAAM2U,KAAcjM,EACrBjpC,KAAK6gC,iBAAiBJ,eAAeyU,GACrCl1C,KAAKq0C,WAAWpa,OAAOib,EAAW9uC,YAClCpG,KAAKmpC,aAAa9oC,OAAO60C,GAG7B,IAAK,MAAMC,KAAcF,EAAS,CAE9B,IADoBj1C,KAAK6gC,iBAAiBT,mBAAmB+U,GAC3C,CAId,MAAMC,EAAcp1C,KAAK0/B,uBAAuBjB,UAAU,CAAEriC,MAAO,WAAa+4C,GAChFC,EAAYnkC,MAAQ0sB,GAAc4C,QAClCvgC,KAAK6gC,iBAAiBhB,YAAYuV,EACtC,CACAp1C,KAAKq0C,WAAWpa,OAAOkb,EAAW/uC,WACtC,CAEA,MAAMivC,GAAiBhe,EAAAA,GAAAA,IAAO4d,GAAStvC,OAAOsjC,GAASz6B,IAAIkR,GAAOA,EAAItZ,YAAYkvC,QAClFt1C,KAAK6gC,iBAAiBjB,IACjB5vB,OAAO5S,IAAQi4C,EAAer/B,IAAI5Y,EAAIsiB,IAAItZ,aAAepG,KAAKu1C,aAAan4C,EAAKi4C,IAChF5gC,QAAQrX,IACU4C,KAAK69B,gBAAgBwB,YAAYjiC,EAAIsiB,KAAKoR,WAAWC,OAC7DuP,OAAOljC,GACdA,EAAI6T,MAAQ6Z,KAAK1S,IAAIhb,EAAI6T,MAAO0sB,GAAcgF,gBAC9CvlC,EAAIiqB,iBAAchpB,UAGpB2B,KAAK+0C,WAAWE,EAAShM,SAEzB/M,GAAkB4C,GAGxB,MAAM0W,EAAmBx1C,KAAKy1C,cAC1Bz1C,KAAK6gC,iBAAiBjB,IACjB5vB,OAAO5S,I,MAEJ,OAAAA,EAAI6T,MAAQ0sB,GAAc+X,UAEiB,QAAvCviC,EAAAnT,KAAKq0C,WAAWpvC,IAAI7H,EAAIsiB,IAAItZ,mBAAW,IAAA+M,OAAA,EAAAA,EAAE2hC,aAEhDa,iBAEH31C,KAAKg1C,eAAeQ,EAAkBx1C,KAAKi0C,mBAAoBnV,EACzE,CAEU,gBAAMiW,CAAWE,EAAgBhM,SACjC3M,QAAQsD,IAAI5/B,KAAKk0C,gBAAgB1lC,IAAI5M,GAAYA,EAASqzC,EAAShM,IAC7E,CASUwM,aAAAA,CAAchB,GACpB,IAAIzmC,EAAO,EACPC,EAAQwmC,EAAUx4C,OAAS,EAE/B,KAAO+R,EAAOC,GAAO,CACjB,KAAOD,EAAOymC,EAAUx4C,QAAU+D,KAAK41C,gBAAgBnB,EAAUzmC,KAC7DA,IAGJ,KAAOC,GAAS,IAAMjO,KAAK41C,gBAAgBnB,EAAUxmC,KACjDA,IAGAD,EAAOC,KACNwmC,EAAUzmC,GAAOymC,EAAUxmC,IAAU,CAACwmC,EAAUxmC,GAAQwmC,EAAUzmC,IAE3E,CAEA,OAAOymC,CACX,CAEQmB,eAAAA,CAAgBx4C,G,MACpB,OAAO8oB,QAA0B,QAAlB/S,EAAAnT,KAAK89B,qBAAa,IAAA3qB,OAAA,EAAAA,EAAElO,IAAI7H,EAAIsiB,KAC/C,CAKU61B,YAAAA,CAAa1rB,EAA2BgsB,GAE9C,QAAIhsB,EAASiH,WAAWse,KAAK9W,QAAqBj6B,IAAdi6B,EAAI/2B,QAIjCvB,KAAKmpC,aAAa2M,WAAWjsB,EAAUgsB,EAClD,CAEA9M,QAAAA,CAASjpC,GAEL,OADAE,KAAKk0C,gBAAgB/zC,KAAKL,GACnB2yC,GAAWxzB,OAAO,KACrB,MAAM1W,EAAQvI,KAAKk0C,gBAAgBzuC,QAAQ3F,GACvCyI,GAAS,GACTvI,KAAKk0C,gBAAgBzzC,OAAO8H,EAAO,IAG/C,CAWU,oBAAMysC,CAAeP,EAA8BxhC,EAAuB6rB,GAChF9+B,KAAK+1C,aAAatB,EAAWxhC,SAEvBjT,KAAKg2C,cAAcvB,EAAW9W,GAAcqB,OAAQF,EAAa1hC,GACnE4C,KAAK0/B,uBAAuBlV,OAAOptB,EAAK0hC,UAGtC9+B,KAAKg2C,cAAcvB,EAAW9W,GAAcsY,eAAgBnX,EAAa1hC,GAC3E4C,KAAKmpC,aAAa+M,cAAc94C,EAAK0hC,UAGnC9+B,KAAKg2C,cAAcvB,EAAW9W,GAAcgF,eAAgB7D,EAAa7C,UAC3E,MAAMka,EAAmBn2C,KAAK69B,gBAAgBwB,YAAYjiC,EAAIsiB,KAAKoR,WAAWslB,iBAC9Eh5C,EAAIojC,wBAA0B2V,EAAiBlP,mBAAmB7pC,EAAK0hC,WAGrE9+B,KAAKg2C,cAAcvB,EAAW9W,GAAc+X,OAAQ5W,EAAa1hC,GACpD4C,KAAK69B,gBAAgBwB,YAAYjiC,EAAIsiB,KAAKoR,WAAWC,OACtDoQ,KAAK/jC,EAAK0hC,UAGtB9+B,KAAKg2C,cAAcvB,EAAW9W,GAAcgX,kBAAmB7V,EAAa1hC,GAC9E4C,KAAKmpC,aAAakN,iBAAiBj5C,EAAK0hC,IAG5C,MAAMwX,EAAgB7B,EAAUzkC,OAAO5S,GAAO4C,KAAKu2C,eAAen5C,UAC5D4C,KAAKg2C,cAAcM,EAAe3Y,GAAc+W,UAAW5V,EAAa1hC,GAC1E4C,KAAKw2C,SAASp5C,EAAK0hC,IAIvB,IAAK,MAAM1hC,KAAOq3C,EAAW,CACzB,MAAMxjC,EAAQjR,KAAKq0C,WAAWpvC,IAAI7H,EAAIsiB,IAAItZ,YACtC6K,IACAA,EAAM6jC,WAAY,EAE1B,CACJ,CAQUiB,YAAAA,CAAatB,EAA8BxhC,GACjD,IAAK,MAAM7V,KAAOq3C,EAAW,CACzB,MAAM/rC,EAAMtL,EAAIsiB,IAAItZ,WACd6K,EAAQjR,KAAKq0C,WAAWpvC,IAAIyD,GAI7BuI,IAASA,EAAM6jC,WAChB90C,KAAKq0C,WAAWnnC,IAAIxE,EAAK,CACrBosC,WAAW,EACX7hC,UACAjR,OAAa,OAALiP,QAAK,IAALA,OAAK,EAALA,EAAOjP,QAG3B,CACJ,CAYU,mBAAMg0C,CAAcvB,EAA8BgC,EAA4B3X,EACpFh/B,GACA,MAAM42C,EAAWjC,EAAUzkC,OAAO5S,GAAOA,EAAI6T,MAAQwlC,GACrD,IAAK,MAAM5sB,KAAY6sB,QACbxa,GAAkB4C,SAClBh/B,EAAS+pB,GACfA,EAAS5Y,MAAQwlC,QACXz2C,KAAK22C,oBAAoB9sB,EAAU4sB,EAAa3X,GAM1D,MAAM8X,EAAkBnC,EAAUzkC,OAAO5S,GAAOA,EAAI6T,QAAUwlC,SACxDz2C,KAAK62C,iBAAiBD,EAAiBH,EAAa3X,GAC1D9+B,KAAKu0C,aAAekC,CACxB,CAEA3N,YAAAA,CAAa2N,EAA4B32C,GAErC,OADAE,KAAKm0C,oBAAoBt0C,IAAI42C,EAAa32C,GACnC2yC,GAAWxzB,OAAO,KACrBjf,KAAKm0C,oBAAoBla,OAAOwc,EAAa32C,IAErD,CAEAg3C,eAAAA,CAAgBL,EAA4B32C,GAExC,OADAE,KAAKo0C,uBAAuBv0C,IAAI42C,EAAa32C,GACtC2yC,GAAWxzB,OAAO,KACrBjf,KAAKo0C,uBAAuBna,OAAOwc,EAAa32C,IAExD,CAIAi3C,SAAAA,CAAU9lC,EAAsB+lC,EAAsClY,GAClE,IAAIpf,EAOJ,GANIs3B,GAAc,SAAUA,EACxBt3B,EAAMs3B,EAENlY,EAAckY,EAEP,OAAXlY,QAAW,IAAXA,IAAAA,EAAgB3C,GAAAA,GAAkBx8B,MAC9B+f,EAAK,CACL,MAAMmK,EAAW7pB,KAAK6gC,iBAAiBd,YAAYrgB,GACnD,GAAImK,GAAYA,EAAS5Y,MAAQA,EAC7B,OAAOqrB,QAAQj5B,QAAQqc,EAE/B,CACA,OAAI1f,KAAKu0C,cAAgBtjC,EACdqrB,QAAQj5B,aAAQhF,GAChBygC,EAAYrC,wBACZH,QAAQM,OAAOb,IAEnB,IAAIO,QAAQ,CAACj5B,EAASu5B,KACzB,MAAMqa,EAAkBj3C,KAAK8oC,aAAa73B,EAAO,KAG7C,GAFAgmC,EAAgBv3C,UAChBw3C,EAAiBx3C,UACbggB,EAAK,CACL,MAAMmK,EAAW7pB,KAAK6gC,iBAAiBd,YAAYrgB,GACnDrc,EAAgB,OAARwmB,QAAQ,IAARA,OAAQ,EAARA,EAAUnK,IACtB,MACIrc,OAAQhF,KAGV64C,EAAmBpY,EAAaqY,wBAAwB,KAC1DF,EAAgBv3C,UAChBw3C,EAAiBx3C,UACjBk9B,EAAOb,OAGnB,CAEU,yBAAM4a,CAAoB9sB,EAA2B5Y,EAAsB6tB,GACjF,MACMsY,EADYp3C,KAAKo0C,uBAAuBnvC,IAAIgM,GAClBnQ,QAChC,IAAK,MAAMc,KAAYw1C,EACnB,UACUx1C,EAASioB,EAAUiV,EAC7B,CAAE,MAAOxM,GAGL,IAAK0J,GAAqB1J,GACtB,MAAMA,CAEd,CAER,CAEU,sBAAMukB,CAAiBpC,EAA8BxjC,EAAsB6tB,GACjF,GAAyB,IAArB2V,EAAUx4C,OAEV,OAEJ,MACMm7C,EADYp3C,KAAKm0C,oBAAoBlvC,IAAIgM,GACfnQ,QAChC,IAAK,MAAMc,KAAYw1C,QACblb,GAAkB4C,SAClBl9B,EAAS6yC,EAAW3V,EAElC,CAOUyX,cAAAA,CAAe1sB,GACrB,OAAO3D,QAAQlmB,KAAKq3C,gBAAgBxtB,GAAUntB,WAClD,CAMU,cAAM85C,CAAS3sB,EAA2BiV,G,QAChD,MAAMriC,EAAYuD,KAAK69B,gBAAgBwB,YAAYxV,EAASnK,KAAKhjB,WAAW4wC,kBACtEgK,EAAoBt3C,KAAKq3C,gBAAgBxtB,GAAUntB,WACnDuW,EAAuC,kBAAtBqkC,EAAiCA,OAAoBj5C,EACtEgpB,QAAoB5qB,EAAUwyC,iBAAiBplB,EAAU5W,EAAS6rB,GACpEjV,EAASxC,YACTwC,EAASxC,YAAYlnB,QAAQknB,GAE7BwC,EAASxC,YAAcA,EAI3B,MAAMpW,EAAQjR,KAAKq0C,WAAWpvC,IAAI4kB,EAASnK,IAAItZ,YAC/C,GAAI6K,EAAO,CACK,QAAZkC,EAAAlC,EAAMjP,cAAM,IAAAmR,IAAZlC,EAAMjP,OAAW,CAAC,GAClB,MAAMu1C,EAAmC,QAAnBpqB,EAAO,OAAPla,QAAO,IAAPA,OAAO,EAAPA,EAASo7B,kBAAU,IAAAlhB,EAAAA,EAAIkgB,GAAmBzN,IAC5D3uB,EAAMjP,OAAO6yC,iBACb5jC,EAAMjP,OAAO6yC,iBAAiB10C,QAAQo3C,GAEtCtmC,EAAMjP,OAAO6yC,iBAAmB,IAAI0C,EAE5C,CACJ,CAEUF,eAAAA,CAAgBxtB,G,QACtB,OAA4D,QAArDsD,EAA4C,QAA5Cha,EAAAnT,KAAKq0C,WAAWpvC,IAAI4kB,EAASnK,IAAItZ,mBAAW,IAAA+M,OAAA,EAAAA,EAAEF,eAAO,IAAAka,EAAAA,EAAI,CAAC,CACrE,ECrbE,MAAOqqB,GAuBTt8C,WAAAA,CAAYsB,GAbO,KAAAi7C,YAAc,IAAI7qC,IAKlB,KAAA8qC,kBAAoB,IAAIpP,GAMxB,KAAAqP,eAAiB,IAAI/qC,IAGpC5M,KAAKy0C,UAAYj4C,EAASuhC,UAAU+C,iBACpC9gC,KAAK69B,gBAAkBrhC,EAASqC,gBAChCmB,KAAKixB,cAAgBz0B,EAAS00B,aAClC,CAEAoU,iBAAAA,CAAkBN,EAAqB4S,GACnC,MAAMC,GAAe9X,EAAAA,GAAAA,IAAYiF,GAAYtlB,IACvC1d,EAAiC,GAQvC,OAPAhC,KAAK23C,eAAeljC,QAAQqjC,IACxBA,EAAQrjC,QAAQsjC,IACRrU,GAASE,OAAOmU,EAASn4B,UAAWi4B,IAAiBE,EAAStS,aAAemS,GAC7E51C,EAAO7B,KAAK43C,QAIjB1gB,EAAAA,GAAAA,IAAOr1B,EAClB,CAEA+nC,WAAAA,CAAYiO,EAAmBC,GAC3B,IAAIC,GAAe7gB,EAAAA,GAAAA,IAAOr3B,KAAKy3C,YAAYz/B,QAI3C,OAHIigC,IACAC,EAAeA,EAAaloC,OAAO0P,IAAQu4B,GAAQA,EAAKjiC,IAAI0J,KAEzDw4B,EACF1pC,IAAIkR,GAAO1f,KAAKm4C,oBAAoBz4B,EAAKs4B,IACzC7R,MACT,CAEUgS,mBAAAA,CAAoBz4B,EAAas4B,G,MACvC,IAAKA,EACD,OAAgC,QAAzB7kC,EAAAnT,KAAKy3C,YAAYxyC,IAAIya,UAAI,IAAAvM,EAAAA,EAAI,GAExC,MAAMszB,EAAezmC,KAAK03C,kBAAkBzyC,IAAIya,EAAKs4B,EAAU,K,MAE3D,OADqD,QAAzB7kC,EAAAnT,KAAKy3C,YAAYxyC,IAAIya,UAAI,IAAAvM,EAAAA,EAAI,IAC9BnD,OAAO5O,GAAKpB,KAAKixB,cAAcwY,UAAUroC,EAAEuK,KAAMqsC,MAEhF,OAAOvR,CACX,CAEApmC,MAAAA,CAAOqf,GACH,MAAMogB,EAAYpgB,EAAItZ,WACtBpG,KAAKy3C,YAAYxd,OAAO6F,GACxB9/B,KAAK03C,kBAAkB5lB,MAAMgO,GAC7B9/B,KAAK23C,eAAe1d,OAAO6F,EAC/B,CAEA,mBAAMoW,CAAcrsB,GAA+D,IAApCiV,EAAW1gC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG+9B,GAAAA,GAAkBx8B,KAC3E,MAAMnD,EAAWwD,KAAK69B,gBAAgBwB,YAAYxV,EAASnK,KACrDtgB,QAAgB5C,EAASs0B,WAAWslB,iBAAiBzP,eAAe9c,EAAUiV,GAC9Epf,EAAMmK,EAASnK,IAAItZ,WACzBpG,KAAKy3C,YAAYvqC,IAAIwS,EAAKtgB,GAC1BY,KAAK03C,kBAAkB5lB,MAAMpS,EACjC,CAEA,sBAAM22B,CAAiBxsB,GAA+D,IAApCiV,EAAW1gC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG+9B,GAAAA,GAAkBx8B,KAC9E,MAAMnD,EAAWwD,KAAK69B,gBAAgBwB,YAAYxV,EAASnK,KACrD04B,QAAkB57C,EAASuhC,UAAUsa,6BAA6B1G,mBAAmB9nB,EAAUiV,GACrG9+B,KAAK23C,eAAezqC,IAAI2c,EAASnK,IAAItZ,WAAYgyC,EACrD,CAEAtC,UAAAA,CAAWjsB,EAA2BgsB,GAClC,MAAM/kB,EAAa9wB,KAAK23C,eAAe1yC,IAAI4kB,EAASnK,IAAItZ,YACxD,QAAK0qB,GAGEA,EAAWse,KAAK9W,IAAQA,EAAIsN,OAASiQ,EAAY7/B,IAAIsiB,EAAI1Y,UAAUxZ,YAC9E,ECxGE,MAAOkyC,GAYTp9C,WAAAA,CAAYsB,GAVZ,KAAA+7C,oBAAoC,CAAC,EAOlB,KAAA5F,OAAS,IAAIjW,GAI5B18B,KAAK69B,gBAAkBrhC,EAASqC,gBAChCmB,KAAK6gC,iBAAmBrkC,EAASuhC,UAAU+C,iBAC3C9gC,KAAKw4C,gBAAkBh8C,EAASuhC,UAAU8K,gBAC1C7oC,KAAKi+B,mBAAqBzhC,EAASuhC,UAAUG,mBAC7Cl+B,KAAKy4C,MAAQj8C,EAASuhC,UAAU2a,aACpC,CAEA,SAAI3F,GACA,OAAO/yC,KAAK2yC,OAAOhW,OACvB,CAEA,oBAAIgc,GACA,OAAO34C,KAAK44C,OAChB,CAEAvlC,UAAAA,CAAW2/B,G,MACPhzC,KAAK44C,QAAiC,QAAvBzlC,EAAA6/B,EAAO2F,wBAAgB,IAAAxlC,EAAAA,OAAI9U,CAC9C,CAEA80C,WAAAA,CAAY0F,GAGR,OAAO74C,KAAKy4C,MAAMK,MAAMjiC,IAAQ,IAAA1D,EAAC,OAAAnT,KAAK+4C,oBAAgC,QAAZ5lC,EAAAnT,KAAK44C,eAAO,IAAAzlC,EAAAA,EAAI,GAAI0D,IAClF,CAEA,yBAAMkiC,CAAoBH,GAAgE,IAApC9Z,EAAW1gC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG+9B,GAAAA,GAAkBx8B,KAClF,MAAM80C,QAAkBz0C,KAAKg5C,eAAeJ,SAGtC1c,GAAkB4C,SAClB9+B,KAAKw4C,gBAAgBhE,MAAMC,EAAWz0C,KAAKu4C,oBAAqBzZ,EAC1E,CAMU,oBAAMka,CAAeJ,GAC3B,MAAM3L,EAAiBjtC,KAAK69B,gBAAgB+B,IAAIxmB,QAAQhY,GAAKA,EAAE+tB,iBAAiB8d,gBAC1EwH,EAA+B,GAC/BwE,EAAapvB,IACf4qB,EAAUt0C,KAAK0pB,GACV7pB,KAAK6gC,iBAAiBV,YAAYtW,EAASnK,MAC5C1f,KAAK6gC,iBAAiBhB,YAAYhW,IAY1C,aANM7pB,KAAKk5C,wBAAwBN,EAASK,SACtC3c,QAAQsD,IACVgZ,EAAQpqC,IAAI2qC,GAAM,CAACA,EAAIn5C,KAAKo5C,cAAcD,KACrC3qC,IAAIytB,SAAej8B,KAAKq5C,kBAAkBtoC,EAAOk8B,EAAgBgM,KAE1Ej5C,KAAK2yC,OAAOtvC,UACLoxC,CACX,CAOUyE,uBAAAA,CAAwBI,EAA6BC,GAC3D,OAAOjd,QAAQj5B,SACnB,CAOU+1C,aAAAA,CAAcI,GACpB,OAAOt/B,GAAAA,EAAIxV,MAAM80C,EAAgB95B,IACrC,CAMU,oBAAM25B,CAAeG,EAAkCC,EAAiBxM,EAA0BgM,GACxG,MAAM5vB,QAAgBrpB,KAAKi+B,mBAAmByb,cAAcD,SACtDnd,QAAQsD,IAAIvW,EAAQ7a,IAAIytB,UAC1B,GAAIj8B,KAAK25C,aAAaH,EAAiBzoC,EAAOk8B,GAC1C,GAAIl8B,EAAM6oC,kBACA55C,KAAKq5C,eAAeG,EAAiBzoC,EAAM2O,IAAKutB,EAAgBgM,QACnE,GAAIloC,EAAM8oC,OAAQ,CACrB,MAAMhwB,QAAiB7pB,KAAK6gC,iBAAiBb,oBAAoBjvB,EAAM2O,KACvEu5B,EAAUpvB,EACd,IAGZ,CAKU8vB,YAAAA,CAAaG,EAAmC/oC,EAAuBk8B,GAC7E,MAAMpxC,EAAO6nC,GAASv/B,SAAS4M,EAAM2O,KACrC,GAAI7jB,EAAKqwC,WAAW,KAChB,OAAO,EAEX,GAAIn7B,EAAM6oC,YACN,MAAgB,iBAAT/9C,GAAoC,QAATA,EAC/B,GAAIkV,EAAM8oC,OAAQ,CACrB,MAAMz1C,EAAUs/B,GAASt/B,QAAQ2M,EAAM2O,KACvC,OAAOutB,EAAeqB,SAASlqC,EACnC,CACA,OAAO,CACX,ECpLE,MAAO21C,GAETC,gCAAAA,CAAiC3sB,EAAkBpD,EAAqBhuB,EAAgBqP,EAAe2kC,GACnG,OAAOgK,EAAAA,GAA0BD,iCAAiC3sB,EAAUpD,EAAahuB,EAAQqP,EAAM2kC,EAC3G,CAEAiK,gCAAAA,CAAiCrjC,GAC7B,OAAOojC,EAAAA,GAA0BC,iCAAiCrjC,EACtE,EAgCE,MAAOsjC,GAOTj/C,WAAAA,CAAYsB,GACRwD,KAAKyvB,qBAAuBjzB,EAASuB,OAAOq8C,0BAC5Cp6C,KAAKq6C,aAAe79C,EAASuB,OAAOC,aACpC,MAAMyuB,EAASzsB,KAAKq6C,aAAaC,YAAY99C,EAASm/B,QAAS,CAC3D4L,gBAAiB/qC,EAAS2yB,iBAAiBoY,kBAE/CvnC,KAAKu6C,WAAav6C,KAAKw6C,sBAAsB/tB,GAC7C,MAAMguB,EAAcC,GAAsBjuB,GAAUvtB,OAAO6Y,OAAO0U,GAAUA,EACtEjf,EAAgD,eAAnChR,EAAS2yB,iBAAiBC,KAC7CpvB,KAAK26C,gBAAkB,IAAIC,EAAAA,GAAgBH,EAAa,CACpDI,iBAAkB,OAClBrrB,gBAAiBhiB,EACjBiiB,qBAAsBzvB,KAAKyvB,sBAEnC,CAEA,cAAIhhB,GACA,OAAOzO,KAAKu6C,UAChB,CAEA1oB,QAAAA,CAASpO,G,UACL,MAAMq3B,EAAmB96C,KAAK26C,gBAAgB9oB,SAASpO,GACvD,MAAO,CACHgJ,OAAQquB,EAAiBruB,OACzBuF,OAAQ8oB,EAAiB9oB,OACzB/E,OAAsC,QAA9B9Z,EAAA2nC,EAAiBC,OAAO9tB,cAAM,IAAA9Z,EAAAA,EAAI,GAC1C+e,OAA2C,QAAnCwZ,GAAAve,EAAAntB,KAAKq6C,cAAaW,yBAAiB,IAAAtP,OAAA,EAAAA,EAAAtpC,KAAA+qB,EAAG1J,GAEtD,CAEU+2B,qBAAAA,CAAsBF,GAC5B,GAAII,GAAsBJ,GAAc,OAAOA,EAC/C,MAAM7tB,EAASwuB,GAA4BX,GAAep7C,OAAO6Y,OAAOuiC,EAAYY,OAAO/U,OAASmU,EAC9Fa,EAA2B,CAAC,EAElC,OADA1uB,EAAOhY,QAAQoC,GAASskC,EAAItkC,EAAMhb,MAAQgb,GACnCskC,CACX,EAaE,SAAUF,GAA4BG,GACxC,OAAOA,GAAmB,UAAWA,GAAmB,gBAAiBA,CAC7E,CAKM,SAAUV,GAAsBU,GAClC,OAfE,SAA2BA,GAC7B,OAAOh7C,MAAMrB,QAAQq8C,KAAgD,IAA3BA,EAAgBn/C,QAAgB,SAAUm/C,EAAgB,GACxG,CAaYC,CAAiBD,KAAqBH,GAA4BG,EAC9E,CCZM,SAAUE,GAAW19C,EAAwByN,EAAsC4H,GACrF,IAAIsoC,EACAn5B,EACgB,kBAATxkB,GACPwkB,EAAW/W,EACXkwC,EAAOtoC,IAEPmP,EAAWxkB,EAAKwN,MAAMC,MACtBkwC,EAAOlwC,GAEN+W,IACDA,EAAW/H,GAAS4E,OAAO,EAAG,IAGlC,MAGMwN,EAkDV,SAAkBtuB,G,UACd,MAAMsuB,EAAuB,GAC7B,IAAI+uB,EAAcr9C,EAAQikB,SAAS9W,KAC/BmwC,EAAmBt9C,EAAQikB,SAAS7W,UACxC,IAAK,IAAIhL,EAAI,EAAGA,EAAIpC,EAAQu9C,MAAMz/C,OAAQsE,IAAK,CAC3C,MAAMiQ,EAAc,IAANjQ,EACRkQ,EAAOlQ,IAAMpC,EAAQu9C,MAAMz/C,OAAS,EAC1C,IAAIqP,EAAOnN,EAAQu9C,MAAMn7C,GACrBgI,EAAQ,EAEZ,GAAIiI,GAASrS,EAAQ8U,QAAQ5H,MAAO,CAChC,MAAMnP,EAA6B,QAArBiX,EAAAhV,EAAQ8U,QAAQ5H,aAAK,IAAA8H,OAAA,EAAAA,EAAEhX,KAAKmP,GACtCpP,IACAqM,EAAQrM,EAAMqM,MAAQrM,EAAM,GAAGD,OAEvC,KAAO,CACH,MAAMC,EAA4B,QAApBixB,EAAAhvB,EAAQ8U,QAAQ3H,YAAI,IAAA6hB,OAAA,EAAAA,EAAEhxB,KAAKmP,GACrCpP,IACAqM,EAAQrM,EAAMqM,MAAQrM,EAAM,GAAGD,OAEvC,CACA,GAAIwU,EAAM,CACN,MAAMvU,EAA2B,QAAnBwvC,EAAAvtC,EAAQ8U,QAAQlE,WAAG,IAAA28B,OAAA,EAAAA,EAAEvvC,KAAKmP,GACpCpP,IACAoP,EAAOA,EAAKtP,UAAU,EAAGE,EAAMqM,OAEvC,CAEA+C,EAAOA,EAAKtP,UAAU,EAAG2/C,GAAcrwC,IAGvC,GAFsBswC,GAAetwC,EAAM/C,IAEtB+C,EAAKrP,QAEtB,GAAIwwB,EAAOxwB,OAAS,EAAG,CACnB,MAAMmmB,EAAW/H,GAAS4E,OAAOu8B,EAAaC,GAC9ChvB,EAAOtsB,KAAK,CACRwL,KAAM,QACN0d,QAAS,GACTje,MAAOkP,GAAM2E,OAAOmD,EAAUA,IAEtC,MACG,CACHy5B,GAAStxC,UAAYhC,EACrB,MAAMuzC,EAAWD,GAAS1/C,KAAKmP,GAC/B,GAAIwwC,EAAU,CACV,MAAMC,EAAYD,EAAS,GACrBh9C,EAAQg9C,EAAS,GACjBzwC,EAAQgP,GAAS4E,OAAOu8B,EAAaC,EAAmBlzC,GACxDwG,EAAMsL,GAAS4E,OAAOu8B,EAAaC,EAAmBlzC,EAAQwzC,EAAU9/C,QAC9EwwB,EAAOtsB,KAAK,CACRwL,KAAM,MACN0d,QAASvqB,EACTsM,MAAOkP,GAAM2E,OAAO5T,EAAO0D,KAE/BxG,GAASwzC,EAAU9/C,OACnBsM,EAAQqzC,GAAetwC,EAAM/C,EACjC,CAEA,GAAIA,EAAQ+C,EAAKrP,OAAQ,CACrB,MAAM+/C,EAAO1wC,EAAKtP,UAAUuM,GACtB0zC,EAAmB77C,MAAMqG,KAAKu1C,EAAKE,SAASC,KAClD1vB,EAAOtsB,QAAQi8C,GAAkBH,EAAkBD,EAAMR,EAAaC,EAAmBlzC,GAC7F,CACJ,CAEAizC,IACAC,EAAmB,CACvB,CAGA,GAAIhvB,EAAOxwB,OAAS,GAAwC,UAAnCwwB,EAAOA,EAAOxwB,OAAS,GAAG0P,KAC/C,OAAO8gB,EAAO3rB,MAAM,GAAI,GAG5B,OAAO2rB,CACX,CA7HmBoF,CAAS,CACpB6pB,MAJUW,GAASz+C,GAKnBwkB,WACAnP,QALsBqpC,GAAiBf,KAQ3C,OA2NJ,SAA2Bp9C,G,YACvB,MAAMo+C,EAA0BliC,GAAS4E,OAAO9gB,EAAQikB,SAAS9W,KAAMnN,EAAQikB,SAAS7W,WACxF,GAA8B,IAA1BpN,EAAQsuB,OAAOxwB,OACf,OAAO,IAAIugD,GAAiB,GAAIliC,GAAM2E,OAAOs9B,EAAeA,IAEhE,MAAMtqC,EAA2B,GACjC,KAAO9T,EAAQoK,MAAQpK,EAAQsuB,OAAOxwB,QAAQ,CAC1C,MAAMmxB,EAAUqvB,GAAkBt+C,EAAS8T,EAASA,EAAShW,OAAS,IAClEmxB,GACAnb,EAAS9R,KAAKitB,EAEtB,CACA,MAAM/hB,EAAgC,QAAxB8hB,EAAW,QAAXha,EAAAlB,EAAS,UAAE,IAAAkB,OAAA,EAAAA,EAAE/H,MAAMC,aAAK,IAAA8hB,EAAAA,EAAIovB,EACpCxtC,EAA8C,QAAxC68B,EAA6B,QAA7BF,EAAAz5B,EAASA,EAAShW,OAAS,UAAE,IAAAyvC,OAAA,EAAAA,EAAEtgC,MAAM2D,WAAG,IAAA68B,EAAAA,EAAI2Q,EACxD,OAAO,IAAIC,GAAiBvqC,EAAUqI,GAAM2E,OAAO5T,EAAO0D,GAC9D,CA1OW2tC,CAAkB,CACrBn0C,MAAO,EACPkkB,SACArK,YAER,CAiBA,SAASi6B,GAASz+C,GACd,IAAIyrB,EAAU,GAEVA,EADgB,kBAATzrB,EACGA,EAEAA,EAAK6lB,KAGnB,OADc4F,EAAQ2a,MAAM2Y,EAAAA,GAEhC,CAUA,MAAMd,GAAW,2+iBACXM,GAAiB,uojBA+EvB,SAASC,GAAkB31B,EAA0Bnb,EAAcsxC,EAAmBC,GAClF,MAAMpwB,EAAuB,GAE7B,GAAoB,IAAhBhG,EAAKxqB,OAAc,CACnB,MAAMoP,EAAQgP,GAAS4E,OAAO29B,EAAWC,GACnC9tC,EAAMsL,GAAS4E,OAAO29B,EAAWC,EAAiBvxC,EAAKrP,QAC7DwwB,EAAOtsB,KAAK,CACRwL,KAAM,OACN0d,QAAS/d,EACTF,MAAOkP,GAAM2E,OAAO5T,EAAO0D,IAEnC,KAAO,CACH,IAAIxE,EAAY,EAChB,IAAK,MAAMrO,KAASuqB,EAAM,CACtB,MAAMq2B,EAAa5gD,EAAMqM,MACnBw0C,EAAezxC,EAAKtP,UAAUuO,EAAWuyC,GAC3CC,EAAa9gD,OAAS,GACtBwwB,EAAOtsB,KAAK,CACRwL,KAAM,OACN0d,QAAS/d,EAAKtP,UAAUuO,EAAWuyC,GACnC1xC,MAAOkP,GAAM2E,OACT5E,GAAS4E,OAAO29B,EAAWryC,EAAYsyC,GACvCxiC,GAAS4E,OAAO29B,EAAWE,EAAaD,MAIpD,IAAIhyB,EAASkyB,EAAa9gD,OAAS,EACnC,MAAM+gD,EAAU9gD,EAAM,GAUtB,GATAuwB,EAAOtsB,KAAK,CACRwL,KAAM,aACN0d,QAAS2zB,EACT5xC,MAAOkP,GAAM2E,OACT5E,GAAS4E,OAAO29B,EAAWryC,EAAYsgB,EAASgyB,GAChDxiC,GAAS4E,OAAO29B,EAAWryC,EAAYsgB,EAASmyB,EAAQ/gD,OAAS4gD,MAGzEhyB,GAAUmyB,EAAQ/gD,OACG,IAAjBC,EAAMD,OAAc,CACpB4uB,GAAU3uB,EAAM,GAAGD,OACnB,MAAM6C,EAAQ5C,EAAM,GACpBuwB,EAAOtsB,KAAK,CACRwL,KAAM,OACN0d,QAASvqB,EACTsM,MAAOkP,GAAM2E,OACT5E,GAAS4E,OAAO29B,EAAWryC,EAAYsgB,EAASgyB,GAChDxiC,GAAS4E,OAAO29B,EAAWryC,EAAYsgB,EAAS/rB,EAAM7C,OAAS4gD,KAG3E,MACIpwB,EAAOtsB,KAAK,CACRwL,KAAM,OACN0d,QAAS,GACTje,MAAOkP,GAAM2E,OACT5E,GAAS4E,OAAO29B,EAAWryC,EAAYsgB,EAASgyB,GAChDxiC,GAAS4E,OAAO29B,EAAWryC,EAAYsgB,EAASgyB,MAI5DtyC,EAAYuyC,EAAa5gD,EAAM,GAAGD,MACtC,CACA,MAAMghD,EAAa3xC,EAAKtP,UAAUuO,GAC9B0yC,EAAWhhD,OAAS,GACpBwwB,EAAOtsB,KAAK,CACRwL,KAAM,OACN0d,QAAS4zB,EACT7xC,MAAOkP,GAAM2E,OACT5E,GAAS4E,OAAO29B,EAAWryC,EAAYsyC,GACvCxiC,GAAS4E,OAAO29B,EAAWryC,EAAYsyC,EAAiBI,EAAWhhD,UAInF,CAEA,OAAOwwB,CACX,CAEA,MAAMywB,GAAqB,KACrBC,GAAqB,OAE3B,SAASvB,GAAetwC,EAAc/C,GAClC,MAAMrM,EAAQoP,EAAKtP,UAAUuM,GAAOrM,MAAMghD,IAC1C,OAAIhhD,EACOqM,EAAQrM,EAAMqM,MAEd+C,EAAKrP,MAEpB,CAEA,SAAS0/C,GAAcrwC,GACnB,MAAMpP,EAAQoP,EAAKpP,MAAMihD,IACzB,GAAIjhD,GAAgC,kBAAhBA,EAAMqM,MACtB,OAAOrM,EAAMqM,KAGrB,CAqBA,SAASk0C,GAAkBt+C,EAAuBsS,GAC9C,MAAMH,EAAOnS,EAAQsuB,OAAOtuB,EAAQoK,OACpC,MAAkB,QAAd+H,EAAK3E,KACEyxC,GAAcj/C,GAAS,GACT,SAAdmS,EAAK3E,MAAiC,eAAd2E,EAAK3E,KAC7B0xC,GAAel/C,IAQ9B,SAAyB0Y,EAAmBuW,GACxC,GAAIA,EAAS,CACT,MAAM9hB,EAAO,IAAIgyC,GAAc,GAAIzmC,EAAMzL,OACrC,YAAagiB,EACbA,EAAQmwB,QAAQp9C,KAAKmL,GAErB8hB,EAAQ/D,QAAQk0B,QAAQp9C,KAAKmL,EAErC,CACJ,CAfQkyC,CAAgBltC,EAAMG,QACtBtS,EAAQoK,QAGhB,CAaA,SAAS80C,GAAel/C,GACpB,IAAI0Y,EAAQ1Y,EAAQsuB,OAAOtuB,EAAQoK,OACnC,MAAMk1C,EAAa5mC,EACnB,IAAI6mC,EAAY7mC,EAChB,MAAM6kC,EAAuB,GAC7B,KAAO7kC,GAAwB,UAAfA,EAAMlL,MAAmC,QAAfkL,EAAMlL,MAC5C+vC,EAAMv7C,KAAKw9C,GAAiBx/C,IAC5Bu/C,EAAY7mC,EACZA,EAAQ1Y,EAAQsuB,OAAOtuB,EAAQoK,OAEnC,OAAO,IAAIq1C,GAAclC,EAAOphC,GAAM2E,OAAOw+B,EAAWryC,MAAMC,MAAOqyC,EAAUtyC,MAAM2D,KACzF,CAEA,SAAS4uC,GAAiBx/C,GAEtB,MAAmB,eADLA,EAAQsuB,OAAOtuB,EAAQoK,OAC3BoD,KACCyxC,GAAcj/C,GAAS,GAEvB0/C,GAAe1/C,EAE9B,CAEA,SAASi/C,GAAcj/C,EAAuB2/C,GAC1C,MAAMC,EAAW5/C,EAAQsuB,OAAOtuB,EAAQoK,SAClC1M,EAAOkiD,EAAS10B,QAAQrtB,UAAU,GAClC+Y,EAAY5W,EAAQsuB,OAAOtuB,EAAQoK,OACzC,GAAwB,UAAX,OAATwM,QAAS,IAATA,OAAS,EAATA,EAAWpJ,MAAiB,CAC5B,GAAImyC,EAAQ,CACR,MAAME,EAAUH,GAAe1/C,GAC/B,OAAO,IAAI8/C,GACPpiD,EACA,IAAI+hD,GAAc,CAACI,GAAUA,EAAQ5yC,OACrC0yC,EACAxjC,GAAM2E,OAAO8+B,EAAS3yC,MAAMC,MAAO2yC,EAAQ5yC,MAAM2D,KAEzD,CAAO,CACH,MAAMwwB,EAAU8d,GAAel/C,GAC/B,OAAO,IAAI8/C,GACPpiD,EACA0jC,EACAue,EACAxjC,GAAM2E,OAAO8+B,EAAS3yC,MAAMC,MAAOk0B,EAAQn0B,MAAM2D,KAEzD,CACJ,CAAO,CACH,MAAM3D,EAAQ2yC,EAAS3yC,MACvB,OAAO,IAAI6yC,GAAapiD,EAAM,IAAI+hD,GAAc,GAAIxyC,GAAQ0yC,EAAQ1yC,EACxE,CACJ,CAEA,SAASyyC,GAAe1/C,GACpB,MAAM0Y,EAAQ1Y,EAAQsuB,OAAOtuB,EAAQoK,SACrC,OAAO,IAAI+0C,GAAczmC,EAAMwS,QAASxS,EAAMzL,MAClD,CAoBA,SAASkxC,GAAiBrpC,GACtB,IAAKA,EACD,OAAOqpC,GAAiB,CACpBjxC,MAAO,MACP0D,IAAK,KACLzD,KAAM,MAGd,MAAM,MAAED,EAAK,IAAE0D,EAAG,KAAEzD,GAAS2H,EAC7B,MAAO,CACH5H,MAAO6yC,GAAgB7yC,GAAO,GAC9B0D,IAAKmvC,GAAgBnvC,GAAK,GAC1BzD,KAAM4yC,GAAgB5yC,GAAM,GAEpC,CAEA,SAAS4yC,GAAgBrvC,EAAqCxD,GAC1D,GAAsB,kBAAXwD,GAAyC,kBAAXA,EAAqB,CAC1D,MAAMsvC,EAA4B,kBAAXtvC,GAAsBuvC,EAAAA,EAAAA,IAAavvC,GAAUA,EAAOtF,OAC3E,OAAI8B,EACO,IAAIgzC,OAAO,QAAD14C,OAASw4C,IAEnB,IAAIE,OAAO,OAAD14C,OAAQw4C,EAAO,SAExC,CACI,OAAOtvC,CAEf,CAEA,MAAM2tC,GAKFthD,WAAAA,CAAY+W,EAA0B7G,GAClCpL,KAAKiS,SAAWA,EAChBjS,KAAKoL,MAAQA,CACjB,CAEAkzC,MAAAA,CAAOziD,GACH,OAAOmE,KAAKu+C,aAAa9W,KAAKrmC,GAAKA,EAAEvF,OAASA,EAClD,CAEA2iD,OAAAA,CAAQ3iD,GACJ,OAAOmE,KAAKu+C,aAAavuC,OAAO5O,GAAKA,EAAEvF,OAASA,EACpD,CAEQ0iD,UAAAA,GACJ,OAAOv+C,KAAKiS,SAASjC,OAAQ5O,GAAqB,SAAUA,EAChE,CAEAgF,QAAAA,GACI,IAAItH,EAAQ,GACZ,IAAK,MAAMsuB,KAAWptB,KAAKiS,SACvB,GAAqB,IAAjBnT,EAAM7C,OACN6C,EAAQsuB,EAAQhnB,eACb,CACH,MAAMqd,EAAO2J,EAAQhnB,WACrBtH,GAAS2/C,GAAa3/C,GAAS2kB,CACnC,CAEJ,OAAO3kB,EAAM4/C,MACjB,CAEAC,UAAAA,CAAW1rC,GACP,IAAInU,EAAQ,GACZ,IAAK,MAAMsuB,KAAWptB,KAAKiS,SACvB,GAAqB,IAAjBnT,EAAM7C,OACN6C,EAAQsuB,EAAQuxB,WAAW1rC,OACxB,CACH,MAAMwQ,EAAO2J,EAAQuxB,WAAW1rC,GAChCnU,GAAS2/C,GAAa3/C,GAAS2kB,CACnC,CAEJ,OAAO3kB,EAAM4/C,MACjB,EAGJ,MAAMT,GAMF/iD,WAAAA,CAAYW,EAAcwtB,EAAyBy0B,EAAiB1yC,GAChEpL,KAAKnE,KAAOA,EACZmE,KAAKqpB,QAAUA,EACfrpB,KAAK89C,OAASA,EACd99C,KAAKoL,MAAQA,CACjB,CAEAhF,QAAAA,GACI,IAAIqd,EAAO,IAAH9d,OAAO3F,KAAKnE,MACpB,MAAMwtB,EAAUrpB,KAAKqpB,QAAQjjB,WAM7B,OALoC,IAAhCpG,KAAKqpB,QAAQk0B,QAAQthD,OACrBwnB,EAAO,GAAH9d,OAAM8d,EAAI,KAAA9d,OAAI0jB,GACXrpB,KAAKqpB,QAAQk0B,QAAQthD,OAAS,IACrCwnB,EAAO,GAAH9d,OAAM8d,EAAI,MAAA9d,OAAK0jB,IAEnBrpB,KAAK89C,OAEE,IAAPn4C,OAAW8d,EAAI,KAERA,CAEf,CAEAk7B,UAAAA,CAAW1rC,G,QACP,OAAiC,QAA1Bka,EAAkB,QAAlBha,EAAO,OAAPF,QAAO,IAAPA,OAAO,EAAPA,EAAS2rC,iBAAS,IAAAzrC,OAAA,EAAAA,EAAA/Q,KAAA6Q,EAAGjT,aAAK,IAAAmtB,EAAAA,EAAIntB,KAAK6+C,kBAAkB5rC,EAChE,CAEQ4rC,iBAAAA,CAAkB5rC,GACtB,MAAMoW,EAAUrpB,KAAKqpB,QAAQs1B,WAAW1rC,GACxC,GAAIjT,KAAK89C,OAAQ,CACb,MAAMgB,EA4BlB,SAAyBC,EAAa11B,EAAiBpW,G,QACnD,GAAY,cAAR8rC,GAA+B,aAARA,GAA8B,SAARA,EAAgB,CAC7D,MAAMx2C,EAAQ8gB,EAAQ5jB,QAAQ,KAC9B,IAAIu5C,EAAU31B,EACd,GAAI9gB,EAAQ,EAAG,CACX,MAAM02C,EAAerD,GAAevyB,EAAS9gB,GAC7Cy2C,EAAU31B,EAAQrtB,UAAUijD,GAC5B51B,EAAUA,EAAQrtB,UAAU,EAAGuM,EACnC,EACY,aAARw2C,GAA+B,SAARA,GAAmC,SAAjB9rC,EAAQkuB,QAEjD6d,EAAU,IAAHr5C,OAAQq5C,EAAO,MAE1B,MAAME,EAAqD,QAAtC/xB,EAAkB,QAAlBha,EAAAF,EAAQksC,kBAAU,IAAAhsC,OAAA,EAAAA,EAAA/Q,KAAA6Q,EAAGoW,EAAS21B,UAAQ,IAAA7xB,EAAAA,EAMnE,SAA2B9D,EAAiB21B,GACxC,IAEI,OADA9kC,GAAAA,EAAIxV,MAAM2kB,GAAS,GACZ,IAAP1jB,OAAWq5C,EAAO,MAAAr5C,OAAK0jB,EAAO,IAClC,CAAE,MAAAlW,GACE,OAAOkW,CACX,CACJ,CAbuE+1B,CAAkB/1B,EAAS21B,GAC1F,OAAOE,CACX,CACA,MACJ,CA7C6BG,CAAgBr/C,KAAKnE,KAAMwtB,EAAgB,OAAPpW,QAAO,IAAPA,EAAAA,EAAW,CAAC,GACjE,GAAwB,kBAAb6rC,EACP,OAAOA,CAEf,CACA,IAAIQ,EAAS,GACQ,YAAV,OAAPrsC,QAAO,IAAPA,OAAO,EAAPA,EAAS8rC,WAAqC1gD,KAAV,OAAP4U,QAAO,IAAPA,OAAO,EAAPA,EAAS8rC,KACtCO,EAAS,IACe,UAAV,OAAPrsC,QAAO,IAAPA,OAAO,EAAPA,EAAS8rC,KAChBO,EAAS,KACe,iBAAV,OAAPrsC,QAAO,IAAPA,OAAO,EAAPA,EAAS8rC,OAChBO,EAAS,OAEb,IAAI77B,EAAO,GAAH9d,OAAM25C,EAAM,KAAA35C,OAAI3F,KAAKnE,MAAI8J,OAAG25C,GAMpC,OALoC,IAAhCt/C,KAAKqpB,QAAQk0B,QAAQthD,OACrBwnB,EAAO,GAAH9d,OAAM8d,EAAI,YAAA9d,OAAM0jB,GACbrpB,KAAKqpB,QAAQk0B,QAAQthD,OAAS,IACrCwnB,EAAO,GAAH9d,OAAM8d,EAAI,MAAA9d,OAAK0jB,IAEnBrpB,KAAK89C,OAEE,IAAPn4C,OAAW8d,EAAI,KAERA,CAEf,EA+BJ,MAAMm6B,GAIF1iD,WAAAA,CAAYwgD,EAAsBtwC,GAC9BpL,KAAKu9C,QAAU7B,EACf17C,KAAKoL,MAAQA,CACjB,CAEAhF,QAAAA,GACI,IAAIqd,EAAO,GACX,IAAK,IAAIljB,EAAI,EAAGA,EAAIP,KAAKu9C,QAAQthD,OAAQsE,IAAK,CAC1C,MAAMu9C,EAAS99C,KAAKu9C,QAAQh9C,GACtB+P,EAAOtQ,KAAKu9C,QAAQh9C,EAAI,GAC9BkjB,GAAQq6B,EAAO13C,WACXkK,GAAQA,EAAKlF,MAAMC,MAAMC,KAAOwyC,EAAO1yC,MAAMC,MAAMC,OACnDmY,GAAQ,KAEhB,CACA,OAAOA,CACX,CAEAk7B,UAAAA,CAAW1rC,GACP,IAAIwQ,EAAO,GACX,IAAK,IAAIljB,EAAI,EAAGA,EAAIP,KAAKu9C,QAAQthD,OAAQsE,IAAK,CAC1C,MAAMu9C,EAAS99C,KAAKu9C,QAAQh9C,GACtB+P,EAAOtQ,KAAKu9C,QAAQh9C,EAAI,GAC9BkjB,GAAQq6B,EAAOa,WAAW1rC,GACtB3C,GAAQA,EAAKlF,MAAMC,MAAMC,KAAOwyC,EAAO1yC,MAAMC,MAAMC,OACnDmY,GAAQ,KAEhB,CACA,OAAOA,CACX,EAGJ,MAAM65B,GAIFpiD,WAAAA,CAAYuoB,EAAcrY,GACtBpL,KAAKyjB,KAAOA,EACZzjB,KAAKoL,MAAQA,CACjB,CAEAhF,QAAAA,GACI,OAAOpG,KAAKyjB,IAChB,CACAk7B,UAAAA,GACI,OAAO3+C,KAAKyjB,IAChB,EAIJ,SAASg7B,GAAah7B,GAClB,OAAIA,EAAKoL,SAAS,MACP,KAEA,MAEf,CCxpBM,MAAO0wB,GAKTrkD,WAAAA,CAAYsB,GACRwD,KAAKmpC,aAAe3sC,EAAS+B,OAAOw/B,UAAUuG,aAC9CtkC,KAAKmqC,gBAAkB3tC,EAASopB,cAAcwkB,eAClD,CAEAoV,gBAAAA,CAAiB5hD,GACb,MAAMiuC,EAAU7rC,KAAKmqC,gBAAgB2B,WAAWluC,GAChD,GAAIiuC,GDgGN,SAAkBjuC,EAAwBqV,GAC5C,MAAMwsC,EAAoBnD,GAAiBrpC,GACrCyoC,EAAQW,GAASz+C,GACvB,GAAqB,IAAjB89C,EAAMz/C,OACN,OAAO,EAGX,MAAMuU,EAAQkrC,EAAM,GACdjrC,EAAOirC,EAAMA,EAAMz/C,OAAS,GAC5ByjD,EAAaD,EAAkBp0C,MAC/Bs0C,EAAYF,EAAkB1wC,IAEpC,OAAOmX,QAAkB,OAAVw5B,QAAU,IAAVA,OAAU,EAAVA,EAAYvjD,KAAKqU,KAAW0V,QAAiB,OAATy5B,QAAS,IAATA,OAAS,EAATA,EAAWxjD,KAAKsU,GACvE,CC7GuBmvC,CAAQ/T,GAAU,CAE7B,OADoByP,GAAWzP,GACZ8S,WAAW,CAC1BQ,WAAYA,CAAChe,EAAM6d,IACRh/C,KAAK6/C,0BAA0BjiD,EAAMujC,EAAM6d,GAEtDJ,UAAYG,GACD/+C,KAAK8/C,yBAAyBliD,EAAMmhD,IAGvD,CAEJ,CAEUc,yBAAAA,CAA0BjiD,EAAe/B,EAAcmjD,G,MAC7D,MAAMz8B,EAA0D,QAA5CpP,EAAAnT,KAAK+/C,4BAA4BniD,EAAM/B,UAAK,IAAAsX,EAAAA,EAAInT,KAAKggD,sBAAsBpiD,EAAM/B,GACrG,GAAI0mB,GAAeA,EAAYivB,YAAa,CACxC,MAAMlmC,EAAOiX,EAAYivB,YAAYpmC,MAAMC,MAAMC,KAAO,EAClDC,EAAYgX,EAAYivB,YAAYpmC,MAAMC,MAAME,UAAY,EAC5DmU,EAAM6C,EAAYqf,YAAYz7B,KAAK,CAAEJ,SAAU,IAAFJ,OAAM2F,EAAI,KAAA3F,OAAI4F,KACjE,MAAO,IAAP5F,OAAWq5C,EAAO,MAAAr5C,OAAK+Z,EAAItZ,WAAU,IACzC,CAGJ,CAEU05C,wBAAAA,CAAyBG,EAAgBC,GAGnD,CAEUH,2BAAAA,CAA4BniD,EAAe/B,GACjD,MACMwtC,GADWtJ,EAAAA,GAAAA,IAAYniC,GACA4iC,kBAC7B,IAAK6I,EACD,OAEJ,IAAIC,EAAmC1rC,EACvC,EAAG,CACC,MACM2kB,EADkB8mB,EAAYpkC,IAAIqkC,GACJ7B,KAAKrmC,GAAKA,EAAEvF,OAASA,GACzD,GAAI0mB,EACA,OAAOA,EAEX+mB,EAAcA,EAAY/N,UAC9B,OAAS+N,EAGb,CAEU0W,qBAAAA,CAAsBpiD,EAAe/B,GAE3C,OADoBmE,KAAKmpC,aAAaY,cAActC,KAAKrmC,GAAKA,EAAEvF,OAASA,EAE7E,ECnEE,MAAOskD,GAETjlD,WAAAA,CAAYsB,GACRwD,KAAKogD,cAAgB,IAAM5jD,EAASuB,OAAOsiD,aAC/C,CACAvU,UAAAA,CAAWluC,G,MACP,OdwBF,SAA+BA,GACjC,MAAwD,kBAAzCA,EAA4BmuC,QAC/C,Cc1BWuU,CAAqB1iD,GACbA,EAAKmuC,SAEiE,QAA1E54B,GAAAotC,EAAAA,EAAAA,GAAgB3iD,EAAKmvB,SAAU/sB,KAAKogD,gBAAgBI,8BAAsB,IAAArtC,OAAA,EAAAA,EAAEsQ,IACvF,ECOE,MAAOg9B,GAITvlD,WAAAA,CAAYsB,GACRwD,KAAK0gD,WAAalkD,EAASuB,OAAO2yB,aACtC,CAEAhsB,KAAAA,CAAyB+e,EAAck9B,GACnC,OAAOrkB,QAAQj5B,QAAQrD,KAAK0gD,WAAWh8C,MAAS+e,GACpD,ECJE,MAAOm9B,GAAb1lD,WAAAA,GAEY,KAAA2lD,oBAAuD,IAAIC,GAAAA,GAC3D,KAAAC,WAA0B,GAC1B,KAAAC,UAAyB,GACzB,KAAAC,MAAO,CA6DnB,CA3DInI,KAAAA,CAAMllB,GACF5zB,KAAKkhD,cACL,MAAMC,G5BvBVtlB,GAAWO,YAAYC,MAChB,IAAIykB,GAAAA,I4BwBP,OADA9gD,KAAK6gD,oBAAsBM,EACpBnhD,KAAKohD,QAAQphD,KAAK+gD,WAAYntB,EAAQutB,EAAYtqC,MAC7D,CAEAwqC,IAAAA,CAAQztB,GACJ,OAAO5zB,KAAKohD,QAAQphD,KAAKghD,UAAWptB,EACxC,CAEQwtB,OAAAA,CAAkBE,EAAoB1tB,GAAiE,IAA1CwK,EAAiBhgC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG+9B,GAAAA,GAAkBx8B,KACvG,MAAM4hD,EAAW,IAAI7kB,GACf3rB,EAAmB,CACrB6iB,SACA2tB,WACAnjB,qBAIJ,OAFAkjB,EAAMnhD,KAAK4Q,GACX/Q,KAAKwhD,uBACED,EAAS5kB,OACpB,CAEQ,0BAAM6kB,GACV,IAAKxhD,KAAKihD,KACN,OAEJ,MAAM3sB,EAAuB,GAC7B,GAAIt0B,KAAK+gD,WAAW9kD,OAAS,EAEzBq4B,EAAQn0B,KAAKH,KAAK+gD,WAAWU,aAC1B,MAAIzhD,KAAKghD,UAAU/kD,OAAS,GAI/B,OAFAq4B,EAAQn0B,QAAQH,KAAKghD,UAAUvgD,OAAO,EAAGT,KAAKghD,UAAU/kD,QAG5D,CACA+D,KAAKihD,MAAO,QACN3kB,QAAQsD,IAAItL,EAAQ9lB,IAAIytB,UAAkD,IAA3C,OAAErI,EAAM,SAAE2tB,EAAQ,kBAAEnjB,GAAmBpJ,EACxE,IAEI,MAAMhzB,QAAes6B,QAAQj5B,UAAU68B,KAAK,IAAMtM,EAAOwK,IACzDmjB,EAASl+C,QAAQrB,EACrB,CAAE,MAAOswB,GACD0J,GAAqB1J,GAErBivB,EAASl+C,aAAQhF,GAEjBkjD,EAAS3kB,OAAOtK,EAExB,KAEJtyB,KAAKihD,MAAO,EACZjhD,KAAKwhD,sBACT,CAEAN,WAAAA,GACIlhD,KAAK6gD,oBAAoBa,QAC7B,ECjEE,MAAOC,GASTzmD,WAAAA,CAAYsB,GAHO,KAAAolD,oBAAsB,IAAIvb,GAC1B,KAAAwb,eAAiB,IAAIxb,GAGpCrmC,KAAKg3B,QAAUx6B,EAASm/B,QACxB37B,KAAKivB,MAAQzyB,EAASuB,OAAOmxB,MAC7BlvB,KAAK6wB,OAASr0B,EAASs0B,WAAWC,MACtC,CAEA+wB,SAAAA,CAAU9/C,GACN,MAAO,CACH+vB,YAAa/vB,EAAO+vB,YACpBE,YAAajwB,EAAOiwB,YAAcjyB,KAAK+hD,qBAAqB//C,EAAOiwB,kBAAe5zB,EAGlF8zB,aAAcnwB,EAAOmwB,aAAa3jB,IAAIpN,GAAKlC,OAAAoS,OAAApS,OAAAoS,OAAC,CAAC,EAAIlQ,GAAC,CAAE+J,QAAS/J,EAAE+J,WAC/DrM,MAAOkB,KAAKgiD,iBAAiBhgD,EAAOlD,MAAOkB,KAAKiiD,wBAAwBjgD,EAAOlD,QAEvF,CAEUijD,oBAAAA,CAAqB9vB,GAE3B,OAAOA,CACX,CAEUgwB,uBAAAA,CAAwBrkD,GAC9B,MAAMskD,EAAW,IAAIt1C,IACfu1C,EAAW,IAAIv1C,IACrB,IAAK,MAAMkgB,KAAWsU,EAAAA,GAAAA,IAAUxjC,GAC5BskD,EAASh1C,IAAI4f,EAAS,CAAC,GAE3B,GAAIlvB,EAAKmvB,SACL,IAAK,MAAMuG,KAAW8uB,EAAAA,EAAAA,IAAUxkD,EAAKmvB,UACjCo1B,EAASj1C,IAAIomB,EAAS,CAAC,GAG/B,MAAO,CACH4uB,WACAC,WAER,CAEUH,gBAAAA,CAAiBpkD,EAAeO,GACtC,MAAM01B,EAAM11B,EAAQ+jD,SAASj9C,IAAIrH,GACjCi2B,EAAIz3B,MAAQwB,EAAKxB,MACjBy3B,EAAI8Y,gBAAkB/uC,EAAK+uC,gBAC3B9Y,EAAI6Y,mBAAqB9uC,EAAK8uC,wBACRruC,IAAlBT,EAAKmvB,WACL8G,EAAI9G,SAAW/sB,KAAKqiD,iBAAiBzkD,EAAKmvB,SAAU5uB,IAExD,IAAK,MAAOtC,EAAMiD,KAAUI,OAAOo1B,QAAQ12B,GACvC,IAAI/B,EAAKqwC,WAAW,KAGpB,GAAI9rC,MAAMrB,QAAQD,GAAQ,CACtB,MAAMwjD,EAAa,GACnBzuB,EAAIh4B,GAAQymD,EACZ,IAAK,MAAM7kD,KAAQqB,GACXwjC,EAAAA,GAAAA,IAAU7kC,GACV6kD,EAAIniD,KAAKH,KAAKgiD,iBAAiBvkD,EAAMU,KAC9BymC,EAAAA,GAAAA,IAAYnnC,GACnB6kD,EAAIniD,KAAKH,KAAKuiD,mBAAmB9kD,EAAMU,IAEvCmkD,EAAIniD,KAAK1C,EAGrB,MAAW6kC,EAAAA,GAAAA,IAAUxjC,GACjB+0B,EAAIh4B,GAAQmE,KAAKgiD,iBAAiBljD,EAAOX,IAClCymC,EAAAA,GAAAA,IAAY9lC,GACnB+0B,EAAIh4B,GAAQmE,KAAKuiD,mBAAmBzjD,EAAOX,QAC1BE,IAAVS,IACP+0B,EAAIh4B,GAAQiD,GAGpB,OAAO+0B,CACX,CAEU0uB,kBAAAA,CAAmB/gB,EAAsBrjC,GAC/C,MAAM01B,EAA+B,CAAC,EAKtC,OAJAA,EAAIiF,SAAW0I,EAAU1I,SACrB0I,EAAUa,WACVxO,EAAIwO,SAAWlkC,EAAQgkD,SAASl9C,IAAIu8B,EAAUa,WAE3CxO,CACX,CAEUwuB,gBAAAA,CAAiBzkD,EAAeO,GACtC,MAAMm1B,EAAUn1B,EAAQgkD,SAASl9C,IAAIrH,GAoBrC,OAnBI4kD,EAAAA,GAAAA,IAAc5kD,GACd01B,EAAQjG,SAAWzvB,EAAKyvB,SAGxBiG,EAAQtH,cAAgBhsB,KAAKyiD,oBAAoB7kD,EAAKouB,eAE1DsH,EAAQrG,OAASrvB,EAAKqvB,OACtBqG,EAAQxG,QAAU3uB,EAAQ+jD,SAASj9C,IAAIrH,EAAKkvB,UACxC41B,EAAAA,GAAAA,IAAmB9kD,GACnB01B,EAAQjK,QAAUzrB,EAAKyrB,QAAQ7a,IAAI2f,GAASnuB,KAAKqiD,iBAAiBl0B,EAAOhwB,KAClEwkD,EAAAA,GAAAA,IAAc/kD,KACrB01B,EAAQrnB,UAAYrO,EAAKqO,UAAUpQ,KACnCy3B,EAAQzI,OAASjtB,EAAKitB,OACtByI,EAAQr3B,OAAS2B,EAAK3B,OACtBq3B,EAAQzS,UAAYjjB,EAAKwN,MAAMC,MAAMC,KACrCgoB,EAAQsvB,YAAchlD,EAAKwN,MAAMC,MAAME,UACvC+nB,EAAQxS,QAAUljB,EAAKwN,MAAM2D,IAAIzD,KACjCgoB,EAAQgd,UAAY1yC,EAAKwN,MAAM2D,IAAIxD,WAEhC+nB,CACX,CAEAuvB,OAAAA,CAAqC7gD,GACjC,MAAMpE,EAAOoE,EAAOlD,MACdX,EAAU6B,KAAK8iD,uBAAuBllD,GAI5C,MAHI,aAAcA,GACdoC,KAAK+iD,eAAenlD,EAAKmvB,SAAU5uB,GAEhC,CACH4zB,YAAa/vB,EAAO+vB,YACpBE,YAAajwB,EAAOiwB,YACpBE,aAAcnwB,EAAOmwB,aACrBrzB,MAAOkB,KAAKgjD,eAAeplD,EAAMO,GAEzC,CAEU2kD,sBAAAA,CAAuBllD,GAC7B,MAAMskD,EAAW,IAAIt1C,IACfu1C,EAAW,IAAIv1C,IACrB,IAAK,MAAMkgB,KAAWsU,EAAAA,GAAAA,IAAUxjC,GAC5BskD,EAASh1C,IAAI4f,EAAS,CAAC,GAE3B,IAAIvoB,EACJ,GAAI3G,EAAKmvB,SACL,IAAK,MAAMuG,KAAW8uB,EAAAA,EAAAA,IAAUxkD,EAAKmvB,UAAW,CAC5C,IAAIk2B,EACA,aAAc3vB,GACd2vB,EAAM,IAAIt3B,GAAgB2H,EAAQjG,UAClC9oB,EAAO0+C,GACA,YAAa3vB,EACpB2vB,EAAM,IAAIl3B,GACH,cAAeuH,IACtB2vB,EAAMjjD,KAAKkjD,mBAAmB5vB,IAE9B2vB,IACAd,EAASj1C,IAAIomB,EAAS2vB,GACtBA,EAAI1+C,KAAOA,EAEnB,CAEJ,MAAO,CACH29C,WACAC,WAER,CAEUa,cAAAA,CAAeplD,EAAWO,GAChC,MAAM2uB,EAAU3uB,EAAQ+jD,SAASj9C,IAAIrH,GACrCkvB,EAAQ1wB,MAAQwB,EAAKxB,MACrB0wB,EAAQ6f,gBAAkB/uC,EAAK+uC,gBAC/B7f,EAAQ4f,mBAAqB9uC,EAAK8uC,mBAC9B9uC,EAAKmvB,WACLD,EAAQC,SAAW5uB,EAAQgkD,SAASl9C,IAAIrH,EAAKmvB,WAEjD,IAAK,MAAOlxB,EAAMiD,KAAUI,OAAOo1B,QAAQ12B,GACvC,IAAI/B,EAAKqwC,WAAW,KAGpB,GAAI9rC,MAAMrB,QAAQD,GAAQ,CACtB,MAAMwjD,EAAiB,GACvBx1B,EAAQjxB,GAAQymD,EAChB,IAAK,MAAM7kD,KAAQqB,GACXwjC,EAAAA,GAAAA,IAAU7kC,GACV6kD,EAAIniD,KAAKH,KAAKmjD,UAAUnjD,KAAKgjD,eAAevlD,EAAMU,GAAU2uB,KACrD8X,EAAAA,GAAAA,IAAYnnC,GACnB6kD,EAAIniD,KAAKH,KAAKojD,iBAAiB3lD,EAAMqvB,EAASjxB,EAAMsC,IAEpDmkD,EAAIniD,KAAK1C,EAGrB,MAAW6kC,EAAAA,GAAAA,IAAUxjC,GACjBguB,EAAQjxB,GAAQmE,KAAKmjD,UAAUnjD,KAAKgjD,eAAelkD,EAAOX,GAAU2uB,IAC7D8X,EAAAA,GAAAA,IAAY9lC,GACnBguB,EAAQjxB,GAAQmE,KAAKojD,iBAAiBtkD,EAAOguB,EAASjxB,EAAMsC,QAC3CE,IAAVS,IACPguB,EAAQjxB,GAAQiD,GAGxB,OAAOguB,CACX,CAEUq2B,SAAAA,CAAUvlD,EAAWmqB,GAE3B,OADAnqB,EAAK29B,WAAaxT,EACXnqB,CACX,CAEUwlD,gBAAAA,CAAiB5hB,EAAgB5jC,EAAe/B,EAAcsC,GACpE,OAAO6B,KAAK6wB,OAAOuD,eAAex2B,EAAM/B,EAAMsC,EAAQgkD,SAASl9C,IAAIu8B,EAAUa,UAAYb,EAAU1I,SACvG,CAEUiqB,cAAAA,CAAezvB,EAAcn1B,GAAgC,IAAPklD,EAAGjlD,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAClE,MAAMklD,EAAanlD,EAAQgkD,SAASl9C,IAAIquB,GAKxC,GAJqC,kBAA1BA,EAAQtH,gBACfs3B,EAAWt3B,cAAgBhsB,KAAKujD,kBAAkBjwB,EAAQtH,gBAE9Ds3B,EAAWx2B,QAAU3uB,EAAQ+jD,SAASj9C,IAAIquB,EAAQxG,UAC9C41B,EAAAA,GAAAA,IAAmBY,GACnB,IAAK,MAAMn1B,KAASmF,EAAQjK,QAAS,CACjC,MAAMm6B,EAAWxjD,KAAK+iD,eAAe50B,EAAOhwB,EAASklD,KACrDC,EAAWj6B,QAAQlpB,KAAKqjD,EAC5B,CAEJ,OAAOF,CACX,CAEUJ,kBAAAA,CAAmB5vB,GACzB,MAAMrnB,EAAYjM,KAAKyjD,aAAanwB,EAAQrnB,WACtC4e,EAASyI,EAAQzI,OACjB5uB,EAASq3B,EAAQr3B,OACjB4kB,EAAYyS,EAAQzS,UACpB+hC,EAActvB,EAAQsvB,YACtB9hC,EAAUwS,EAAQxS,QAClBwvB,EAAYhd,EAAQgd,UACpBrjB,EAASqG,EAAQrG,OAiBvB,OAhBa,IAAId,GACbtB,EACA5uB,EACA,CACIoP,MAAO,CACHC,KAAMuV,EACNtV,UAAWq3C,GAEf7zC,IAAK,CACDzD,KAAMwV,EACNvV,UAAW+kC,IAGnBrkC,EACAghB,EAGR,CAEUw2B,YAAAA,CAAa5nD,GACnB,OAAOmE,KAAKivB,MAAMxgB,WAAW5S,EACjC,CAEU4mD,mBAAAA,CAAoB7kD,GAC1B,GAAKA,EAML,OAHsC,IAAlCoC,KAAK4hD,oBAAoB/vC,MACzB7R,KAAK0jD,4BAEF1jD,KAAK4hD,oBAAoB38C,IAAIrH,EACxC,CAEU2lD,iBAAAA,CAAkBI,GACc,IAAlC3jD,KAAK4hD,oBAAoB/vC,MACzB7R,KAAK0jD,4BAGT,OADgB1jD,KAAK4hD,oBAAoBrb,OAAOod,EAEpD,CAEUD,yBAAAA,GACN,IAAIC,EAAK,EACT,IAAK,MAAMv2B,KAAWgU,EAAAA,GAAAA,IAAUphC,KAAKg3B,UAC7B4sB,EAAAA,EAAAA,IAAkBx2B,IAClBptB,KAAK4hD,oBAAoB10C,IAAIkgB,EAASu2B,IAGlD,EClRE,SAAUhlD,GAAwBR,GACpC,MAAO,CACHynB,cAAe,CACXwkB,gBAAkB5tC,GAAa,IAAI2jD,GAAuB3jD,GAC1DqnD,sBAAwBrnD,GAAa,IAAI+iD,GAA2B/iD,IAExEuB,OAAQ,CACJuhC,YAAc9iC,GAAa,IAAIikD,GAAmBjkD,GAClD6jD,cAAgB7jD,GC9BtB,SAA8BA,GAChC,MAAM+P,EAAkB,GAClByqB,EAAUx6B,EAASm/B,QACzB,IAAK,MAAMjgC,KAAQs7B,EAAQzqB,OACnBqsB,EAAAA,EAAAA,IAAel9B,KAASooD,EAAAA,EAAAA,IAAkBpoD,KAASqoD,EAAAA,EAAAA,KAAmBC,EAAAA,EAAAA,GAActoD,KACpF6Q,EAAMpM,KAAKzE,EAAKG,MAGxB,MAAO,CACH2kD,sBAAuBj0C,EACvB03C,WAAYC,EAAAA,GAEpB,CDkByCC,CAAoB3nD,GACjDk0B,cAAgBl0B,GAAak/B,GAAoBl/B,GACjD4nD,iBAAmB5nD,GEjDzB,SAAiCA,GACnC,MAAMw6B,EAAUx6B,EAASm/B,QACnB1M,EAAQzyB,EAASuB,OAAOmxB,MACxBnxB,EAAS,IAAIw3B,GAAwB/4B,GAG3C,OAFAu6B,GAAaC,EAASj5B,EAAQkxB,EAAMxgB,YACpC1Q,EAAO+T,WACA/T,CACX,CF0C4CsmD,CAAuB7nD,GACvDyB,eAAgBA,IAAM,IAAIqmD,GAAAA,EAC1BtmD,aAAcA,IAAM,IAAIumD,GAAAA,EACxBr1B,MAAQ1yB,GAAa,IAAI29C,GAAa39C,GACtCkzB,2BAA4BA,IAAM,IAAIqF,GACtCqlB,0BAA2BA,IAAM,IAAIL,IAEzChc,UAAW,CACPmD,eAAgBA,IAAM,IAAI6Q,GAC1BrL,2BAA6BlqC,GAAa,IAAI60C,GAAkC70C,GAChF67C,6BAA+B77C,GAAa,IAAIk1C,GAAoCl1C,IAExFs0B,WAAY,CACRC,OAASv0B,GAAa,IAAImkC,GAAcnkC,GACxC6nC,aAAcA,IAAM,IAAIhB,GACxBrC,cAAgBxkC,GAAa,IAAI0sC,GAAqB1sC,GACtD45C,iBAAmB55C,GAAa,IAAIgqC,GAAwBhqC,GAC5DgoD,WAAahoD,GAAa,IAAI2nC,GAAkB3nC,IAEpDioD,WAAY,CACRC,SAAWloD,GAAa,IAAImlD,GAAgBnlD,GAC5CmoD,eAAiBnoD,GAAa,IAAIytC,GAAsBztC,IAE5DE,WAAY,CACR4wC,kBAAoB9wC,GAAa,IAAIsyC,GAAyBtyC,GAC9DK,mBAAqBL,GAAa,IAAIK,GAAmBL,IAE7D+B,OAAQA,IAAMJ,EAAQI,OAE9B,CAoBM,SAAUE,GAA8BN,GAC1C,MAAO,CACHU,gBAAkBrC,GAAa,IAAIswC,GAAuBtwC,GAC1DuhC,UAAW,CACP+C,iBAAmBtkC,GAAa,IAAIgjC,GAAwBhjC,GAC5DmjC,uBAAyBnjC,GAAa,IAAIohC,GAA8BphC,GACxEqsC,gBAAkBrsC,GAAa,IAAIw3C,GAAuBx3C,GAC1D8nC,aAAe9nC,GAAa,IAAIg7C,GAAoBh7C,GACpDooD,iBAAmBpoD,GAAa,IAAI87C,GAAwB97C,GAC5D0hC,mBAAqB1hC,GAAa2B,EAAQ8/B,mBAAmBzhC,GAC7Dk8C,cAAeA,IAAM,IAAIkI,GACzBiE,sBAAwBroD,GAAa,IAAIk2C,GAA6Bl2C,IAGlF,C,gGGjHO,MAAMmgD,EAAiB,UAExBmI,EAAe,IAAIC,EAAAA,EAezB,MAAMC,UAA8BC,EAAAA,EAApC/pD,WAAAA,G,oBAEY,KAAAgqD,YAAa,EAEb,KAAAC,eAA2B,GACnC,KAAAC,WAAY,CAoEhB,CAjEI,YAAIC,GACA,OAAOrlD,KAAKmlD,eAAezhD,KAAK,GACpC,CAEA4hD,KAAAA,CAAMC,GACFvlD,KAAKolD,WAAY,EACjBplD,KAAKulD,MAAQA,EACbvlD,KAAKwlD,YAAc,GACnBxlD,KAAKklD,YAAa,EAClBllD,KAAKmlD,eAAiB,EAC1B,CAESM,UAAAA,CAAW7nD,GACZA,EAAK8nD,aACL1lD,KAAKklD,YAAa,EAClBllD,KAAKmlD,eAAiB,GAE9B,CAESQ,cAAAA,CAAe/nD,GACpB,MAAM4/B,EAAOj2B,OAAOC,aAAa5J,EAAKkB,OAItC,GAHKkB,KAAKolD,WAAsB,OAAT5nB,IACnBx9B,KAAKolD,WAAY,GAEjBxnD,EAAK8nD,WACL1lD,KAAKklD,YAAa,EAClBllD,KAAKmlD,eAAiB,OACnB,CACH,MAAMS,EAAcxH,EAAa5gB,GACjCx9B,KAAKmlD,eAAehlD,KAAKylD,GACrB5lD,KAAKklD,aACLllD,KAAKwlD,aAAeI,EAE5B,CACJ,CAESC,QAAAA,CAASjoD,GACd,IAAKoC,KAAKolD,UAAW,CACjB,MAAMl4C,EAAMlN,KAAKulD,MAAMvpD,UAAU4B,EAAKkoD,IAAIC,MAAOnoD,EAAKkoD,IAAI/2C,KACpDw2C,EAAQ,IAAIlH,OAAOnxC,GACzBlN,KAAKolD,UAAYl/B,QAAQ,KAAKhqB,MAAMqpD,GACxC,CACA,GAAI3nD,EAAK8nD,WACL1lD,KAAKklD,YAAa,EAClBllD,KAAKmlD,eAAiB,OACnB,CACH,MAAMj4C,EAAMlN,KAAKulD,MAAMvpD,UAAU4B,EAAKkoD,IAAIC,MAAOnoD,EAAKkoD,IAAI/2C,KAC1D/O,KAAKmlD,eAAehlD,KAAK+M,GACrBlN,KAAKklD,aACLllD,KAAKwlD,aAAet4C,EAE5B,CACJ,CAES84C,aAAAA,CAAcpoD,GACnB,GAAkB,UAAdA,EAAK+N,KAAkB,CAIvB,GADc/N,EACJ8nD,WACN,MAER,CACAvqD,MAAM6qD,cAAcpoD,EACxB,EAGJ,MAAMqoD,EAAU,IAAIjB,EAwBd,SAAUjB,EAAmBmC,GAC/B,IAQI,MAPsB,kBAAXA,IACPA,EAAS,IAAI7H,OAAO6H,IAExBA,EAASA,EAAO9/C,WAChB6/C,EAAQX,MAAMY,GAEdD,EAAQE,MAAMrB,EAAasB,QAAQF,IAC5BD,EAAQb,SACnB,CAAE,MAAAjyC,GACE,OAAO,CACX,CACJ,CAMO,MAAMkzC,EAAuB,8HAE0BriB,MAAM,IAE9D,SAAUsiB,EAAaxnD,GACzB,MAAMonD,EAA0B,kBAAVpnD,EAAqB,IAAIu/C,OAAOv/C,GAASA,EAC/D,OAAOunD,EAAqBjX,KAAMmX,GAAOL,EAAOlgD,KAAKugD,GACzD,CAEM,SAAUnI,EAAat/C,GACzB,OAAOA,EAAM/C,QAAQ,sBAAuB,OAChD,CAEM,SAAUyqD,EAA0B3uB,GACtC,OAAOz3B,MAAM8E,UAAUsJ,IAAIpM,KAAKy1B,EAAS4uB,GACrC,KAAKzgD,KAAKygD,GAAU,IAAH9gD,OAAO8gD,EAAOn/C,eAAa3B,OAAG8gD,EAAOC,cAAa,KAAMtI,EAAaqI,IACxF/iD,KAAK,GACX,CAQM,SAAUijD,EAAepB,EAAwB5pD,GACnD,MAAM0V,EAWJ,SAAwBk0C,GACL,kBAAVA,IACPA,EAAQ,IAAIlH,OAAOkH,IAEvB,MAAMqB,EAAKrB,EAAOh8C,EAASg8C,EAAMh8C,OACjC,IAAIhJ,EAAI,EAER,SAAS+C,IACL,IACIujD,EADA7kD,EAAS,GAGb,SAAS8kD,EAAUC,GACf/kD,GAAUuH,EAAOnC,OAAO7G,EAAGwmD,GAC3BxmD,GAAKwmD,CACT,CAEA,SAASC,EAAeD,GACpB/kD,GAAU,MAAQuH,EAAOnC,OAAO7G,EAAGwmD,GAAW,MAC9CxmD,GAAKwmD,CACT,CAEA,KAAOxmD,EAAIgJ,EAAOtN,QACd,OAAQsN,EAAOhJ,IACX,IAAK,KACD,OAAQgJ,EAAOhJ,EAAI,IACf,IAAK,IACDymD,EAAe,GACf,MACJ,IAAK,IACDA,EAAe,GACf,MACJ,IAAK,IACGJ,EAAGK,QACmB,MAAlB19C,EAAOhJ,EAAI,GACXymD,EAAez9C,EAAO9D,QAAQ,IAAKlF,GAAKA,EAAI,GAE5CymD,EAAe,GAGnBA,EAAe,GAEnB,MACJ,IAAK,IACL,IAAK,IACGJ,EAAGK,QACHD,EAAez9C,EAAO9D,QAAQ,IAAKlF,GAAKA,EAAI,GAE5CymD,EAAe,GAEnB,MACJ,IAAK,IACDA,EAAez9C,EAAO9D,QAAQ,IAAKlF,GAAKA,EAAI,GAC5C,MACJ,QACIymD,EAAe,GAGvB,MAEJ,IAAK,IACDH,EAAM,mBACNA,EAAIt8C,UAAYhK,EAChBsmD,EAAMA,EAAI1qD,KAAKoN,IAAW,GAC1By9C,EAAeH,EAAI,GAAG5qD,QACtB,MAEJ,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACD6qD,EAAU,GACV,MACJ,IAAK,IACDD,EAAM,gBACNA,EAAIt8C,UAAYhK,EAChBsmD,EAAMA,EAAI1qD,KAAKoN,GACXs9C,EACAC,EAAUD,EAAI,GAAG5qD,QAEjB+qD,EAAe,GAEnB,MACJ,IAAK,IACD,GAAsB,MAAlBz9C,EAAOhJ,EAAI,GACX,OAAQgJ,EAAOhJ,EAAI,IACf,IAAK,IACDyB,GAAU,MACVzB,GAAK,EACLyB,GAAUsB,IAAY,MACtB,MACJ,IAAK,IACDtB,GAAU,MACVzB,GAAK,EACLyB,GAAUsB,IAAY,IACtB,MACJ,IAAK,IACDujD,EAAMtmD,EACNA,GAAK,EACL+C,IACAtB,GAAUuH,EAAOnC,OAAOy/C,EAAKtmD,EAAIsmD,GACjC,MACJ,IAAK,IACD,OAAQt9C,EAAOhJ,EAAI,IACf,IAAK,IACL,IAAK,IACDsmD,EAAMtmD,EACNA,GAAK,EACL+C,IACAtB,GAAUuH,EAAOnC,OAAOy/C,EAAKtmD,EAAIsmD,GACjC,MACJ,QACIC,EAAUv9C,EAAO9D,QAAQ,IAAKlF,GAAKA,EAAI,GACvCyB,GAAUsB,IAAY,YAMtCwjD,EAAU,GACV9kD,GAAUsB,IAAY,MAE1B,MACJ,IAAK,IAED,QADE/C,EACKyB,EACX,QACIglD,EAAe,GAK3B,OAAOhlD,CACX,CAEA,OAAO,IAAIq8C,OAAO/6C,IAAWiiD,EAAM2B,MACvC,CApJoBC,CAAc5B,GACxBrpD,EAAQP,EAAMO,MAAMmV,GAC1B,QAASnV,GAASA,EAAM,GAAGD,OAAS,CACxC,C,kDC1IA,QAJA,SAAe6C,GACb,OAAOsoD,EAAAA,EAAAA,GAAUtoD,EA7BM,EA8BzB,C,mCChCA,IAAIuoD,EAAe,KAiBnB,QAPA,SAAyB1nC,GAGvB,IAFA,IAAIpX,EAAQoX,EAAO1jB,OAEZsM,KAAW8+C,EAAarhD,KAAK2Z,EAAOxY,OAAOoB,MAClD,OAAOA,CACT,ECbA,IAAI++C,EAAc,OAelB,QANA,SAAkB3nC,GAChB,OAAOA,EACHA,EAAO7e,MAAM,EAAGymD,EAAgB5nC,GAAU,GAAG5jB,QAAQurD,EAAa,IAClE3nC,CACN,E,0BCRI6nC,EAAa,qBAGbC,EAAa,aAGbC,EAAY,cAGZC,EAAehqD,SA8CnB,QArBA,SAAkBmB,GAChB,GAAoB,iBAATA,EACT,OAAOA,EAET,IAAI8oD,EAAAA,EAAAA,GAAS9oD,GACX,OA1CM,IA4CR,IAAIuL,EAAAA,EAAAA,GAASvL,GAAQ,CACnB,IAAI+oD,EAAgC,mBAAjB/oD,EAAMgpD,QAAwBhpD,EAAMgpD,UAAYhpD,EACnEA,GAAQuL,EAAAA,EAAAA,GAASw9C,GAAUA,EAAQ,GAAMA,CAC3C,CACA,GAAoB,iBAAT/oD,EACT,OAAiB,IAAVA,EAAcA,GAASA,EAEhCA,EAAQipD,EAASjpD,GACjB,IAAIkpD,EAAWP,EAAWzhD,KAAKlH,GAC/B,OAAQkpD,GAAYN,EAAU1hD,KAAKlH,GAC/B6oD,EAAa7oD,EAAMgC,MAAM,GAAIknD,EAAW,EAAI,GAC3CR,EAAWxhD,KAAKlH,GAvDb,KAuD6BA,CACvC,EC1DA,IAAImpD,EAAW,IAsCf,QAZA,SAAkBnpD,GAChB,OAAKA,GAGLA,EAAQopD,EAASppD,MACHmpD,GAAYnpD,KAAU,IA9BpB,uBA+BFA,EAAQ,GAAK,EAAI,GAGxBA,IAAUA,EAAQA,EAAQ,EAPd,IAAVA,EAAcA,EAAQ,CAQjC,C,+UC9BO,MAoEMqpD,EAAe,eAQrB,MAAMC,EAAe,eAQrB,MAAMC,EAAY,YAoBlB,MAAMC,EAAiB,iBAQvB,MAAMC,EAAe,eAYrB,MAAMC,EAAkB,kBAEzB,SAAU5E,EAAkBnmD,GAC9B,OAAOmjC,GAAW6nB,WAAWhrD,EAAM+qD,EACvC,CAQO,MAAME,EAAe,eAYrB,MAAMC,EAAY,YAYlB,MAAMC,EAAiB,iBAExB,SAAU9tB,EAAiBr9B,GAC7B,OAAOmjC,GAAW6nB,WAAWhrD,EAAMmrD,EACvC,CASO,MAAMC,EAAc,cAErB,SAAUnuB,EAAcj9B,GAC1B,OAAOmjC,GAAW6nB,WAAWhrD,EAAMorD,EACvC,CASO,MAAMC,EAAc,cAErB,SAAUruB,EAAch9B,GAC1B,OAAOmjC,GAAW6nB,WAAWhrD,EAAMqrD,EACvC,CAeO,MAAMntB,EAAU,UAYhB,MAAMotB,EAAgB,gBAYtB,MAAMC,EAAe,eAEtB,SAAUC,EAAexrD,GAC3B,OAAOmjC,GAAW6nB,WAAWhrD,EAAMurD,EACvC,CAUO,MAAM7kC,EAAY,YAEnB,SAAU+kC,EAAYzrD,GACxB,OAAOmjC,GAAW6nB,WAAWhrD,EAAM0mB,EACvC,CAUO,MAAMglC,EAAgB,gBAYtB,MAAMC,EAAW,WAElB,SAAUzuB,EAAWl9B,GACvB,OAAOmjC,GAAW6nB,WAAWhrD,EAAM2rD,EACvC,CAQO,MAAMC,EAAgB,gBAYtB,MAAM9gC,EAAY,YAYlB,MAAM+gC,EAAqB,qBAE5B,SAAU1uB,EAAqBn9B,GACjC,OAAOmjC,GAAW6nB,WAAWhrD,EAAM6rD,EACvC,CAkBO,MAAMC,EAAa,aAEpB,SAAUjyB,EAAa75B,GACzB,OAAOmjC,GAAW6nB,WAAWhrD,EAAM8rD,EACvC,CAQO,MAAMC,EAAgB,gBAYtB,MAAMC,EAAa,aAEpB,SAAUC,EAAajsD,GACzB,OAAOmjC,GAAW6nB,WAAWhrD,EAAMgsD,EACvC,CAUO,MAAME,EAAa,aAEpB,SAAUC,EAAansD,GACzB,OAAOmjC,GAAW6nB,WAAWhrD,EAAMksD,EACvC,CAQO,MAAME,EAAgB,gBAgBtB,MAAMC,EAAe,eAEtB,SAAUlxB,EAAen7B,GAC3B,OAAOmjC,GAAW6nB,WAAWhrD,EAAMqsD,EACvC,CASO,MAAMxhC,EAAO,OAEd,SAAUyhC,EAAOtsD,GACnB,OAAOmjC,GAAW6nB,WAAWhrD,EAAM6qB,EACvC,CAWO,MAAM0hC,EAAgB,gBAYtB,MAAMC,EAAY,YAclB,MAAMC,EAAS,SAEhB,SAAUnyB,EAASt6B,GACrB,OAAOmjC,GAAW6nB,WAAWhrD,EAAMysD,EACvC,CAOO,MAAMC,EAAe,eAEtB,SAAUnxB,EAAev7B,GAC3B,OAAOmjC,GAAW6nB,WAAWhrD,EAAM0sD,EACvC,CASO,MAAMC,EAAa,aAEpB,SAAUn2B,EAAax2B,GACzB,OAAOmjC,GAAW6nB,WAAWhrD,EAAM2sD,EACvC,CAQO,MAAMC,EAAiB,iBAExB,SAAUC,EAAiB7sD,GAC7B,OAAOmjC,GAAW6nB,WAAWhrD,EAAM4sD,EACvC,CASO,MAAME,GAAiB,iBAExB,SAAUr2B,GAAiBz2B,GAC7B,OAAOmjC,GAAW6nB,WAAWhrD,EAAM8sD,GACvC,CAMO,MAAMC,GAAY,YAEnB,SAAUnwB,GAAY58B,GACxB,OAAOmjC,GAAW6nB,WAAWhrD,EAAM+sD,GACvC,CAQO,MAAMC,GAAQ,QAEf,SAAUtwB,GAAQ18B,GACpB,OAAOmjC,GAAW6nB,WAAWhrD,EAAMgtD,GACvC,CAQO,MAAMhmC,GAAU,UAEjB,SAAUuO,GAAUv1B,GACtB,OAAOmjC,GAAW6nB,WAAWhrD,EAAMgnB,GACvC,CAOO,MAAMimC,GAAe,eAEtB,SAAUC,GAAeltD,GAC3B,OAAOmjC,GAAW6nB,WAAWhrD,EAAMitD,GACvC,CAOO,MAAME,GAAa,aAEpB,SAAUC,GAAaptD,GACzB,OAAOmjC,GAAW6nB,WAAWhrD,EAAMmtD,GACvC,CAQO,MAAME,GAAW,WAElB,SAAU1yB,GAAW36B,GACvB,OAAOmjC,GAAW6nB,WAAWhrD,EAAMqtD,GACvC,CAOO,MAAMC,GAAuB,uBAE9B,SAAUC,GAAuBvtD,GACnC,OAAOmjC,GAAW6nB,WAAWhrD,EAAMstD,GACvC,CAOO,MAAME,GAAgB,gBAEvB,SAAUC,GAAgBztD,GAC5B,OAAOmjC,GAAW6nB,WAAWhrD,EAAMwtD,GACvC,CAOO,MAAME,GAAmB,mBAE1B,SAAUC,GAAmB3tD,GAC/B,OAAOmjC,GAAW6nB,WAAWhrD,EAAM0tD,GACvC,CAOO,MAAME,GAAiB,iBAExB,SAAU/xB,GAAiB77B,GAC7B,OAAOmjC,GAAW6nB,WAAWhrD,EAAM4tD,GACvC,CAOO,MAAMC,GAAa,aAEpB,SAAUC,GAAa9tD,GACzB,OAAOmjC,GAAW6nB,WAAWhrD,EAAM6tD,GACvC,CAMO,MAAME,GAAW,WAElB,SAAUC,GAAWhuD,GACvB,OAAOmjC,GAAW6nB,WAAWhrD,EAAM+tD,GACvC,CAmDM,MAAOE,WAAoCC,EAAAA,GAE7CC,WAAAA,GACI,MAAO,CAACpD,EAAiBL,EAAcC,EAAc8B,EAAQC,EAAczB,EAAcC,EAAWyB,EAAYxB,EAAgByB,EAAgBhC,EAAWQ,EAAa0B,GAAgBzB,EAAa0B,GAAW7uB,EAASotB,EAAe0B,GAAOzB,EAAc7kC,EAAWM,GAAS0kC,EAAeuB,GAActB,EAAUC,EAAe9gC,EAAW+gC,EAAoBC,EAAYC,EAAeoB,GAAYnB,EAAYqB,GAAUnB,EAAYE,EAAekB,GAAsBE,GAAenB,EAAcqB,GAAkB7iC,EAAM0hC,EAAe1B,EAAgB2B,EAAWoB,GAAgBC,GAAY/C,EAAciD,GACjmB,CAEmBK,gBAAAA,CAAiB3d,EAAiB4d,GACjD,OAAQ5d,GACJ,KAAKgc,EACL,KAAKC,EACL,KAAKC,EACL,KAAKC,EACL,KAAKE,GACL,KAAKC,GACL,KAAKC,GACL,KAAKhmC,GACL,KAAKimC,GACL,KAAKE,GACL,KAAKE,GACL,KAAKC,GACL,KAAKE,GACL,KAAKE,GACL,KAAKE,GACL,KAAKC,GACL,KAAKE,GACD,OAAOxrD,KAAKypC,UAAU+e,EAAiBsD,GAE3C,KAAKpD,EACL,KAAKW,EACL,KAAKQ,EACD,OAAO7pD,KAAKypC,UAAU8e,EAAcuD,GAExC,KAAKnD,EACL,KAAKa,EACL,KAAKG,EACL,KAAKM,EACD,OAAOjqD,KAAKypC,UAAU6e,EAAgBwD,GAE1C,KAAKlD,EACD,OAAO5oD,KAAKypC,UAAU4e,EAAWyD,IAAc9rD,KAAKypC,UAAU8e,EAAcuD,GAEhF,KAAKjD,EACL,KAAKC,EACL,KAAKM,EACL,KAAKE,EACD,OAAOtpD,KAAKypC,UAAU4e,EAAWyD,GAErC,KAAK9C,EACL,KAAK7kC,EACL,KAAKmE,EACD,OAAOtoB,KAAKypC,UAAU2e,EAAc0D,GAExC,KAAKvC,EACD,OAAOvpD,KAAKypC,UAAU0e,EAAc2D,IAAc9rD,KAAKypC,UAAU2e,EAAc0D,GAEnF,KAAKhC,EACD,OAAO9pD,KAAKypC,UAAU0e,EAAc2D,GAExC,QACI,OAAO,EAGnB,CAEA1oB,gBAAAA,CAAiB7B,GACb,MAAMwqB,EAAc,GAAHpmD,OAAM47B,EAAQhV,UAAUnwB,MAAK,KAAAuJ,OAAI47B,EAAQ1jC,UAC1D,OAAQkuD,GACJ,IAAK,cACL,IAAK,sBACL,IAAK,uBACL,IAAK,wBACL,IAAK,qBACD,OAAO3D,EAEX,IAAK,uBACL,IAAK,0BACL,IAAK,gBACD,OAAOD,EAEX,IAAK,uBACD,OAAOxsB,EAEX,IAAK,0BACL,IAAK,+BACD,OAAOpT,EAEX,IAAK,wBACD,OAAOuhC,EAEX,QACI,MAAM,IAAIppD,MAAM,GAADiF,OAAIomD,EAAW,kCAG1C,CAEAC,eAAAA,CAAgBrgD,GACZ,OAAQA,GACJ,KAAK68C,EACD,MAAO,CACH3sD,KAAM2sD,EACNyD,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,eAIpB,KAAK6sD,EACD,MAAO,CACH7sD,KAAM6sD,EACNuD,WAAY,CACR,CAAEpwD,KAAM,WAAYqwD,aAAc,MAI9C,KAAKvD,EACD,MAAO,CACH9sD,KAAM8sD,EACNsD,WAAY,CACR,CAAEpwD,KAAM,iBAIpB,KAAK+sD,EACD,MAAO,CACH/sD,KAAM+sD,EACNqD,WAAY,CACR,CAAEpwD,KAAM,OAAQqwD,cAAc,KAI1C,KAAKrD,EACD,MAAO,CACHhtD,KAAMgtD,EACNoD,WAAY,CACR,CAAEpwD,KAAM,QACR,CAAEA,KAAM,WAIpB,KAAKitD,EACD,MAAO,CACHjtD,KAAMitD,EACNmD,WAAY,CACR,CAAEpwD,KAAM,QACR,CAAEA,KAAM,WAIpB,KAAK8/B,EACD,MAAO,CACH9/B,KAAM8/B,EACNswB,WAAY,CACR,CAAEpwD,KAAM,sBAAuBqwD,cAAc,GAC7C,CAAErwD,KAAM,eAAgBqwD,aAAc,IACtC,CAAErwD,KAAM,UAAWqwD,aAAc,IACjC,CAAErwD,KAAM,aAAcqwD,aAAc,IACpC,CAAErwD,KAAM,aAAcqwD,cAAc,GACpC,CAAErwD,KAAM,QACR,CAAEA,KAAM,QAASqwD,aAAc,IAC/B,CAAErwD,KAAM,QAASqwD,aAAc,IAC/B,CAAErwD,KAAM,eAAgBqwD,aAAc,MAIlD,KAAKnD,EACD,MAAO,CACHltD,KAAMktD,EACNkD,WAAY,CACR,CAAEpwD,KAAM,UAIpB,KAAKmtD,EACD,MAAO,CACHntD,KAAMmtD,EACNiD,WAAY,CACR,CAAEpwD,KAAM,UAIpB,KAAKsoB,EACD,MAAO,CACHtoB,KAAMsoB,EACN8nC,WAAY,CACR,CAAEpwD,KAAM,aAAcqwD,aAAc,IACpC,CAAErwD,KAAM,QACR,CAAEA,KAAM,aAAcqwD,aAAc,MAIhD,KAAK/C,EACD,MAAO,CACHttD,KAAMstD,EACN8C,WAAY,CACR,CAAEpwD,KAAM,eAAgBqwD,cAAc,GACtC,CAAErwD,KAAM,aACR,CAAEA,KAAM,WAIpB,KAAKutD,EACD,MAAO,CACHvtD,KAAMutD,EACN6C,WAAY,CACR,CAAEpwD,KAAM,WAIpB,KAAKwtD,EACD,MAAO,CACHxtD,KAAMwtD,EACN4C,WAAY,CACR,CAAEpwD,KAAM,WAIpB,KAAK0sB,EACD,MAAO,CACH1sB,KAAM0sB,EACN0jC,WAAY,CACR,CAAEpwD,KAAM,UAIpB,KAAKytD,EACD,MAAO,CACHztD,KAAMytD,EACN2C,WAAY,CACR,CAAEpwD,KAAM,eAIpB,KAAK0tD,EACD,MAAO,CACH1tD,KAAM0tD,EACN0C,WAAY,CACR,CAAEpwD,KAAM,YACR,CAAEA,KAAM,sBAAuBqwD,cAAc,GAC7C,CAAErwD,KAAM,cACR,CAAEA,KAAM,QAASqwD,cAAc,GAC/B,CAAErwD,KAAM,WAAYqwD,cAAc,GAClC,CAAErwD,KAAM,eAAgBqwD,aAAc,IACtC,CAAErwD,KAAM,gBACR,CAAEA,KAAM,QACR,CAAEA,KAAM,aAAcqwD,aAAc,IACpC,CAAErwD,KAAM,cACR,CAAEA,KAAM,WAAYqwD,cAAc,KAI9C,KAAK1C,EACD,MAAO,CACH3tD,KAAM2tD,EACNyC,WAAY,CACR,CAAEpwD,KAAM,mBAIpB,KAAK4tD,EACD,MAAO,CACH5tD,KAAM4tD,EACNwC,WAAY,CACR,CAAEpwD,KAAM,UAIpB,KAAK8tD,EACD,MAAO,CACH9tD,KAAM8tD,EACNsC,WAAY,CACR,CAAEpwD,KAAM,iBACR,CAAEA,KAAM,cACR,CAAEA,KAAM,aAIpB,KAAKguD,EACD,MAAO,CACHhuD,KAAMguD,EACNoC,WAAY,CACR,CAAEpwD,KAAM,WAIpB,KAAKiuD,EACD,MAAO,CACHjuD,KAAMiuD,EACNmC,WAAY,CACR,CAAEpwD,KAAM,cACR,CAAEA,KAAM,WAAYqwD,cAAc,GAClC,CAAErwD,KAAM,SAAUqwD,cAAc,GAChC,CAAErwD,KAAM,QACR,CAAEA,KAAM,UAIpB,KAAKysB,EACD,MAAO,CACHzsB,KAAMysB,EACN2jC,WAAY,CACR,CAAEpwD,KAAM,QACR,CAAEA,KAAM,UAIpB,KAAKmuD,EACD,MAAO,CACHnuD,KAAMmuD,EACNiC,WAAY,CACR,CAAEpwD,KAAM,gBACR,CAAEA,KAAM,aAAcqwD,cAAc,GACpC,CAAErwD,KAAM,QACR,CAAEA,KAAM,UAIpB,KAAKouD,EACD,MAAO,CACHpuD,KAAMouD,EACNgC,WAAY,CACR,CAAEpwD,KAAM,QAASqwD,aAAc,MAI3C,KAAKhC,EACD,MAAO,CACHruD,KAAMquD,EACN+B,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,WACR,CAAEA,KAAM,gBACR,CAAEA,KAAM,aACR,CAAEA,KAAM,YACR,CAAEA,KAAM,UAIpB,KAAKsuD,EACD,MAAO,CACHtuD,KAAMsuD,EACN8B,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,WAAYqwD,aAAc,IAClC,CAAErwD,KAAM,eAIpB,KAAKuuD,EACD,MAAO,CACHvuD,KAAMuuD,EACN6B,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,WACR,CAAEA,KAAM,aACR,CAAEA,KAAM,YACR,CAAEA,KAAM,cAIpB,KAAKwuD,EACD,MAAO,CACHxuD,KAAMwuD,EACN4B,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,QACR,CAAEA,KAAM,aACR,CAAEA,KAAM,WAIpB,KAAK0uD,GACD,MAAO,CACH1uD,KAAM0uD,GACN0B,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,mBAAoBqwD,cAAc,GAC1C,CAAErwD,KAAM,aACR,CAAEA,KAAM,YACR,CAAEA,KAAM,UAIpB,KAAK2uD,GACD,MAAO,CACH3uD,KAAM2uD,GACNyB,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,eAIpB,KAAK4uD,GACD,MAAO,CACH5uD,KAAM4uD,GACNwB,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,WAAYqwD,aAAc,IAClC,CAAErwD,KAAM,kBACR,CAAEA,KAAM,eAIpB,KAAK4oB,GACD,MAAO,CACH5oB,KAAM4oB,GACNwnC,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,aACR,CAAEA,KAAM,WAIpB,KAAK6uD,GACD,MAAO,CACH7uD,KAAM6uD,GACNuB,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,aACR,CAAEA,KAAM,cAIpB,KAAK+uD,GACD,MAAO,CACH/uD,KAAM+uD,GACNqB,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,aACR,CAAEA,KAAM,WAIpB,KAAKivD,GACD,MAAO,CACHjvD,KAAMivD,GACNmB,WAAY,CACR,CAAEpwD,KAAM,YAAaqwD,aAAc,IACnC,CAAErwD,KAAM,eACR,CAAEA,KAAM,aACR,CAAEA,KAAM,UAIpB,KAAKkvD,GACD,MAAO,CACHlvD,KAAMkvD,GACNkB,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,WAAYqwD,aAAc,IAClC,CAAErwD,KAAM,eAIpB,KAAKovD,GACD,MAAO,CACHpvD,KAAMovD,GACNgB,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,WAAYqwD,aAAc,IAClC,CAAErwD,KAAM,eAIpB,KAAKsvD,GACD,MAAO,CACHtvD,KAAMsvD,GACNc,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,aACR,CAAEA,KAAM,UAIpB,KAAKwvD,GACD,MAAO,CACHxvD,KAAMwvD,GACNY,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,WAAYqwD,aAAc,IAClC,CAAErwD,KAAM,eAIpB,KAAKyvD,GACD,MAAO,CACHzvD,KAAMyvD,GACNW,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,aACR,CAAEA,KAAM,cAIpB,KAAK2vD,GACD,MAAO,CACH3vD,KAAM2vD,GACNS,WAAY,CACR,CAAEpwD,KAAM,eACR,CAAEA,KAAM,eAIpB,QACI,MAAO,CACHA,KAAM8P,EACNsgD,WAAY,IAI5B,EAGG,MAAMrrB,GAAa,IAAI8qB,E,kBChqCxB,IAAWtnC,EA0BX,SAAU5lB,EACZ2tD,EAAwBC,EAAyBC,EAAyBC,EAAyBC,EAAyBC,EAAyBC,EAAyBC,EAAyBC,GAGvM,OAAOC,EADQ,CAACT,EAASC,EAASC,EAASC,EAASC,EAASC,EAASC,EAASC,EAASC,GAASn4C,OAAOq4C,EAAQ,CAAC,GAErH,C,kBA/BA,SAAiBzoC,GACAA,EAAA0oC,MAAQ,CAA4BC,EAAmBC,IAAuBH,EAAOA,EAAO,CAAC,EAAGE,GAAKC,EACrH,CAFD,CAAiB5oC,IAAAA,EAAM,KAiCvB,MAAM6oC,EAAU7nD,OAAO,WAmBvB,SAASwnD,EAAcM,EAAsBC,GACzC,MAAMC,EAAa,IAAIC,MAAM,CAAC,EAAU,CACpCC,eAAgBA,KAAM,EACtBpgD,IAAKA,KACD,MAAM,IAAIxM,MAAM,sDAEpBuE,IAAKA,CAAC4uB,EAAK05B,IACHA,IAASN,GAGFO,EAAS35B,EAAK05B,EAAML,EAAQC,GAAYC,GAGvDK,yBAA0BA,CAAC55B,EAAK05B,KAAUC,EAAS35B,EAAK05B,EAAML,EAAQC,GAAYC,GAAQluD,OAAOuuD,yBAAyB55B,EAAK05B,IAC/Hv3C,IAAKA,CAACvK,EAAG8hD,IAASA,KAAQL,EAC1BQ,QAASA,IAAM,IAAIxuD,OAAOyuD,oBAAoBT,MAElD,OAAOE,CACX,CAMA,MAAMQ,EAAgBxoD,SActB,SAASooD,EAAe35B,EAAU05B,EAAgCL,EAAsBC,GACpF,GAAII,KAAQ15B,EAAK,CACb,GAAIA,EAAI05B,aAAiB7sD,MACrB,MAAM,IAAIA,MAAM,mFAAoF,CAACmtD,MAAOh6B,EAAI05B,KAEpH,GAAI15B,EAAI05B,KAAUK,EACd,MAAM,IAAIltD,MAAM,gCAAkC6G,OAAOgmD,GAAQ,0GAErE,OAAO15B,EAAI05B,EACf,CAAO,GAAIA,KAAQL,EAAQ,CACvB,MAAMpuD,EAA+DouD,EAAOK,GAC5E15B,EAAI05B,GAAQK,EACZ,IACI/5B,EAAI05B,GAA0B,oBAAVzuD,EAAwBA,EAAMquD,GAAYP,EAAQ9tD,EAAOquD,EACjF,CAAE,MAAO5rD,GAEL,MADAsyB,EAAI05B,GAAQhsD,aAAiBb,MAAQa,OAAQlD,EACvCkD,CACV,CACA,OAAOsyB,EAAI05B,EACf,CAGJ,CASA,SAASV,EAAO/gD,EAAqBvC,GACjC,GAAIA,EACA,IAAK,MAAOb,EAAKolD,KAAW5uD,OAAOo1B,QAAQ/qB,GACvC,QAAelL,IAAXyvD,EAAsB,CACtB,MAAMC,EAASjiD,EAAOpD,GAElBoD,EAAOpD,GADI,OAAXqlD,GAA8B,OAAXD,GAAqC,kBAAXC,GAAyC,kBAAXD,EAC7DjB,EAAOkB,EAAQD,GAEfA,CAEtB,CAGR,OAAOhiD,CACX,C,mCCzIA,QALA,SAAczJ,GACZ,IAAIpG,EAAkB,MAAToG,EAAgB,EAAIA,EAAMpG,OACvC,OAAOA,EAASoG,EAAMpG,EAAS,QAAKoC,CACtC,C,kBCYM,SAAUikC,EAAUzO,GACtB,MAAsB,kBAARA,GAA4B,OAARA,GAAkD,kBAA1BA,EAAgBz3B,KAC9E,CAkCM,SAAUwoC,EAAY/Q,GACxB,MAAsB,kBAARA,GAA4B,OAARA,GAAuD,kBAA/BA,EAAkBiF,QAChF,CA8BM,SAAUyJ,EAAqB1O,GACjC,MAAsB,kBAARA,GAA4B,OAARA,GACiB,kBAApCA,EAA2Bh4B,MACS,kBAApCg4B,EAA2BloB,MACS,kBAApCkoB,EAA2BhuB,IAC9C,CAqBM,SAAU67B,EAAe7N,GAC3B,MAAsB,kBAARA,GAA4B,OAARA,GAC3ByO,EAAWzO,EAAqBtH,YAChCqY,EAAa/Q,EAAqB2N,YACO,kBAAjC3N,EAAqB1oB,OACxC,C,iFAmBM,MAAgBwgD,EAAtBzwD,WAAAA,GAEc,KAAA8yD,SAAgE,CAAC,EACjE,KAAAC,YAAoD,CAAC,CA6CnE,CAtCIxF,UAAAA,CAAW7qD,EAAe+N,GACtB,OAAO22B,EAAU1kC,IAASoC,KAAKypC,UAAU7rC,EAAKxB,MAAOuP,EACzD,CAEA89B,SAAAA,CAAUyE,EAAiB4d,GACvB,GAAI5d,IAAY4d,EACZ,OAAO,EAEX,IAAIthD,EAASxK,KAAKguD,SAAS9f,GACtB1jC,IACDA,EAASxK,KAAKguD,SAAS9f,GAAW,CAAC,GAEvC,MAAMz7B,EAAWjI,EAAOshD,GACxB,QAAiBztD,IAAboU,EACA,OAAOA,EACJ,CACH,MAAMzQ,EAAShC,KAAK6rD,iBAAiB3d,EAAS4d,GAE9C,OADAthD,EAAOshD,GAAa9pD,EACbA,CACX,CACJ,CAEAmsC,cAAAA,CAAexiC,GACX,MAAM8G,EAAWzS,KAAKiuD,YAAYtiD,GAClC,GAAI8G,EACA,OAAOA,EACJ,CACH,MAAMy7C,EAAWluD,KAAK4rD,cAChBuC,EAAkB,GACxB,IAAK,MAAMC,KAAmBF,EACtBluD,KAAKypC,UAAU2kB,EAAiBziD,IAChCwiD,EAAMhuD,KAAKiuD,GAInB,OADApuD,KAAKiuD,YAAYtiD,GAAQwiD,EAClBA,CACX,CACJ,EA8DE,SAAUzL,EAAmB9kD,GAC/B,MAAuB,kBAATA,GAA8B,OAATA,GAAiBwC,MAAMrB,QAASnB,EAA0ByrB,QACjG,CASM,SAAUs5B,EAAc/kD,GAC1B,MAAuB,kBAATA,GAA8B,OAATA,GAA4D,kBAAnCA,EAAqBqO,SACrF,CAMM,SAAUu2C,EAAc5kD,GAC1B,OAAO8kD,EAAmB9kD,IAAmD,kBAAlCA,EAAqByvB,QACpE,C,qFCpQIghC,GAAgBrzD,EAAG,cAAcC,EAAAA,GAInCC,WAAAA,GACEC,MAAM,CAAC,OAAQ,YACjB,IAJEC,EAAAA,EAAAA,IAAMJ,EAAO,oBAAmBA,GAQhCszD,EAAa,CACfvwD,OAAQ,CACNC,cAA8B5C,EAAAA,EAAAA,IAAO,IAAM,IAAIizD,EAAoB,gBACnEpwD,gBAAgC7C,EAAAA,EAAAA,IAAO,IAAM,IAAI4O,EAAAA,GAAwB,oBAG7E,SAASukD,IAA8C,IAA3BpwD,EAAOC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGE,EAAAA,EACpC,MAAMC,GAASC,EAAAA,EAAAA,KACbC,EAAAA,EAAAA,GAA8BN,GAC9BO,EAAAA,IAEI8vD,GAAOhwD,EAAAA,EAAAA,KACXG,EAAAA,EAAAA,GAAwB,CAAEJ,WAC1BkwD,EAAAA,GACAH,GAGF,OADA/vD,EAAOM,gBAAgB3B,SAASsxD,GACzB,CAAEjwD,SAAQiwD,OACnB,EACApzD,EAAAA,EAAAA,IAAOmzD,EAAoB,qB,iJC5BrB,SAAUz6B,EAAuBl2B,GACnC,IAAK,MAAO/B,EAAMiD,KAAUI,OAAOo1B,QAAQ12B,GAClC/B,EAAKqwC,WAAW,OACb9rC,MAAMrB,QAAQD,GACdA,EAAM2V,QAAQ,CAAChX,EAAM8K,MACb+5B,EAAAA,EAAAA,IAAU7kC,KACTA,EAA0B89B,WAAa39B,EACvCH,EAA0BivC,mBAAqB7wC,EAC/C4B,EAA0BkvC,gBAAkBpkC,MAG9C+5B,EAAAA,EAAAA,IAAUxjC,KAChBA,EAA2By8B,WAAa39B,EACxCkB,EAA2B4tC,mBAAqB7wC,GAIjE,CAOM,SAAUm4B,EAAsCp2B,EAA2B8wD,GAC7E,IAAIjxD,EAAOG,EACX,KAAOH,GAAM,CACT,GAAIixD,EAAcjxD,GACd,OAAOA,EAEXA,EAAOA,EAAK89B,UAChB,CAEJ,CAuBM,SAAUwE,EAAyCniC,GACrD,MACMoE,EADWwgC,EAAa5kC,GACNuhC,UACxB,IAAKn9B,EACD,MAAM,IAAItB,MAAM,6BAEpB,OAAOsB,CACX,CAKM,SAAUwgC,EAAa5kC,GACzB,KAAOA,EAAK29B,YACR39B,EAAOA,EAAK29B,WAEhB,OAAO39B,CACX,CAaM,SAAUkpC,EAAelpC,EAAeqV,GAC1C,IAAKrV,EACD,MAAM,IAAI8C,MAAM,4BAEpB,MAAM0K,EAAe,OAAP6H,QAAO,IAAPA,OAAO,EAAPA,EAAS7H,MAEvB,OAAO,IAAIujD,EAAAA,GAA2B,KAAM,CACxC32C,KAAM9Y,OAAO8Y,KAAKpa,GAClBgxD,SAAU,EACVpc,WAAY,IACZvhC,IACA,KAAOA,EAAM29C,SAAW39C,EAAM+G,KAAK/b,QAAQ,CACvC,MAAM4B,EAAWoT,EAAM+G,KAAK/G,EAAM29C,UAClC,IAAK/wD,EAASquC,WAAW,KAAM,CAC3B,MAAMptC,EAASlB,EAAwBC,GACvC,IAAIykC,EAAAA,EAAAA,IAAUxjC,IAEV,GADAmS,EAAM29C,WACFC,EAAiB/vD,EAAOsM,GACxB,MAAO,CAAE61C,MAAM,EAAOniD,cAEvB,GAAIsB,MAAMrB,QAAQD,GAAQ,CAC7B,KAAOmS,EAAMuhC,WAAa1zC,EAAM7C,QAAQ,CACpC,MACMmxB,EAAUtuB,EADFmS,EAAMuhC,cAEpB,IAAIlQ,EAAAA,EAAAA,IAAUlV,IAAYyhC,EAAiBzhC,EAAShiB,GAChD,MAAO,CAAE61C,MAAM,EAAOniD,MAAOsuB,EAErC,CACAnc,EAAMuhC,WAAa,CACvB,CACJ,CACAvhC,EAAM29C,UACV,CACA,OAAOE,EAAAA,IAEf,CAMM,SAAU3nB,EAAkB5iC,EAAe0O,GAC7C,IAAK1O,EACD,MAAM,IAAI7D,MAAM,iCAEpB,OAAO,IAAIquD,EAAAA,GAAexqD,EAAM3G,GAAQkpC,EAAelpC,EAAMqV,GACjE,CAMM,SAAUmuB,EAAU78B,EAAe0O,GACrC,IAAK1O,EACD,MAAM,IAAI7D,MAAM,iCACb,OAAW,OAAPuS,QAAO,IAAPA,OAAO,EAAPA,EAAS7H,SAAUyjD,EAAiBtqD,EAAM0O,EAAQ7H,OAElD,IAAI2jD,EAAAA,GAAexqD,EAAM,IAAM,IAEnC,IAAIwqD,EAAAA,GAAexqD,EAAM3G,GAAQkpC,EAAelpC,EAAMqV,GAAU,CAAE+7C,aAAa,GAC1F,CAEA,SAASH,EAAiB/hC,EAAkB1hB,G,MACxC,IAAKA,EACD,OAAO,EAEX,MAAM6jD,EAA4B,QAAhB97C,EAAA2Z,EAAQC,gBAAQ,IAAA5Z,OAAA,EAAAA,EAAE/H,MACpC,QAAK6jD,IAGEC,EAAAA,EAAAA,IAAQD,EAAW7jD,EAC9B,CAMM,SAAUi2B,EAAiBzjC,GAE7B,OAAO,IAAI+wD,EAAAA,GAAiC,KAAM,CAC9C32C,KAAM9Y,OAAO8Y,KAAKpa,GAClBgxD,SAAU,EACVpc,WAAY,IACZvhC,IACA,KAAOA,EAAM29C,SAAW39C,EAAM+G,KAAK/b,QAAQ,CACvC,MAAM4B,EAAWoT,EAAM+G,KAAK/G,EAAM29C,UAClC,IAAK/wD,EAASquC,WAAW,KAAM,CAC3B,MAAMptC,EAASlB,EAAwBC,GACvC,IAAI+mC,EAAAA,EAAAA,IAAY9lC,GAEZ,OADAmS,EAAM29C,WACC,CAAE3N,MAAM,EAAOniD,MAAO,CAAE0iC,UAAW1iC,EAAOytB,UAAW3uB,EAAMC,aAC/D,GAAIuC,MAAMrB,QAAQD,GAAQ,CAC7B,KAAOmS,EAAMuhC,WAAa1zC,EAAM7C,QAAQ,CACpC,MAAMsM,EAAQ0I,EAAMuhC,aACdplB,EAAUtuB,EAAMyJ,GACtB,IAAIq8B,EAAAA,EAAAA,IAAYxX,GACZ,MAAO,CAAE6zB,MAAM,EAAOniD,MAAO,CAAE0iC,UAAWpU,EAASb,UAAW3uB,EAAMC,WAAU0K,SAEtF,CACA0I,EAAMuhC,WAAa,CACvB,CACJ,CACAvhC,EAAM29C,UACV,CACA,OAAOE,EAAAA,IAEf,CA0BM,SAAU/6B,EAA0B6M,EAA2BhjC,GACjE,MAAMuxD,EAAevuB,EAAWorB,gBAAgBpuD,EAAKxB,OAC/CgzD,EAAcxxD,EACpB,IAAK,MAAMC,KAAYsxD,EAAalD,gBAEF5tD,IAA1BR,EAASquD,mBAA6D7tD,IAA/B+wD,EAAYvxD,EAAShC,QAC5DuzD,EAAYvxD,EAAShC,MAAQwzD,EAAiBxxD,EAASquD,cAGnE,CAEA,SAASmD,EAAiBC,GACtB,OAAIlvD,MAAMrB,QAAQuwD,GACP,IAAIA,EAAa9gD,IAAI6gD,IAErBC,CAEf,C,4QC5PM,SAAUC,EAAiBC,GAC/B,SAASC,IAAmB,CAG5BA,EAAgBvqD,UAAYsqD,EAC5B,MAAME,EAAe,IAAKD,EAE1B,SAASE,IACP,cAAcD,EAAaE,GAC7B,CASO,OALPD,IACAA,IAIcH,CAOhB,CCIA,QArBA,SAAmBntD,EAAOgJ,EAAO0D,GAC/B,IAAIxG,GAAS,EACTtM,EAASoG,EAAMpG,OAEfoP,EAAQ,IACVA,GAASA,EAAQpP,EAAS,EAAKA,EAASoP,IAE1C0D,EAAMA,EAAM9S,EAASA,EAAS8S,GACpB,IACRA,GAAO9S,GAETA,EAASoP,EAAQ0D,EAAM,EAAMA,EAAM1D,IAAW,EAC9CA,KAAW,EAGX,IADA,IAAIrJ,EAAS5B,MAAMnE,KACVsM,EAAQtM,GACf+F,EAAOuG,GAASlG,EAAMkG,EAAQ8C,GAEhC,OAAOrJ,CACT,E,eCSA,QATA,SAAcK,EAAOS,EAAGuG,GACtB,IAAIpN,EAAkB,MAAToG,EAAgB,EAAIA,EAAMpG,OACvC,OAAKA,GAGL6G,EAAKuG,QAAehL,IAANyE,EAAmB,GAAI+sD,EAAAA,EAAAA,GAAU/sD,GACxCgtD,EAAUztD,EAAOS,EAAI,EAAI,EAAIA,EAAG7G,IAH9B,EAIX,E,gFCxBIkJ,EAHcjG,OAAOgG,UAGQC,eA8CjC,SAZa4qD,EAAAA,EAAAA,GAAe,SAASpnD,EAAQY,GAC3C,IAAIymD,EAAAA,EAAAA,GAAYzmD,KAAWf,EAAAA,EAAAA,GAAYe,IACrC0mD,EAAAA,EAAAA,GAAW1mD,GAAQyO,EAAAA,EAAAA,GAAKzO,GAASZ,QAGnC,IAAK,IAAID,KAAOa,EACVpE,EAAe/C,KAAKmH,EAAQb,KAC9BmC,EAAAA,EAAAA,GAAYlC,EAAQD,EAAKa,EAAOb,GAGtC,G,+CCnBA,QAbA,SAAgBC,EAAQoC,GACtB,GAAc,MAAVpC,EACF,MAAO,CAAC,EAEV,IAAIa,GAAQ0mD,EAAAA,EAAAA,IAASC,EAAAA,EAAAA,GAAaxnD,GAAS,SAAS4kD,GAClD,MAAO,CAACA,EACV,GAEA,OADAxiD,GAAYsH,EAAAA,EAAAA,GAAatH,IAClBqlD,EAAAA,EAAAA,GAAWznD,EAAQa,EAAO,SAAS1K,EAAO+G,GAC/C,OAAOkF,EAAUjM,EAAO+G,EAAK,GAC/B,EACF,E,0BCjBA,QAJA,SAAsB/G,GACpB,OAAOE,EAAAA,EAAAA,GAAaF,IAVN,oBAUgBG,EAAAA,EAAAA,GAAWH,EAC3C,E,0BCVIuxD,EAAeC,EAAAA,GAAYA,EAAAA,EAASC,SAqBxC,QAFeF,GAAeG,EAAAA,EAAAA,GAAUH,GAAgBI,ECdxD,SAAS93C,EAAW7C,GAClB,OASA+d,EATkB/d,GAWX46C,EAAAA,EAAAA,GAAS78B,EAAIuB,QAAwB,KAAdvB,EAAIuB,MAVzBtf,EAAQsf,MAERtf,EAAQja,KAKnB,IACEg4B,CAJF,CASM,MAAgB88B,EAGpB,cAAWliD,GACT,OAAOzO,KAAK4wD,WACd,CACA,cAAWniD,CAAW3P,GACpBkB,KAAK4wD,YAAc9xD,CACrB,CAEA5D,WAAAA,CAAsB01D,GAAA,KAAAA,YAAAA,CAAmB,CAEzCvzD,MAAAA,CAAO4oD,GACLA,EAAQE,MAAMnmD,OACdyU,EAAAA,EAAAA,GAAQzU,KAAKyO,WAAaoK,IACxBA,EAAKxb,OAAO4oD,IAEhB,EAGI,MAAOr4C,UACH+iD,EAQRz1D,WAAAA,CAAY+X,GAMV9X,MAAM,IARD,KAAA8T,IAAc,EASnBqC,EACEtR,KACA6wD,EAAO59C,EAAUxL,QAAYpJ,IAANoJ,GAE3B,CAEA,cAAIgH,CAAWA,GACb,CAGF,cAAIA,GACF,YAA4BpQ,IAAxB2B,KAAK+N,eACA/N,KAAK+N,eAAeU,WAEtB,EACT,CAEApR,MAAAA,CAAO4oD,GACLA,EAAQE,MAAMnmD,KAEhB,EAGI,MAAO8wD,UAAaH,EAIxBz1D,WAAAA,CAAY+X,GAKV9X,MAAM8X,EAAQxE,YAPT,KAAAsiD,QAAkB,GAQvBz/C,EACEtR,KACA6wD,EAAO59C,EAAUxL,QAAYpJ,IAANoJ,GAE3B,EAGI,MAAOupD,UAAoBL,EAG/Bz1D,WAAAA,CAAY+X,GAIV9X,MAAM8X,EAAQxE,YANT,KAAAwiD,mBAA6B,EAOlC3/C,EACEtR,KACA6wD,EAAO59C,EAAUxL,QAAYpJ,IAANoJ,GAE3B,EAGI,MAAOmH,UACH+hD,EAMRz1D,WAAAA,CAAY+X,GAKV9X,MAAM8X,EAAQxE,YART,KAAAQ,IAAc,EASnBqC,EACEtR,KACA6wD,EAAO59C,EAAUxL,QAAYpJ,IAANoJ,GAE3B,EAGI,MAAOgI,UACHkhD,EAMRz1D,WAAAA,CAAY+X,GAKV9X,MAAM8X,EAAQxE,YART,KAAAQ,IAAc,EASnBqC,EACEtR,KACA6wD,EAAO59C,EAAUxL,QAAYpJ,IAANoJ,GAE3B,EAGI,MAAOoI,UACH8gD,EAORz1D,WAAAA,CAAY+X,GAKV9X,MAAM8X,EAAQxE,YART,KAAAQ,IAAc,EASnBqC,EACEtR,KACA6wD,EAAO59C,EAAUxL,QAAYpJ,IAANoJ,GAE3B,EAGI,MAAOyH,UACHyhD,EAORz1D,WAAAA,CAAY+X,GAKV9X,MAAM8X,EAAQxE,YART,KAAAQ,IAAc,EASnBqC,EACEtR,KACA6wD,EAAO59C,EAAUxL,QAAYpJ,IAANoJ,GAE3B,EAGI,MAAO6H,UACHqhD,EAORz1D,WAAAA,CAAY+X,GAKV9X,MAAM8X,EAAQxE,YART,KAAAQ,IAAc,EASnBqC,EACEtR,KACA6wD,EAAO59C,EAAUxL,QAAYpJ,IAANoJ,GAE3B,EAGI,MAAO2G,UACHuiD,EAQR,cAAWliD,GACT,OAAOzO,KAAK4wD,WACd,CACA,cAAWniD,CAAW3P,GACpBkB,KAAK4wD,YAAc9xD,CACrB,CAEA5D,WAAAA,CAAY+X,GAOV9X,MAAM8X,EAAQxE,YAnBT,KAAAQ,IAAc,EACd,KAAAgiD,mBAA6B,EAC7B,KAAAn9C,eAAyB,EAkB9BxC,EACEtR,KACA6wD,EAAO59C,EAAUxL,QAAYpJ,IAANoJ,GAE3B,EAGI,MAAOgG,EAKXvS,WAAAA,CAAY+X,GAFL,KAAAhE,IAAc,EAOnBqC,EACEtR,KACA6wD,EAAO59C,EAAUxL,QAAYpJ,IAANoJ,GAE3B,CAEApK,MAAAA,CAAO4oD,GACLA,EAAQE,MAAMnmD,KAChB,EAoDI,SAAUkxD,EAAoBtzD,GAClC,SAASuzD,EAAkB1iD,GACzB,OAAOD,EAAAA,EAAAA,GAAIC,EAAYyiD,EACzB,CAEA,GAAItzD,aAAgBgQ,EAAa,CAC/B,MAAMwjD,EAAgD,CACpDzlD,KAAM,cACN9P,KAAM+B,EAAKyzD,gBACXpiD,IAAKrR,EAAKqR,KAOZ,OAJIyhD,EAAAA,EAAAA,GAAS9yD,EAAK0iB,SAChB8wC,EAAsB9wC,MAAQ1iB,EAAK0iB,OAG9B8wC,C,CACF,GAAIxzD,aAAgBozD,EACzB,MAAyB,CACvBrlD,KAAM,cACN8C,WAAY0iD,EAAkBvzD,EAAK6Q,aAEhC,GAAI7Q,aAAgBgR,EACzB,MAAyB,CACvBjD,KAAM,SACNsD,IAAKrR,EAAKqR,IACVR,WAAY0iD,EAAkBvzD,EAAK6Q,aAEhC,GAAI7Q,aAAgB6R,EACzB,MAAyB,CACvB9D,KAAM,sBACNsD,IAAKrR,EAAKqR,IACVR,WAAY0iD,EAAkBvzD,EAAK6Q,aAEhC,GAAI7Q,aAAgBiS,EACzB,MAAyC,CACvClE,KAAM,mCACNsD,IAAKrR,EAAKqR,IACVM,UACE2hD,EAAoB,IAAIzjD,EAAS,CAAEE,aAAc/P,EAAK2R,aAExDd,WAAY0iD,EAAkBvzD,EAAK6Q,aAEhC,GAAI7Q,aAAgB0R,EACzB,MAAyC,CACvC3D,KAAM,0BACNsD,IAAKrR,EAAKqR,IACVM,UACE2hD,EAAoB,IAAIzjD,EAAS,CAAEE,aAAc/P,EAAK2R,aAExDd,WAAY0iD,EAAkBvzD,EAAK6Q,aAEhC,GAAI7Q,aAAgBsR,EACzB,MAAyB,CACvBvD,KAAM,aACNsD,IAAKrR,EAAKqR,IACVR,WAAY0iD,EAAkBvzD,EAAK6Q,aAEhC,GAAI7Q,aAAgBwQ,EACzB,MAAyB,CACvBzC,KAAM,cACNsD,IAAKrR,EAAKqR,IACVR,WAAY0iD,EAAkBvzD,EAAK6Q,aAEhC,GAAI7Q,aAAgB6P,EAAU,CACnC,MAAM6jD,EAA0C,CAC9C3lD,KAAM,WACN9P,KAAM+B,EAAK+P,aAAa9R,KACxBykB,MAAO3H,EAAW/a,EAAK+P,cACvBsB,IAAKrR,EAAKqR,MAGRyhD,EAAAA,EAAAA,GAAS9yD,EAAK0iB,SAChBgxC,EAAmBC,cAAgB3zD,EAAK0iB,OAG1C,MAAM8lC,EAAUxoD,EAAK+P,aAAa6jD,QAOlC,OANI5zD,EAAK+P,aAAa6jD,UACpBF,EAAmBlL,QAAUmK,EAASnK,GAC5BA,EAAS78C,OACf68C,GAGCkL,C,CACF,GAAI1zD,aAAgBkzD,EACzB,MAA4B,CAC1BnlD,KAAM,OACN9P,KAAM+B,EAAK/B,KACXk1D,QAASnzD,EAAKmzD,QACdtiD,WAAY0iD,EAAkBvzD,EAAK6Q,aAIrC,MAAM/N,MAAM,uBAEhB,CCjZM,MAAgB+wD,EACbtL,KAAAA,CAAMvoD,GACX,MAAM8zD,EAAe9zD,EACrB,OAAQ8zD,EAAQx2D,aACd,KAAK0S,EACH,OAAO5N,KAAK2xD,iBAAiBD,GAC/B,KAAKV,EACH,OAAOhxD,KAAK4xD,iBAAiBF,GAC/B,KAAK9iD,EACH,OAAO5O,KAAK6xD,YAAYH,GAC1B,KAAKjiD,EACH,OAAOzP,KAAK8xD,yBAAyBJ,GACvC,KAAK7hD,EACH,OAAO7P,KAAK+xD,sCAAsCL,GACpD,KAAKpiD,EACH,OAAOtP,KAAKgyD,6BAA6BN,GAC3C,KAAKxiD,EACH,OAAOlP,KAAKiyD,gBAAgBP,GAC9B,KAAKtjD,EACH,OAAOpO,KAAKkyD,iBAAiBR,GAC/B,KAAKjkD,EACH,OAAOzN,KAAKmyD,cAAcT,GAC5B,KAAKZ,EACH,OAAO9wD,KAAKoyD,UAAUV,GAExB,QACE,MAAMhxD,MAAM,wBAElB,CAGOixD,gBAAAA,CAAiB/zD,GAAyB,CAG1Cg0D,gBAAAA,CAAiBh0D,GAAyB,CAG1Ci0D,WAAAA,CAAYj0D,GAAoB,CAGhCq0D,eAAAA,CAAgBr0D,GAAwB,CAGxCk0D,wBAAAA,CAAyBl0D,GAAiC,CAG1Dm0D,qCAAAA,CACLn0D,GACM,CAGDo0D,4BAAAA,CAA6Bp0D,GAAqC,CAGlEs0D,gBAAAA,CAAiBt0D,GAAyB,CAG1Cu0D,aAAAA,CAAcv0D,GAAsB,CAGpCw0D,SAAAA,CAAUx0D,GAAkB,E,yBCrDrC,QAVA,SAAkByK,EAAY0C,GAC5B,IAAI/I,EAMJ,OAJAyG,EAAAA,EAAAA,GAASJ,EAAY,SAASvJ,EAAOyJ,EAAOF,GAE1C,QADArG,EAAS+I,EAAUjM,EAAOyJ,EAAOF,GAEnC,KACSrG,CACX,E,0BC+BA,QARA,SAAcqG,EAAY0C,EAAW1B,GACnC,IAAImgB,GAAOzqB,EAAAA,EAAAA,GAAQsJ,GAAcgqD,EAAAA,EAAYC,EAI7C,OAHIjpD,IAASC,EAAAA,EAAAA,GAAejB,EAAY0C,EAAW1B,KACjD0B,OAAY1M,GAEPmrB,EAAKnhB,GAAYgK,EAAAA,EAAAA,GAAatH,EAAW,GAClD,E,eCzCIwnD,GAAYznC,KAAKC,IA6CrB,SAbA,SAAkB1iB,EAAYvJ,EAAO0zD,EAAWnpD,GAC9ChB,GAAaG,EAAAA,EAAAA,GAAYH,GAAcA,GAAa0P,EAAAA,EAAAA,GAAO1P,GAC3DmqD,EAAaA,IAAcnpD,GAASwmD,EAAAA,EAAAA,GAAU2C,GAAa,EAE3D,IAAIv2D,EAASoM,EAAWpM,OAIxB,OAHIu2D,EAAY,IACdA,EAAYD,GAAUt2D,EAASu2D,EAAW,KAErC9B,EAAAA,EAAAA,GAASroD,GACXmqD,GAAav2D,GAAUoM,EAAW5C,QAAQ3G,EAAO0zD,IAAc,IAC7Dv2D,IAAUw2D,EAAAA,GAAAA,GAAYpqD,EAAYvJ,EAAO0zD,IAAc,CAChE,EC5BA,SAZA,SAAoBnwD,EAAO0I,GAIzB,IAHA,IAAIxC,GAAS,EACTtM,EAAkB,MAAToG,EAAgB,EAAIA,EAAMpG,SAE9BsM,EAAQtM,GACf,IAAK8O,EAAU1I,EAAMkG,GAAQA,EAAOlG,GAClC,OAAO,EAGX,OAAO,CACT,ECAA,SATA,SAAmBgG,EAAY0C,GAC7B,IAAI/I,GAAS,EAKb,OAJAyG,EAAAA,EAAAA,GAASJ,EAAY,SAASvJ,EAAOyJ,EAAOF,GAE1C,OADArG,IAAW+I,EAAUjM,EAAOyJ,EAAOF,EAErC,GACOrG,CACT,ECqCA,SARA,SAAeqG,EAAY0C,EAAW1B,GACpC,IAAImgB,GAAOzqB,EAAAA,EAAAA,GAAQsJ,GAAcqqD,GAAaC,GAI9C,OAHItpD,IAASC,EAAAA,EAAAA,GAAejB,EAAY0C,EAAW1B,KACjD0B,OAAY1M,GAEPmrB,EAAKnhB,GAAYgK,EAAAA,EAAAA,GAAatH,EAAW,GAClD,ECtBM,SAAU6nD,GACd/5C,GACkC,IAAlCg6C,EAAAz0D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAgC,GAMhC,SAHEya,aAAgBjK,GAChBiK,aAAgB3J,GAChB2J,aAAgBvJ,KAQduJ,aAAgBzK,EAEXghC,EAAmBv2B,EAAMpK,WAAaqkD,GACpCF,GAAeE,EAASD,MAExBh6C,aAAgBjL,GAAe0gC,GAASukB,EAAgBh6C,MAGxDA,aAAgB83C,IACrB93C,aAAgBjL,GAClBilD,EAAe1yD,KAAK0Y,GAEfwK,GACgBxK,EAAMpK,WAC1BqkD,GACQF,GAAeE,EAASD,MAMvC,CAQM,SAAU/5C,GAAqBD,GAEnC,GAAIA,aAAgBjL,EAClB,MAAO,UACF,GAAIiL,aAAgBjK,EACzB,MAAO,SACF,GAAIiK,aAAgBzK,EACzB,MAAO,KACF,GAAIyK,aAAgBpJ,EACzB,MAAO,eACF,GAAIoJ,aAAgBhJ,EACzB,MAAO,mBACF,GAAIgJ,aAAgBvJ,EACzB,MAAO,WACF,GAAIuJ,aAAgB3J,EACzB,MAAO,OACF,GAAI2J,aAAgBpL,EACzB,MAAO,UAGP,MAAM/M,MAAM,uBAEhB,CChFM,MAAgBqyD,GACpBC,IAAAA,CAAKn6C,GAAyD,IAApBo6C,EAAA70D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAkB,IAC1DqW,EAAAA,EAAAA,GAAQoE,EAAKpK,WAAY,CAACqkD,EAAsBvqD,KAC9C,MAAM2qD,EAAWC,EAAKt6C,EAAKpK,WAAYlG,EAAQ,GAE/C,GAAIuqD,aAAmBllD,EACrB5N,KAAKozD,YAAYN,EAASI,EAAUD,QAC/B,GAAIH,aAAmBrlD,EAC5BzN,KAAKqzD,aAAaP,EAASI,EAAUD,QAChC,GAAIH,aAAmB9B,EAC5BhxD,KAAKszD,SAASR,EAASI,EAAUD,QAC5B,GAAIH,aAAmBlkD,EAC5B5O,KAAKuzD,WAAWT,EAASI,EAAUD,QAC9B,GAAIH,aAAmBrjD,EAC5BzP,KAAKwzD,eAAeV,EAASI,EAAUD,QAClC,GAAIH,aAAmBjjD,EAC5B7P,KAAKyzD,kBAAkBX,EAASI,EAAUD,QACrC,GAAIH,aAAmBxjD,EAC5BtP,KAAK0zD,YAAYZ,EAASI,EAAUD,QAC/B,GAAIH,aAAmB5jD,EAC5BlP,KAAK2zD,SAASb,EAASI,EAAUD,OAC5B,MAAIH,aAAmB1kD,GAG5B,MAAM1N,MAAM,wBAFZV,KAAK4zD,OAAOd,EAASI,EAAUD,E,GAKrC,CAEAI,YAAAA,CACEl/B,EACA++B,EACAD,GACO,CAETG,WAAAA,CACES,EACAX,EACAD,GACO,CAETK,QAAAA,CACEQ,EACAZ,EACAD,GAGA,MAAMc,EAAab,EAASvtD,OAAOstD,GACnCjzD,KAAKgzD,KAAKc,EAAeC,EAC3B,CAEAR,UAAAA,CACES,EACAd,EACAD,GAGA,MAAMc,EAAab,EAASvtD,OAAOstD,GACnCjzD,KAAKgzD,KAAKgB,EAAiBD,EAC7B,CAEAP,cAAAA,CACES,EACAf,EACAD,GAGA,MAAMiB,EAAoC,CACxC,IAAItlD,EAAO,CAAEH,WAAYwlD,EAAexlD,cACxC9I,OAAYutD,EAAeD,GAC7BjzD,KAAKgzD,KAAKiB,EAAgBC,EAC5B,CAEAT,iBAAAA,CACEU,EACAjB,EACAD,GAGA,MAAMmB,EAAwBC,GAC5BF,EACAjB,EACAD,GAEFjzD,KAAKgzD,KAAKmB,EAAmBC,EAC/B,CAEAT,QAAAA,CACEW,EACApB,EACAD,GAGA,MAAMsB,EAA8B,CAClC,IAAI3lD,EAAO,CAAEH,WAAY6lD,EAAS7lD,cAClC9I,OAAYutD,EAAeD,GAC7BjzD,KAAKgzD,KAAKsB,EAAUC,EACtB,CAEAb,WAAAA,CACEc,EACAtB,EACAD,GAGA,MAAMwB,EAAkBJ,GACtBG,EACAtB,EACAD,GAEFjzD,KAAKgzD,KAAKwB,EAAaC,EACzB,CAEAb,MAAAA,CACEc,EACAxB,EACAD,GAGA,MAAMc,EAAab,EAASvtD,OAAOstD,IAEnCx+C,EAAAA,EAAAA,GAAQigD,EAAOjmD,WAAa0C,IAI1B,MAAMwjD,EAAc,IAAI3D,EAAY,CAAEviD,WAAY,CAAC0C,KACnDnR,KAAKgzD,KAAK2B,EAAkBZ,IAEhC,EAGF,SAASM,GACPO,EACA1B,EACAD,GAUA,MARmB,CACjB,IAAIrkD,EAAO,CACTH,WAAY,CACV,IAAIhB,EAAS,CAAEE,aAAcinD,EAAWrlD,aACxC5J,OAAOivD,EAAWnmD,eAGyB9I,OAAOutD,EAAUD,EAEpE,C,gBC1IA,SAJA,SAAc5wD,GACZ,OAAQA,GAASA,EAAMpG,QAAUmW,EAAAA,GAAAA,GAAS/P,GAAS,EACrD,E,gBCZM,SAAUmO,GAAMqI,GAEpB,GAAIA,aAAgBjL,EASlB,OAAO4C,GAAoBqI,EAAM9K,gBAC5B,GAAI8K,aAAgBpL,EACzB,MA6CK,CA7C6BoL,EA6CnBlL,cA5CV,GHRH,SACJkL,GAEA,OACEA,aAAgBm4C,GAChBn4C,aAAgBjK,GAChBiK,aAAgB3J,GAChB2J,aAAgBpJ,GAChBoJ,aAAgBhJ,GAChBgJ,aAAgBvJ,GAChBuJ,aAAgBpL,GAChBoL,aAAgBi4C,CAEpB,CGLa+D,CAAeh8C,GACxB,OAQE,SAA2BA,GAG/B,IAAIi8C,EAAwB,GAC5B,MAAMC,EAAMl8C,EAAKpK,WACjB,IAEIumD,EAFAC,EAAiB,EACjBC,EAAyBH,EAAI94D,OAASg5D,EAGtCE,GAA0B,EAE9B,KAAOD,GAA0BC,GAC/BH,EAAcD,EAAIE,GAClBE,EAA0BvC,GAAeoC,GACzCF,EAAWA,EAASnvD,OAAO6K,GAAMwkD,IACjCC,GAAkC,EAClCC,EAAyBH,EAAI94D,OAASg5D,EAGxC,OAAOG,GAAKN,EACd,CA5BWO,CAAiBx8C,GACnB,GH2CH,SACJA,GAEA,OAAOA,aAAgBzK,CACzB,CG/CaknD,CAAgBz8C,GACzB,OA4BE,SAA4BA,GAGhC,MAAM08C,GAAuC/mD,EAAAA,EAAAA,GAC3CqK,EAAKpK,WACJ+mD,GACQhlD,GAAMglD,IAGjB,OAAOJ,IAAK7/C,EAAAA,GAAAA,GAAmBggD,GACjC,CAtCWE,CAAkB58C,GAEzB,MAAMnY,MAAM,uBAEhB,CC9BO,MAAMg1D,GAAK,SCQZ,MAAOC,WAA4B5C,GAGvC73D,WAAAA,CAAoB06D,GAClBz6D,QADkB,KAAAy6D,QAAAA,EAFb,KAAAC,QAAuC,CAAC,CAI/C,CAEAC,YAAAA,GAEE,OADA91D,KAAKgzD,KAAKhzD,KAAK41D,SACR51D,KAAK61D,OACd,CAEAxC,YAAAA,CACEl/B,EACA++B,EACAD,GAEA,CAGFG,WAAAA,CACES,EACAX,EACAD,GAEA,MAAM8C,GAuBRC,EAtBkCnC,EAAQ9lD,eAuB1CkoD,EAvB0DpC,EAAQ5kD,IAyB3D+mD,EAAMn6D,KAAOo6D,EAAoBP,GAxBpC11D,KAAK41D,QAAQ/5D,MAoBb,IACJm6D,EACAC,EArBE,MAAMC,EAA0BhD,EAASvtD,OAAOstD,GAE1CkD,EAAuB3lD,GADZ,IAAIwgD,EAAY,CAAEviD,WAAYynD,KAE/Cl2D,KAAK61D,QAAQE,GAAcI,CAC7B,E,gECFF,SAhBA,SAAgBprD,GACd,GAAwB,mBAAbA,EACT,MAAM,IAAIrI,UAxBQ,uBA0BpB,OAAO,WACL,IAAIzB,EAAO7C,UACX,OAAQ6C,EAAKhF,QACX,KAAK,EAAG,OAAQ8O,EAAU3I,KAAKpC,MAC/B,KAAK,EAAG,OAAQ+K,EAAU3I,KAAKpC,KAAMiB,EAAK,IAC1C,KAAK,EAAG,OAAQ8J,EAAU3I,KAAKpC,KAAMiB,EAAK,GAAIA,EAAK,IACnD,KAAK,EAAG,OAAQ8J,EAAU3I,KAAKpC,KAAMiB,EAAK,GAAIA,EAAK,GAAIA,EAAK,IAE9D,OAAQ8J,EAAU5J,MAAMnB,KAAMiB,EAChC,CACF,ECQA,SALA,SAAgBoH,EAAY0C,GAE1B,QADWhM,EAAAA,EAAAA,GAAQsJ,GAAc+tD,GAAAA,EAAcC,GAAAA,GACnChuD,EAAYiuD,IAAOjkD,EAAAA,EAAAA,GAAatH,EAAW,IACzD,E,gBCvCIwnD,GAAYznC,KAAKC,IAqCrB,SAZA,SAAiB1oB,EAAOvD,EAAO0zD,GAC7B,IAAIv2D,EAAkB,MAAToG,EAAgB,EAAIA,EAAMpG,OACvC,IAAKA,EACH,OAAQ,EAEV,IAAIsM,EAAqB,MAAbiqD,EAAoB,GAAI3C,EAAAA,EAAAA,GAAU2C,GAI9C,OAHIjqD,EAAQ,IACVA,EAAQgqD,GAAUt2D,EAASsM,EAAO,KAE7BkqD,EAAAA,GAAAA,GAAYpwD,EAAOvD,EAAOyJ,EACnC,E,2EC2BA,SA7CA,SAAwBlG,EAAO0V,EAAQzP,EAAUiuD,GAC/C,IAAIhuD,GAAS,EACT+lC,EAAWkoB,GAAAA,EACXC,GAAW,EACXx6D,EAASoG,EAAMpG,OACf+F,EAAS,GACT00D,EAAe3+C,EAAO9b,OAE1B,IAAKA,EACH,OAAO+F,EAELsG,IACFyP,GAASm4C,EAAAA,EAAAA,GAASn4C,GAAQy4C,EAAAA,EAAAA,GAAUloD,KAElCiuD,GACFjoB,EAAWqoB,GAAAA,EACXF,GAAW,GAEJ1+C,EAAO9b,QA/BK,MAgCnBqyC,EAAWsoB,GAAAA,EACXH,GAAW,EACX1+C,EAAS,IAAI8+C,GAAAA,EAAS9+C,IAExB++C,EACA,OAASvuD,EAAQtM,GAAQ,CACvB,IAAI6C,EAAQuD,EAAMkG,GACdwuD,EAAuB,MAAZzuD,EAAmBxJ,EAAQwJ,EAASxJ,GAGnD,GADAA,EAASy3D,GAAwB,IAAVz3D,EAAeA,EAAQ,EAC1C23D,GAAYM,IAAaA,EAAU,CAErC,IADA,IAAIC,EAAcN,EACXM,KACL,GAAIj/C,EAAOi/C,KAAiBD,EAC1B,SAASD,EAGb90D,EAAO7B,KAAKrB,EACd,MACUwvC,EAASv2B,EAAQg/C,EAAUR,IACnCv0D,EAAO7B,KAAKrB,EAEhB,CACA,OAAOkD,CACT,E,sCChCA,UANiBmH,EAAAA,GAAAA,GAAS,SAAS9G,EAAO0V,GACxC,OAAOk/C,EAAAA,GAAAA,GAAkB50D,GACrB60D,GAAe70D,GAAOwH,EAAAA,GAAAA,GAAYkO,EAAQ,EAAGk/C,GAAAA,GAAmB,IAChE,EACN,GCAA,SAfA,SAAiB50D,GAMf,IALA,IAAIkG,GAAS,EACTtM,EAAkB,MAAToG,EAAgB,EAAIA,EAAMpG,OACnCk7D,EAAW,EACXn1D,EAAS,KAEJuG,EAAQtM,GAAQ,CACvB,IAAI6C,EAAQuD,EAAMkG,GACdzJ,IACFkD,EAAOm1D,KAAcr4D,EAEzB,CACA,OAAOkD,CACT,ECNA,SAJA,SAAcK,GACZ,OAAQA,GAASA,EAAMpG,OAAUoG,EAAM,QAAKhE,CAC9C,E,gBCpBM,SAAU+4D,GAAYC,GAEtB/1D,SAAWA,QAAQC,OACrBD,QAAQC,MAAM,UAADoE,OAAW0xD,GAE5B,CAEM,SAAUC,GAAcD,GAExB/1D,SAAWA,QAAQ4hC,MAErB5hC,QAAQ4hC,KAAK,YAADv9B,OAAa0xD,GAE7B,CCJA,IAAIE,GAAqD,CAAC,EAC1D,MAAMC,GAAe,IAAIzS,GAAAA,EAUnB,SAAU0S,GAAaC,GAC3B,MAAMC,EAAYD,EAAOtxD,WACzB,GAAImxD,GAAepyD,eAAewyD,GAChC,OAAOJ,GAAeI,GACjB,CACL,MAAMC,EAAYJ,GAAapR,QAAQuR,GAEvC,OADAJ,GAAeI,GAAaC,EACrBA,C,CAEX,CCfA,MAAMC,GACJ,gEACWC,GACX,oDAEI,SAAUC,GACdL,GAC2B,IAA3BM,EAAmB55D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAEnB,IACE,MAAM65D,EAAMR,GAAaC,GAMzB,OALmBQ,GACjBD,EAAIn5D,MACJ,CAAC,EACDm5D,EAAI/Q,MAAMiR,W,CAGZ,MAAO/2D,GAIP,GAAIA,EAAE+J,UAAY0sD,GACZG,GACFV,GACE,GAAA3xD,OAAGmyD,IAA2B,2BAAAnyD,OACD+xD,EAAOtxD,WAAU,QAD9C,oNAOC,CACL,IAAIgyD,EAAY,GACZJ,IACFI,EACE,gKAGJhB,GACE,GAAAzxD,OAAGmyD,GAA2B,6BAAAnyD,OACL+xD,EAAOtxD,WAAU,QAD1C,4HAIEgyD,E,EAKR,MAAO,EACT,CAEM,SAAUF,GACdD,EACAj2D,EACAm2D,GAEA,OAAQF,EAAItsD,MACV,IAAK,cACH,IAAK,IAAIpL,EAAI,EAAGA,EAAI03D,EAAIn5D,MAAM7C,OAAQsE,IACpC23D,GAA0BD,EAAIn5D,MAAMyB,GAAIyB,EAAQm2D,GAElD,MACF,IAAK,cACH,MAAME,EAAQJ,EAAIn5D,MAClB,IAAK,IAAIyB,EAAI,EAAGA,EAAI83D,EAAMp8D,OAAQsE,IAAK,CACrC,MAAM+3D,EAAOD,EAAM93D,GAGnB,OAAQ+3D,EAAK3sD,MACX,IAAK,YAIL,IAAK,qBAEL,IAAK,YACL,IAAK,oBACL,IAAK,cACL,IAAK,eACL,IAAK,kBACH,SAGJ,MAAM4B,EAAO+qD,EACb,OAAQ/qD,EAAK5B,MACX,IAAK,YACH4sD,GAAwBhrD,EAAKzO,MAAOkD,EAAQm2D,GAC5C,MACF,IAAK,MACH,IAAwB,IAApB5qD,EAAKirD,WACP,MAAM93D,MAAMm3D,KAEdpjD,EAAAA,EAAAA,GAAQlH,EAAKzO,MAAQ8iB,IACnB,GAAoB,kBAATA,EACT22C,GAAwB32C,EAAM5f,EAAQm2D,OACjC,CAEL,MAAM/sD,EAAQwW,EAEd,IAAmB,IAAfu2C,EACF,IACE,IAAIM,EAAYrtD,EAAM3E,KACtBgyD,GAAartD,EAAMuO,GACnB8+C,IAEAF,GAAwBE,EAAWz2D,EAAQm2D,OAI1C,CAEH,IACE,IAAIM,EAAYrtD,EAAM3E,KACtBgyD,GAAartD,EAAMuO,IAAM8+C,EAAYC,GACrCD,IAEAF,GAAwBE,EAAWz2D,EAAQm2D,GAI7C,GAAI/sD,EAAMuO,IAAM++C,GAAoB,CAClC,MAAMC,EACJvtD,EAAM3E,MAAQiyD,GACVttD,EAAM3E,KACNiyD,GACAE,EAAcxtD,EAAMuO,GACpBk/C,EAAYC,GAAyBH,GACrCI,EAAYD,GAAyBF,GAE3C,IACE,IAAII,EAAaH,EACjBG,GAAcD,EACdC,IAEAh3D,EAAOg3D,GAAcA,C,MAM/B,MACF,IAAK,QACHd,GAA0B3qD,EAAKzO,MAAOkD,EAAQm2D,GAC9C,MAEF,QACE,MAAMz3D,MAAM,wBAIhB,MAAMu4D,OACgB56D,IAApBkP,EAAKm4C,YAAwD,IAA5Bn4C,EAAKm4C,WAAWwT,QACnD,GAGiB,UAAd3rD,EAAK5B,OAA8C,IAA1BwtD,GAAgB5rD,IAE3B,UAAdA,EAAK5B,OAA6C,IAAzBstD,EAE1B,K,CAGJ,MAEF,QACE,MAAMv4D,MAAM,yBAIhB,OAAOqX,EAAAA,EAAAA,GAAO/V,EAChB,CAEA,SAASu2D,GACP32C,EACA5f,EACAm2D,GAEA,MAAMiB,EAAmBN,GAAyBl3C,GAClD5f,EAAOo3D,GAAoBA,GAER,IAAfjB,GAKN,SACEv2C,EACA5f,GAEA,MAAMw7B,EAAOj2B,OAAOC,aAAaoa,GAC3By3C,EAAY77B,EAAKkpB,cAEvB,GAAI2S,IAAc77B,EAAM,CACtB,MAAM47B,EAAmBN,GAAyBO,EAAUn2D,WAAW,IACvElB,EAAOo3D,GAAoBA,C,KACtB,CACL,MAAME,EAAY97B,EAAKl2B,cACvB,GAAIgyD,IAAc97B,EAAM,CACtB,MAAM47B,EAAmBN,GACvBQ,EAAUp2D,WAAW,IAEvBlB,EAAOo3D,GAAoBA,C,EAGjC,CAvBIG,CAAiB33C,EAAM5f,EAE3B,CAuBA,SAASw3D,GAASC,EAAcC,GAC9B,OAAOjyB,EAAAA,GAAAA,GAAKgyB,EAAQ36D,MAAQ66D,IAC1B,GAA2B,kBAAhBA,EACT,OAAOrrB,GAASorB,EAAiBC,GAC5B,CAEL,MAAMvuD,EAAauuD,EACnB,YAIQt7D,KAHNopC,EAAAA,GAAAA,GACEiyB,EACCE,GAAexuD,EAAM3E,MAAQmzD,GAAcA,GAAcxuD,EAAMuO,G,GAK1E,CAEA,SAASw/C,GAAgBlB,GACvB,MAAMvS,EAAcuS,EAAavS,WACjC,SAAIA,GAAqC,IAAvBA,EAAWwT,YAIxBjB,EAAIn5D,SAIFC,EAAAA,EAAAA,GAAQk5D,EAAIn5D,OACfukB,GAAM40C,EAAIn5D,MAAOq6D,IACjBA,GAAgBlB,EAAIn5D,OAC1B,CAEA,MAAM+6D,WAAuB5U,GAAAA,EAG3B/pD,WAAAA,CAAoBw+D,GAClBv+D,QADkB,KAAAu+D,gBAAAA,EAFpB,KAAAI,OAAiB,CAIjB,CAEA9T,aAAAA,CAAcpoD,GAEZ,IAAmB,IAAfoC,KAAK85D,MAAT,CAMA,OAAQl8D,EAAK+N,MACX,IAAK,YAEH,YADA3L,KAAK+5D,eAAen8D,GAEtB,IAAK,oBAEH,YADAoC,KAAKg6D,uBAAuBp8D,GAIhCzC,MAAM6qD,cAAcpoD,E,CACtB,CAEA+nD,cAAAA,CAAe/nD,GACT0wC,GAAStuC,KAAK05D,gBAAiB97D,EAAKkB,SACtCkB,KAAK85D,OAAQ,EAEjB,CAEAjU,QAAAA,CAASjoD,GACHA,EAAK46D,gBACsCn6D,IAAzCm7D,GAAS57D,EAAMoC,KAAK05D,mBACtB15D,KAAK85D,OAAQ,QAG8Bz7D,IAAzCm7D,GAAS57D,EAAMoC,KAAK05D,mBACtB15D,KAAK85D,OAAQ,EAGnB,EAGI,SAAUG,GACdC,EACA9T,GAEA,GAAIA,aAAmB/H,OAAQ,CAC7B,MAAM4Z,EAAMR,GAAarR,GACnB+T,EAAiB,IAAIN,GAAeK,GAE1C,OADAC,EAAehU,MAAM8R,GACdkC,EAAeL,K,CAEtB,YAGSz7D,KAFPopC,EAAAA,GAAAA,GAAU2e,EAAU5oB,GACX8Q,GAAS4rB,EAAoB18B,EAAMt6B,WAAW,IAI7D,CC7QA,MAAMsuD,GAAU,UACH4I,GAAe,cACfC,GAAQ,QAuBd,IAAIC,GACmC,mBAA/B,IAAIjc,OAAO,QAASkc,OAU7B,SAAUC,GACdjgB,EACAtnC,GAmBA,MAAMwnD,GATNxnD,GAAUynD,EAAAA,GAAAA,GAASznD,EAAS,CAC1B0nD,UAAWL,GACXM,OAAO,EACPC,UAAU,EACVhgB,iBAAkB,OAClBigB,yBAA0B,CAAC,KAAM,MACjCL,OAAQA,CAACpD,EAAazjC,IAAqBA,OAGtB6mC,OAMvB,IAAIM,EAJJN,EAAO,kCAAmC,MAuiC5C,WACE,IAAIj5D,EAAAA,EAAAA,GAAQw5D,IAA4B,CACtCA,GAA4B,IAAI56D,MAAM,OACtC,IAAK,IAAIG,EAAI,EAAGA,EAAI,MAAOA,IACzBy6D,GAA0Bz6D,GAAKA,EAAI,IAAM,OAASA,EAAI,KAAOA,C,CAGnE,CA7iCI06D,KAIFR,EAAO,kBAAmB,KACxBM,EAAoBn+B,GAAO2d,EAAa2gB,GAC/BA,EAAS1J,MAAatiC,GAAMisC,MAIvC,IACIC,EAmFAC,EACAC,EACAC,EACAC,EACAC,EA0CAC,EAuBAC,EACAC,EACAC,EACAC,EA5JAC,GAAY,EAEhBtB,EAAO,qBAAsB,KAC3BsB,GAAY,EACZX,GAAyB5sD,EAAAA,EAAAA,GACvBusD,EACCG,IACC,MAAMc,EAAcd,EAAS1J,IAG7B,GAAIjB,EAASyL,GAAc,CACzB,MAAMC,EAAeD,EAAYzyD,OACjC,OAC0B,IAAxB0yD,EAAahgE,QAEI,MAAjBggE,GACiB,MAAjBA,GACiB,MAAjBA,GACCD,EAAY7D,WAIW,IAAxB8D,EAAahgE,QACO,OAApBggE,EAAa,IAEZ3tB,GACC,CACE,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,KAEF2tB,EAAa,IAQRhpD,EAAQ0nD,UACXuB,GAAcF,GACdG,GAAgBH,GAJbC,EAAa,GA9BbA,C,CAoCJ,IAAIG,EAAAA,GAAAA,GAAWJ,GAGpB,OAFAD,GAAY,EAEL,CAAE5/D,KAAM6/D,GACV,GAA2B,kBAAhBA,EAGhB,OAFAD,GAAY,EAELC,EACF,GAA2B,kBAAhBA,EAA0B,CAC1C,GAA2B,IAAvBA,EAAY//D,OACd,OAAO+/D,EACF,CACL,MAAMK,EAAsBL,EAAYjgE,QACtC,sBACA,QAEIugE,EAAgB,IAAIje,OAAOge,GACjC,OAAOppD,EAAQ0nD,UACXuB,GAAcI,GACdH,GAAgBG,E,EAGtB,MAAM57D,MAAM,4BAWpB+5D,EAAO,eAAgB,KACrBY,GAAmB7sD,EAAAA,EAAAA,GACjBusD,EACCG,GAAaA,EAASvmD,cAGzB2mD,GAAoB9sD,EAAAA,EAAAA,GAAIusD,EAAoBwB,IAC1C,MAAMC,EAAYD,EAAME,MAExB,GAAID,IAActtC,GAAMwtC,QAAxB,CAEO,IAAIhM,EAAAA,EAAAA,GAAS8L,GAClB,OAAOA,EACF,IAAIG,EAAAA,GAAAA,GAAYH,GACrB,OAAO,EAEP,MAAM97D,MAAM,uB,IAIhB66D,GAA8B/sD,EAAAA,EAAAA,GAAIusD,EAAoBwB,IACpD,MAAMK,EAAgBL,EAAMM,WAE5B,GAAID,EAAe,CAIjB,OAHwB79D,EAAAA,EAAAA,GAAQ69D,IAC5BpuD,EAAAA,EAAAA,GAAIouD,EAAgBjxD,GAAclG,GAAQs1D,EAAmBpvD,IAC7D,CAAClG,GAAQs1D,EAAmB6B,G,IAKpCpB,GAAuBhtD,EAAAA,EAAAA,GACrBusD,EACCwB,GAAeA,EAAMO,WAGxBrB,GAAsBjtD,EAAAA,EAAAA,GAAIusD,EAAoBwB,IAC5CvmD,EAAAA,EAAAA,GAAIumD,EAAO,eAKf9B,EAAO,2BAA4B,KACjC,MAAMsC,EAA0BC,GAC9B/pD,EAAQ6nD,0BAEVY,GAAgCltD,EAAAA,EAAAA,GAAIusD,EAAoBjlD,IAAY,GACnC,eAA7B7C,EAAQ4nC,mBACV6gB,GAAgCltD,EAAAA,EAAAA,GAAIusD,EAAoBjlD,IAClDE,EAAAA,EAAAA,GAAIF,EAAS,iBACNA,EAAQmnD,aAG6C,IAA5DC,GAAsBpnD,EAASinD,IAC/B9C,GACE8C,EACAjnD,EAAQ07C,aAYpBiJ,EAAO,kBAAmB,KACxBkB,GAAuBntD,EAAAA,EAAAA,GAAIusD,EAAmBoC,IAC9CvB,GAAoBptD,EAAAA,EAAAA,GAAI4sD,EAAwBgC,IAEhDvB,GAAcrnD,EAAAA,GAAAA,GACZumD,EACA,CAACsC,EAAKd,KACJ,MAAMC,EAAYD,EAAME,MAIxB,OAHI/L,EAAAA,EAAAA,GAAS8L,IAAgBA,IAActtC,GAAMwtC,UAC/CW,EAAIb,GAAa,IAEZa,GAET,CAAC,GAGHvB,GAAqBttD,EAAAA,EAAAA,GACnB4sD,EACA,CAACrzD,EAAGkH,KACK,CACLm3C,QAASgV,EAAuBnsD,GAChCquD,UAAW/B,EAA4BtsD,GACvCsuD,kBAAmB7B,EAA8BzsD,GACjDuuD,SAAU7B,EAAqB1sD,GAC/BwuD,MAAO7B,EAAkB3sD,GACzBsqB,MAAO+hC,EAAkBrsD,GACzB9O,KAAMq7D,EAAqBvsD,GAC3B8K,IAAK0hD,EAAoBxsD,GACzB0F,aAAc0mD,EAAiBpsD,GAC/BhD,UAAW8uD,EAAkB9rD,QAMrC,IAAIyuD,GAAiB,EACjBC,EACF,GAiFF,OA/EK1qD,EAAQ4nD,UACXJ,EAAO,0BAA2B,KAChCkD,GAA+BnpD,EAAAA,GAAAA,GAC7BumD,EACA,CAAC/4D,EAAQ0S,EAAazF,KACpB,GAAmC,kBAAxByF,EAAY88C,QAAsB,CAC3C,MACMoM,EAAe9E,GADJpkD,EAAY88C,QAAQtuD,WAAW,IAEhD26D,GAAiB77D,EAAQ47D,EAAc9B,EAAmB7sD,G,MACrD,IAAIlQ,EAAAA,EAAAA,GAAQ2V,EAAYopD,kBAAmB,CAChD,IAAIC,GACJtpD,EAAAA,EAAAA,GAAQC,EAAYopD,iBAAmBE,IACrC,MAIMC,EAAmBnF,GAHF,kBAAdkF,EACHA,EAAU96D,WAAW,GACrB86D,GAMFD,IAAqBE,IACvBF,EAAmBE,EACnBJ,GACE77D,EACAi8D,EACAnC,EAAmB7sD,M,MAIpB,GAAIshD,EAAS77C,EAAY88C,SAC9B,GAAI98C,EAAY88C,QAAQvK,QACtByW,GAAiB,EACbzqD,EAAQ+kD,qBACVZ,GACE,GAAAzxD,OAAGmyD,IAA2B,yBAAAnyD,OACH+O,EAAY88C,QAAQprD,WAAU,iBADzD,uPAOC,CACL,MAAM83D,EAAiBnG,GACrBrjD,EAAY88C,QACZv+C,EAAQ+kD,sBAKNx2D,EAAAA,EAAAA,GAAQ08D,KAIVR,GAAiB,IAEnBjpD,EAAAA,EAAAA,GAAQypD,EAAiBt8C,IACvBi8C,GAAiB77D,EAAQ4f,EAAMk6C,EAAmB7sD,K,MAIlDgE,EAAQ+kD,qBACVZ,GACE,GAAAzxD,OAAGmyD,IAA2B,iBAAAnyD,OACX+O,EAAY7Y,KAAI,uFADnC,8JAMJ6hE,GAAiB,EAGnB,OAAO17D,GAET,MAKC,CACL65D,YAAaA,EACbC,mBAAoBA,EACpB6B,6BAA8BA,EAC9B5B,UAAWA,EACX2B,eAAgBA,EAEpB,CAEM,SAAUS,GACd5jB,EACA6jB,GAEA,IAAIpsC,EAAkC,GAEtC,MAAMqsC,EA8CF,SACJ9jB,GAEA,MAAM+jB,GAA+BtuD,EAAAA,GAAAA,GAAOuqC,EAAa2gB,KAC/CllD,EAAAA,EAAAA,GAAIklD,EAAU1J,KAGlBx/B,GAASxjB,EAAAA,EAAAA,GAAI8vD,EAA+BpD,IACzC,CACL/vD,QACE,iBACA+vD,EAASr/D,KACT,uCACF8P,KAAM4yD,GAAyBC,gBAC/BjkB,WAAY,CAAC2gB,MAIXuD,EAAQC,GAAWnkB,EAAY+jB,GACrC,MAAO,CAAEtsC,SAAQysC,QACnB,CAlEwBE,CAAoBpkB,GAC1CvoB,EAASA,EAAOrsB,OAAO04D,EAAcrsC,QAErC,MAAM4sC,EAiEF,SACJrkB,GAEA,MAAMskB,GAA+B7uD,EAAAA,GAAAA,GAAOuqC,EAAa2gB,IACvD,MAAM9U,EAAU8U,EAAS1J,IACzB,OACGjB,EAASnK,MACTgW,EAAAA,GAAAA,GAAWhW,MACXpwC,EAAAA,EAAAA,GAAIowC,EAAS,WACbsK,EAAAA,EAAAA,GAAStK,KAIRp0B,GAASxjB,EAAAA,EAAAA,GAAIqwD,EAA+B3D,IACzC,CACL/vD,QACE,iBACA+vD,EAASr/D,KADT,0JAIF8P,KAAM4yD,GAAyBO,gBAC/BvkB,WAAY,CAAC2gB,MAIXuD,EAAQC,GAAWnkB,EAAYskB,GACrC,MAAO,CAAE7sC,SAAQysC,QACnB,CA5FwBM,CAAoBV,EAAcI,OAClDO,EAAkBJ,EAAcH,MAatC,OAZAzsC,EAASA,EAAOrsB,OAAOi5D,EAAc5sC,QAErCA,EAASA,EAAOrsB,OAalB,SACE40C,GAEA,IAAIvoB,EAAkC,GACtC,MAAMitC,GAAqBjvD,EAAAA,GAAAA,GAAOuqC,EAAa7lC,GAC7C67C,EAAS77C,EAAY88C,MAavB,OAVAx/B,EAASA,EAAOrsB,OAuEZ,SACJ40C,GAEA,MAAM2kB,UAAwBja,GAAAA,EAA9B/pD,WAAAA,G,oBACE,KAAA4+D,OAAQ,CAKV,CAHEqF,cAAAA,CAAevhE,GACboC,KAAK85D,OAAQ,CACf,EAGF,MAAMsF,GAAepvD,EAAAA,GAAAA,GAAOuqC,EAAa2gB,IACvC,MAAM9U,EAAU8U,EAAS1J,QAEzB,IACE,MAAM6N,EAAY5H,GAAarR,GACzBkZ,EAAmB,IAAIJ,EAG7B,OAFAI,EAAiBnZ,MAAMkZ,GAEhBC,EAAiBxF,K,CACxB,MAAO14D,GAGP,OAAOm+D,GAAav5D,KAAMogD,EAAmB78C,O,IAI3CyoB,GAASxjB,EAAAA,EAAAA,GAAI4wD,EAAelE,IACzB,CACL/vD,QACE,oDAEA+vD,EAASr/D,KAFT,+IAMF8P,KAAM4yD,GAAyBiB,iBAC/BjlB,WAAY,CAAC2gB,MAIjB,OAAOlpC,CACT,CAjHyBytC,CAAqBR,IAE5CjtC,EAASA,EAAOrsB,OAyIZ,SACJ40C,GAEA,MAAMmlB,UAA0Bza,GAAAA,EAAhC/pD,WAAAA,G,oBACE,KAAA4+D,OAAQ,CAKV,CAHE6F,gBAAAA,CAAiB/hE,GACfoC,KAAK85D,OAAQ,CACf,EAGF,MAAMsF,GAAepvD,EAAAA,GAAAA,GAAOuqC,EAAa2gB,IACvC,MAAM9U,EAAU8U,EAAS1J,QACzB,IACE,MAAM6N,EAAY5H,GAAarR,GACzBwZ,EAAqB,IAAIF,EAG/B,OAFAE,EAAmBzZ,MAAMkZ,GAElBO,EAAmB9F,K,CAC1B,MAAO14D,GAGP,OAAOy+D,GAAe75D,KAAKogD,EAAQ78C,O,IAIjCyoB,GAASxjB,EAAAA,EAAAA,GAAI4wD,EAAelE,IACzB,CACL/vD,QACE,oDAEA+vD,EAASr/D,KAFT,yJAMF8P,KAAM4yD,GAAyBuB,iBAC/BvlB,WAAY,CAAC2gB,MAIjB,OAAOlpC,CACT,CAlLyB+tC,CAAuBd,IAE9CjtC,EAASA,EAAOrsB,OAkLZ,SACJ40C,GAEA,MAAMylB,GAAehwD,EAAAA,GAAAA,GAAOuqC,EAAa2gB,IACvC,MAAM9U,EAAU8U,EAAS1J,IACzB,OAAOpL,aAAmB/H,SAAW+H,EAAQhB,WAAagB,EAAQ6Z,UAG9DjuC,GAASxjB,EAAAA,EAAAA,GAAIwxD,EAAe9E,IACzB,CACL/vD,QACE,iBACA+vD,EAASr/D,KACT,oEACF8P,KAAM4yD,GAAyB2B,wBAC/B3lB,WAAY,CAAC2gB,MAIjB,OAAOlpC,CACT,CAtMyBmuC,CAAqBlB,IAE5CjtC,EAASA,EAAOrsB,OAuMZ,SACJ40C,GAEA,MAAMuf,EAAqB,GAC3B,IAAIsG,GAAoB5xD,EAAAA,EAAAA,GAAI+rC,EAAa8lB,IAChC7rD,EAAAA,GAAAA,GACL+lC,EACA,CAACv4C,EAAQs+D,KAELD,EAAU7O,QAAQjoD,SAAY+2D,EAAU9O,QAAmBjoD,QAC1D+kC,GAASwrB,EAAOwG,IACjBA,EAAU9O,UAAYtiC,GAAMisC,KAI5BrB,EAAM35D,KAAKmgE,GACXt+D,EAAO7B,KAAKmgE,IAGPt+D,GAET,KAIJo+D,EAAoBG,GAAQH,GAE5B,MAAMI,GAAoBxwD,EAAAA,GAAAA,GAAOowD,EAAoBK,GAC5CA,EAAiBxkE,OAAS,GAG7B+1B,GAASxjB,EAAAA,EAAAA,GAAIgyD,EAAoBE,IACrC,MAAMC,GAAiBnyD,EAAAA,EAAAA,GAAIkyD,EAAiBxF,GACnCA,EAASr/D,MAGZ+kE,EAAsBpwD,GAAMkwD,GAAiBlP,QACnD,MAAO,CACLrmD,QACE,6BAAAxF,OAA6Bi7D,EAAa,4DAAAj7D,OACYg7D,EAAej9D,KACnE,MACD,OACHiI,KAAM4yD,GAAyBsC,yBAC/BtmB,WAAYmmB,KAIhB,OAAO1uC,CACT,CAxPyB8uC,CAAsB7B,IAE7CjtC,EAASA,EAAOrsB,OA2GZ,SACJ40C,GAEA,MAAMwmB,GAAqB/wD,EAAAA,GAAAA,GAAOuqC,EAAa2gB,GAC7BA,EAAS1J,QACVxrD,KAAK,KAGhBgsB,GAASxjB,EAAAA,EAAAA,GAAIuyD,EAAqB7F,IAC/B,CACL/vD,QACE,iBACA+vD,EAASr/D,KACT,qDACF8P,KAAM4yD,GAAyByC,oBAC/BzmB,WAAY,CAAC2gB,MAIjB,OAAOlpC,CACT,CA/HyBivC,CAAsBhC,IAEtCjtC,CACT,CAhCyBkvC,CAAsBlC,IAE7ChtC,EAASA,EAAOrsB,OAmRZ,SACJ40C,GAEA,MAAM4mB,GAAenxD,EAAAA,GAAAA,GAAOuqC,EAAagiB,IACvC,KAAKvmD,EAAAA,EAAAA,GAAIumD,EAAO,SACd,OAAO,EAET,MAAMhjC,EAAQgjC,EAAME,MAEpB,OAAOljC,IAAUrK,GAAMwtC,SAAWnjC,IAAUrK,GAAMisC,MAAOzK,EAAAA,EAAAA,GAASn3B,KAG9DvH,GAASxjB,EAAAA,EAAAA,GAAI2yD,EAAejG,IACzB,CACL/vD,QACE,iBACA+vD,EAASr/D,KACT,gEACF8P,KAAM4yD,GAAyB6C,yBAC/B7mB,WAAY,CAAC2gB,MAIjB,OAAOlpC,CACT,CA3SyBqvC,CAAqBrC,IAE5ChtC,EAASA,EAAOrsB,OA2SZ,SACJ40C,EACA+mB,GAEA,MAAMC,GAAevxD,EAAAA,GAAAA,GAAOuqC,EAAagiB,QAEjBl+D,IAApBk+D,EAAMO,YAA4BxuB,GAASgzB,EAAY/E,EAAMO,YAI3D9qC,GAASxjB,EAAAA,EAAAA,GAAI+yD,EAAezrD,IAIzB,CACL3K,QAHA,iBAAAxF,OAAiBmQ,EAAQja,KAAI,+DAAA8J,OAA8DmQ,EAAQgnD,UAAS,6BAI5GnxD,KAAM4yD,GAAyBiD,yBAC/BjnB,WAAY,CAACzkC,MAIjB,OAAOkc,CACT,CAhUIyvC,CAAwBzC,EAAiBZ,IAG3CpsC,EAASA,EAAOrsB,OA+TZ,SACJ40C,GAEA,MAAMvoB,EAAkC,GAElC0vC,GAAcltD,EAAAA,GAAAA,GAClB+lC,EACA,CAACv4C,EAAQ8T,EAAS7G,KAChB,MAAMm3C,EAAUtwC,EAAQ07C,QAExB,OAAIpL,IAAYl3B,GAAMisC,MAMlBzK,EAAAA,EAAAA,GAAStK,GACXpkD,EAAO7B,KAAK,CAAEwhE,IAAKvb,EAASn3C,MAAKhD,UAAW6J,IACnCy6C,EAASnK,IA8C1B,SAAoBsR,GAElB,MAAMkK,EAAY,CAChB,IACA,KACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,KAEF,YACoEvjE,KAAlEopC,EAAAA,GAAAA,GAAKm6B,EAAYpkC,IAA0C,IAAjCk6B,EAAOnuD,OAAO9D,QAAQ+3B,GAEpD,CAlEsCqkC,CAAWzb,IACzCpkD,EAAO7B,KAAK,CAAEwhE,IAAKvb,EAAQ78C,OAAQ0F,MAAKhD,UAAW6J,KAR5C9T,GAYX,IAoBF,OAjBAyS,EAAAA,EAAAA,GAAQ8lC,EAAY,CAACzkC,EAASgsD,MAC5BrtD,EAAAA,EAAAA,GAAQitD,EAAa1sC,IAA4B,IAA3B,IAAE2sC,EAAG,IAAE1yD,EAAG,UAAEhD,GAAW+oB,EAC3C,GAAI8sC,EAAU7yD,GAkBpB,SAAuB0yD,EAAavb,GAElC,GAAImK,EAASnK,GAAU,CACrB,MAAM2b,EAAc3b,EAAQjqD,KAAKwlE,GACjC,OAAuB,OAAhBI,GAA8C,IAAtBA,EAAYx5D,K,CACtC,IAAI6zD,EAAAA,GAAAA,GAAWhW,GAEpB,OAAOA,EAAQub,EAAK,EAAG,GAAI,CAAC,GACvB,IAAI3rD,EAAAA,EAAAA,GAAIowC,EAAS,QAEtB,OAAOA,EAAQjqD,KAAKwlE,EAAK,EAAG,GAAI,CAAC,GAC5B,GAAuB,kBAAZvb,EAChB,OAAOA,IAAYub,EAEnB,MAAMjhE,MAAM,uBAEhB,CAlC2BshE,CAAcL,EAAK7rD,EAAQ07C,SAAU,CACxD,MAAM6F,EACJ,YAAA1xD,OAAYsG,EAAUpQ,KAAI,2EAAA8J,OACmBmQ,EAAQja,KAAI,MADzD,2GAIFm2B,EAAO7xB,KAAK,CACVgL,QAASksD,EACT1rD,KAAM4yD,GAAyB0D,oBAC/B1nB,WAAY,CAACzkC,EAAS7J,I,MAMvB+lB,CACT,CA3WyBkwC,CAAwBlD,IAExChtC,CACT,CA+EA,MAAMutC,GAAe,WAoErB,MAAMM,GAAiB,iBA+PjB,SAAU1D,GAAgB/V,GAC9B,MAAMc,EAAQd,EAAQ+R,WAAa,IAAM,GAGzC,OAAO,IAAI9Z,OAAO,OAAD14C,OAAQygD,EAAQ78C,OAAM,KAAK29C,EAC9C,CAEM,SAAUgV,GAAc9V,GAC5B,MAAMc,EAAQd,EAAQ+R,WAAa,KAAO,IAG1C,OAAO,IAAI9Z,OAAO,GAAD14C,OAAIygD,EAAQ78C,QAAU29C,EACzC,CA2EM,SAAUib,GACdC,EACAC,EACAvH,GAEA,MAAMwH,EAAW,GACjB,IAAIC,GAAkB,EACtB,MAAMC,EAAgBjC,IAAQhrD,EAAAA,GAAAA,IAAQwC,EAAAA,EAAAA,GAAOqqD,EAAgBlnB,SAEvDunB,EAAqB7lC,GACzB4lC,EACCtH,GAAaA,EAAS1J,MAAatiC,GAAMisC,IAEtCuH,EAAsB1F,GAAalC,GAwCzC,OAvCIuH,IACF5tD,EAAAA,EAAAA,GAAQguD,EAAqB3sD,IAC3B,MAAM6sD,EAAYzF,GAAsBpnD,EAAS4sD,GACjD,IAAkB,IAAdC,EAAqB,CACvB,MAAMx3D,EAyJR,SACJ2K,EACA8sD,GAQA,GAAIA,EAAQC,QAAUtE,GAAyBuE,oBAC7C,MACE,kEAAiE,4BAAAn9D,OACrCmQ,EAAQja,KAAI,kBAAgB,kBAAA8J,OACtCi9D,EAAQG,OAAM,OAChC,sGAEG,GAAIH,EAAQC,QAAUtE,GAAyByE,kBACpD,MACE,6EAA4E,4BAAAr9D,OAChDmQ,EAAQja,KAAI,kBACxC,oGAGF,MAAM6E,MAAM,uBAEhB,CAnLwBuiE,CAA2BntD,EAAS6sD,GAC9CO,EAAoB,CACxB/3D,UACAQ,KAAMg3D,EAAUE,MAChB52D,UAAW6J,GAEbwsD,EAASniE,KAAK+iE,E,MAGVltD,EAAAA,EAAAA,GAAIF,EAAS,gBACa,IAAxBA,EAAQmnD,cACVsF,GAAkB,GAIlBtI,GAAiByI,EAAqB5sD,EAAQ07C,WAE9C+Q,GAAkB,KAOxBF,IAAeE,GACjBD,EAASniE,KAAK,CACZgL,QACE,uRAKFQ,KAAM4yD,GAAyB4E,uBAG5Bb,CACT,CAuBM,SAAUnF,GAAgBlxD,GAC9B,MAAMm6C,EAAUn6C,EAAUulD,QAE1B,GAAIjB,EAASnK,GACX,OAAO,EACF,IAAIgW,EAAAA,GAAAA,GAAWhW,GAEpB,OAAO,EACF,IAAIpwC,EAAAA,EAAAA,GAAIowC,EAAS,QAEtB,OAAO,EACF,IAAIsK,EAAAA,EAAAA,GAAStK,GAClB,OAAO,EAEP,MAAM1lD,MAAM,uBAEhB,CAEM,SAAU08D,GAAehX,GAC7B,UAAIsK,EAAAA,EAAAA,GAAStK,IAA+B,IAAnBA,EAAQnqD,SACxBmqD,EAAQljD,WAAW,EAI9B,CAKO,MAAMkgE,GAAwD,CAEnEp9D,KAAM,SAAUyd,GACd,MAAMjjB,EAAMijB,EAAKxnB,OACjB,IAAK,IAAIsE,EAAIP,KAAKuK,UAAWhK,EAAIC,EAAKD,IAAK,CACzC,MAAMqD,EAAI6f,EAAKvgB,WAAW3C,GAC1B,GAAU,KAANqD,EAEF,OADA5D,KAAKuK,UAAYhK,EAAI,GACd,EACF,GAAU,KAANqD,EAMT,OAL+B,KAA3B6f,EAAKvgB,WAAW3C,EAAI,GACtBP,KAAKuK,UAAYhK,EAAI,EAErBP,KAAKuK,UAAYhK,EAAI,GAEhB,C,CAGX,OAAO,CACT,EAEAgK,UAAW,GAGb,SAAS2yD,GACPpnD,EACAinD,GASA,IAAI/mD,EAAAA,EAAAA,GAAIF,EAAS,eAGf,OAAO,EAGP,GAAIy6C,EAASz6C,EAAQ07C,SAAU,CAC7B,IAEEyI,GAAiB8C,EAAyBjnD,EAAQ07C,Q,CAClD,MAAOpwD,GAEP,MAAO,CACLyhE,MAAOtE,GAAyBuE,oBAChCC,OAAS3hE,EAAY+J,Q,CAGzB,OAAO,C,CACF,IAAIulD,EAAAA,EAAAA,GAAS56C,EAAQ07C,SAE1B,OAAO,EACF,GAAI2L,GAAgBrnD,GAEzB,MAAO,CAAE+sD,MAAOtE,GAAyByE,mBAEzC,MAAMtiE,MAAM,uBAGlB,CA8BA,SAASs8D,GAAaqG,GASpB,OARkB70D,EAAAA,EAAAA,GAAI60D,EAAeC,IAC/B5S,EAAAA,EAAAA,GAAS4S,GACJA,EAAYpgE,WAAW,GAEvBogE,EAKb,CAEA,SAASzF,GACPrvD,EACA9F,EACA5J,QAEiBT,IAAbmQ,EAAI9F,GACN8F,EAAI9F,GAAO,CAAC5J,GAEZ0P,EAAI9F,GAAKvI,KAAKrB,EAElB,CAEO,MAAM45D,GAAqB,IAiBlC,IAAIsC,GAAsC,GACpC,SAAUlC,GAAyByK,GACvC,OAAOA,EAAW7K,GACd6K,EACAvI,GAA0BuI,EAChC,C,wCCroCM,SAAUC,GAASh6C,GACvB,MAAMne,GAAQ,IAAIo4D,MAAOC,UACnBC,EAAMn6C,IAGZ,MAAO,CAAEo6C,MAFG,IAAIH,MAAOC,UACHr4D,EACEvM,MAAO6kE,EAC/B,CCQM,SAAUE,GACdC,EACAC,GAEA,MAAMC,EAAeF,EAAYnvD,aACjC,OAAIqvD,IAAiBD,EAAepvD,eAIJ,IAA5BovD,EAAeE,WACsC,IAArDF,EAAeG,mBAAoBF,EAGzC,CAIM,SAAUG,GACdttD,EACAf,GAEA,OAAOe,EAAMlC,eAAiBmB,EAAQnB,YACxC,CAEO,IAAIyvD,GAAoB,EACxB,MAAMC,GAAqD,CAAC,EAE7D,SAAUC,GAAkB/pB,GAEhC,MAAMgqB,EAcF,SAA2BhqB,GAC/B,IAAIv4C,GAASwiE,EAAAA,EAAAA,GAAMjqB,GAEflM,EAAakM,EACbkqB,GAAY,EAChB,KAAOA,GAAW,CAChBp2B,EAAakyB,IACXhrD,EAAAA,GAAAA,IAAQ/G,EAAAA,EAAAA,GAAI6/B,EAAa35B,GAAgBA,EAAYgwD,cAGvD,MAAMntB,EAAgBmnB,GAAWrwB,EAAYrsC,GAE7CA,EAASA,EAAO2D,OAAO4xC,IAEnB/1C,EAAAA,EAAAA,GAAQ+1C,GACVktB,GAAY,EAEZp2B,EAAakJ,C,CAGjB,OAAOv1C,CACT,CAnC+B2iE,CAAiBpqB,IAqC1C,SAAkCA,IACtC9lC,EAAAA,EAAAA,GAAQ8lC,EAAa7lC,IAyEjB,IAA0CoB,EAxEvC8uD,GAAoBlwD,KACvB2vD,GAAgBD,IAAqB1vD,EAC/BA,EAAaC,aAAeyvD,MAKlCS,GAAsBnwD,MACrB3V,EAAAA,EAAAA,GAAQ2V,EAAYgwD,cAIrBhwD,EAAYgwD,WAAa,CAAChwD,EAAYgwD,aAGnCG,GAAsBnwD,KACzBA,EAAYgwD,WAAa,IAwDiB5uD,EArDPpB,GAsDhCsB,EAAAA,EAAAA,GAAIF,EAAS,qBArDhBpB,EAAYE,gBAAkB,IAwD9B,SACJkB,GAEA,OAAOE,EAAAA,EAAAA,GAAIF,EAAS,qBACtB,CAzDSgvD,CAAmCpwD,KACtCA,EAAYwvD,mBAAqB,CAAC,IAGxC,CA/DEa,CAAwBR,GA6EpB,SAAkChqB,IACtC9lC,EAAAA,EAAAA,GAAQ8lC,EAAa7lC,IACnBswD,GAA8B,GAAItwD,IAEtC,CA9EEuwD,CAAwBV,GA8DpB,SAAqChqB,IACzC9lC,EAAAA,EAAAA,GAAQ8lC,EAAa7lC,IAEnBA,EAAYE,gBAAkB,IAC9BH,EAAAA,EAAAA,GAAQC,EAAYwvD,mBAAqB,CAACP,EAAKj7D,KAC7CgM,EAAYE,gBAAiBzU,KAC3BkkE,GAAgB37D,GAA0BiM,iBAIlD,CAvEEuwD,CAA2BX,IAE3B9vD,EAAAA,EAAAA,GAAQ8vD,EAAuBzuD,IAC7BA,EAAQmuD,SAAWnuD,EAAQlB,gBAAiB3Y,OAAS,GAEzD,CA0EM,SAAU+oE,GACdn/D,EACAs/D,IAEA1wD,EAAAA,EAAAA,GAAQ5O,EAAOu/D,IACbD,EAASjB,mBAAoBkB,EAASzwD,eAAiB,KAGzDF,EAAAA,EAAAA,GAAQ0wD,EAAST,WAAaW,IAC5B,MAAMC,EAAUz/D,EAAKF,OAAOw/D,GAEvB72B,GAASg3B,EAASD,IACrBL,GAA8BM,EAASD,IAG7C,CAEM,SAAUT,GAAoB9uD,GAClC,OAAOE,EAAAA,EAAAA,GAAIF,EAAS,eACtB,CAEM,SAAU+uD,GAAsB/uD,GACpC,OAAOE,EAAAA,EAAAA,GAAIF,EAAS,aACtB,CAYM,SAAUyvD,GAAYzvD,GAC1B,OAAOE,EAAAA,EAAAA,GAAIF,EAAS,eACtB,CCpKO,MAAMmkC,GAAwD,CACnEC,iCAAiCrjC,GACxB,uDAAPlR,OAA8DkR,EAAMuV,MAAK,8BAG3E4tB,iCAAgCA,CAC9B3sB,EACApD,EACAhuB,EACAqP,EACA2kC,IAGE,2BAAAtqC,OAA2B0nB,EAASlmB,OAClC8iB,GACD,kBAAAtkB,OAAiBskB,EAAW,iBAAAtkB,OAAkB1J,EAAM,iBCgCpD,IAAKsiE,IAAZ,SAAYA,GACVA,EAAAA,EAAA,qCACAA,EAAAA,EAAA,qCACAA,EAAAA,EAAA,uCACAA,EAAAA,EAAA,qDACAA,EAAAA,EAAA,uDACAA,EAAAA,EAAA,uDACAA,EAAAA,EAAA,uDACAA,EAAAA,EAAA,iFACAA,EAAAA,EAAA,qFACAA,EAAAA,EAAA,2GACAA,EAAAA,EAAA,0FACAA,EAAAA,EAAA,wCACAA,EAAAA,EAAA,8CACAA,EAAAA,EAAA,gDACAA,EAAAA,EAAA,8CACAA,EAAAA,EAAA,8CACAA,EAAAA,EAAA,0CACAA,EAAAA,EAAA,qGACD,CAnBD,CAAYA,KAAAA,GAAwB,KAyBpC,MAAMiH,GAA+C,CACnDC,+BAA+B,EAC/B5qB,iBAAkB,OAClB6qB,uBAAwB,YACxB5K,yBAA0B,CAAC,KAAM,MACjC9C,qBAAqB,EACrB6C,UAAU,EACVprC,qBAAsBwqB,GACtB0rB,eAAe,EACfn2C,iBAAiB,EACjB6G,iBAAiB,GAGnBn3B,OAAO0mE,OAAOJ,IAER,MAAOt2C,GA4BXh0B,WAAAA,CACYknE,GACiC,IAA3CrwD,EAAA3T,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAuBonE,GAEvB,GAHU,KAAApD,gBAAAA,EAvBL,KAAAyD,sBAAiD,GACjD,KAAAC,uBAAkD,GAE/C,KAAAhK,mBAAuD,CAAC,EACxD,KAAA6B,6BAEN,CAAC,EAEK,KAAAziB,MAAkB,GAElB,KAAA2gB,YAA+C,CAAC,EAGlD,KAAAkK,iBAA2B,EAC3B,KAAAC,eAAyB,EACzB,KAAAjK,WAAqB,EACrB,KAAAkK,mBAA8C,CAAC,EAu0BvD,KAAAC,WAAa,CAAIC,EAAmBC,KAGlC,IAA2B,IAAvBpmE,KAAK2lE,cAAwB,CAC/B3lE,KAAKqmE,kBACL,MAAM3oE,EAAS,IAAI0C,MAAMJ,KAAKqmE,gBAAkB,GAAG3iE,KAAK,MACpD1D,KAAKqmE,gBAAkBrmE,KAAKsmE,mBAC9BhlE,QAAQ8R,IAAI,GAADzN,OAAIjI,EAAM,YAAAiI,OAAQwgE,EAAS,MAExC,MAAM,KAAEvC,EAAI,MAAE9kE,GAAU0kE,GAAM4C,GAExBG,EAAc3C,EAAO,GAAKtiE,QAAQ4hC,KAAO5hC,QAAQ8R,IAKvD,OAJIpT,KAAKqmE,gBAAkBrmE,KAAKsmE,mBAC9BC,EAAY,GAAD5gE,OAAIjI,EAAM,SAAAiI,OAAQwgE,EAAS,YAAAxgE,OAAWi+D,EAAI,OAEvD5jE,KAAKqmE,kBACEvnE,C,CAEP,OAAOsnE,KA/0Ba,mBAAXr0D,EACT,MAAMrR,MACJ,8HAMJV,KAAK+R,OAAST,EAAO,CAAC,EAAGk0D,GAAsBzzD,GAE/C,MAAMy0D,EAAexmE,KAAK+R,OAAO4zD,eACZ,IAAjBa,GACFxmE,KAAKsmE,kBAAoBG,IACzBzmE,KAAK2lE,eAAgB,GACY,kBAAjBa,IAChBxmE,KAAKsmE,kBAAoBE,EACzBxmE,KAAK2lE,eAAgB,GAEvB3lE,KAAKqmE,iBAAmB,EAExBrmE,KAAKkmE,WAAW,oBAAqB,KACnC,IAAIQ,EACAC,GAAoB,EACxB3mE,KAAKkmE,WAAW,wBAAyB,KACvC,GACElmE,KAAK+R,OAAO2zD,yBACZF,GAAqBE,uBAGrB1lE,KAAK+R,OAAO2zD,uBAAyBtC,QAErC,GACEpjE,KAAK+R,OAAO+oD,2BACZ0K,GAAqB1K,yBAErB,MAAMp6D,MACJ,oLAMN,GAAIqR,EAAO8oD,UAAY9oD,EAAOimD,oBAC5B,MAAMt3D,MACJ,sEAIJV,KAAK+lE,gBAAkB,kBAAkB//D,KACvChG,KAAK+R,OAAO8oC,kBAEd76C,KAAKgmE,cAAgB,QAAQhgE,KAAKhG,KAAK+R,OAAO8oC,mBAG1C97C,EAAAA,EAAAA,GAAQqjE,GACVsE,EAAmB,CACjBxrB,MAAO,CAAE0rB,aAAapC,EAAAA,EAAAA,GAAMpC,IAC5BwE,YAAaxM,KAIfuM,GAAoB,EACpBD,GAAmBlC,EAAAA,EAAAA,GAAiCpC,OAIpB,IAAhCpiE,KAAK+R,OAAOyd,kBACdxvB,KAAKkmE,WAAW,uBAAwB,KACtClmE,KAAK6lE,sBAAwB7lE,KAAK6lE,sBAAsBlgE,OJ0oB5D,SACJy8D,GAIA,MAAMpwC,EAAkC,GAiExC,OA9DKhc,EAAAA,EAAAA,GAAIosD,EAAiBhI,KACxBpoC,EAAO7xB,KAAK,CACVgL,QACE,sDACAivD,GACA,iCACFzuD,KAAM4yD,GAAyBsI,yCAG9B7wD,EAAAA,EAAAA,GAAIosD,EAAiB/H,KACxBroC,EAAO7xB,KAAK,CACVgL,QACE,yFAGFQ,KAAM4yD,GAAyBuI,2CAKjC9wD,EAAAA,EAAAA,GAAIosD,EAAiB/H,MACrBrkD,EAAAA,EAAAA,GAAIosD,EAAiBhI,OACpBpkD,EAAAA,EAAAA,GAAIosD,EAAgBlnB,MAAOknB,EAAgBwE,cAE5C50C,EAAO7xB,KAAK,CACVgL,QACE,kDAAAxF,OAAkDy0D,GAAY,OAAAz0D,OAAMy8D,EAAgBwE,YAAW,8BAEjGj7D,KAAM4yD,GAAyBwI,sDAI/B/wD,EAAAA,EAAAA,GAAIosD,EAAiB/H,MACvB5lD,EAAAA,EAAAA,GAAQ2tD,EAAgBlnB,MAAO,CAAC8rB,EAAeC,MAC7CxyD,EAAAA,EAAAA,GAAQuyD,EAAe,CAACtyD,EAAauhB,KACnC,IAAI0mC,EAAAA,GAAAA,GAAYjoD,GACdsd,EAAO7xB,KAAK,CACVgL,QACE,yEAAAxF,OACIshE,EAAY,iBAAAthE,OAAgBswB,EAAO,OACzCtqB,KAAM4yD,GAAyB2I,iDAE5B,IAAIlxD,EAAAA,EAAAA,GAAItB,EAAa,cAAe,CACzC,MAAM4oD,GAAYv+D,EAAAA,EAAAA,GAAQ2V,EAAYmoD,YAClCnoD,EAAYmoD,WACZ,CAACnoD,EAAYmoD,aACjBpoD,EAAAA,EAAAA,GAAQ6oD,EAAY6J,KAEfxK,EAAAA,GAAAA,GAAYwK,IACZ74B,GAAS04B,EAAeG,IAEzBn1C,EAAO7xB,KAAK,CACVgL,QAAS,8DAAFxF,OAAgEwhE,EAActrE,KAAI,gBAAA8J,OAAe+O,EAAY7Y,KAAI,uBAAA8J,OAAsBshE,EAAY,OAC1Jt7D,KAAM4yD,GAAyB6I,mD,MAStCp1C,CACT,CIhtBYq1C,CACEX,EACA1mE,KAAK+lE,gBACL/lE,KAAK+R,OAAO+oD,6BAKlB96D,KAAKkmE,WAAW,8BAA+B,KAC7ClmE,KAAK8lE,uBAAyB9lE,KAAK8lE,uBAAuBngE,OACxDw8D,GACEuE,EACA1mE,KAAK+lE,gBACL/lE,KAAK+R,OAAO+oD,8BAOpB4L,EAAiBxrB,MAAQwrB,EAAiBxrB,MACtCwrB,EAAiBxrB,MACjB,CAAC,GAILzmC,EAAAA,EAAAA,GAAQiyD,EAAiBxrB,MAAO,CAAC8rB,EAAeC,KAC9CP,EAAiBxrB,MAAM+rB,GAAgBrqC,GACrCoqC,EACCtyD,IAAgBioD,EAAAA,GAAAA,GAAYjoD,MAIjC,MAAM4yD,GAAetvD,EAAAA,EAAAA,GAAK0uD,EAAiBxrB,OAyD3C,IAvDAzmC,EAAAA,EAAAA,GACEiyD,EAAiBxrB,MACjB,CAACqsB,EAAyBC,KACxBxnE,KAAKkmE,WAAW,UAADvgE,OAAW6hE,EAAW,gBAAgB,KAcnD,GAbAxnE,KAAKk7C,MAAM/6C,KAAKqnE,IAEoB,IAAhCxnE,KAAK+R,OAAOyd,iBACdxvB,KAAKkmE,WAAW,mBAAoB,KAClClmE,KAAK6lE,sBAAwB7lE,KAAK6lE,sBAAsBlgE,OACtDw4D,GAAiBoJ,EAAYD,OAQ/B9lE,EAAAA,EAAAA,GAAQxB,KAAK6lE,uBAAwB,CAGvC,IAAI4B,EAFJnD,GAAkBiD,GAGlBvnE,KAAKkmE,WAAW,oBAAqB,KACnCuB,EAAoBjN,GAAkB+M,EAAY,CAChDzM,yBACE96D,KAAK+R,OAAO+oD,yBACdjgB,iBAAkB9oC,EAAO8oC,iBACzBmd,oBAAqBjmD,EAAOimD,oBAC5B6C,SAAU9oD,EAAO8oD,SACjBJ,OAAQz6D,KAAKkmE,eAIjBlmE,KAAK87D,mBAAmB0L,GACtBC,EAAkB3L,mBAEpB97D,KAAK29D,6BAA6B6J,GAChCC,EAAkB9J,6BAEpB39D,KAAK67D,YAAcvqD,EACjB,CAAC,EACDtR,KAAK67D,YACL4L,EAAkB5L,aAGpB77D,KAAK+7D,UAAY0L,EAAkB1L,WAAa/7D,KAAK+7D,UAErD/7D,KAAKimE,mBAAmBuB,GACtBC,EAAkB/J,c,MAM5B19D,KAAK4mE,YAAcF,EAAiBE,cAGjCplE,EAAAA,EAAAA,GAAQxB,KAAK6lE,yBACb7lE,KAAK+R,OAAO0zD,8BACb,CACA,MAGMiC,GAHiBl5D,EAAAA,EAAAA,GAAIxO,KAAK6lE,sBAAwBtkE,GAC/CA,EAAM4J,SAE6BzH,KAC1C,6BAEF,MAAM,IAAIhD,MACR,4CAA8CgnE,E,EAKlDjzD,EAAAA,EAAAA,GAAQzU,KAAK8lE,uBAAyB5C,IACpC5L,GAAc4L,EAAkB/3D,WAGlCnL,KAAKkmE,WAAW,uCAAwC,KAwBtD,GApBI5L,IACFt6D,KAAK2nE,UAAiBplE,GAAAA,EACtBvC,KAAK9D,MAAQ8D,KAAK4nE,gBAElB5nE,KAAK6nE,gBAAkBC,GAAAA,EACvB9nE,KAAK9D,MAAQ8D,KAAK+nE,eAGhBpB,IACF3mE,KAAKgoE,YAAcF,GAAAA,IAGQ,IAAzB9nE,KAAK+lE,kBACP/lE,KAAKioE,iBAAmB1lE,GAAAA,IAGC,IAAvBvC,KAAKgmE,gBACPhmE,KAAKkoE,iCAAmCJ,GAAAA,GAGtC,QAAQ9hE,KAAKhG,KAAK+R,OAAO8oC,kBAC3B76C,KAAKmoE,oBAAsBnoE,KAAKooE,qBAC3B,GAAI,aAAapiE,KAAKhG,KAAK+R,OAAO8oC,kBACvC76C,KAAKmoE,oBAAsBnoE,KAAKqoE,yBAC3B,KAAI,cAAcriE,KAAKhG,KAAK+R,OAAO8oC,kBAGxC,MAAMn6C,MAAM,8CAADiF,OACqC3F,KAAK+R,OAAO8oC,iBAAgB,MAH5E76C,KAAKmoE,oBAAsBnoE,KAAKsoE,qB,CAO9BtoE,KAAK+7D,WACP/7D,KAAKuoE,SAAWvoE,KAAKwoE,kBACrBxoE,KAAKyoE,cAAgBzoE,KAAK0oE,0BAE1B1oE,KAAKuoE,SAAWvoE,KAAK2oE,0BACrB3oE,KAAKyoE,cAAgBzoE,KAAK4oE,yBAI9B5oE,KAAKkmE,WAAW,+BAAgC,KAC9C,MAAM2C,GAAmBr0D,EAAAA,GAAAA,GACvBxU,KAAKimE,mBACL,CAAC6C,EAAmBpL,EAAgBqL,MACX,IAAnBrL,GACFoL,EAAkB3oE,KAAK4oE,GAElBD,GAET,IAGF,GAAI/2D,EAAOimD,uBAAwBx2D,EAAAA,EAAAA,GAAQqnE,GACzC,MAAMnoE,MACJ,kBAAAiF,OAAkBkjE,EAAiBnlE,KACjC,MACD,6BAFD,0MASN1D,KAAKkmE,WAAW,yBAA0B,KNhV9C3O,GAAiB,CAAC,IMoVdv3D,KAAKkmE,WAAW,mBAAoB,KAClC3W,EAAiBvvD,SAGvB,CAEO6xB,QAAAA,CACLpO,GACsC,IAAtCulD,EAAA5qE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAsB4B,KAAK4mE,YAE3B,KAAKplE,EAAAA,EAAAA,GAAQxB,KAAK6lE,uBAAwB,CACxC,MAGM6B,GAHiBl5D,EAAAA,EAAAA,GAAIxO,KAAK6lE,sBAAwBtkE,GAC/CA,EAAM4J,SAE6BzH,KAC1C,6BAEF,MAAM,IAAIhD,MACR,uEACEgnE,E,CAIN,OAAO1nE,KAAKipE,iBAAiBxlD,EAAMulD,EACrC,CAMQC,gBAAAA,CAAiBxlD,EAAculD,GACrC,IAAIzoE,EACF2oE,EACAh3D,EACAi3D,EACA7L,EACA8L,EACAC,EACAC,EACAC,EACAhwC,EACAzjB,EACA0zD,EACAC,EAEApS,EACAn7D,EACF,MAAM60D,EAAUttC,EACVimD,EAAY3Y,EAAQ90D,OAC1B,IAAI4uB,EAAS,EACT8+C,EAAqB,EAKzB,MAAMC,EAAwB5pE,KAAK+7D,UAC/B,EACAjxC,KAAKK,MAAM1H,EAAKxnB,OAAS,IACvB4tE,EAAgB,IAAIzpE,MAAMwpE,GAC1B53C,EAAyB,GAC/B,IAAI1mB,EAAOtL,KAAK+lE,gBAAkB,OAAI1nE,EAClC4xC,EAASjwC,KAAK+lE,gBAAkB,OAAI1nE,EACxC,MAAM08C,EJshBJ,SAA2B8gB,GAG/B,MAAMiO,EAAoB,CAAC,EACrBC,GAAY/xD,EAAAA,EAAAA,GAAK6jD,GAavB,OAXApnD,EAAAA,EAAAA,GAAQs1D,EAAYC,IAClB,MAAMC,EAAiBpO,EAAYmO,GAGnC,KAAIjrE,EAAAA,EAAAA,GAAQkrE,GAGV,MAAMvpE,MAAM,wBAFZopE,EAAaE,GAAW,KAMrBF,CACT,CIxiBwBI,CAAiBlqE,KAAK67D,aACpCwG,EAAariE,KAAK+lE,gBAClBoE,EAAwBnqE,KAAK+R,OAAO2zD,uBAE1C,IAAI0E,EAAyB,EACzBtO,EAAuC,GACvCuO,EAEA,GAEJ,MAAMC,EAAsB,GAEtBC,EAA+B,GAErC,IAAIC,EAEJ,SAASC,IACP,OAAO3O,CACT,CAEA,SAAS4O,EAA6BnH,GACpC,MAAMnK,EAAmBN,GAAyByK,GAC5CoH,EACJN,EAAiCjR,GACnC,YAAyB/6D,IAArBssE,EACKJ,EAEAI,CAEX,CAhBAzrE,OAAO0mE,OAAO2E,GAkBd,MAAMK,EAAYC,IAEhB,GACuB,IAArBP,EAAUruE,aAGuBoC,IAAjCwsE,EAAS5+D,UAAU6wD,UACnB,CAGA,MAAMzF,EACJr3D,KAAK+R,OAAO0d,qBAAqByqB,iCAC/B2wB,GAGJ74C,EAAO7xB,KAAK,CACV0qB,OAAQggD,EAAS5gD,YACjB3e,KAAMu/D,EAAShqD,UACfovB,OAAQ46B,EAASjoB,YACjB3mD,OAAQ4uE,EAASz+C,MAAMnwB,OACvBkP,QAASksD,G,KAEN,CACLiT,EAAUvwD,MACV,MAAM+wD,GAAUr6D,EAAAA,GAAAA,GAAK65D,GACrBxO,EAAqB97D,KAAK87D,mBAAmBgP,GAC7CT,EACErqE,KAAK29D,6BAA6BmN,GACpCV,EAAyBtO,EAAmB7/D,OAC5C,MAAM8uE,EACJ/qE,KAAKimE,mBAAmB6E,KAAqC,IAAzB9qE,KAAK+R,OAAO8oD,SAGhD2P,EADEH,GAAoCU,EAChBL,EAEAD,C,GAK5B,SAASO,EAAuBF,GAC9BR,EAAUnqE,KAAK2qE,GACfT,EACErqE,KAAK29D,6BAA6BmN,GAEpChP,EAAqB97D,KAAK87D,mBAAmBgP,GAC7CV,EAAyBtO,EAAmB7/D,OAE5CmuE,EAAyBtO,EAAmB7/D,OAC5C,MAAM8uE,EACJ/qE,KAAKimE,mBAAmB6E,KAAqC,IAAzB9qE,KAAK+R,OAAO8oD,SAGhD2P,EADEH,GAAoCU,EAChBL,EAEAD,CAE1B,CAMA,IAAIQ,EAFJD,EAAU5oE,KAAKpC,KAAMgpE,GAIrB,MAAM3yC,EAAkBr2B,KAAK+R,OAAOskB,gBAEpC,KAAOxL,EAAS6+C,GAAW,CACzBN,EAAe,KAEf,MAAM8B,EAAena,EAAQ7tD,WAAW2nB,GAClCsgD,EAA2BX,EAAoBU,GAC/CE,EAAuBD,EAAyBlvE,OAEtD,IAAKsE,EAAI,EAAGA,EAAI6qE,EAAsB7qE,IAAK,CACzC0qE,EAAaE,EAAyB5qE,GACtC,MAAMy7D,EAAciP,EAAW7kB,QAC/BijB,EAAU,KAGV,MAAMgC,EAAiBJ,EAAWxN,MA0BlC,IAzBuB,IAAnB4N,EACEH,IAAiBG,IAEnBjC,EAAepN,IAEgB,IAAxBiP,EAAWzN,UACpBthE,EAAS8/D,EAA4B7/D,KACnC40D,EACAlmC,EACAg/C,EACA9uB,GAEY,OAAV7+C,GACFktE,EAAeltE,EAAM,QACiCmC,IAAjDnC,EAAqCmtE,UACxCA,EAAWntE,EAAqCmtE,UAGlDD,EAAe,OAGjBppE,KAAK6nE,gBAAgB7L,EAAuBnxC,GAC5Cu+C,EAAeppE,KAAK9D,MAAM8/D,EAAuBv4C,EAAMoH,IAGpC,OAAjBu+C,EAAuB,CAIzB,GADA9L,EAAY2N,EAAW3N,eACLj/D,IAAdi/D,EAAyB,CAG3B,MAAMgO,EAAkBhO,EAAUrhE,OAClC,IAAKiW,EAAI,EAAGA,EAAIo5D,EAAiBp5D,IAAK,CACpC,MAAMq5D,EAAkBzP,EAAmBwB,EAAUprD,IAC/Cs5D,EAAmBD,EAAgBnlB,QA+BzC,GA9BAkjB,EAAa,MAIoB,IAA7BiC,EAAgB/N,UAClBthE,EAASsvE,EAAiCrvE,KACxC40D,EACAlmC,EACAg/C,EACA9uB,GAEY,OAAV7+C,GACFitE,EAAgBjtE,EAAM,QAE8BmC,IAAjDnC,EAAqCmtE,UAEtCC,EAAcptE,EAAqCmtE,UAGrDF,EAAgB,OAGlBnpE,KAAK6nE,gBAAgB2D,EAA4B3gD,GACjDs+C,EAAgBnpE,KAAK9D,MACnBsvE,EACA/nD,EACAoH,IAIAs+C,GAAiBA,EAAcltE,OAASmtE,EAAantE,OAAQ,CAC/DmtE,EAAeD,EACfE,EAAUC,EACV2B,EAAaM,EAGb,K,GAIN,K,EAKJ,GAAqB,OAAjBnC,EAAuB,CAoCzB,GAnCAG,EAAcH,EAAantE,OAC3Bs9B,EAAQ0xC,EAAW1xC,WACLl7B,IAAVk7B,IACFzjB,EAAUm1D,EAAWt2D,aAGrB60D,EAAWxpE,KAAKmoE,oBACdiB,EACAv+C,EACA/U,EACAm1D,EAAWh/D,UACXX,EACA2kC,EACAs5B,GAGFvpE,KAAKyoE,cAAce,EAAUH,IAGf,IAAV9vC,EACFowC,EAAqB3pE,KAAKuoE,SACxBsB,EACAF,EACAH,GAGFzuB,EAAOxhB,GAAOp5B,KAAKqpE,IAGvB/lD,EAAOzjB,KAAK2nE,UAAUlkD,EAAM8lD,GAC5B1+C,GAAkB0+C,EAGlBt5B,EAASjwC,KAAKioE,iBAAiBh4B,EAASs5B,IAErB,IAAflH,IAAwD,IAAjC4I,EAAW1N,kBAA4B,CAChE,IACIkO,EACAC,EAFAC,EAAkB,EAGtBxB,EAAsB5/D,UAAY,EAClC,GACEkhE,EAAkBtB,EAAsBnkE,KAAKojE,IACrB,IAApBqC,IACFC,EAAkBvB,EAAsB5/D,UAAY,EACpDohE,YAEyB,IAApBF,GAEe,IAApBE,IACFrgE,GAAeqgE,EACf17B,EAASs5B,EAAcmC,EACvB1rE,KAAKkoE,iCACHsB,EACAjwC,EACAmyC,EACAC,EACArgE,EACA2kC,EACAs5B,G,CAKNvpE,KAAKgoE,YAAYiD,EAAYL,EAAUI,EAAWxB,E,KAC7C,CAEL,MAAMoC,EAAmB/gD,EACnBghD,EAAYvgE,EACZwgE,EAAc77B,EACpB,IAAI87B,GAAuC,IAApB11C,EAEvB,MAA4B,IAArB01C,GAA8BlhD,EAAS6+C,GAI5C,IAFAjmD,EAAOzjB,KAAK2nE,UAAUlkD,EAAM,GAC5BoH,IACKq+C,EAAI,EAAGA,EAAIkB,EAAwBlB,IAAK,CAC3C,MAAM+B,EAAanP,EAAmBoN,GAChClN,EAAciP,EAAW7kB,QAGzBilB,EAAiBJ,EAAWxN,MAmBlC,IAlBuB,IAAnB4N,EACEta,EAAQ7tD,WAAW2nB,KAAYwgD,IAEjCU,GAAmB,IAEY,IAAxBd,EAAWzN,SACpBuO,EAMQ,OALL/P,EAA4B7/D,KAC3B40D,EACAlmC,EACAg/C,EACA9uB,IAGJ/6C,KAAK6nE,gBAAgB7L,EAAuBnxC,GAC5CkhD,EAA0D,OAAtC/P,EAAuB7/D,KAAKsnB,KAGzB,IAArBsoD,EACF,K,CAuBN,GAlBAtC,EAAY5+C,EAAS+gD,EACrB37B,EAASjwC,KAAKioE,iBAAiBh4B,EAASw5B,GAExCpS,EAAMr3D,KAAK+R,OAAO0d,qBAAqBuqB,iCACrC+W,EACA6a,EACAnC,EACAoC,EACAC,GAEF95C,EAAO7xB,KAAK,CACV0qB,OAAQ+gD,EACRtgE,KAAMugE,EACN57B,OAAQ67B,EACR7vE,OAAQwtE,EACRt+D,QAASksD,KAGa,IAApBhhC,EACF,K,EAYN,OALKr2B,KAAK+7D,YAER8N,EAAc5tE,OAAS0tE,GAGlB,CACLl9C,OAAQo9C,EACR9uB,OAAQA,EACR/oB,OAAQA,EAEZ,CAEQg2C,WAAAA,CACNj2D,EACA64D,EACAI,EACAxB,GAEA,IAAmB,IAAfz3D,EAAOgI,IAAc,CAGvB,MAAMiyD,EAAWj6D,EAAO5R,KACxByqE,EAASpB,QACQnrE,IAAb2tE,GACFhB,EAAU5oE,KAAKpC,KAAMgsE,E,WAEE3tE,IAAhB0T,EAAO5R,MAChB6qE,EAAU5oE,KAAKpC,KAAM+R,EAAO5R,KAEhC,CAEQwnE,SAAAA,CAAUlkD,EAAcxnB,GAC9B,OAAOwnB,EAAKznB,UAAUC,EACxB,CAEQ4rE,eAAAA,CAAgBnQ,EAAgBuU,GACtCvU,EAAOntD,UAAY0hE,CACrB,CAGQ/D,gCAAAA,CACNsB,EACAjwC,EACA2yC,EACAP,EACArgE,EACA2kC,EACAs5B,GAEA,IAAI4C,EAAcC,OACJ/tE,IAAVk7B,IAEF4yC,EAAeD,IAAc3C,EAAc,EAC3C6C,EAAmBD,GAAgB,EAAI,EACb,IAApBR,IAA0C,IAAjBQ,IAE7B3C,EAAS1oD,QAAUxV,EAAO8gE,EAG1B5C,EAASl5B,UAAYL,EAAS,EAAKm8B,GAIzC,CAEQnE,gBAAAA,CAAiBoE,EAAmB9C,GAC1C,OAAO8C,EAAY9C,CACrB,CAMQjB,qBAAAA,CACNl8C,EACAnC,EACAtV,EACA1I,GAEA,MAAO,CACLmgB,QACAnC,cACAtV,eACA1I,YAEJ,CAEQo8D,oBAAAA,CACNj8C,EACAnC,EACAtV,EACA1I,EACA4U,EACA+hC,GAEA,MAAO,CACLx2B,QACAnC,cACApJ,YACA+hC,cACAjuC,eACA1I,YAEJ,CAEQm8D,eAAAA,CACNh8C,EACAnC,EACAtV,EACA1I,EACA4U,EACA+hC,EACA2mB,GAEA,MAAO,CACLn9C,QACAnC,cACAC,UAAWD,EAAcs/C,EAAc,EACvC1oD,YACAC,QAASD,EACT+hC,cACAtS,UAAWsS,EAAc2mB,EAAc,EACvC50D,eACA1I,YAEJ,CAUQu8D,iBAAAA,CACN8D,EACA/jE,EACAgkE,GAGA,OADAD,EAAYnsE,KAAKosE,GACVhkE,CACT,CAEQogE,yBAAAA,CACN2D,EACA/jE,EACAgkE,GAIA,OAFAD,EAAY/jE,GAASgkE,IACrBhkE,CAEF,CAKQqgE,qBAAAA,CAAsB/xD,EAAewyD,GAAqB,CAE1DX,uBAAAA,CAAwB7xD,EAAewyD,GAC7B,OAAZA,IACFxyD,EAAMwyD,QAAUA,EAEpB,CASQzB,aAAAA,CACNxhB,EACA3iC,EACAoH,GAGA,OAAc,IADAu7B,EAAQpgD,KAAKyd,GAElBA,EAAKznB,UAAU6uB,EAAQu7B,EAAQ77C,WAEjC,IACT,CAEQw9D,aAAAA,CAAc3hB,EAAiB3iC,GACrC,MAAMs+C,EAAc3b,EAAQjqD,KAAKsnB,GACjC,OAAuB,OAAhBs+C,EAAuBA,EAAY,GAAK,IACjD,EC76BI,SAAUppD,GAAW7C,GACzB,OAAI02D,GAAc12D,GACTA,EAAQsf,MAERtf,EAAQja,IAEnB,CAMM,SAAU2wE,GACd34C,GAEA,OAAO68B,EAAAA,EAAAA,GAAS78B,EAAIuB,QAAwB,KAAdvB,EAAIuB,KACpC,CDqEgBlG,GAAAwtC,QACZ,6LAGYxtC,GAAAisC,GAAK,iBCvErB,MAAMsR,GAAS,SACT/H,GAAa,aACbtvC,GAAQ,QACRqnC,GAAQ,QACRK,GAAY,YACZ4P,GAAW,WACX7P,GAAa,aACbI,GAAc,cACda,GAAmB,mBAEnB,SAAU6O,GAAY56D,GAC1B,OAGF,SAA6BA,GAC3B,MAAMq0C,EAAUr0C,EAAOq0C,QAEjBn6C,EAA4B,CAAC,EACnCA,EAAUpQ,KAAOkW,EAAOlW,MAEnB8gE,EAAAA,GAAAA,GAAYvW,KACfn6C,EAAUulD,QAAUpL,GAGtB,IAAIpwC,EAAAA,EAAAA,GAAIjE,EAAQ06D,IACd,KACE,6IAKAz2D,EAAAA,EAAAA,GAAIjE,EAAQ2yD,MAEdz4D,EAAUy4D,WAAkB3yD,EAAO2yD,KAGrCJ,GAAkB,CAACr4D,KAEf+J,EAAAA,EAAAA,GAAIjE,EAAQqjB,MACdnpB,EAAUmpB,MAAQrjB,EAAOqjB,MAGvBpf,EAAAA,EAAAA,GAAIjE,EAAQ0qD,MACdxwD,EAAUwwD,MAAQ1qD,EAAO0qD,MAGvBzmD,EAAAA,EAAAA,GAAIjE,EAAQ26D,MACdzgE,EAAUygE,SAAW36D,EAAO26D,MAG1B12D,EAAAA,EAAAA,GAAIjE,EAAQ+qD,MACd7wD,EAAU6wD,UAAY/qD,EAAO+qD,MAG3B9mD,EAAAA,EAAAA,GAAIjE,EAAQ8qD,MACd5wD,EAAU4wD,WAAa9qD,EAAO8qD,MAG5B7mD,EAAAA,EAAAA,GAAIjE,EAAQkrD,MACdhxD,EAAUgxD,YAAclrD,EAAOkrD,MAG7BjnD,EAAAA,EAAAA,GAAIjE,EAAQ+rD,MACd7xD,EAAU6xD,iBAAmB/rD,EAAO+rD,KAGtC,OAAO7xD,CACT,CAxDS2gE,CAAoB76D,EAC7B,CAyDO,MAAMuoB,GAAMqyC,GAAY,CAAE9wE,KAAM,MAAOuqD,QAASl3B,GAAMisC,KAGvD,SAAUgN,GACdryD,EACAsW,EACAnC,EACAC,EACArJ,EACAC,EACA8hC,EACAtS,GAEA,MAAO,CACLlkB,QACAnC,cACAC,YACArJ,YACAC,UACA8hC,cACAtS,YACA37B,aAAoBmB,EAASnB,aAC7B1I,UAAW6J,EAEf,CAEM,SAAU4D,GAAa7C,EAAef,GAC1C,OAAO+tD,GAAuBhtD,EAAOf,EACvC,CA3BAwuD,GAAkB,CAAChqC,KC1EZ,MAAM3F,GAA0D,CACrED,yBAAAA,CAAyBM,GAAyC,IAAxC,SAAEC,EAAQ,OAAEC,EAAM,SAAEjc,EAAQ,SAAEuiB,GAAUxG,EAChE,MACMG,EADWq3C,GAAcv3C,GACH,UAAAtvB,OACjBgT,GAAWsc,GAAS,gCAAAtvB,OACNsvB,EAASp5B,KAAI,QAItC,MAFY,aAAH8J,OAAgBwvB,EAAW,uBAAAxvB,OAAmBuvB,EAAO9I,MAAK,QAGrE,EAEAwI,6BAAAA,CAA6BS,GAA6B,IAA5B,eAAEC,EAAc,SAAEkG,GAAUnG,EACxD,MAAO,6CAA+CC,EAAelJ,KACvE,EAEAyI,uBAAAA,CAAuBg4C,GAMtB,IANuB,oBACtBC,EAAmB,OACnB53C,EAAM,SACNjc,EAAQ,sBACR8zD,EAAqB,SACrBvxC,GACDqxC,EACC,MAAMG,EAAY,cAGZC,EAAY,iBADCz8D,GAAM0kB,GAAS9I,MACgB,IAElD,GAAI2gD,EACF,OAAOC,EAAYD,EAAwBE,EACtC,CACL,MAAMC,GAAoB14D,EAAAA,GAAAA,GACxBs4D,EACA,CAAC9qE,EAAQmrE,IAAiBnrE,EAAO2D,OAAOwnE,GACxC,IAEIC,GAA0B5+D,EAAAA,EAAAA,GAC9B0+D,EACCG,GAAQ,IAAA1nE,QACH6I,EAAAA,EAAAA,GAAI6+D,EAAWC,GAAkB30D,GAAW20D,IAAgB5pE,KAC9D,MACD,MAEC6pE,GAAyB/+D,EAAAA,EAAAA,GAC7B4+D,EACA,CAACI,EAASv+D,IAAQ,KAALtJ,OAAUsJ,EAAM,EAAC,MAAAtJ,OAAK6nE,IAMrC,OAAOR,EAJuB,2CAAHrnE,OAA8C4nE,EAAuB7pE,KAC9F,OAGyCupE,C,CAE/C,EAEAn4C,qBAAAA,CAAqB24C,GAKpB,IALqB,uBACpBC,EAAsB,OACtBx4C,EAAM,sBACN63C,EAAqB,SACrBvxC,GACDiyC,EACC,MAAMT,EAAY,cAGZC,EAAY,iBADCz8D,GAAM0kB,GAAS9I,MACgB,IAElD,GAAI2gD,EACF,OAAOC,EAAYD,EAAwBE,EACtC,CACL,MAAMG,GAA0B5+D,EAAAA,EAAAA,GAC9Bk/D,EACCL,GAAQ,IAAA1nE,QACH6I,EAAAA,EAAAA,GAAI6+D,EAAWC,GAAkB30D,GAAW20D,IAAgB5pE,KAC9D,KACD,MAML,OAAOspE,GAHL,qGAAArnE,OACIynE,EAAwB1pE,KAAK,MAAK,MAEGupE,C,CAE/C,GAGF/tE,OAAO0mE,OAAOjxC,IAEP,MAAMg5C,GACX,CACEC,uBAAsBA,CACpB70D,EACA80D,IAGE,gEACAA,EAAcxc,gBADd,gCAIAt4C,EAAald,KACb,MAKKiyE,GACX,CACEC,wBAAAA,CACEh1D,EACAi1D,GAcA,MAAMC,EAAel1D,EAAald,KAC5BqyE,EAAgB19D,GAAMw9D,GACtBzlE,EAAQ2lE,EAAcj/D,IACtBk/D,EAAUr1D,GAAqBo1D,GAC/BE,GAfJv1D,EAe+Cq1D,aAb3BzgE,EACXoL,EAAKlL,aAAa9R,KAChBgd,aAAgBjL,EAClBiL,EAAKw4C,gBAEL,GARX,IACEx4C,EAiBF,MAAMw1D,EAAmB9lE,EAAQ,EACjC,IAAI8uD,EAAM,KAAH1xD,OAAQwoE,GAAOxoE,OAAG0oE,EAAmB9lE,EAAQ,GAAE,OAAA5C,OACpDyoE,EAAgB,oBAAHzoE,OAAuByoE,EAAa,MAAO,GAC1D,gDAAAzoE,OAEcqoE,EAAe/xE,OACjB,qCAAA0J,OAAoCsoE,EAAY,iJAQ5D,OAHA5W,EAAMA,EAAIt7D,QAAQ,UAAW,KAC7Bs7D,EAAMA,EAAIt7D,QAAQ,SAAU,MAErBs7D,CACT,EAEAiX,4BAA4B5yE,GAExB,oHAAAiK,OAC2EjK,EAAKG,KAAI,QADpF,2OASJ0yE,oCAAAA,CAAqCt7D,GAMnC,MAAMwF,GAAUjK,EAAAA,EAAAA,GAAIyE,EAAQsF,WAAai2D,GACvC71D,GAAW61D,IACX9qE,KAAK,MACDkI,EACwB,IAA5BqH,EAAQ5E,YAAYY,IAAY,GAAKgE,EAAQ5E,YAAYY,IAU3D,MARE,4BAAAtJ,OAA4BsN,EAAQqF,iBAAiB5U,KACnD,MACD,+CAAAiC,OACQiG,EAAU,cAAAjG,OAAasN,EAAQ8F,aAAald,KAAI,aAAW,IAAA8J,OAChE8S,EAAO,+DAJX,yGASJ,EAEAg2D,8BAAAA,CAA+Bx7D,GAM7B,MAAMwF,GAAUjK,EAAAA,EAAAA,GAAIyE,EAAQsF,WAAaG,GACvCC,GAAWD,IACXhV,KAAK,MACDkI,EACwB,IAA5BqH,EAAQ5E,YAAYY,IAAY,GAAKgE,EAAQ5E,YAAYY,IAC3D,IAAI2J,EACF,qCAAAjT,OAAqCsN,EAAQqF,iBAAiB5U,KAC5D,MACD,YAAAiC,OAAWiG,EAAU,iBAAAjG,OACVsN,EAAQ8F,aAAald,KAAI,aAAW,IAAA8J,OAC5C8S,EAAO,+DAMb,OAJAG,GACEA,mHAGKA,CACT,EAEA81D,yBAAAA,CAA0Bz7D,GAIxB,IAAIk7D,EAAUr1D,GAAqB7F,EAAQ9D,YACZ,IAA3B8D,EAAQ9D,WAAWF,MACrBk/D,GAAWl7D,EAAQ9D,WAAWF,KAOhC,MAHE,mBAAAtJ,OAAmBwoE,EAAO,mBAAAxoE,OAAkBsN,EAAQ8F,aAAald,KAAI,2EAIzE,EAIA8yE,oBAAoB17D,GAKX,aAGT27D,2BAA2B37D,GAMvB,iCAAAtN,OAAiCsN,EAAQ47D,eAAiB,EAAC,eAAAlpE,OACjDsN,EAAQ5E,YAAYY,IAAG,cAAAtJ,OAAasN,EAAQ8F,aAAald,KAAI,aAAW,yDAMtFizE,8BAA8B77D,GAK1B,iEAAAtN,OACMsN,EAAQ5E,YAAYY,IAAG,cAAAtJ,OAC3BsN,EAAQ8F,aAAald,KACvB,kBAAA8J,OACEsN,EAAQ5E,YAAYI,WAAWxS,OAAS,EAC1C,kBAKJ8yE,uBAAAA,CAAwB97D,GAItB,MAAMuoB,EAAWvoB,EAAQ8F,aAAald,KAChCmzE,GAAYxgE,EAAAA,EAAAA,GAChByE,EAAQg8D,kBACPC,GAAaA,EAASrzE,MAEnBszE,EAAoB,GAAHxpE,OAAM61B,EAAQ,YAAA71B,OAAQqpE,EAC1CrpE,OAAO,CAAC61B,IACR93B,KAAK,aAQR,MANE,+CAAAiC,OACU61B,EAAQ,2DAAyD,0EAAA71B,OACDwpE,EAAiB,MAF3F,gIAOJ,EAIAC,0BAA0Bn8D,GAKjB,aAGTo8D,2BAAAA,CAA4Bp8D,GAI1B,IAAIuoB,EAEFA,EADEvoB,EAAQ8F,wBAAwB+3C,EACvB79C,EAAQ8F,aAAald,KAErBoX,EAAQ8F,aAKrB,MAFe,iCAAHpT,OAAoC61B,EAAQ,4CAAA71B,OAA2CsN,EAAQq8D,YAAW,KAGxH,GC/SE,MAAOC,WAA+B9d,EAI1Cv2D,WAAAA,CACUs0E,EACAC,GAERt0E,QAHQ,KAAAq0E,cAAAA,EACA,KAAAC,eAAAA,EALH,KAAAz9C,OAAgD,EAQvD,CAEO09C,WAAAA,IACLj7D,EAAAA,EAAAA,IAAQsD,EAAAA,EAAAA,GAAO/X,KAAKwvE,eAAiB32D,IACnC7Y,KAAK2vE,aAAe92D,EACpBA,EAAKxb,OAAO2C,OAEhB,CAEO2xD,gBAAAA,CAAiB/zD,GACtB,MAAM06B,EAAMt4B,KAAKwvE,cAAc5xE,EAAKyzD,iBAEpC,GAAK/4B,EAYH16B,EAAKmQ,eAAiBuqB,MAZd,CACR,MAAM++B,EAAMr3D,KAAKyvE,eAAe7B,uBAC9B5tE,KAAK2vE,aACL/xE,GAEFoC,KAAKgyB,OAAO7xB,KAAK,CACfgL,QAASksD,EACT1rD,KAAMikE,GAA0BC,uBAChCr0C,SAAUx7B,KAAK2vE,aAAa9zE,KAC5Bi0E,kBAAmBlyE,EAAKyzD,iB,CAK9B,E,4BClCF,SAXA,SAAyBhvD,EAAO0tE,EAAQznE,EAAU0nE,GAIhD,IAHA,IAAIznE,GAAS,EACTtM,EAAkB,MAAToG,EAAgB,EAAIA,EAAMpG,SAE9BsM,EAAQtM,GAAQ,CACvB,IAAI6C,EAAQuD,EAAMkG,GAClBwnE,EAAOC,EAAalxE,EAAOwJ,EAASxJ,GAAQuD,EAC9C,CACA,OAAO2tE,CACT,ECCA,SAPA,SAAwB3nE,EAAY0nE,EAAQznE,EAAU0nE,GAIpD,OAHAvnE,EAAAA,EAAAA,GAASJ,EAAY,SAASvJ,EAAO4J,EAAKL,GACxC0nE,EAAOC,EAAalxE,EAAOwJ,EAASxJ,GAAQuJ,EAC9C,GACO2nE,CACT,ECIA,SATA,SAA0BD,EAAQE,GAChC,OAAO,SAAS5nE,EAAYC,GAC1B,IAAIkhB,GAAOzqB,EAAAA,EAAAA,GAAQsJ,GAAc6nE,GAAkBC,GAC/CH,EAAcC,EAAcA,IAAgB,CAAC,EAEjD,OAAOzmD,EAAKnhB,EAAY0nE,GAAQ19D,EAAAA,EAAAA,GAAa/J,EAAU,GAAI0nE,EAC7D,CACF,EChBA,IAGI7qE,GAHcjG,OAAOgG,UAGQC,eAiCjC,SARcirE,GAAiB,SAASpuE,EAAQlD,EAAO4J,GACjDvD,GAAe/C,KAAKJ,EAAQ0G,GAC9B1G,EAAO0G,GAAKvI,KAAKrB,IAEjBuxE,EAAAA,GAAAA,GAAgBruE,EAAQ0G,EAAK,CAAC5J,GAElC,GCAA,SAVA,SAAmBuD,EAAOS,EAAGuG,GAC3B,IAAIpN,EAAkB,MAAToG,EAAgB,EAAIA,EAAMpG,OACvC,OAAKA,GAGL6G,EAAKuG,QAAehL,IAANyE,EAAmB,GAAI+sD,EAAAA,EAAAA,GAAU/sD,GAExCgtD,EAAUztD,EAAO,GADxBS,EAAI7G,EAAS6G,GACkB,EAAI,EAAIA,IAJ9B,EAKX,ECHM,MAAgBwtE,WAAyCvd,GAU7D73D,WAAAA,CACY06D,EACA/vD,GAEV1K,QAHU,KAAAy6D,QAAAA,EACA,KAAA/vD,KAAAA,EAXF,KAAA0qE,iBAAgC,GAIhC,KAAAC,mBAAqB,GACrB,KAAAC,yBAA2B,EAC3B,KAAA3W,OAAQ,EACR,KAAA4W,eAAgB,CAO1B,CAEA5a,YAAAA,GAGE,GAFA91D,KAAK85D,OAAQ,EAET95D,KAAK6F,KAAK8qE,UAAU,KAAO3wE,KAAK41D,QAAQ/5D,KAC1C,MAAM6E,MAAM,uDAcd,OAVAV,KAAK2wE,WAAYnM,EAAAA,EAAAA,GAAMxkE,KAAK6F,KAAK8qE,WAAWC,UAC5C5wE,KAAK6wE,iBAAkBrM,EAAAA,EAAAA,GAAMxkE,KAAK6F,KAAKgrE,iBAAiBD,UAGxD5wE,KAAK2wE,UAAU52D,MACf/Z,KAAK6wE,gBAAgB92D,MAErB/Z,KAAK8wE,qBACL9wE,KAAKgzD,KAAKhzD,KAAK41D,SAER51D,KAAKuwE,gBACd,CAEAvd,IAAAA,CACEn6C,GAC4B,IAA5Bo6C,EAAA70D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAA0B,GAGrB4B,KAAK85D,OACR3+D,MAAM63D,KAAKn6C,EAAMo6C,EAErB,CAEAG,WAAAA,CACES,EACAX,EACAD,GAGA,GACEY,EAAQ9lD,eAAelS,OAASmE,KAAKwwE,oBACrC3c,EAAQ5kD,MAAQjP,KAAKywE,yBACrB,CACA,MAAMva,EAAWhD,EAASvtD,OAAOstD,GACjCjzD,KAAK8wE,qBACL9wE,KAAKgzD,KAAKa,EAAQ9lD,eAAqBmoD,E,CAE3C,CAEA4a,kBAAAA,IAEMtvE,EAAAA,EAAAA,GAAQxB,KAAK2wE,YAGf3wE,KAAKwwE,mBAAqB,GAC1BxwE,KAAKywE,yBAA2B,EAChCzwE,KAAK0wE,eAAgB,IAErB1wE,KAAKwwE,mBAAqBxwE,KAAK2wE,UAAU52D,MACzC/Z,KAAKywE,yBAA2BzwE,KAAK6wE,gBAAgB92D,MAEzD,EAGI,MAAOg3D,WAA6BT,GAIxCp1E,WAAAA,CACE06D,EACU/vD,GAEV1K,MAAMy6D,EAAS/vD,GAFL,KAAAA,KAAAA,EALJ,KAAAmrE,iBAAmB,GACnB,KAAAC,uBAAyB,EAO/BjxE,KAAKgxE,iBAAmBhxE,KAAK6F,KAAKqrE,QAAQr1E,KAC1CmE,KAAKixE,uBAAyBjxE,KAAK6F,KAAKsrE,iBAC1C,CAEA9d,YAAAA,CACEl/B,EACA++B,EACAD,GAEA,GACEjzD,KAAK0wE,eACLv8C,EAASxmB,aAAa9R,OAASmE,KAAKgxE,kBACpC78C,EAASllB,MAAQjP,KAAKixE,yBACrBjxE,KAAK85D,MACN,CACA,MAAM5D,EAAWhD,EAASvtD,OAAOstD,GAC3Bme,EAAW,IAAIpgB,EAAY,CAAEviD,WAAYynD,IAC/Cl2D,KAAKuwE,iBAAmB//D,GAAM4gE,GAC9BpxE,KAAK85D,OAAQ,C,CAEjB,EAeI,MAAOuX,WAAkDte,GAO7D73D,WAAAA,CACYo2E,EACA1lE,GAEVzQ,QAHU,KAAAm2E,QAAAA,EACA,KAAA1lE,WAAAA,EARF,KAAA5J,OAAgC,CACxC6U,WAAOxY,EACPuN,gBAAYvN,EACZkzE,iBAAalzE,EAQf,CAEAy3D,YAAAA,GAEE,OADA91D,KAAKgzD,KAAKhzD,KAAKsxE,SACRtxE,KAAKgC,MACd,EAGI,MAAOwvE,WAAoCH,GAC/C1d,QAAAA,CACEW,EACApB,EACAD,GAEA,GAAIqB,EAASrlD,MAAQjP,KAAK4L,WAAY,CACpC,MAAM6lE,EAAiBC,GAAOxe,EAASvtD,OAAOstD,IAC9CjzD,KAAKgC,OAAOuvE,iBAAiClzE,IAAnBozE,EACtBA,aAA0BhkE,IAC5BzN,KAAKgC,OAAO6U,MAAQ46D,EAAe9jE,aACnC3N,KAAKgC,OAAO4J,WAAa6lE,EAAexiE,I,MAG1C9T,MAAMw4D,SAASW,EAAUpB,EAAUD,EAEvC,EAGI,MAAO0e,WAAuCN,GAClD3d,WAAAA,CACEc,EACAtB,EACAD,GAEA,GAAIuB,EAAYvlD,MAAQjP,KAAK4L,WAAY,CACvC,MAAMgmE,EAAoBF,GAAOxe,EAASvtD,OAAOstD,IACjDjzD,KAAKgC,OAAOuvE,iBAAoClzE,IAAtBuzE,EACtBA,aAA6BnkE,IAC/BzN,KAAKgC,OAAO6U,MAAQ+6D,EAAkBjkE,aACtC3N,KAAKgC,OAAO4J,WAAagmE,EAAkB3iE,I,MAG7C9T,MAAMu4D,YAAYc,EAAatB,EAAUD,EAE7C,EAGI,MAAO4e,WAA0CR,GACrD7d,cAAAA,CACES,EACAf,EACAD,GAEA,GAAIgB,EAAehlD,MAAQjP,KAAK4L,WAAY,CAC1C,MAAMkmE,EAAuBJ,GAAOxe,EAASvtD,OAAOstD,IACpDjzD,KAAKgC,OAAOuvE,iBAAuClzE,IAAzByzE,EACtBA,aAAgCrkE,IAClCzN,KAAKgC,OAAO6U,MAAQi7D,EAAqBnkE,aACzC3N,KAAKgC,OAAO4J,WAAakmE,EAAqB7iE,I,MAGhD9T,MAAMq4D,eAAeS,EAAgBf,EAAUD,EAEnD,EAII,MAAO8e,WAA6CV,GACxD5d,iBAAAA,CACEue,EACA9e,EACAD,GAEA,GAAI+e,EAAkB/iE,MAAQjP,KAAK4L,WAAY,CAC7C,MAAMqmE,EAAoCP,GACxCxe,EAASvtD,OAAOstD,IAElBjzD,KAAKgC,OAAOuvE,iBAAoDlzE,IAAtC4zE,EACtBA,aAA6CxkE,IAC/CzN,KAAKgC,OAAO6U,MAAQo7D,EAAkCtkE,aACtD3N,KAAKgC,OAAO4J,WAAaqmE,EAAkChjE,I,MAG7D9T,MAAMs4D,kBAAkBue,EAAmB9e,EAAUD,EAEzD,EAQI,SAAUif,GACdC,EACAC,GAC0B,IAA1B/E,EAAAjvE,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAwB,GAGxBivE,GAAW7I,EAAAA,EAAAA,GAAM6I,GACjB,IAAIrrE,EAAmC,GACnCzB,EAAI,EAQR,SAAS8xE,EAAuB5jE,GAC9B,MAAMkhB,EAAeuiD,GACDzjE,EANL9I,OAAOwtD,EAAKgf,EAAW5xE,EAAI,IAOxC6xE,EACA/E,GAEF,OAAOrrE,EAAO2D,OAAOgqB,EACvB,CASA,KAAO09C,EAASpxE,OAASm2E,GAAa7xE,EAAI4xE,EAAUl2E,QAAQ,CAC1D,MAAM4c,EAAOs5D,EAAU5xE,GAGvB,GAAIsY,aAAgBm4C,EAClB,OAAOqhB,EAAuBx5D,EAAKpK,YAC9B,GAAIoK,aAAgBjL,EACzB,OAAOykE,EAAuBx5D,EAAKpK,YAC9B,GAAIoK,aAAgBjK,EACzB5M,EAASqwE,EAAuBx5D,EAAKpK,gBAChC,IAAIoK,aAAgBpJ,EAAqB,CAM9C,OAAO4iE,EALQx5D,EAAKpK,WAAW9I,OAAO,CACpC,IAAIuJ,EAAW,CACbT,WAAYoK,EAAKpK,e,CAIhB,GAAIoK,aAAgBhJ,EAAkC,CAS3D,OAAOwiE,EARQ,CACb,IAAIrhB,EAAY,CAAEviD,WAAYoK,EAAKpK,aACnC,IAAIS,EAAW,CACbT,WAAY,CAAC,IAAIhB,EAAS,CAAEE,aAAckL,EAAKtJ,aAAc5J,OACtDkT,EAAKpK,e,CAKX,GAAIoK,aAAgBvJ,EAAyB,CAClD,MAAMgjE,EAASz5D,EAAKpK,WAAW9I,OAAO,CACpC,IAAIuJ,EAAW,CACbT,WAAY,CAAC,IAAIhB,EAAS,CAAEE,aAAckL,EAAKtJ,aAAc5J,OACtDkT,EAAKpK,gBAIhBzM,EAASqwE,EAAuBC,E,MAC3B,GAAIz5D,aAAgB3J,EAAY,CACrC,MAAMojE,EAASz5D,EAAKpK,WAAW9I,OAAO,CACpC,IAAIuJ,EAAW,CACbT,WAAYoK,EAAKpK,eAGrBzM,EAASqwE,EAAuBC,E,KAC3B,IAAIz5D,aAAgBzK,EASzB,OARAqG,EAAAA,EAAAA,GAAQoE,EAAKpK,WAAa4F,KAIY,KAAhC7S,EAAAA,EAAAA,GAAQ6S,EAAQ5F,cAClBzM,EAASqwE,EAAuBh+D,EAAQ5F,eAGrCzM,EACF,KAAI6W,aAAgBpL,GAGzB,MAAM/M,MAAM,wBAFZ2sE,EAASltE,KAAK0Y,EAAKlL,a,EAKrBpN,G,CAOF,OALAyB,EAAO7B,KAAK,CACVoyE,YAAalF,EACbmF,UAAWrf,EAAKgf,EAAW5xE,KAGtByB,CACT,CASM,SAAUywE,GACdC,EACApG,EACAqG,EACAC,GAEA,MAAMC,EAAyB,qBAEzBC,EAAwB,CAACD,GACzBE,EAAwB,mBAC9B,IAAIC,GAAoB,EAExB,MAAMC,EAAoB3G,EAAYrwE,OAChCi3E,EAA2BD,EAAoBL,EAAe,EAE9D5wE,EAAwC,GAExCmxE,EAAkC,GAQxC,IAPAA,EAAchzE,KAAK,CACjB8O,KAAM,EACNmkE,IAAKV,EACL/B,UAAW,GACXE,gBAAiB,OAGXrvE,EAAAA,EAAAA,GAAQ2xE,IAAgB,CAC9B,MAAM9F,EAAW8F,EAAcp5D,MAG/B,GAAIszD,IAAa0F,EAAkB,CAE/BC,IACAviE,EAAAA,GAAAA,GAAK0iE,GAAgBlkE,KAAOikE,GAG5BC,EAAcp5D,MAEhB,Q,CAGF,MAAMs5D,EAAUhG,EAAS+F,IACnBn9C,EAAUo3C,EAASp+D,IACnBqkE,EAAgBjG,EAASsD,UACzB4C,EAAsBlG,EAASwD,gBAGrC,IAAIrvE,EAAAA,EAAAA,GAAQ6xE,GACV,SAGF,MAAMx6D,EAAOw6D,EAAQ,GAErB,GAAIx6D,IAASg6D,EAAmB,CAC9B,MAAMW,EAAW,CACfvkE,IAAKgnB,EACLm9C,IAAKjgB,EAAKkgB,GACV1C,UAAW8C,GAAUH,GACrBzC,gBAAiB4C,GAAUF,IAE7BJ,EAAchzE,KAAKqzE,E,MACd,GAAI36D,aAAgBpL,EAEzB,GAAIwoB,EAAUg9C,EAAoB,EAAG,CACnC,MAAMS,EAAUz9C,EAAU,EAE1B,GAAI08C,EADgBrG,EAAYoH,GACH76D,EAAKlL,cAAe,CAC/C,MAAM6lE,EAAW,CACfvkE,IAAKykE,EACLN,IAAKjgB,EAAKkgB,GACV1C,UAAW2C,EACXzC,gBAAiB0C,GAEnBJ,EAAchzE,KAAKqzE,E,MAGhB,IAAIv9C,IAAYg9C,EAAoB,EAUzC,MAAMvyE,MAAM,wBARZsB,EAAO7B,KAAK,CACVwzE,cAAe96D,EAAKlL,aACpBimE,oBAAqB/6D,EAAK5J,IAC1B0hE,UAAW2C,EACXzC,gBAAiB0C,IAEnBP,GAAoB,C,MAIjB,GAAIn6D,aAAgBjL,EAAa,CACtC,MAAMimE,GAAerP,EAAAA,EAAAA,GAAM8O,GAC3BO,EAAa1zE,KAAK0Y,EAAKw4C,iBAEvB,MAAMyiB,GAAqBtP,EAAAA,EAAAA,GAAM+O,GACjCO,EAAmB3zE,KAAK0Y,EAAK5J,KAE7B,MAAMukE,EAAW,CACfvkE,IAAKgnB,EACLm9C,IAAKv6D,EAAKpK,WAAW9I,OAAOmtE,EAAuB3f,EAAKkgB,IACxD1C,UAAWkD,EACXhD,gBAAiBiD,GAEnBX,EAAchzE,KAAKqzE,E,MACd,GAAI36D,aAAgBjK,EAAQ,CAEjC,MAAMmlE,EAAkB,CACtB9kE,IAAKgnB,EACLm9C,IAAKjgB,EAAKkgB,GACV1C,UAAW2C,EACXzC,gBAAiB0C,GAEnBJ,EAAchzE,KAAK4zE,GAEnBZ,EAAchzE,KAAK4yE,GAEnB,MAAMiB,EAAe,CACnB/kE,IAAKgnB,EACLm9C,IAAKv6D,EAAKpK,WAAW9I,OAAOwtD,EAAKkgB,IACjC1C,UAAW2C,EACXzC,gBAAiB0C,GAEnBJ,EAAchzE,KAAK6zE,E,MACd,GAAIn7D,aAAgBpJ,EAAqB,CAE9C,MAAMwkE,EAAkB,IAAI/kE,EAAW,CACrCT,WAAYoK,EAAKpK,WACjBQ,IAAK4J,EAAK5J,MAGNukE,EAAW,CACfvkE,IAAKgnB,EACLm9C,IAHcv6D,EAAKpK,WAAW9I,OAAO,CAACsuE,GAAkB9gB,EAAKkgB,IAI7D1C,UAAW2C,EACXzC,gBAAiB0C,GAEnBJ,EAAchzE,KAAKqzE,E,MACd,GAAI36D,aAAgBhJ,EAAkC,CAE3D,MAAMqkE,EAAgB,IAAIzmE,EAAS,CACjCE,aAAckL,EAAKtJ,YAEf0kE,EAAkB,IAAI/kE,EAAW,CACrCT,WAAY,CAAMylE,GAAevuE,OAAOkT,EAAKpK,YAC7CQ,IAAK4J,EAAK5J,MAGNukE,EAAW,CACfvkE,IAAKgnB,EACLm9C,IAHcv6D,EAAKpK,WAAW9I,OAAO,CAACsuE,GAAkB9gB,EAAKkgB,IAI7D1C,UAAW2C,EACXzC,gBAAiB0C,GAEnBJ,EAAchzE,KAAKqzE,E,MACd,GAAI36D,aAAgBvJ,EAAyB,CAElD,MAAMykE,EAAkB,CACtB9kE,IAAKgnB,EACLm9C,IAAKjgB,EAAKkgB,GACV1C,UAAW2C,EACXzC,gBAAiB0C,GAEnBJ,EAAchzE,KAAK4zE,GAEnBZ,EAAchzE,KAAK4yE,GAEnB,MAAMmB,EAAgB,IAAIzmE,EAAS,CACjCE,aAAckL,EAAKtJ,YAEf4kE,EAAgB,IAAIjlE,EAAW,CACnCT,WAAY,CAAMylE,GAAevuE,OAAOkT,EAAKpK,YAC7CQ,IAAK4J,EAAK5J,MAGN+kE,EAAe,CACnB/kE,IAAKgnB,EACLm9C,IAHcv6D,EAAKpK,WAAW9I,OAAO,CAACwuE,GAAgBhhB,EAAKkgB,IAI3D1C,UAAW2C,EACXzC,gBAAiB0C,GAEnBJ,EAAchzE,KAAK6zE,E,MACd,GAAIn7D,aAAgB3J,EAAY,CAErC,MAAM6kE,EAAkB,CACtB9kE,IAAKgnB,EACLm9C,IAAKjgB,EAAKkgB,GACV1C,UAAW2C,EACXzC,gBAAiB0C,GAEnBJ,EAAchzE,KAAK4zE,GAEnBZ,EAAchzE,KAAK4yE,GAGnB,MAAMoB,EAAgB,IAAIjlE,EAAW,CACnCT,WAAYoK,EAAKpK,WACjBQ,IAAK4J,EAAK5J,MAGN+kE,EAAe,CACnB/kE,IAAKgnB,EACLm9C,IAHcv6D,EAAKpK,WAAW9I,OAAO,CAACwuE,GAAgBhhB,EAAKkgB,IAI3D1C,UAAW2C,EACXzC,gBAAiB0C,GAEnBJ,EAAchzE,KAAK6zE,E,MACd,GAAIn7D,aAAgBzK,EAEzB,IAAK,IAAI7N,EAAIsY,EAAKpK,WAAWxS,OAAS,EAAGsE,GAAK,EAAGA,IAAK,CACpD,MACM6zE,EAAc,CAClBnlE,IAAKgnB,EACLm9C,IAHmBv6D,EAAKpK,WAAWlO,GAGtBkO,WAAW9I,OAAOwtD,EAAKkgB,IACpC1C,UAAW2C,EACXzC,gBAAiB0C,GAEnBJ,EAAchzE,KAAKi0E,GACnBjB,EAAchzE,KAAK4yE,E,MAEhB,GAAIl6D,aAAgBm4C,EACzBmiB,EAAchzE,KAAK,CACjB8O,IAAKgnB,EACLm9C,IAAKv6D,EAAKpK,WAAW9I,OAAOwtD,EAAKkgB,IACjC1C,UAAW2C,EACXzC,gBAAiB0C,QAEd,MAAI16D,aAAgBi4C,GAMzB,MAAMpwD,MAAM,wBAJZyyE,EAAchzE,KACZk0E,GAAmBx7D,EAAMod,EAASq9C,EAAeC,G,EAMvD,OAAOvxE,CACT,CAEA,SAASqyE,GACP/C,EACAr7C,EACAq9C,EACAC,GAEA,MAAMM,GAAerP,EAAAA,EAAAA,GAAM8O,GAC3BO,EAAa1zE,KAAKmxE,EAAQz1E,MAE1B,MAAMy4E,GAAyB9P,EAAAA,EAAAA,GAAM+O,GAIrC,OAFAe,EAAuBn0E,KAAK,GAErB,CACL8O,IAAKgnB,EACLm9C,IAAK9B,EAAQ7iE,WACbkiE,UAAWkD,EACXhD,gBAAiByD,EAErB,CCjlBO,IAAKC,GASN,SAAUnjE,GACdyH,GAGA,GAAIA,aAAgBjK,GAAmB,WAATiK,EAC5B,OAAO07D,GAAUC,OACZ,GAAI37D,aAAgB3J,GAAuB,eAAT2J,EACvC,OAAO07D,GAAUE,WACZ,GACL57D,aAAgBpJ,GACP,wBAAToJ,EAEA,OAAO07D,GAAUG,qBACZ,GACL77D,aAAgBhJ,GACP,qCAATgJ,EAEA,OAAO07D,GAAUI,oCACZ,GACL97D,aAAgBvJ,GACP,4BAATuJ,EAEA,OAAO07D,GAAUK,0BACZ,GAAI/7D,aAAgBzK,GAAwB,gBAATyK,EACxC,OAAO07D,GAAUM,YAEjB,MAAMn0E,MAAM,uBAEhB,CAEM,SAAUwT,GAAkBjB,GAMhC,MAAM,WAAErH,EAAU,KAAElQ,EAAI,SAAE0Y,EAAQ,aAAED,GAAiBlB,EAC/CtH,EAAOyF,GAAYgD,GACzB,OAAIzI,IAAS4oE,GAAUM,YACdC,GAAuBlpE,EAAYlQ,EAAMyY,GAEzC4gE,GACLnpE,EACAlQ,EACAiQ,EACAwI,EAGN,CAwEM,SAAU6gE,GACdzmE,EACAuF,EACA4F,EACA3F,GAEA,MAAMkhE,EAAY1mE,EAAKtS,OACjBi5E,EAA0B7xD,GAAM9U,EAAO8F,GACpCgP,GAAMhP,EAAUg5D,GACM,IAApBA,EAASpxE,SAKpB,GAAI6X,EAIF,OAAO,SAELgB,GAKA,MAAMlC,GAAwCpE,EAAAA,EAAAA,GAC5CsG,EACCT,GAAYA,EAAQc,MAGvB,IAAK,IAAI1S,EAAI,EAAGA,EAAIwyE,EAAWxyE,IAAK,CAClC,MAAM4R,EAAU9F,EAAK9L,GACf0yE,EAAiB9gE,EAAQpY,OAEzBm5E,EAAgBxiE,EAAWnQ,GACjC,QAAsBpE,IAAlB+2E,IAA4D,IAA7BA,EAAchzE,KAAKpC,MAItDwzE,EAAU,IAAK,IAAItK,EAAI,EAAGA,EAAIiM,EAAgBjM,IAAK,CACjD,MAAMmE,EAAWh5D,EAAQ60D,GACnBmM,EAAiBhI,EAASpxE,OAChC,IAAK,IAAIsE,EAAI,EAAGA,EAAI80E,EAAgB90E,IAAK,CACvC,MAAMwU,EAAY/U,KAAKgV,GAAGzU,EAAI,GAC9B,IAA6C,IAAzCmZ,EAAa3E,EAAWs4D,EAAS9sE,IAGnC,SAASizE,C,CAKb,OAAO/wE,C,EAOb,EACK,GAAIyyE,IAA4BnhE,EAAsB,CAG3D,MAAMuhE,GAAkB9mE,EAAAA,EAAAA,GAAID,EAAO8F,IAC1BkB,EAAAA,GAAAA,GAAQlB,IAGXE,GAAcC,EAAAA,GAAAA,GAClB8gE,EACA,CAACtzE,EAAQqS,EAASpF,MAChBwF,EAAAA,EAAAA,GAAQJ,EAAUK,KACXsB,EAAAA,EAAAA,GAAIhU,EAAQ0S,EAAYC,gBAC3B3S,EAAO0S,EAAYC,cAAiB1F,IAEtCwF,EAAAA,EAAAA,GAAQC,EAAYE,gBAAmBC,KAChCmB,EAAAA,EAAAA,GAAIhU,EAAQ6S,KACf7S,EAAO6S,GAAqB5F,OAI3BjN,GAET,CAAC,GAMH,OAAO,WACL,MAAM+S,EAAY/U,KAAKgV,GAAG,GAC1B,OAAOT,EAAYQ,EAAUJ,aAC/B,C,CAOA,OAAO,WACL,IAAK,IAAIlS,EAAI,EAAGA,EAAIwyE,EAAWxyE,IAAK,CAClC,MAAM4R,EAAU9F,EAAK9L,GACf0yE,EAAiB9gE,EAAQpY,OAC/Bu3E,EAAU,IAAK,IAAItK,EAAI,EAAGA,EAAIiM,EAAgBjM,IAAK,CACjD,MAAMmE,EAAWh5D,EAAQ60D,GACnBmM,EAAiBhI,EAASpxE,OAChC,IAAK,IAAIsE,EAAI,EAAGA,EAAI80E,EAAgB90E,IAAK,CACvC,MAAMwU,EAAY/U,KAAKgV,GAAGzU,EAAI,GAC9B,IAA6C,IAAzCmZ,EAAa3E,EAAWs4D,EAAS9sE,IAGnC,SAASizE,C,CAKb,OAAO/wE,C,EAOb,CAEJ,CAEM,SAAU8yE,GACdpkE,EACAuI,EACA3F,GAEA,MAAMmhE,EAA0B7xD,GAAMlS,EAAMk8D,GACf,IAApBA,EAASpxE,QAGZu5E,EAAarkE,EAAIlV,OAIvB,GAAIi5E,IAA4BnhE,EAAsB,CACpD,MAAMuB,GAAoBC,EAAAA,GAAAA,GAAQpE,GAElC,GAC+B,IAA7BmE,EAAkBrZ,SAClBuF,EAAAA,EAAAA,GAAc8T,EAAkB,GAAIV,iBACpC,CACA,MACMY,EADoBF,EAAkB,GACYX,aAExD,OAAO,WACL,OAAO3U,KAAKgV,GAAG,GAAGL,eAAiBa,CACrC,C,CACK,CACL,MAAMjB,GAAcC,EAAAA,GAAAA,GAClBc,EACA,CAACtT,EAAQ0S,EAAazF,KACpBjN,EAAO0S,EAAYC,eAAiB,GACpCF,EAAAA,EAAAA,GAAQC,EAAYE,gBAAmBC,IACrC7S,EAAO6S,IAAqB,IAEvB7S,GAET,IAGF,OAAO,WACL,MAAM+S,EAAY/U,KAAKgV,GAAG,GAC1B,OAA+C,IAAxCT,EAAYQ,EAAUJ,aAC/B,C,EAGF,OAAO,WACL6+D,EAAU,IAAK,IAAItK,EAAI,EAAGA,EAAIsM,EAAYtM,IAAK,CAC7C,MAAMmE,EAAWl8D,EAAI+3D,GACfmM,EAAiBhI,EAASpxE,OAChC,IAAK,IAAIsE,EAAI,EAAGA,EAAI80E,EAAgB90E,IAAK,CACvC,MAAMwU,EAAY/U,KAAKgV,GAAGzU,EAAI,GAC9B,IAA6C,IAAzCmZ,EAAa3E,EAAWs4D,EAAS9sE,IAGnC,SAASizE,C,CAIb,OAAO,C,CAIT,OAAO,CACT,CAEJ,EAhUA,SAAYe,GACVA,EAAAA,EAAA,mBACAA,EAAAA,EAAA,2BACAA,EAAAA,EAAA,+CACAA,EAAAA,EAAA,6EACAA,EAAAA,EAAA,yDACAA,EAAAA,EAAA,4BACD,CAPD,CAAYA,KAAAA,GAAS,KAkUrB,MAAMkB,WAAmC1iB,GAGvC73D,WAAAA,CACU06D,EACA8f,EACAC,GAERx6E,QAJQ,KAAAy6D,QAAAA,EACA,KAAA8f,iBAAAA,EACA,KAAAC,eAAAA,CAGV,CAEA7f,YAAAA,GAEE,OADA91D,KAAKgzD,KAAKhzD,KAAK41D,SACR51D,KAAK41E,OACd,CAEQC,aAAAA,CACNj4E,EACAk4E,EACA5iB,EACAD,GAEA,OACEr1D,EAAKqR,MAAQjP,KAAK01E,kBAClB11E,KAAK21E,iBAAmBG,IAExB91E,KAAK41E,QAAU1iB,EAASvtD,OAAOstD,IACxB,EAIX,CAEAM,UAAAA,CACES,EACAd,EACAD,GAEKjzD,KAAK61E,cAAc7hB,EAAYugB,GAAUC,OAAQthB,EAAUD,IAC9D93D,MAAMo4D,WAAWS,EAAYd,EAAUD,EAE3C,CAEAO,cAAAA,CACES,EACAf,EACAD,GAGGjzD,KAAK61E,cACJ5hB,EACAsgB,GAAUG,qBACVxhB,EACAD,IAGF93D,MAAMo4D,WAAWU,EAAgBf,EAAUD,EAE/C,CAEAQ,iBAAAA,CACEU,EACAjB,EACAD,GAGGjzD,KAAK61E,cACJ1hB,EACAogB,GAAUI,oCACVzhB,EACAD,IAGF93D,MAAMo4D,WAAWY,EAAmBjB,EAAUD,EAElD,CAEAU,QAAAA,CACEW,EACApB,EACAD,GAGGjzD,KAAK61E,cAAcvhB,EAAUigB,GAAUE,WAAYvhB,EAAUD,IAE9D93D,MAAMo4D,WAAWe,EAAUpB,EAAUD,EAEzC,CAEAS,WAAAA,CACEc,EACAtB,EACAD,GAGGjzD,KAAK61E,cACJrhB,EACA+f,GAAUK,0BACV1hB,EACAD,IAGF93D,MAAMo4D,WAAWiB,EAAatB,EAAUD,EAE5C,EAMF,MAAM8iB,WAAsCtkB,EAG1Cv2D,WAAAA,CACUw6E,EACAC,EACAK,GAER76E,QAJQ,KAAAu6E,iBAAAA,EACA,KAAAC,eAAAA,EACA,KAAAK,UAAAA,EALH,KAAAh0E,OAAwB,EAQ/B,CAEQ6zE,aAAAA,CACNj4E,EACAq4E,GAGEr4E,EAAKqR,MAAQjP,KAAK01E,kBAClB11E,KAAK21E,iBAAmBM,QACJ53E,IAAnB2B,KAAKg2E,WAA2Bp4E,IAASoC,KAAKg2E,YAE/Ch2E,KAAKgC,OAASpE,EAAK6Q,WAEvB,CAEOojD,WAAAA,CAAYj0D,GACjBoC,KAAK61E,cAAcj4E,EAAM22E,GAAUC,OACrC,CAEOviB,eAAAA,CAAgBr0D,GACrBoC,KAAK61E,cAAcj4E,EAAM22E,GAAUE,WACrC,CAEO3iB,wBAAAA,CAAyBl0D,GAC9BoC,KAAK61E,cAAcj4E,EAAM22E,GAAUG,qBACrC,CAEO3iB,qCAAAA,CACLn0D,GAEAoC,KAAK61E,cAAcj4E,EAAM22E,GAAUI,oCACrC,CAEO3iB,4BAAAA,CAA6Bp0D,GAClCoC,KAAK61E,cAAcj4E,EAAM22E,GAAUK,0BACrC,CAEO1iB,gBAAAA,CAAiBt0D,GACtBoC,KAAK61E,cAAcj4E,EAAM22E,GAAUM,YACrC,EAGF,SAASqB,GAAwBrkE,GAC/B,MAAM7P,EAAS,IAAI5B,MAAMyR,GACzB,IAAK,IAAItR,EAAI,EAAGA,EAAIsR,EAAMtR,IACxByB,EAAOzB,GAAK,GAEd,OAAOyB,CACT,CAOA,SAASm0E,GAAetwE,GACtB,IAAImS,EAAO,CAAC,IACZ,IAAK,IAAIzX,EAAI,EAAGA,EAAIsF,EAAK5J,OAAQsE,IAAK,CACpC,MAAMuV,EAAUjQ,EAAKtF,GACf61E,EAAa,GACnB,IAAK,IAAIlN,EAAI,EAAGA,EAAIlxD,EAAK/b,OAAQitE,IAAK,CACpC,MAAMmN,EAAiBr+D,EAAKkxD,GAC5BkN,EAAWj2E,KAAKk2E,EAAiB,IAAMvgE,EAAQnB,cAC/C,IAAK,IAAIlS,EAAI,EAAGA,EAAIqT,EAAQlB,gBAAiB3Y,OAAQwG,IAAK,CACxD,MAAM6zE,EAAsB,IAAMxgE,EAAQlB,gBAAiBnS,GAC3D2zE,EAAWj2E,KAAKk2E,EAAiBC,E,EAGrCt+D,EAAOo+D,C,CAET,OAAOp+D,CACT,CAKA,SAASu+D,GACPC,EACAC,EACAxnE,GAEA,IACE,IAAIynE,EAAa,EACjBA,EAAaF,EAAkBv6E,OAC/By6E,IACA,CAEA,GAAIA,IAAeznE,EACjB,SAEF,MAAM0nE,EAAyBH,EAAkBE,GACjD,IAAK,IAAIE,EAAY,EAAGA,EAAYH,EAAex6E,OAAQ26E,IAAa,CAEtE,IAA0C,IAAtCD,EADcF,EAAeG,IAE/B,OAAO,C,EAKb,OAAO,CACT,CAEM,SAAUC,GACdC,EACA5kE,GAEA,MAAM+B,GAAczF,EAAAA,EAAAA,GAAIsoE,EAAWziE,GACjC69D,GAAkB,CAAC79D,GAAU,IAEzB0iE,EAAcb,GAAwBjiE,EAAYhY,QAClD+6E,GAAaxoE,EAAAA,EAAAA,GAAIyF,EAAck5D,IACnC,MAAM8J,EAAmC,CAAC,EAO1C,OANAxiE,EAAAA,EAAAA,GAAQ04D,EAAe1vE,IACrB,MAAMua,EAAOm+D,GAAe14E,EAAK80E,cACjC99D,EAAAA,EAAAA,GAAQuD,EAAOgyD,IACbiN,EAAKjN,IAAW,MAGbiN,IAET,IAAIC,EAAUjjE,EAGd,IAAK,IAAIkjE,EAAa,EAAGA,GAAcjlE,EAAGilE,IAAc,CACtD,MAAMC,EAAcF,EACpBA,EAAUhB,GAAwBkB,EAAYn7E,QAG9C,IAAK,IAAIo7E,EAAS,EAAGA,EAASD,EAAYn7E,OAAQo7E,IAAU,CAC1D,MAAMC,EAA0BF,EAAYC,GAE5C,IACE,IAAIE,EAAc,EAClBA,EAAcD,EAAwBr7E,OACtCs7E,IACA,CACA,MAAMC,EAAiBF,EAAwBC,GAAahF,YACtDC,EAAY8E,EAAwBC,GAAa/E,UACjDiF,EAAatB,GAAeqB,GAGlC,GAFiBjB,GAAmBS,EAAYS,EAAYJ,KAE5C71E,EAAAA,EAAAA,GAAQgxE,IAAcgF,EAAev7E,SAAWiW,EAAG,CACjE,MAAMwlE,EAAgBX,EAAYM,GAElC,IAAoD,IAAhDM,GAAaD,EAAeF,GAA2B,CACzDE,EAAcv3E,KAAKq3E,GAEnB,IAAK,IAAItO,EAAI,EAAGA,EAAIuO,EAAWx7E,OAAQitE,IAAK,CAC1C,MAAMc,EAAUyN,EAAWvO,GAC3B8N,EAAWK,GAAQrN,IAAW,C,OAK/B,CACH,MAAM4N,EAA6B1F,GACjCM,EACA2E,EAAa,EACbK,GAEFN,EAAQG,GAAUH,EAAQG,GAAQ1xE,OAAOiyE,IAGzCnjE,EAAAA,EAAAA,GAAQmjE,EAA6Bn6E,IACnC,MAAMg6E,EAAatB,GAAe14E,EAAK80E,cACvC99D,EAAAA,EAAAA,GAAQgjE,EAAa/uE,IACnBsuE,EAAWK,GAAQ3uE,IAAO,K,IAQtC,OAAOquE,CACT,CAEM,SAAUjC,GACdlpE,EACAisE,EACA3lE,EACAwiD,GAEA,MAAMzO,EAAU,IAAI8vB,GAClBnqE,EACA2oE,GAAUM,YACVngB,GAGF,OADAmjB,EAAYx6E,OAAO4oD,GACZ4wB,GAAkC5wB,EAAQjkD,OAAQkQ,EAC3D,CAEM,SAAU6iE,GACdnpE,EACAisE,EACAzjE,EACAlC,GAEA,MAAM4lE,EAAmB,IAAI/B,GAC3BnqE,EACAwI,GAEFyjE,EAAYx6E,OAAOy6E,GACnB,MAAMC,EAAYD,EAAiB91E,OAO7Bg2E,EALiB,IAAIvC,GACzBoC,EACAjsE,EACAwI,GAE8B0hD,eAKhC,OAAO+gB,GAAkC,CAHtB,IAAIoB,EAAgB,CAAExpE,WAAYspE,IACnC,IAAIE,EAAgB,CAAExpE,WAAYupE,KAEc9lE,EACpE,CAEM,SAAUylE,GACdO,EACAC,GAEAC,EAAkB,IAAK,IAAI73E,EAAI,EAAGA,EAAI23E,EAAYj8E,OAAQsE,IAAK,CAC7D,MAAM83E,EAAYH,EAAY33E,GAC9B,GAAI83E,EAAUp8E,SAAWk8E,EAAWl8E,OAApC,CAGA,IAAK,IAAIitE,EAAI,EAAGA,EAAImP,EAAUp8E,OAAQitE,IAAK,CACzC,MAAMoP,EAAYH,EAAWjP,GACvBqP,EAAWF,EAAUnP,GAK3B,IAAuB,KAFrBoP,IAAcC,QAC4Cl6E,IAA1Dk6E,EAASrU,mBAAoBoU,EAAU3jE,eAEvC,SAASyjE,C,CAGb,OAAO,C,EAGT,OAAO,CACT,CAkBM,SAAUI,GACdC,GAEA,OAAOp1D,GAAMo1D,EAAiBC,GAC5Br1D,GAAMq1D,EAAiBC,GACrBt1D,GAAMs1D,EAAa9hE,IAAUrV,EAAAA,EAAAA,GAAQqV,EAAMjC,mBAGjD,CCnpBM,SAAUgkE,GACdC,EACAt+B,EACAk1B,EACAH,GAEA,MAAMwJ,GAA4C1/D,EAAAA,GAAAA,GAChDy/D,EACClJ,GA8BL,SACE52D,EACA02D,GAEA,MAAMsJ,EAAmB,IAAIC,GAC7BjgE,EAAa1b,OAAO07E,GACpB,MAAME,EAAqBF,EAAiBG,eAEtCC,EAAmBC,GACvBH,EACAI,IAGIC,EAAkBzoB,EAAOsoB,EAAmBI,GACzCA,EAAUt9E,OAAS,GAGtB+1B,GAASxjB,EAAAA,EAAAA,IAAIuJ,EAAAA,EAAAA,GAAOuhE,GAAcE,IACtC,MAAMC,EAAiBjpE,GAAMgpE,GACvBniB,EAAMoY,EAAe1B,yBACzBh1D,EACAygE,GAEIrL,EAAUr1D,GAAqB2gE,GAC/BC,EAA6C,CACjDvuE,QAASksD,EACT1rD,KAAMikE,GAA0B+J,sBAChCn+C,SAAUziB,EAAald,KACvBsyE,QAASA,EACTviE,WAAY6tE,EAAUxqE,KAGlB2qE,EAAQC,GAA2BJ,GAKzC,OAJIG,IACFF,EAAS7+C,UAAY++C,GAGhBF,IAET,OAAO1nD,CACT,CArEM8nD,CAA6BnK,EAAcF,IAGzCsK,EAqlBR,SACElB,EACAt+B,EACAk1B,GAEA,MAAMz9C,EAAmC,GAEnCgoD,GAAaxrE,EAAAA,EAAAA,GAAI+rC,EAAa0/B,GAAcA,EAAUp+E,MAe5D,OAbA4Y,EAAAA,EAAAA,GAAQokE,EAAY3J,IAClB,MAAMgL,EAAehL,EAASrzE,KAC9B,GAAIyyC,GAAS0rC,EAAYE,GAAe,CACtC,MAAMnX,EAAS0M,EAAenB,4BAA4BY,GAE1Dl9C,EAAO7xB,KAAK,CACVgL,QAAS43D,EACTp3D,KAAMikE,GAA0BuK,gCAChC3+C,SAAU0+C,G,IAKTloD,CACT,CA5mBuCooD,CACnCvB,EACAt+B,EACAk1B,GAGI4K,GAAoBjhE,EAAAA,GAAAA,GAAQy/D,EAAYyB,GAyX1C,SACJvhE,EACA02D,GAEA,MAAM8K,EAAc,IAAIC,GACxBzhE,EAAa1b,OAAOk9E,GACpB,MAAME,EAAMF,EAAYG,aAElB1oD,GAAS5Y,EAAAA,GAAAA,GAAQqhE,EAAME,GACvBA,EAAOlsE,WAAWxS,OAAS,IACtB,CACL,CACEkP,QAASskE,EAAeX,8BAA8B,CACpD/1D,aAAcA,EACd1K,YAAassE,IAEfhvE,KAAMikE,GAA0BgL,cAChCp/C,SAAUziB,EAAald,KACvB+P,WAAY+uE,EAAO1rE,MAIhB,IAIX,OAAO+iB,CACT,CAnZI6oD,CAAoBP,EAAS7K,IAGzBqL,GAAsB1hE,EAAAA,GAAAA,GAAQy/D,EAAYyB,GAkH5C,SACJ5+E,EACAszB,EACA3yB,EACAozE,GAEA,MAAMz9C,EAAS,GACT+oD,GAAcvmE,EAAAA,GAAAA,GAClBwa,EACA,CAAChtB,EAAQs4E,IACHA,EAAQz+E,OAASH,EAAKG,KACjBmG,EAAS,EAEXA,EAET,GAEF,GAAI+4E,EAAc,EAAG,CACnB,MAAMhY,EAAS0M,EAAeJ,4BAA4B,CACxDt2D,aAAcrd,EACd4zE,YAAajzE,IAEf21B,EAAO7xB,KAAK,CACVgL,QAAS43D,EACTp3D,KAAMikE,GAA0BoL,oBAChCx/C,SAAU9/B,EAAKG,M,CAInB,OAAOm2B,CACT,CA/IIipD,CACEX,EACAzB,EACAvJ,EACAG,IAIJ,OAAOqJ,EAAgBnzE,OACrBo0E,EACAM,EACAS,EAEJ,CA4CM,SAAUzB,GACdxgE,GAEA,MAAO,GAAPlT,OAAUmT,GAAqBD,GAAK,OAAAlT,OAClCkT,EAAK5J,IACP,OAAAtJ,OAAMk0E,GAA2BhhE,GACnC,CAEA,SAASghE,GAA2BhhE,GAClC,OAAIA,aAAgBpL,EACXoL,EAAKlL,aAAa9R,KAChBgd,aAAgBjL,EAClBiL,EAAKw4C,gBAEL,EAEX,CAEM,MAAO2nB,WAAsCvnB,EAAnDv2D,WAAAA,G,oBACS,KAAAg+E,eAA8C,EAmCvD,CAjCSvnB,gBAAAA,CAAiBt+B,GACtBrzB,KAAKk5E,eAAe/4E,KAAKkzB,EAC3B,CAEOw+B,WAAAA,CAAYhjD,GACjB7O,KAAKk5E,eAAe/4E,KAAK0O,EAC3B,CAEOmjD,4BAAAA,CAA6BkpB,GAClCl7E,KAAKk5E,eAAe/4E,KAAK+6E,EAC3B,CAEOppB,wBAAAA,CAAyB7hC,GAC9BjwB,KAAKk5E,eAAe/4E,KAAK8vB,EAC3B,CAEO8hC,qCAAAA,CACLopB,GAEAn7E,KAAKk5E,eAAe/4E,KAAKg7E,EAC3B,CAEOlpB,eAAAA,CAAgBliC,GACrB/vB,KAAKk5E,eAAe/4E,KAAK4vB,EAC3B,CAEOmiC,gBAAAA,CAAiBp7B,GACtB92B,KAAKk5E,eAAe/4E,KAAK22B,EAC3B,CAEOq7B,aAAAA,CAAch+B,GACnBn0B,KAAKk5E,eAAe/4E,KAAKg0B,EAC3B,EA4DI,SAAUinD,GACd9J,EACApC,EACAO,GACiB,IAAjB5pE,EAAAzH,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAe,GAEf,MAAM4zB,EAAmC,GACnCqpD,EAAmBC,GAAqBpM,EAASzgE,YACvD,IAAIjN,EAAAA,EAAAA,GAAQ65E,GACV,MAAO,GACF,CACL,MAAM7/C,EAAW81C,EAAQz1E,KACEyyC,GAAS+sC,EAAkB/J,IAEpDt/C,EAAO7xB,KAAK,CACVgL,QAASskE,EAAeV,wBAAwB,CAC9Ch2D,aAAcu4D,EACdrC,kBAAmBppE,IAErB8F,KAAMikE,GAA0B2L,eAChC//C,SAAUA,IAMd,MAAMggD,EAAiB9c,GAAW2c,EAAkBx1E,EAAKF,OAAO,CAAC2rE,KAC3DmK,GAAsBriE,EAAAA,GAAAA,GAAQoiE,EAAiBE,IACnD,MAAMpW,GAAUd,EAAAA,EAAAA,GAAM3+D,GAEtB,OADAy/D,EAAQnlE,KAAKu7E,GACNN,GACL9J,EACAoK,EACAjM,EACAnK,KAIJ,OAAOtzC,EAAOrsB,OAAO81E,E,CAEzB,CAEM,SAAUH,GAAqB7sE,GACnC,IAAIzM,EAAiB,GACrB,IAAIR,EAAAA,EAAAA,GAAQiN,GACV,OAAOzM,EAET,MAAMy3E,EAAYjpE,GAAM/B,GAGxB,GAAIgrE,aAAqB7rE,EACvB5L,EAAO7B,KAAKs5E,EAAU1rE,qBACjB,GACL0rE,aAAqBxB,GACrBwB,aAAqB7qE,GACrB6qE,aAAqBhqE,GACrBgqE,aAAqB5pE,GACrB4pE,aAAqBnqE,GACrBmqE,aAAqBvqE,EAErBlN,EAASA,EAAO2D,OACd21E,GAAoC7B,EAAUhrE,kBAE3C,GAAIgrE,aAAqBrrE,EAE9BpM,GAASuT,EAAAA,GAAAA,IACP/G,EAAAA,EAAAA,GAAIirE,EAAUhrE,WAAaktE,GACzBL,GAAuCK,EAAYltE,mBAGlD,KAAIgrE,aAAqBhsE,GAG9B,MAAM/M,MAAM,wBAGd,MAAMk7E,EAAkBhpB,GAAe6mB,GACjCoC,EAAUptE,EAAWxS,OAAS,EACpC,GAAI2/E,GAAmBC,EAAS,CAC9B,MAAM7/B,EAAOmX,EAAK1kD,GAClB,OAAOzM,EAAO2D,OAAO21E,GAAqBt/B,G,CAE1C,OAAOh6C,CAEX,CAEA,MAAMw4E,WAAoB/oB,EAA1Bv2D,WAAAA,G,oBACS,KAAAw/E,aAA8B,EAKvC,CAHSxoB,gBAAAA,CAAiBt0D,GACtBoC,KAAK06E,aAAav6E,KAAKvC,EACzB,EA8CI,SAAU8V,GACdqF,EACA+iE,EACArM,GAEA,MAAM8K,EAAc,IAAIC,GACxBzhE,EAAa1b,OAAOk9E,GACpB,IAAIE,EAAMF,EAAYG,aAItBD,EAAM79C,GAAO69C,EAAME,IAAwC,IAA7BA,EAAO1pB,mBAErC,MAAMj/B,GAAS5Y,EAAAA,GAAAA,GAAQqhE,EAAME,IAC3B,MAAMoB,EAAiBpB,EAAO1rE,IACxB+sE,EAAqBrB,EAAOxmE,cAAgB2nE,EAC5CnsD,EAAemlD,GACnBiH,EACAhjE,EACAijE,EACArB,GAEIsB,EAmHV,SACEtsD,EACAthB,EACA3S,EACA+zE,GAEA,MAAMyM,EAAmC,GACnCC,GAAuB3nE,EAAAA,GAAAA,GAC3Bmb,EACA,CAAC3tB,EAAQqS,EAASqiE,MAE6C,IAAzDroE,EAAYI,WAAWioE,GAAYzlB,oBAIvCx8C,EAAAA,EAAAA,GAAQJ,EAAUg5D,IAChB,MAAM+O,EAAwB,CAAC1F,IAC/BjiE,EAAAA,EAAAA,GAAQkb,EAAc,CAAC0sD,EAAcC,KAEjC5F,IAAe4F,GACf3E,GAAa0E,EAAchP,KAEmC,IAA9Dh/D,EAAYI,WAAW6tE,GAAiBrrB,mBAExCmrB,EAAsBj8E,KAAKm8E,KAK7BF,EAAsBngF,OAAS,IAC9B07E,GAAauE,EAAqB7O,KAEnC6O,EAAoB/7E,KAAKktE,GACzBrrE,EAAO7B,KAAK,CACVoO,KAAM6tE,EACNv2E,KAAMwnE,OAvBHrrE,GA6BX,IAGIu6E,GAAa/tE,EAAAA,EAAAA,GAAI2tE,EAAuBK,IAC5C,MAAMC,GAAcjuE,EAAAA,EAAAA,GAClBguE,EAAkBjuE,KACjBmoE,GAAeA,EAAa,GAU/B,MAAO,CACLvrE,QARkBskE,EAAehB,+BAA+B,CAChE11D,aAAcrd,EACd2S,YAAaA,EACbiK,iBAAkBmkE,EAClBlkE,WAAYikE,EAAkB32E,OAK9B8F,KAAMikE,GAA0B8M,eAChClhD,SAAU9/B,EAAKG,KACf+P,WAAYyC,EAAYY,IACxB0gB,aAAc6sD,EAAkBjuE,QAIpC,OAAOguE,CACT,CAtLgCI,CAC1BhtD,EACAgrD,EACA5hE,EACA02D,GAEImN,EAkLJ,SACJjtD,EACAthB,EACA3S,EACA+zE,GAGA,MAAMoN,GAAkBroE,EAAAA,GAAAA,GACtBmb,EACA,CAAC3tB,EAAQqS,EAASpF,KAChB,MAAM6tE,GAAkBtuE,EAAAA,EAAAA,GAAI6F,EAAUg5D,IAC7B,CAAEp+D,IAAKA,EAAKpJ,KAAMwnE,KAE3B,OAAOrrE,EAAO2D,OAAOm3E,IAEvB,IAGI9qD,EAASuuC,IACbnnD,EAAAA,GAAAA,GAAQyjE,EAAkBE,IAGxB,IAA0C,IAFlB1uE,EAAYI,WAAWsuE,EAAe9tE,KAE1CgiD,kBAClB,MAAO,GAET,MAAM+rB,EAAYD,EAAe9tE,IAC3Bw2B,EAAas3C,EAAel3E,KAE5Bo3E,GAAmCjtE,EAAAA,GAAAA,GACvC6sE,EACCK,IAEC,OAGI,IADF7uE,EAAYI,WAAWyuE,EAAiBjuE,KAAKgiD,mBAE7CisB,EAAiBjuE,IAAM+tE,IDgEjCG,EC7D+BD,EAAiBr3E,KD8DhDgiD,EC9DsDpiB,EDiEpD03C,EAAOlhF,OAAS4rD,EAAM5rD,QACtBonB,GAAM85D,EAAQ,CAACrnE,EAAS7G,KACtB,MAAMmuE,EAAev1B,EAAM54C,GAC3B,OACE6G,IAAYsnE,GACZA,EAAalZ,mBAAoBpuD,EAAQnB,iBAV3C,IACJwoE,EACAt1B,ICnCI,OAtB6Br5C,EAAAA,EAAAA,GAC3ByuE,EACCI,IACC,MAAMZ,EAAc,CAACY,EAAkBpuE,IAAM,EAAG+tE,EAAY,GACtDpxE,EAAiC,IAApByC,EAAYY,IAAY,GAAKZ,EAAYY,IAQ5D,MAAO,CACL9D,QAPcskE,EAAelB,qCAAqC,CAClEx1D,aAAcrd,EACd2S,YAAaA,EACbiK,iBAAkBmkE,EAClBlkE,WAAY8kE,EAAkBx3E,OAI9B8F,KAAMikE,GAA0B0N,sBAChC9hD,SAAU9/B,EAAKG,KACf+P,WAAYA,EACZ+jB,aAAc8sD,QASxB,OAAOzqD,CACT,CAzPsCurD,CAChC5tD,EACAgrD,EACA5hE,EACA02D,GAGF,OAAOwM,EAAoBt2E,OAAOi3E,KAGpC,OAAO5qD,CACT,CAEM,MAAOwrD,WAA4B/rB,EAAzCv2D,WAAAA,G,oBACS,KAAAg+E,eAEA,EAmBT,CAjBSlnB,4BAAAA,CAA6BkpB,GAClCl7E,KAAKk5E,eAAe/4E,KAAK+6E,EAC3B,CAEOppB,wBAAAA,CAAyB7hC,GAC9BjwB,KAAKk5E,eAAe/4E,KAAK8vB,EAC3B,CAEO8hC,qCAAAA,CACLopB,GAEAn7E,KAAKk5E,eAAe/4E,KAAKg7E,EAC3B,CAEOlpB,eAAAA,CAAgBliC,GACrB/vB,KAAKk5E,eAAe/4E,KAAK4vB,EAC3B,ECpcI,SAAU0tD,GACdxqE,GAEA,MAAMyqE,GAA8ChjB,EAAAA,GAAAA,GAASznD,EAAS,CACpEw8D,eAAgB9B,KAGZgQ,EAA8C,CAAC,EAIrD,OAHAlpE,EAAAA,EAAAA,GAAQxB,EAAQ1G,MAAQ7Q,IACtBiiF,EAAcjiF,EAAKG,MAAQH,ITjBzB,SACJm9E,EACApJ,GAEA,MAAMmO,EAAc,IAAIrO,GAAuBsJ,EAAWpJ,GAE1D,OADAmO,EAAYlO,cACLkO,EAAY5rD,MACrB,CSYS6rD,CAAkBF,EAAeD,EAAcjO,eACxD,CCxBA,MAAMqO,GAA6B,2BAC7BC,GAA0B,uBAC1BC,GAAuB,qBACvBC,GAAiC,6BAEjCC,GAA8B,CAClCJ,GACAC,GACAC,GACAC,IAMI,SAAUE,GAAuB58E,GAErC,OAAO+sC,GAAS4vC,GAA6B38E,EAAM1F,KACrD,CANAqD,OAAO0mE,OAAOsY,IAQd,MAAeE,WACL19E,MAMRxF,WAAAA,CACEiQ,EACO0L,GAEP1b,MAAMgQ,GAFC,KAAA0L,MAAAA,EAJT,KAAAwnE,eAA2B,GASzBn/E,OAAOkvB,eAAepuB,gBAAiBkF,WAGnCxE,MAAM49E,mBACR59E,MAAM49E,kBAAkBt+E,KAAMA,KAAK9E,YAEvC,EAGI,MAAOqjF,WAAiCH,GAC5CljF,WAAAA,CACEiQ,EACA0L,EACOw5B,GAEPl1C,MAAMgQ,EAAS0L,GAFR,KAAAw5B,cAAAA,EAGPrwC,KAAKnE,KAAOiiF,EACd,EAGI,MAAOU,WAA6BJ,GACxCljF,WAAAA,CACEiQ,EACA0L,EACOw5B,GAEPl1C,MAAMgQ,EAAS0L,GAFR,KAAAw5B,cAAAA,EAGPrwC,KAAKnE,KAAOkiF,EACd,EAGI,MAAOU,WAAmCL,GAC9CljF,WAAAA,CAAYiQ,EAAiB0L,GAC3B1b,MAAMgQ,EAAS0L,GACf7W,KAAKnE,KAAOoiF,EACd,EAGI,MAAOS,WAA2BN,GACtCljF,WAAAA,CACEiQ,EACA0L,EACOw5B,GAEPl1C,MAAMgQ,EAAS0L,GAFR,KAAAw5B,cAAAA,EAGPrwC,KAAKnE,KAAOmiF,EACd,ECzDK,MAAMW,GAAsB,CAAC,EAQvBC,GAA6B,0BAEpC,MAAOC,WAAgCn+E,MAC3CxF,WAAAA,CAAYiQ,GACVhQ,MAAMgQ,GACNnL,KAAKnE,KAAO+iF,EACd,EAiXI,SAAUE,GAEdC,EACA99E,EACA+9E,EACAC,EACAprE,EACAqrE,EACAC,GAEA,MAAMz2E,EAAM1I,KAAKo/E,4BAA4BH,EAAcprE,GAC3D,IAAIwrE,EAAoBr/E,KAAKs/E,iBAAiB52E,GAC9C,QAA0BrK,IAAtBghF,EAAiC,CACnC,MAAMnF,EAAel6E,KAAKu/E,sBAI1BF,EADE,IAAIH,EAFcl/E,KAAKw/E,qBAAqBtF,GAEZrmE,GACPiiD,eAC3B91D,KAAKs/E,iBAAiB52E,GAAO22E,C,CAG/B,IAAII,EAA0BJ,EAAkBxoE,MAC5C6oE,EAAaL,EAAkBzzE,WACnC,MAAM2lE,EAAc8N,EAAkB9N,YAKT,IAA3BvxE,KAAKwwB,WAAWv0B,QAChBs1E,QAC4BlzE,IAA5BohF,IAEAA,EAA0BnlD,GAC1BolD,EAAa,QAKiBrhF,IAA5BohF,QAAwDphF,IAAfqhF,GAK3C1/E,KAAK2/E,kCACHF,EACAC,EACAP,IAMFn/E,KAAK4/E,wBACHb,EACA99E,EACA+9E,EACAS,EAGN,CCjdO,MAYMI,GAAmB,KACnBC,GAAe,KACfC,GAAuB,KAG9B,SAAUX,GACdY,EACAf,EACArzE,GAEA,OAAOA,EAAaqzE,EAAee,CACrC,CCJM,MAAOhtE,GAGX9X,WAAAA,CAAY+X,G,MACVjT,KAAKmU,aACkB,QAArBhB,EAAO,OAAPF,QAAO,IAAPA,OAAO,EAAPA,EAASkB,oBAAY,IAAAhB,EAAAA,EAAI8sE,GAAsB9rE,YACnD,CAEAqiC,QAAAA,CAASvjC,GAKP,MAAMitE,EAAsBlgF,KAAKo7E,wBAAwBnoE,EAAQ1G,OAEjE,IAAI/K,EAAAA,EAAAA,GAAQ0+E,GAAsB,CAChC,MAAMC,EAAiBngF,KAAK2T,4BAA4BV,EAAQ1G,OAC1D6zE,EAAsBpgF,KAAK0T,yCAC/BT,EAAQ1G,MACRvM,KAAKmU,cAEDksE,EAAwBrgF,KAAKsgF,kCACjCrtE,EAAQ1G,MACRvM,KAAKmU,cAQP,MANkB,IACb+rE,KACAC,KACAC,KACAC,E,CAIP,OAAOH,CACT,CAEA9E,uBAAAA,CAAwB7uE,GACtB,OAAO6M,EAAAA,GAAAA,GAAQ7M,EAAQg0E,GACrBnF,GACEmF,EACAA,EACAzS,IAGN,CAEAn6D,2BAAAA,CAA4BpH,GAC1B,OAAO6M,EAAAA,GAAAA,GAAQ7M,EAAQg0E,GLqSrB,SACJxnE,EACA02D,GAEA,MAAM8K,EAAc,IAAIC,GACxBzhE,EAAa1b,OAAOk9E,GACpB,MAAME,EAAMF,EAAYG,aAkCxB,OAhCethE,EAAAA,GAAAA,GACbqhE,EACCE,IACC,MAAM6F,EAAa/M,GAAUkH,EAAOlsE,YACpC,OAAO2K,EAAAA,GAAAA,GAAQonE,EAAY,CAACC,EAAiB/J,KAC3C,MAAMgK,EAAqBjO,GACzB,CAACgO,GACD,GACA5c,GACA,GAEF,OAAIriE,EAAAA,EAAAA,GAAQk/E,GACH,CACL,CACEv1E,QAASskE,EAAeb,2BAA2B,CACjD71D,aAAcA,EACd1K,YAAassE,EACb9L,eAAgB6H,IAElB/qE,KAAMikE,GAA0B+Q,oBAChCnlD,SAAUziB,EAAald,KACvB+P,WAAY+uE,EAAO1rE,IACnBipE,YAAaxB,EAAa,IAIvB,MAOjB,CK7UMkK,CACEL,EACAzS,IAGN,CAEAp6D,wCAAAA,CACEnH,EACA4H,GAEA,OAAOiF,EAAAA,GAAAA,GAAQ7M,EAAQg0E,GACrB7sE,GACE6sE,EACApsE,EACA25D,IAGN,CAEAwS,iCAAAA,CACE/zE,EACA4H,GAEA,OLqZE,SACJ0sE,EACA1sE,EACAs7D,GAEA,MAAMz9C,EAAmC,GA8BzC,OA7BAvd,EAAAA,EAAAA,GAAQosE,EAAgBN,IACtB,MAAMxH,EAAmB,IAAIyE,GAC7B+C,EAAYljF,OAAO07E,GACnB,MAAME,EAAqBF,EAAiBG,gBAC5CzkE,EAAAA,EAAAA,GAAQwkE,EAAqB6H,IAC3B,MAAM1sE,EAAWhD,GAAY0vE,GACvB9E,EAAqB8E,EAAS3sE,cAAgBA,EAQ9C4sE,EANQhM,GADS+L,EAAS7xE,IAG9BsxE,EACAnsE,EACA4nE,GAEkC,GACpC,IAAIx6E,EAAAA,EAAAA,IAAQ+T,EAAAA,GAAAA,GAAQwrE,IAAyB,CAC3C,MAAMhe,EAAS0M,EAAef,0BAA0B,CACtD31D,aAAcwnE,EACdpxE,WAAY2xE,IAEd9uD,EAAO7xB,KAAK,CACVgL,QAAS43D,EACTp3D,KAAMikE,GAA0BoR,uBAChCxlD,SAAU+kD,EAAY1kF,M,MAMvBm2B,CACT,CKzbWsuD,CACL/zE,EACA4H,EACA25D,GAEJ,CAEAl6D,4BAAAA,CAA6BX,GAO3B,ONxBE,SACJrH,EACAisE,EACA1jE,EACAL,EACAC,EACAktE,GAEA,MAAMxI,EAAiB3D,GACrBlpE,EACAisE,EACA1jE,GAOF,OAAO8sE,EACLxI,EACA3kE,EANmB0kE,GAA0BC,GAC3CtU,GACAN,GAMF9vD,EAEJ,CMAWmtE,CACLjuE,EAAQY,eACRZ,EAAQvX,KACRuX,EAAQkB,aACRlB,EAAQa,cACRb,EAAQc,qBACRihE,GAEJ,CAEA3/D,yBAAAA,CAA0BpC,GAOxB,ONHE,SACJrH,EACAisE,EACA3lE,EACA6B,EACAK,EACA+sE,GAMA,MAAM1I,EAAiB1D,GACrBnpE,EACAisE,EACAzjE,EACAlC,GAGIwH,EAAe8+D,GAA0BC,GAC3CtU,GACAN,GAEJ,OAAOsd,EACL1I,EAAe,GACf/+D,EACA3F,EAEJ,CMzBWqtE,CACLnuE,EAAQY,eACRZ,EAAQvX,KACRuX,EAAQkB,aACRlB,EAAQc,qBACR3C,GAAY6B,EAAQmB,UACpBmhE,GAEJ,ECoHF,MAAMwD,GAAmB,IAvDzB,cAAyCtnB,EAAzCv2D,WAAAA,G,oBACS,KAAAmmF,WAOH,CACFxyE,OAAQ,GACRR,YAAa,GACbc,WAAY,GACZmyE,wBAAyB,GACzB1xE,oBAAqB,GACrB2xE,iCAAkC,GAuCtC,CApCEj8B,KAAAA,GACEtlD,KAAKqhF,WAAa,CAChBxyE,OAAQ,GACRR,YAAa,GACbc,WAAY,GACZmyE,wBAAyB,GACzB1xE,oBAAqB,GACrB2xE,iCAAkC,GAEtC,CAEO1vB,WAAAA,CAAYhjD,GACjB7O,KAAKqhF,WAAWxyE,OAAO1O,KAAK0O,EAC9B,CAEOmjD,4BAAAA,CAA6BkpB,GAClCl7E,KAAKqhF,WAAWC,wBAAwBnhF,KAAK+6E,EAC/C,CAEOppB,wBAAAA,CAAyB7hC,GAC9BjwB,KAAKqhF,WAAWzxE,oBAAoBzP,KAAK8vB,EAC3C,CAEO8hC,qCAAAA,CACLopB,GAEAn7E,KAAKqhF,WAAWE,iCAAiCphF,KAAKg7E,EACxD,CAEOlpB,eAAAA,CAAgBliC,GACrB/vB,KAAKqhF,WAAWlyE,WAAWhP,KAAK4vB,EAClC,CAEOmiC,gBAAAA,CAAiBp7B,GACtB92B,KAAKqhF,WAAWhzE,YAAYlO,KAAK22B,EACnC,GCjPI,SAAU0qD,GACdC,EACAC,IAG4C,IAAxCtuD,MAAMquD,EAAiBx3D,cAIzBw3D,EAAiBx3D,YAAcy3D,EAAgBz3D,YAC/Cw3D,EAAiBv3D,UAAYw3D,EAAgBx3D,WAMtCu3D,EAAiBv3D,UAAaw3D,EAAgBx3D,aAAc,IACnEu3D,EAAiBv3D,UAAYw3D,EAAgBx3D,UAEjD,CASM,SAAUy3D,GACdF,EACAC,IAG4C,IAAxCtuD,MAAMquD,EAAiBx3D,cAIzBw3D,EAAiBx3D,YAAcy3D,EAAgBz3D,YAC/Cw3D,EAAiB7+B,YAAc8+B,EAAgB9+B,YAC/C6+B,EAAiB5gE,UAAY6gE,EAAgB7gE,UAC7C4gE,EAAiBv3D,UAAYw3D,EAAgBx3D,UAC7Cu3D,EAAiBnxC,UAAYoxC,EAAgBpxC,UAC7CmxC,EAAiB3gE,QAAU4gE,EAAgB5gE,SAMpC2gE,EAAiBv3D,UAAaw3D,EAAgBx3D,aAAe,IACpEu3D,EAAiBv3D,UAAYw3D,EAAgBx3D,UAC7Cu3D,EAAiBnxC,UAAYoxC,EAAgBpxC,UAC7CmxC,EAAiB3gE,QAAU4gE,EAAgB5gE,QAE/C,CC5DM,SAAU8gE,GAAe/tD,EAASguD,GACtC3iF,OAAOC,eAAe00B,EAHX,OAGsB,CAC/B7uB,YAAY,EACZ88E,cAAc,EACdC,UAAU,EACVjjF,MAAO+iF,GAEX,CCKM,SAAUG,GAAiBzqD,EAAUqiD,GACzC,MAAMqI,GAAgBjqE,EAAAA,EAAAA,GAAKuf,GACrB2qD,EAAsBD,EAAchmF,OAC1C,IAAK,IAAIsE,EAAI,EAAGA,EAAI2hF,EAAqB3hF,IAAK,CAC5C,MACM4hF,EAAiB5qD,EADD0qD,EAAc1hF,IAE9B6hF,EAAuBD,EAAelmF,OAC5C,IAAK,IAAIitE,EAAI,EAAGA,EAAIkZ,EAAsBlZ,IAAK,CAC7C,MAAMmZ,EAAiBF,EAAejZ,QAEP7qE,IAA3BgkF,EAAU1tE,cACZ3U,KAAKqiF,EAAUxmF,MAAMwmF,EAAU97D,SAAUqzD,E,EAKjD,CAEM,SAAU0I,GACdhT,EACA53C,GAIA,MAAM6qD,EAA0B,WAAa,EAK7CX,GAAeW,EAAoBjT,EAAc,iBAEjD,MAAMkT,EAAgB,CACpBr8B,MAAO,SAAU7yB,EAA8BsmD,GAS7C,IAPI76E,EAAAA,EAAAA,GAAQu0B,KAGVA,EAAUA,EAAQ,MAIhBqpC,EAAAA,GAAAA,GAAYrpC,GAIhB,OAAOtzB,KAAKszB,EAAQz3B,MAAMy3B,EAAQ/M,SAAUqzD,EAC9C,EAEA6I,gBAAiB,WACf,MAAMC,EA0DN,SACJC,EACAjrD,GAEA,MAAMkrD,EAKF,SACJD,EACAjrD,GAEA,MAAMmrD,GAAmB7yE,EAAAA,GAAAA,GAAO0nB,EAAYwiD,IACoB,KAAvD9d,EAAAA,GAAAA,GAAYumB,EAAwBzI,KAGvCloD,GAAoCxjB,EAAAA,EAAAA,GACxCq0E,EACC3I,IACQ,CACL7iB,IAAK,4BAAF1xD,OAA8Bu0E,EAAY,SAAAv0E,OAC3Cg9E,EAAgBznF,YAAYW,KAAI,iBAElC8P,KAAMm3E,GAA0BC,eAChCC,WAAY9I,KAKlB,OAAO3Z,GAAiCvuC,EAC1C,CA3BwBixD,CAA0BN,EAAiBjrD,GAEjE,OAAOkrD,CACT,CAjEuCH,CAAgBziF,KAAM03B,GACvD,KAAKl2B,EAAAA,EAAAA,GAAQkhF,GAA2B,CACtC,MAAMQ,GAAgB10E,EAAAA,EAAAA,GACpBk0E,EACCS,GAAiBA,EAAa9rB,KAEjC,MAAM32D,MACJ,mCAAAiF,OAAmC3F,KAAK9E,YAAYW,KAAI,aAAA8J,OACnDu9E,EAAcx/E,KAAK,QAAQ3H,QAAQ,MAAO,S,CAGrD,GAQF,OALAwmF,EAAmBr9E,UAAYs9E,GACFtnF,YAAcqnF,EAE3CA,EAAmBa,YAAc1rD,EAE1B6qD,CACT,CA2BO,IAAKO,IAAZ,SAAYA,GACVA,EAAAA,EAAA,uCACAA,EAAAA,EAAA,kCACD,CAHD,CAAYA,KAAAA,GAAyB,K,gBC3DrC,MAAMO,GAAwB,CAC5B9gE,YAAa,8DAEfrjB,OAAO0mE,OAAOyd,IAEd,MAAMC,IAAmB,EACnBC,GAAiBz4D,KAAK04D,IAAI,ENjDO,GMiDuB,EAExDC,GAAM9W,GAAY,CAAE9wE,KAAM,wBAAyBuqD,QAASl3B,GAAMisC,KACxEmJ,GAAkB,CAACmf,KACnB,MAAMC,GAAwBvb,GAC5Bsb,GACA,gJAKC,GACA,GACA,GACA,GACA,GACA,GAEHvkF,OAAO0mE,OAAO8d,IAEd,MAAMC,GAAmC,CACvC9nF,KACE,gJAEF0qB,SAAU,CAAC,GAqSb,SAASq9D,GACPC,EACAC,EACAl4E,GAC0B,IAA1Bm4E,EAAA3lF,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAEA4lF,GAAuBp4E,GACvB,MAAMq4E,GAAgBC,EAAAA,GAAAA,GAAKlkF,KAAKmkF,oBAC1BC,GAAgBhoB,EAAAA,GAAAA,GAAW0nB,GAAeA,EAAcA,EAAYxoD,IAEpE+oD,EAAU,IAAIR,EAAgB,CAAEp1E,WAAY,GAAIQ,IAAKrD,IAa3D,OAZIm4E,IACFM,EAAQ90E,UAAYu0E,EAAYQ,MAE9BtuE,EAAAA,EAAAA,GAAI8tE,EAAa,mBACnBO,EAAQlwE,aAAe2vE,EAAYS,eAGrCvkF,KAAKmkF,mBAAmBhkF,KAAKkkF,GAC7BD,EAAchiF,KAAKpC,MACnBikF,EAASx1E,WAAWtO,KAAKkkF,GACzBrkF,KAAKmkF,mBAAmBpqE,MAEjBspE,EACT,CAEA,SAASmB,GAAaV,EAAkBl4E,GACtCo4E,GAAuBp4E,GACvB,MAAMq4E,GAAgBC,EAAAA,GAAAA,GAAKlkF,KAAKmkF,oBAE1BM,GAAsC,KAAzB1lF,EAAAA,EAAAA,GAAQ+kF,GACrBv1E,GACW,IAAfk2E,EAAuBX,EAAcA,EAAYxoD,IAE7CopD,EAAY,IAAIt2E,EAAY,CAChCK,WAAY,GACZQ,IAAKrD,EACLqlD,kBAAmBwzB,IAAiD,IAAnCX,EAAYa,sBAE3C3uE,EAAAA,EAAAA,GAAI8tE,EAAa,mBACnBY,EAAUvwE,aAAe2vE,EAAYS,eAGvC,MAAMzwE,EAAgBs7B,EAAK7gC,EAAO8F,IAAiB+nD,EAAAA,GAAAA,GAAW/nD,EAAQc,OAmBtE,OAlBAuvE,EAAU5wE,cAAgBA,EAE1BmwE,EAASx1E,WAAWtO,KAAKukF,IAEzBjwE,EAAAA,EAAAA,GAAQlG,EAAO8F,IACb,MAAMuwE,EAAc,IAAI5zB,EAAY,CAAEviD,WAAY,KAClDi2E,EAAUj2E,WAAWtO,KAAKykF,IACtB5uE,EAAAA,EAAAA,GAAI3B,EAAS,sBACfuwE,EAAY3zB,kBAAoB58C,EAAQswE,oBAGjC3uE,EAAAA,EAAAA,GAAI3B,EAAS,UACpBuwE,EAAY3zB,mBAAoB,GAElCjxD,KAAKmkF,mBAAmBhkF,KAAKykF,GAC7BvwE,EAAQ8kB,IAAI/2B,KAAKpC,MACjBA,KAAKmkF,mBAAmBpqE,QAEnBspE,EACT,CAEA,SAASwB,GAAa51E,GACpB,OAAe,IAARA,EAAY,GAAK,GAAHtJ,OAAMsJ,EAC7B,CAEA,SAAS+0E,GAAuB/0E,GAC9B,GAAIA,EAAM,GAAKA,EAAMs0E,GAAgB,CACnC,MAAMhiF,EAAa,IAAIb,MAErB,kCAAAiF,OAAkCsJ,EAAG,iEAAAtJ,OAEjC49E,GAAiB,IAIvB,MADAhiF,EAAMujF,sBAAuB,EACvBvjF,C,CAEV,CChaO,MAAMwjF,GAAc5c,GACzB7tC,GACA,GACA0qD,IACAA,IACAA,IACAA,IACAA,IACAA,KAEF9lF,OAAO0mE,OAAOmf,IAIP,MAAM9E,GAET/gF,OAAO0mE,OAAO,CAChBvvC,iBAAiB,EACjBliB,aAAc,EACdJ,sBAAsB,EACtBkxE,WAAW,EACXx1D,qBAAsBkF,GACtB2B,qBAAsB,OACtBqvC,eAAe,EACfn2C,iBAAiB,IAGN01D,GAAkDhmF,OAAO0mE,OAAO,CAC3Euf,kBAAmBA,OACnBC,eAAe,IAGV,IAAKxV,GCvEgByV,GD2HtB,SAAUhqD,KAAgC,IAAtBv8B,EAAAV,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,QAAaC,EACrC,OAAO,WACL,OAAOS,CACT,CACF,EAxDA,SAAY8wE,GACVA,EAAAA,EAAA,yCACAA,EAAAA,EAAA,6CACAA,EAAAA,EAAA,iDACAA,EAAAA,EAAA,iDACAA,EAAAA,EAAA,mDACAA,EAAAA,EAAA,mCACAA,EAAAA,EAAA,6CACAA,EAAAA,EAAA,mCACAA,EAAAA,EAAA,qEACAA,EAAAA,EAAA,2CACAA,EAAAA,EAAA,oDACAA,EAAAA,EAAA,kDACAA,EAAAA,EAAA,kCACAA,EAAAA,EAAA,6DACD,CAfD,CAAYA,KAAAA,GAAyB,KA0D/B,MAAO0V,GAYX,0BAAO1uD,CAAoB2uD,GACzB,MAAM7kF,MACJ,8HAGJ,CAEOk2B,mBAAAA,GACL52B,KAAKkmE,WAAW,sBAAuB,KACrC,IAAIsf,EAEJxlF,KAAKylF,kBAAmB,EACxB,MAAMppF,EAAY2D,KAAK3D,UAEvB2D,KAAKkmE,WAAW,cAAe,KAI7B3W,EAAiBvvD,QAGnBA,KAAKkmE,WAAW,oBAAqB,KACnC,IACElmE,KAAK0lF,mBAELjxE,EAAAA,EAAAA,GAAQzU,KAAK2lF,kBAAoBzL,IAC/B,MAGM0L,EAHe5lF,KACnBk6E,GAE+D,sBACjE,IAAI2L,EACJ7lF,KAAKkmE,WAAW,GAADvgE,OAAIu0E,EAAY,SAAS,KACtC2L,EAAmB7lF,KAAK8lF,mBACtB5L,EACA0L,KAGJ5lF,KAAK+lF,qBAAqB7L,GAAgB2L,G,CAE5C,QACA7lF,KAAKgmF,kB,IAIT,IAAIC,EAA2C,GAmD/C,GAlDAjmF,KAAKkmE,WAAW,oBAAqB,KACnC+f,EAAiBxI,GAAe,CAC9BlxE,OAAOwL,EAAAA,EAAAA,GAAO/X,KAAK+lF,wBAErB/lF,KAAKw0B,iBAAmBx0B,KAAKw0B,iBAAiB7uB,OAAOsgF,KAGvDjmF,KAAKkmE,WAAW,sBAAuB,KAGrC,IAAI1kE,EAAAA,EAAAA,GAAQykF,KAA4C,IAAzBjmF,KAAKwvB,gBAA2B,CAC7D,MAAM02D,GVpKgBjzE,EUoKmB,CACvC1G,OAAOwL,EAAAA,EAAAA,GAAO/X,KAAK+lF,sBACnBxrC,YAAYxiC,EAAAA,EAAAA,GAAO/X,KAAKmmF,WACxB1W,eAAgB3B,GAChBwB,YAAajzE,GV9JhB+pF,IAJPnzE,GAAUynD,EAAAA,GAAAA,GAASznD,EAAS,CAC1Bw8D,eAAgB3B,MAIRvhE,MACR0G,EAAQsnC,WACRtnC,EAAQw8D,eACRx8D,EAAQq8D,cU4JI+W,EX7IV,SAA4BpzE,GAMhC,MAAMqzE,EAAmCrzE,EAAQwjB,kBAAkB+f,SAAS,CAC1EjqC,MAAO0G,EAAQ1G,MACfguC,WAAYtnC,EAAQsnC,WACpB+0B,YAAar8D,EAAQq8D,cAEvB,OAAO9gE,EAAAA,EAAAA,GAAI83E,EAAmCtkD,GAAiB9iC,OAAAoS,OAAC,CAC9D3F,KAAMikE,GAA0B2W,6BAC7BvkD,GAEP,CW8H4CwkD,CAAkB,CAClD/vD,kBAAmBz2B,KAAKy2B,kBACxBlqB,OAAOwL,EAAAA,EAAAA,GAAO/X,KAAK+lF,sBACnBxrC,YAAYxiC,EAAAA,EAAAA,GAAO/X,KAAKmmF,WACxB7W,YAAajzE,IAEf2D,KAAKw0B,iBAAmBx0B,KAAKw0B,iBAAiB7uB,OAC5CugF,EACAG,E,CVlLN,IAA0BpzE,KUwLtBzR,EAAAA,EAAAA,GAAQxB,KAAKw0B,oBAEXx0B,KAAKq2B,iBACPr2B,KAAKkmE,WAAW,yBAA0B,KACxC,MAAMugB,ErCjLZ,SACJC,GAEA,MAAMC,EAAgB,CAAC,EAMvB,OAJAlyE,EAAAA,EAAAA,GAAQiyE,EAAiB9wB,IACvB,MAAMgxB,EAAiB,IAAIjxB,GAAoBC,GAASE,eACxDxkD,EAAOq1E,EAAeC,KAEjBD,CACT,CqCuK+BE,EACjB9uE,EAAAA,EAAAA,GAAO/X,KAAK+lF,uBAEd/lF,KAAK8mF,cAAgBL,IAIzBzmF,KAAKkmE,WAAW,4BAA6B,K,QACV,QAAjC/4C,GAAAha,EAAAnT,KAAKy2B,mBAAkBpjB,kBAAU,IAAA8Z,GAAAA,EAAA/qB,KAAA+Q,EAAG,CAClC5G,OAAOwL,EAAAA,EAAAA,GAAO/X,KAAK+lF,wBAErB/lF,KAAK+mF,8BAA6BhvE,EAAAA,EAAAA,GAAO/X,KAAK+lF,2BAK/CT,GAAO0B,oCACPxlF,EAAAA,EAAAA,GAAQxB,KAAKw0B,kBAMd,MAJAgxD,GAAgBh3E,EAAAA,EAAAA,GACdxO,KAAKw0B,iBACJklD,GAAaA,EAASvuE,SAEnB,IAAIzK,MAAM,wCAADiF,OAC2B6/E,EAAc9hF,KACpD,0CAKV,CAMAxI,WAAAA,CAAYkgD,EAAkCrpC,GAJ9C,KAAAyiB,iBAA6C,GAC7C,KAAAixD,kBAAmB,EAIjB,MAAMwB,EAAsBjnF,KAW5B,GAVAinF,EAAKC,iBAAiBn1E,GACtBk1E,EAAKE,mBACLF,EAAKG,eAAer1E,GACpBk1E,EAAKI,qBAAqBjsC,EAAiBrpC,GAC3Ck1E,EAAKK,gBAAgBv1E,GACrBk1E,EAAKM,gBAAgBx1E,GACrBk1E,EAAKO,oBACLP,EAAKQ,iBAAiB11E,GACtBk1E,EAAKS,sBAAsB31E,IAEvBiE,EAAAA,EAAAA,GAAIjE,EAAQ,iBACd,MAAM,IAAIrR,MACR,uQAOJV,KAAKwvB,iBAAkBxZ,EAAAA,EAAAA,GAAIjE,EAAQ,mBAC9BA,EAAOyd,gBACRywD,GAAsBzwD,eAC5B,EAjJO81D,GAAA0B,kCAA4C,ECxIzB3B,GD4RhBC,GAAQ,CR1Od,MAKJgC,eAAAA,CAAgBv1E,GACd/R,KAAKs/E,iBAAmB,CAAC,EACzBt/E,KAAK8mF,cAAgB,CAAC,EAEtB9mF,KAAKq2B,iBAAkBrgB,EAAAA,EAAAA,GAAIjE,EAAQ,mBAC9BA,EAAOskB,gBACR4pD,GAAsB5pD,gBAKtBr2B,KAAKq2B,kBACPr2B,KAAK8+E,4BAA8BA,GAEvC,CAEO6I,gBAAAA,CAAiB7xE,GACtB,MAAM8xE,EAAczf,GAClBryD,EACA,GACAkvE,IACAA,IACAA,IACAA,IACAA,IACAA,KAGF,OADA4C,EAAYz0D,sBAAuB,EAC5By0D,CACT,CAEOC,gCAAAA,CAAiC/xE,GACtC,OAAO,CACT,CAEOgyE,+BAAAA,CAAgChyE,GACrC,OAAO,CACT,CAEA8pE,uBAAAA,CAEEmI,EACAC,EACAC,EACAC,GAGA,MAAMC,EAAgBnoF,KAAKooF,sBACrBC,EAAkBroF,KAAKsoF,mBACvBjK,EAA2B,GACjC,IAAIkK,GAAoB,EAExB,MAAMC,EAAyBxoF,KAAKgV,GAAG,GACvC,IAAIilE,EAAYj6E,KAAKgV,GAAG,GAExB,MAAMyzE,EAAuBA,KAC3B,MAAMp4C,EAAgBrwC,KAAKgV,GAAG,GAGxBqiD,EAAMr3D,KAAKyvB,qBAAqBiF,0BAA0B,CAC9DO,SAAUizD,EACVhzD,OAAQszD,EACRvvE,SAAUo3B,EACV7U,SAAUx7B,KAAKu/E,wBAEXh+E,EAAQ,IAAIg9E,GAChBlnB,EACAmxB,EACAxoF,KAAKgV,GAAG,IAGVzT,EAAM88E,eAAiB5K,GAAU4K,GACjCr+E,KAAK0oF,WAAWnnF,IAGlB,MAAQgnF,GAAmB,CAEzB,GAAIvoF,KAAK0Z,aAAaugE,EAAWiO,GAE/B,YADAO,IAEK,GAAIR,EAAc7lF,KAAKpC,MAK5B,OAHAyoF,SAEAV,EAAY5mF,MAAMnB,KAAMgoF,GAEfhoF,KAAK0Z,aAAaugE,EAAWkO,GACtCI,GAAoB,GAEpBtO,EAAYj6E,KAAK2oF,aACjB3oF,KAAK4oF,kBAAkB3O,EAAWoE,G,CAOtCr+E,KAAK6oF,iBAAiBR,EACxB,CAEA1I,iCAAAA,CAEEF,EACAC,EACAP,GAIA,OAAiB,IAAbA,IAKAn/E,KAAK0Z,aAAa1Z,KAAKgV,GAAG,GAAIyqE,KAM9Bz/E,KAAK8oF,mBAQP9oF,KAAK+oF,yBACHtJ,EACAz/E,KAAKgpF,4BAA4BvJ,EAAyBC,GAOhE,CAGAsJ,2BAAAA,CAEElzE,EACAmzE,GAEA,MAAMC,EAAclpF,KAAKmpF,sBAAsBrzE,EAASmzE,GAExD,OADgBjpF,KAAKopF,0BAA0BF,EAEjD,CAEAG,iBAAAA,CAEEnB,EACAryB,GAEA,GAAI71D,KAAKspF,mCAAmCpB,EAAiBryB,GAE3D,OADoB71D,KAAK2nF,iBAAiBO,GAI5C,GAAIloF,KAAKupF,kCAAkCrB,GAAkB,CAC3D,MAAMsB,EAAUxpF,KAAK2oF,aAErB,OADA3oF,KAAKypF,eACED,C,CAGT,MAAM,IAAI3K,GAAwB,gBACpC,CAEAkK,wBAAAA,CAEEW,EACA7zB,GAEA,OACE71D,KAAKspF,mCAAmCI,EAAe7zB,IACvD71D,KAAKupF,kCAAkCG,EAE3C,CAEAJ,kCAAAA,CAEEpB,EACAryB,GAEA,IAAK71D,KAAK6nF,iCAAiCK,GACzC,OAAO,EAIT,IAAI1mF,EAAAA,EAAAA,GAAQq0D,GACV,OAAO,EAGT,MAAM8zB,EAAgB3pF,KAAKgV,GAAG,GAM9B,YAFS3W,KAFPopC,EAAAA,GAAAA,GAAKouB,EAAU+zB,GACN5pF,KAAK0Z,aAAaiwE,EAAeC,GAI9C,CAEAL,iCAAAA,CAEErB,GAEA,QAAKloF,KAAK8nF,gCAAgCI,IAIRloF,KAAK0Z,aACrC1Z,KAAKgV,GAAG,GACRkzE,EAGJ,CAEA2B,wBAAAA,CAEEl1E,GAEA,MAAMm1E,EAAY9pF,KAAK+pF,mBACjBC,EAAuBhqF,KAAKiqF,0BAA0BH,GAC5D,OAAOx7C,GAAS07C,EAAsBr1E,EACxC,CAEAyzE,mBAAAA,GACE,MAAM8B,EAA4BlqF,KAAKmqF,mBAEvC,IAAIp1E,EAAY/U,KAAKgV,GAAG,GACpB9C,EAAI,EACR,OAAa,CACX,MAAMk4E,GAAa3iD,EAAAA,GAAAA,GAAKyiD,EAA4BG,GACjC3wE,GAAa3E,EAAWs1E,IAG3C,QAAmBhsF,IAAf+rF,EACF,OAAOA,EAETr1E,EAAY/U,KAAKgV,GAAG9C,GACpBA,G,CAEJ,CAEA63E,gBAAAA,GAEE,GAA+B,IAA3B/pF,KAAKwwB,WAAWv0B,OAClB,OAAO0iF,GAET,MAAM2L,EAAoBtqF,KAAKuqF,+BACzBC,EAAcxqF,KAAKyqF,qCACnBC,EAAoB1qF,KAAK2qF,mCAE/B,MAAO,CACLnvD,SAAUx7B,KAAK4qF,wBAAwBN,GACvCO,iBAAkBL,EAClBM,OAAQ9qF,KAAK4qF,wBAAwBF,GAEzC,CAEAK,uBAAAA,GACE,MAAMC,EAAoBhrF,KAAKwwB,WACzBy6D,EAA0BjrF,KAAKkrF,sBAErC,OAAO18E,EAAAA,EAAAA,GAAIw8E,EAAmB,CAACxvD,EAAUvsB,IAC3B,IAARA,EACK0vE,GAEF,CACLnjD,SAAUx7B,KAAK4qF,wBAAwBpvD,GACvCqvD,iBAAkBI,EAAwBh8E,GAC1C67E,OAAQ9qF,KAAK4qF,wBAAwBI,EAAkB/7E,EAAM,KAGnE,CAEAk7E,gBAAAA,GACE,MAAMgB,GAAc38E,EAAAA,EAAAA,GAAIxO,KAAK+qF,0BAA4B/gB,GAChDhqE,KAAKiqF,0BAA0BjgB,IAExC,OAAYz0D,EAAAA,GAAAA,GAAQ41E,EACtB,CAEAlB,yBAAAA,CAEEH,GAEA,GAAIA,IAAcnL,GAChB,MAAO,CAACrkD,IAGV,MAAMy7B,EACJ+zB,EAAUtuD,SAAWsuD,EAAUe,iBAAmBn1B,GAAKo0B,EAAUgB,OAEnE,OAAO9qF,KAAK8mF,cAAc/wB,EAC5B,CAIA6yB,iBAAAA,CAEE/xE,EACAu0E,GAKA,OAHKprF,KAAK0Z,aAAa7C,EAAOyjB,KAC5B8wD,EAAajrF,KAAK0W,GAEbu0E,CACT,CAEAC,QAAAA,CAA8Bv1E,GAC5B,MAAMuoE,EAA2B,GACjC,IAAImL,EAAUxpF,KAAKgV,GAAG,GACtB,MAA+C,IAAxChV,KAAK0Z,aAAa8vE,EAAS1zE,IAChC0zE,EAAUxpF,KAAK2oF,aACf3oF,KAAK4oF,kBAAkBY,EAASnL,GAGlC,OAAO5K,GAAU4K,EACnB,CAEAS,2BAAAA,CAEEC,EACA99E,EACA+9E,EACAC,EACAprE,EACAqrE,EACAC,GAGA,CAGFgK,qBAAAA,CAEErzE,EACAmzE,GAWA,MAPyB,CACvBtY,UAH8B3wE,KAAKsrF,4BAInCza,iBAHoCrM,EAAAA,EAAAA,GAAMxkE,KAAKkrF,uBAI/Cha,QAASp7D,EACTq7D,kBAAmB8X,EAIvB,CACAqC,yBAAAA,GACE,OAAO98E,EAAAA,EAAAA,GAAIxO,KAAKwwB,WAAa+6D,GAC3BvrF,KAAK4qF,wBAAwBW,GAEjC,GGzXI,MAMJnE,cAAAA,CAAer1E,GACb/R,KAAK+T,sBAAuBiC,EAAAA,EAAAA,GAAIjE,EAAQ,wBACnCA,EAAOgC,qBACRksE,GAAsBlsE,qBAE1B/T,KAAKmU,cAAe6B,EAAAA,EAAAA,GAAIjE,EAAQ,gBAC3BA,EAAOoC,aACR8rE,GAAsB9rE,aAE1BnU,KAAKy2B,mBAAoBzgB,EAAAA,EAAAA,GAAIjE,EAAQ,qBAChCA,EAAO0kB,kBACR,IAAIzjB,GAAqB,CAAEmB,aAAcnU,KAAKmU,eAElDnU,KAAKwrF,oBAAsB,IAAI5+E,GACjC,CAEAm6E,4BAAAA,CAAkDx6E,IAChDkI,EAAAA,EAAAA,GAAQlI,EAAQ2iE,IACdlvE,KAAKkmE,WAAW,GAADvgE,OAAIupE,EAASrzE,KAAI,mBAAmB,KACjD,MAAM,YACJwS,EAAW,WACXc,EAAU,OACVN,EAAM,oBACNe,EAAmB,iCACnB2xE,EAAgC,wBAChCD,GA8LJ,SAAyB5lF,GAQ7Bq9E,GAAiBzzB,QACjB5pD,EAAK2B,OAAO07E,IACZ,MAAMsI,EAAatI,GAAiBsI,WAGpC,OADAtI,GAAiBzzB,QACL+7B,CACd,CA3MYoK,CAAevc,IAEnBz6D,EAAAA,EAAAA,GAAQpG,EAAcyyE,IACpB,MAAM4K,EAA2B,IAAjB5K,EAAS7xE,IAAY,GAAK6xE,EAAS7xE,IACnDjP,KAAKkmE,WAAW,GAADvgE,OAAImT,GAAqBgoE,IAASn7E,OAAG+lF,GAAW,KAC7D,MAAMC,EAAS3rF,KAAKy2B,kBAAkB7iB,6BAA6B,CACjEC,eAAgBitE,EAAS7xE,IACzBvT,KAAMwzE,EACN/6D,aAAc2sE,EAAS3sE,cAAgBnU,KAAKmU,aAC5CL,cAAegtE,EAAShtE,cACxBC,qBAAsB/T,KAAK+T,uBAGvBrL,EAAM02E,GACVp/E,KAAK4rF,oBAAoB1c,EAASrzE,MF/D1B,IEiERilF,EAAS7xE,KAEXjP,KAAK6rF,eAAenjF,EAAKijF,QAI7Bl3E,EAAAA,EAAAA,GAAQtF,EAAa2xE,IACnB9gF,KAAK8rF,qBACH5c,EACA4R,EAAS7xE,IFxEG,IE0EZ,aACA6xE,EAAS3sE,aACT2E,GAAqBgoE,OAIzBrsE,EAAAA,EAAAA,GAAQ5F,EAASiyE,IACf9gF,KAAK8rF,qBACH5c,EACA4R,EAAS7xE,IFpFK,IEsFd,SACA6xE,EAAS3sE,aACT2E,GAAqBgoE,OAIzBrsE,EAAAA,EAAAA,GAAQ7E,EAAsBkxE,IAC5B9gF,KAAK8rF,qBACH5c,EACA4R,EAAS7xE,IACT4wE,GACA,sBACAiB,EAAS3sE,aACT2E,GAAqBgoE,OAIzBrsE,EAAAA,EAAAA,GAAQ8sE,EAAmCT,IACzC9gF,KAAK8rF,qBACH5c,EACA4R,EAAS7xE,IACT8wE,GACA,mCACAe,EAAS3sE,aACT2E,GAAqBgoE,OAIzBrsE,EAAAA,EAAAA,GAAQ6sE,EAA0BR,IAChC9gF,KAAK8rF,qBACH5c,EACA4R,EAAS7xE,IACT6wE,GACA,0BACAgB,EAAS3sE,aACT2E,GAAqBgoE,SAK/B,CAEAgL,oBAAAA,CAEEpwF,EACAmY,EACAk4E,EACA33E,EACA43E,EACAC,GAEAjsF,KAAKkmE,WAAW,GAADvgE,OACVsmF,GAAatmF,OAAsB,IAAnBkO,EAAuB,GAAKA,GAC/C,KACE,MAAM83E,EAAS3rF,KAAKy2B,kBAAkBphB,0BAA0B,CAC9DxB,iBACAnY,OACAyY,aAAc63E,GAAoBhsF,KAAKmU,aACvCJ,qBAAsB/T,KAAK+T,qBAC3BK,aAEI1L,EAAM02E,GACVp/E,KAAK4rF,oBAAoBlwF,EAAKG,MAC9BkwF,EACAl4E,GAEF7T,KAAK6rF,eAAenjF,EAAKijF,IAG/B,CAGAvM,2BAAAA,CAEEH,EACArzE,GAGA,OAAOwzE,GADwBp/E,KAAKuqF,+BAGlCtL,EACArzE,EAEJ,CAEAsgF,kBAAAA,CAAwCxjF,GACtC,OAAO1I,KAAKwrF,oBAAoBvmF,IAAIyD,EACtC,CAGAmjF,cAAAA,CAAoCnjF,EAAa5J,GAC/CkB,KAAKwrF,oBAAoBt+E,IAAIxE,EAAK5J,EACpC,GO1KI,MAoBJyoF,eAAAA,CAAqCx1E,GAUnC,GATA/R,KAAKmsF,UAAY,GAGjBnsF,KAAKilF,UAAalzE,EAAekzE,UAEjCjlF,KAAKs2B,sBAAuBtgB,EAAAA,EAAAA,GAAIjE,EAAQ,wBACnCA,EAAOukB,qBACR2pD,GAAsB3pD,qBAErBt2B,KAAKilF,UAOR,GAAI,QAAQj/E,KAAKhG,KAAKs2B,sBAChBt2B,KAAKq2B,iBACPr2B,KAAKosF,yBAA2BzK,GAChC3hF,KAAKqsF,wBAA0B1K,GAC/B3hF,KAAKssF,YAAcxkB,GAAAA,EACnB9nE,KAAKusF,uBAAyBvsF,KAAKwsF,qCAEnCxsF,KAAKosF,yBAA2BtkB,GAAAA,EAChC9nE,KAAKqsF,wBAA0BvkB,GAAAA,EAC/B9nE,KAAKssF,YAActsF,KAAKysF,gBACxBzsF,KAAKusF,uBAAyBvsF,KAAK0sF,wCAEhC,GAAI,cAAc1mF,KAAKhG,KAAKs2B,sBAC7Bt2B,KAAKq2B,iBACPr2B,KAAKosF,yBAAgC5K,GACrCxhF,KAAKqsF,wBAA+B7K,GACpCxhF,KAAKssF,YAAcxkB,GAAAA,EACnB9nE,KAAKusF,uBACHvsF,KAAK2sF,2CAEP3sF,KAAKosF,yBAA2BtkB,GAAAA,EAChC9nE,KAAKqsF,wBAA0BvkB,GAAAA,EAC/B9nE,KAAKssF,YAActsF,KAAK4sF,sBACxB5sF,KAAKusF,uBACHvsF,KAAK6sF,6CAEJ,KAAI,QAAQ7mF,KAAKhG,KAAKs2B,sBAM3B,MAAM51B,MAAM,kDAADiF,OACyCoM,EAAOukB,qBAAoB,MAN/Et2B,KAAKosF,yBAA2BtkB,GAAAA,EAChC9nE,KAAKqsF,wBAA0BvkB,GAAAA,EAC/B9nE,KAAKssF,YAAcxkB,GAAAA,EACnB9nE,KAAKusF,uBAAyBzkB,GAAAA,C,MApChC9nE,KAAK8sF,yBAA2BhlB,GAAAA,EAChC9nE,KAAK+sF,sBAAwBjlB,GAAAA,EAC7B9nE,KAAKgtF,gBAAkBllB,GAAAA,EACvB9nE,KAAKitF,mBAAqBnlB,GAAAA,EAC1B9nE,KAAKssF,YAAcxkB,GAAAA,CAuCvB,CAEA6kB,wCAAAA,CAEEr5D,GAEAA,EAAQlS,SAAW,CACjB6I,YAAa+6D,IACb96D,UAAW86D,IAEf,CAEA6H,uCAAAA,CAEEv5D,GAEAA,EAAQlS,SAAW,CAKjB6I,YAAajqB,KAAKgV,GAAG,GAAGiV,YACxBC,UAAW86D,IAEf,CAEAwH,kCAAAA,CAAwDl5D,GACtDA,EAAQlS,SAAW,CACjB6I,YAAa+6D,IACbnkE,UAAWmkE,IACXpiC,YAAaoiC,IACb96D,UAAW86D,IACXlkE,QAASkkE,IACT10C,UAAW00C,IAEf,CAOA0H,iCAAAA,CAAuDp5D,GACrD,MAAMve,EAAY/U,KAAKgV,GAAG,GAC1Bse,EAAQlS,SAAW,CACjB6I,YAAalV,EAAUkV,YACvBpJ,UAAW9L,EAAU8L,UACrB+hC,YAAa7tC,EAAU6tC,YACvB14B,UAAW86D,IACXlkE,QAASkkE,IACT10C,UAAW00C,IAEf,CAEA8H,wBAAAA,CAA8CI,GAC5C,MAAM55D,EAAmB,CACvBz3B,KAAMqxF,EACN3mE,SAAUrnB,OAAO+f,OAAO,OAG1Bjf,KAAKusF,uBAAuBj5D,GAC5BtzB,KAAKmsF,UAAUhsF,KAAKmzB,EACtB,CAEAy5D,qBAAAA,GACE/sF,KAAKmsF,UAAUpyE,KACjB,CAEA0yE,eAAAA,CAAqCU,GAEnC,MAAMC,EAAYptF,KAAKgV,GAAG,GACpB8wC,EAAMqnC,EAAY/rE,SAIpB0kC,EAAI77B,aAAemjE,EAAUnjE,eAAgB,GAC/C67B,EAAI57B,UAAYkjE,EAAUljE,UAC1B47B,EAAIhlC,QAAUssE,EAAUtsE,QACxBglC,EAAIxV,UAAY88C,EAAU98C,YAI1BwV,EAAI77B,YAAc+6D,IAClBl/B,EAAIjlC,UAAYmkE,IAChBl/B,EAAIlD,YAAcoiC,IAEtB,CAEA4H,qBAAAA,CAA2CO,GACzC,MAAMC,EAAYptF,KAAKgV,GAAG,GAEpB8wC,EAAMqnC,EAAY/rE,SAIpB0kC,EAAI77B,aAAemjE,EAAUnjE,eAAgB,EAC/C67B,EAAI57B,UAAYkjE,EAAUljE,UAI1B47B,EAAI77B,YAAc+6D,GAEtB,CAEAgI,eAAAA,CAEEtkF,EACA2kF,GAEA,MAAMC,EAAUttF,KAAKmsF,UAAUnsF,KAAKmsF,UAAUlwF,OAAS,GNhJrD,IACJ2B,EACAiZ,EACA02E,EADA12E,EM+I4Bw2E,EN9I5BE,EM8I2C7kF,ON5INrK,KAJrCT,EMgJmB0vF,GN5IV/mE,SAASgnE,GAChB3vF,EAAK2oB,SAASgnE,GAAiB,CAAC12E,GAEhCjZ,EAAK2oB,SAASgnE,GAAeptF,KAAK0W,GM2IlC7W,KAAKosF,yBAAyBkB,EAAQlsE,SAAgBisE,EACxD,CAEAJ,kBAAAA,CAEEO,EACAhyD,GAEA,MAAMiyD,EAAaztF,KAAKmsF,UAAUnsF,KAAKmsF,UAAUlwF,OAAS,IN/IxD,SACJ2B,EACA49B,EACAkyD,QAEgCrvF,IAA5BT,EAAK2oB,SAASiV,GAChB59B,EAAK2oB,SAASiV,GAAY,CAACkyD,GAE3B9vF,EAAK2oB,SAASiV,GAAUr7B,KAAKutF,EAEjC,CMsIIC,CAAqBF,EAAYjyD,EAAUgyD,GAE3CxtF,KAAKqsF,wBAAwBoB,EAAWrsE,SAAWosE,EAAcpsE,SACnE,CAEAwsE,4BAAAA,GAKE,IAAIjxB,EAAAA,GAAAA,GAAY38D,KAAK6tF,2BAA4B,CAC/C,MAAMC,EAA+BxL,GACnCtiF,KAAK3D,WACL2b,EAAAA,EAAAA,GAAKhY,KAAK+lF,uBAGZ,OADA/lF,KAAK6tF,0BAA4BC,EAC1BA,C,CAGT,OAAY9tF,KAAK6tF,yBACnB,CAEAE,wCAAAA,GAKE,IAAIpxB,EAAAA,GAAAA,GAAY38D,KAAKguF,uCAAwC,CAC3D,MAAMC,EJnKN,SACJ3e,EACA53C,EACAw2D,GAIA,MAAM3L,EAA0B,WAAa,EAK7CX,GAAeW,EAAoBjT,EAAc,6BAEjD,MAAM6e,EAAoBjvF,OAAO+f,OAAOivE,EAAgBhpF,WAQxD,OAPAuP,EAAAA,EAAAA,GAAQijB,EAAY8D,IAClB2yD,EAAkB3yD,GAAYwmD,MAGhCO,EAAmBr9E,UAAYipF,GACFjzF,YAAcqnF,EAEpCA,CACT,CI4I6B6L,CACrBpuF,KAAK3D,WACL2b,EAAAA,EAAAA,GAAKhY,KAAK+lF,sBACV/lF,KAAK4tF,gCAGP,OADA5tF,KAAKguF,sCAAwCC,EACtCA,C,CAGT,OAAYjuF,KAAKguF,qCACnB,CAEAzD,4BAAAA,GACE,MAAM5Z,EAAY3wE,KAAKwwB,WACvB,OAAOmgD,EAAUA,EAAU10E,OAAS,EACtC,CAEA0uF,gCAAAA,GACE,MAAMha,EAAY3wE,KAAKwwB,WACvB,OAAOmgD,EAAUA,EAAU10E,OAAS,EACtC,CAEAwuF,kCAAAA,GACE,MAAM5Z,EAAkB7wE,KAAKkrF,sBAC7B,OAAOra,EAAgBA,EAAgB50E,OAAS,EAClD,GCtQI,MAKJkrF,gBAAAA,GACEnnF,KAAKquF,UAAY,GACjBruF,KAAKsuF,gBAAkB,EACvBtuF,KAAKi2B,SAAW,CAClB,CAEA,SAAIt6B,CAAM4yF,GAGR,IAA8B,IAA1BvuF,KAAKylF,iBACP,MAAM/kF,MAAM,oFAMdV,KAAKslD,QACLtlD,KAAKquF,UAAYE,EACjBvuF,KAAKsuF,gBAAkBC,EAAStyF,MAClC,CAEA,SAAIN,GACF,OAAOqE,KAAKquF,SACd,CAGA1F,UAAAA,GACE,OAAI3oF,KAAKi2B,SAAWj2B,KAAKquF,UAAUpyF,OAAS,GAC1C+D,KAAKypF,eACEzpF,KAAKgV,GAAG,IAER+vE,EAEX,CAIA/vE,EAAAA,CAAwBw5E,GACtB,MAAMC,EAAYzuF,KAAKi2B,QAAUu4D,EACjC,OAAIC,EAAY,GAAKzuF,KAAKsuF,iBAAmBG,EACpC1J,GAEA/kF,KAAKquF,UAAUI,EAE1B,CAEAhF,YAAAA,GACEzpF,KAAKi2B,SACP,CAEAqyD,gBAAAA,GACE,OAAOtoF,KAAKi2B,OACd,CAEA4yD,gBAAAA,CAAsC77E,GACpChN,KAAKi2B,QAAUjpB,CACjB,CAEA0hF,eAAAA,GACE1uF,KAAKi2B,SAAW,CAClB,CAEA04D,qBAAAA,GACE3uF,KAAKi2B,QAAUj2B,KAAKquF,UAAUpyF,OAAS,CACzC,CAEA2yF,gBAAAA,GACE,OAAO5uF,KAAKsoF,kBACd,GCdI,MAeJjB,oBAAAA,CACEjsC,EACArpC,GAiBA,GAfA/R,KAAK3D,UAAY2D,KAAK9E,YAAYW,KAElCmE,KAAK6uF,oBAAsB,CAAC,EAC5B7uF,KAAK4rF,oBAAsB,CAAC,EAC5B5rF,KAAK8uF,iBAAmB,IACxB9uF,KAAK0Z,aAAeyqD,GACpBnkE,KAAK+uF,WAAa,EAElB/uF,KAAK2lF,kBAAoB,GACzB3lF,KAAKmmF,UAAY,CAAC,EAClBnmF,KAAKgvF,oBAAsB,GAC3BhvF,KAAKwwB,WAAa,GAClBxwB,KAAKkrF,sBAAwB,GAC7BlrF,KAAK+lF,qBAAuB,CAAC,GAEzB/vE,EAAAA,EAAAA,GAAIjE,EAAQ,qBACd,MAAMrR,MACJ,oLAMJ,IAAI3B,EAAAA,EAAAA,GAAQq8C,GAAkB,CAI5B,IAAI55C,EAAAA,EAAAA,GAAQ45C,GACV,MAAM16C,MACJ,+IAMJ,GAAyD,kBAA7C06C,EAA0B,GAAGnxB,YACvC,MAAMvpB,MACJ,iL,CAON,IAAI3B,EAAAA,EAAAA,GAAQq8C,GACVp7C,KAAKmmF,WAAY3xE,EAAAA,GAAAA,GACf4mC,EACA,CAACiiB,EAAKvnD,KACJunD,EAAIvnD,EAAQja,MAAQia,EACbunD,GAET,CAAC,QAEE,IACLrnD,EAAAA,EAAAA,GAAIolC,EAAiB,UACrB/3B,IAAM9N,EAAAA,GAAAA,IAAQwC,EAAAA,EAAAA,GAAaqjC,EAAiBF,QAASqqB,IACrD,CACA,MAAM/C,GAAgBjtD,EAAAA,GAAAA,IAAQwC,EAAAA,EAAAA,GAAaqjC,EAAiBF,QACtD+zC,EAAe75B,GAAKoN,GAC1BxiE,KAAKmmF,WAAiB3xE,EAAAA,GAAAA,GACpBy6E,EACA,CAAC5xB,EAAKvnD,KACJunD,EAAIvnD,EAAQja,MAAQia,EACbunD,GAET,CAAC,E,KAEE,MAAIhzD,EAAAA,GAAAA,GAAS+wC,GAGlB,MAAM,IAAI16C,MACR,0IAHFV,KAAKmmF,WAAY3hB,EAAAA,EAAAA,GAAMppB,E,CAUzBp7C,KAAKmmF,UAAe,IAAI7rD,GAExB,MAAMkoC,GAAgBxsD,EAAAA,EAAAA,GAAIolC,EAAiB,UACvC7lC,EAAAA,GAAAA,IAAQwC,EAAAA,EAAAA,GAAaqjC,EAAiBF,SACtCnjC,EAAAA,EAAAA,GAAOqjC,GACL8zC,EAAwB7rE,GAAMm/C,EAAgB2sB,IAClD3tF,EAAAA,EAAAA,GAAQ2tF,EAAiBv6E,kBAG3B5U,KAAK0Z,aAAew1E,EAChB/qB,GACAN,GAKJS,IAAkBvsD,EAAAA,EAAAA,GAAO/X,KAAKmmF,WAChC,CAEAiJ,UAAAA,CAEE5zD,EACArK,EACApf,GAEA,GAAI/R,KAAKylF,iBACP,MAAM/kF,MACJ,iBAAAiF,OAAiB61B,EAAQ,kLAI7B,MAAM4pD,GAAyBpvE,EAAAA,EAAAA,GAAIjE,EAAQ,iBACtCA,EAAOqzE,cACRF,GAAoBE,cAClBD,GAAoBnvE,EAAAA,EAAAA,GAAIjE,EAAQ,qBACjCA,EAAOozE,kBACRD,GAAoBC,kBAIlBkK,EACJrvF,KAAK8uF,kBAAqBQ,GAM5B,IAAIC,EA0CJ,OA9CAvvF,KAAK8uF,mBACL9uF,KAAK6uF,oBAAoBQ,GAAa7zD,EACtCx7B,KAAK4rF,oBAAoBpwD,GAAY6zD,EAOnCE,GADqB,IAAnBvvF,KAAKilF,UACa,WAIlB,IACEjlF,KAAKwvF,0BAA0BH,EAAW7zD,EAAUx7B,KAAK+uF,YAAY,QAAA/tF,EAAA5C,UAAAnC,OAHpEgF,EAAU,IAAAb,MAAAY,GAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAAVD,EAAUC,GAAA9C,UAAA8C,GAIXiwB,EAAKhwB,MAAMnB,KAAMiB,GACjB,MAAMgiD,EAAMjjD,KAAKmsF,UAAUnsF,KAAKmsF,UAAUlwF,OAAS,GAEnD,OADA+D,KAAKssF,YAAYrpC,GACVA,C,CACP,MAAO7hD,GACP,OAAOpB,KAAKyvF,gBAAgBruF,EAAGgkF,EAAeD,E,CAC9C,QACAnlF,KAAK0vF,wB,CAET,EAEoB,WAIlB,IACE1vF,KAAKwvF,0BAA0BH,EAAW7zD,EAAUx7B,KAAK+uF,YAAY,QAAA5mF,EAAA/J,UAAAnC,OAHpEgF,EAAU,IAAAb,MAAA+H,GAAAC,EAAA,EAAAA,EAAAD,EAAAC,IAAVnH,EAAUmH,GAAAhK,UAAAgK,GAIX,OAAO+oB,EAAKhwB,MAAMnB,KAAMiB,E,CACxB,MAAOG,GACP,OAAOpB,KAAKyvF,gBAAgBruF,EAAGgkF,EAAeD,E,CAC9C,QACAnlF,KAAK0vF,wB,CAET,EAGwDxwF,OAAOoS,OAC/Di+E,EACA,CAAE/zD,WAAUoqD,sBAAuBz0D,GAIvC,CAEAs+D,eAAAA,CAEEruF,EACAuuF,EACAxK,GAEA,MAAMyK,EAAgD,IAA3B5vF,KAAKwwB,WAAWv0B,OAKrC4zF,EACJF,IAAwB3vF,KAAK8oF,kBAAoB9oF,KAAKq2B,gBAExD,GAAI8nD,GAAuB/8E,GAAI,CAC7B,MAAM0uF,EAAkB1uF,EACxB,GAAIyuF,EAAe,CACjB,MAAM1H,EAAgBnoF,KAAKooF,sBAC3B,GAAIpoF,KAAK6pF,yBAAyB1B,GAAgB,CAEhD,GADA2H,EAAWzR,eAAiBr+E,KAAKqrF,SAASlD,GACtCnoF,KAAKilF,UAAW,CAClB,MAAM8K,EACJ/vF,KAAKmsF,UAAUnsF,KAAKmsF,UAAUlwF,OAAS,GAEzC,OADA8zF,EAAiBC,eAAgB,EAC1BD,C,CAEP,OAAO5K,EAAkB/jF,E,CAG3B,GAAIpB,KAAKilF,UAAW,CAClB,MAAM8K,EACJ/vF,KAAKmsF,UAAUnsF,KAAKmsF,UAAUlwF,OAAS,GACzC8zF,EAAiBC,eAAgB,EACjCF,EAAWC,iBAAmBA,C,CAGhC,MAAMD,C,CAEH,GAAIF,EAKT,OAHA5vF,KAAK2uF,wBAGExJ,EAAkB/jF,GAGzB,MAAM0uF,C,CAIR,MAAM1uF,CAEV,CAGA6uF,cAAAA,CAEEC,EACAtkF,GAEA,MAAMlD,EAAM1I,KAAKo/E,4BX9SK,IW8SmCxzE,GACzD,OAAO5L,KAAKmwF,oBAAoBD,EAAmBtkF,EAAYlD,EACjE,CAEAynF,mBAAAA,CAEED,EACAtkF,EACAlD,GAEA,IACIkrB,EADAq0D,EAAgBjoF,KAAKksF,mBAAmBxjF,GAE5C,GAAiC,oBAAtBwnF,EAAkC,CAC3Ct8D,EAASs8D,EAAkB50D,IAC3B,MAAMvwB,EAAYmlF,EAAkB/6E,KAEpC,QAAkB9W,IAAd0M,EAAyB,CAC3B,MAAMqlF,EAAuBnI,EAC7BA,EAAgBA,IACPl9E,EAAU3I,KAAKpC,OAASowF,EAAqBhuF,KAAKpC,K,OAI7D4zB,EAASs8D,EAGX,IAAiC,IAA7BjI,EAAc7lF,KAAKpC,MACrB,OAAO4zB,EAAOxxB,KAAKpC,KAGvB,CAEAqwF,kBAAAA,CAEEx8E,EACAq8E,GAEA,MAAMI,EAAQtwF,KAAKo/E,4BACjBS,GACAhsE,GAEF,OAAO7T,KAAKuwF,wBACV18E,EACAq8E,EACAI,EAEJ,CAEAC,uBAAAA,CAEE18E,EACAq8E,EACAxnF,GAEA,IACIkrB,EADAq0D,EAAgBjoF,KAAKksF,mBAAmBxjF,GAE5C,GAAiC,oBAAtBwnF,EAAkC,CAC3Ct8D,EAASs8D,EAAkB50D,IAC3B,MAAMvwB,EAAYmlF,EAAkB/6E,KAEpC,QAAkB9W,IAAd0M,EAAyB,CAC3B,MAAMqlF,EAAuBnI,EAC7BA,EAAgBA,IACPl9E,EAAU3I,KAAKpC,OAASowF,EAAqBhuF,KAAKpC,K,OAI7D4zB,EAASs8D,EAGX,IAA6C,IAA9BjI,EAAe7lF,KAAKpC,MASjC,MAAMA,KAAKwwF,wBACT38E,EACA0gE,GAAUG,qBACkBwb,EAAmBO,SAZA,CACjD,IAAItR,EAAWn/E,KAAK0wF,mBAAmB98D,GACvC,MAC2C,IAA9Bq0D,EAAe7lF,KAAKpC,QAClB,IAAbm/E,GAEAA,EAAWn/E,KAAK0wF,mBAAmB98D,E,CAevC5zB,KAAK8+E,4BACH9+E,KAAKqwF,mBACL,CAACx8E,EAAgBq8E,GACZjI,EACLpI,GACAhsE,EACAg+D,GAEJ,CAEA8e,0BAAAA,CAEE98E,EACAZ,GAEA,MAAMq9E,EAAQtwF,KAAKo/E,4BACjBW,GACAlsE,GAEF7T,KAAK4wF,gCAAgC/8E,EAAgBZ,EAASq9E,EAChE,CAEAM,+BAAAA,CAEE/8E,EACAZ,EACAvK,GAEA,MAAMkrB,EAAS3gB,EAAQqoB,IACjB/rB,EAAY0D,EAAQqxE,IAK1B,IAA+C,IAHXtkF,KAAKksF,mBAAmBxjF,GAG5BtG,KAAKpC,MAkCnC,MAAMA,KAAKwwF,wBACT38E,EACA0gE,GAAUI,oCACV1hE,EAAQw9E,SArCyC,CAC9B78D,EAAQxxB,KAAKpC,MAIlC,MAAM6wF,EAAyBA,IACtB7wF,KAAK0Z,aAAa1Z,KAAKgV,GAAG,GAAIzF,GAIvC,MAAoD,IAA7CvP,KAAK0Z,aAAa1Z,KAAKgV,GAAG,GAAIzF,IAGnCvP,KAAK8wF,QAAQvhF,GAEQqkB,EAAQxxB,KAAKpC,MAIpCA,KAAK8+E,4BACH9+E,KAAK+wF,4BACL,CACEl9E,EACAtE,EACAshF,EACAj9D,EACAm+C,IAEF8e,EACA9Q,GACAlsE,EACAk+D,G,CASN,CAEAif,YAAAA,CAEEn9E,EACAq8E,GAEA,MAAMI,EAAQtwF,KAAKo/E,4BXzdC,IWydqCvrE,GACzD,OAAO7T,KAAKixF,kBAAkBp9E,EAAgBq8E,EAAmBI,EACnE,CAEAW,iBAAAA,CAEEp9E,EACAq8E,EACAxnF,GAEA,IACIkrB,EADAs9D,EAAoBlxF,KAAKksF,mBAAmBxjF,GAEhD,GAAiC,oBAAtBwnF,EAAkC,CAC3Ct8D,EAASs8D,EAAkB50D,IAC3B,MAAMvwB,EAAYmlF,EAAkB/6E,KAEpC,QAAkB9W,IAAd0M,EAAyB,CAC3B,MAAMqlF,EAAuBc,EAC7BA,EAAoBA,IACXnmF,EAAU3I,KAAKpC,OAASowF,EAAqBhuF,KAAKpC,K,OAI7D4zB,EAASs8D,EAGX,IAAI/Q,GAAW,EACf,MAAwC,IAAjC+R,EAAkB9uF,KAAKpC,QAA+B,IAAbm/E,GAC9CA,EAAWn/E,KAAK0wF,mBAAmB98D,GAIrC5zB,KAAK8+E,4BACH9+E,KAAKgxF,aACL,CAACn9E,EAAgBq8E,GACZgB,EX5fa,IW8flBr9E,EACA29D,GAMA2N,EAEJ,CAEAgS,oBAAAA,CAEEt9E,EACAZ,GAEA,MAAMq9E,EAAQtwF,KAAKo/E,4BACjBU,GACAjsE,GAEF7T,KAAKoxF,0BAA0Bv9E,EAAgBZ,EAASq9E,EAC1D,CAEAc,yBAAAA,CAEEv9E,EACAZ,EACAvK,GAEA,MAAMkrB,EAAS3gB,EAAQqoB,IACjB/rB,EAAY0D,EAAQqxE,IAI1B,IAAwC,IAHXtkF,KAAKksF,mBAAmBxjF,GAG5BtG,KAAKpC,MAAgB,CAC5C4zB,EAAOxxB,KAAKpC,MAEZ,MAAM6wF,EAAyBA,IACtB7wF,KAAK0Z,aAAa1Z,KAAKgV,GAAG,GAAIzF,GAGvC,MAAoD,IAA7CvP,KAAK0Z,aAAa1Z,KAAKgV,GAAG,GAAIzF,IAGnCvP,KAAK8wF,QAAQvhF,GAEbqkB,EAAOxxB,KAAKpC,MAIdA,KAAK8+E,4BACH9+E,KAAK+wF,4BACL,CACEl9E,EACAtE,EACAshF,EACAj9D,EACA+9C,IAEFkf,EACA/Q,GACAjsE,EACA89D,G,CAGN,CAEAof,2BAAAA,CAEEl9E,EACAtE,EACAshF,EACAj9D,EACAy9D,GAEA,KAAOR,KAGL7wF,KAAK8wF,QAAQvhF,GACbqkB,EAAOxxB,KAAKpC,MASdA,KAAK8+E,4BACH9+E,KAAK+wF,4BACL,CACEl9E,EACAtE,EACAshF,EACAj9D,EACAy9D,GAEFR,EACA9Q,GACAlsE,EACAw9E,EAEJ,CAEAX,kBAAAA,CAAwC98D,GACtC,MAAM09D,EAAkBtxF,KAAK4uF,mBAM7B,OALAh7D,EAAOxxB,KAAKpC,MACWA,KAAK4uF,mBAIJ0C,CAC1B,CAEAC,UAAAA,CAEEC,EACA5lF,GAEA,MAAM0kF,EAAQtwF,KAAKo/E,4BXvnBD,IWunBqCxzE,GACjD2C,GAAOxP,EAAAA,EAAAA,GAAQyyF,GAAcA,EAAaA,EAAWl2D,IAGrDm2D,EADSzxF,KAAKksF,mBAAmBoE,GACXluF,KAAKpC,KAAMuO,GACvC,QAAqBlQ,IAAjBozF,EAEF,OAD+BljF,EAAKkjF,GACXt4D,IAAI/2B,KAAKpC,MAEpCA,KAAK0xF,oBACH9lF,EACC4lF,EAAqCf,QAE1C,CAEAf,sBAAAA,GAOE,GANA1vF,KAAKwwB,WAAWzW,MAChB/Z,KAAKkrF,sBAAsBnxE,MAG3B/Z,KAAK+sF,wBAE0B,IAA3B/sF,KAAKwwB,WAAWv0B,SAA0C,IAA1B+D,KAAK2xF,iBAA4B,CACnE,MAAMC,EAAoB5xF,KAAKgV,GAAG,GAC5B+tD,EAAS/iE,KAAKyvB,qBAAqBmF,8BAA8B,CACrEU,eAAgBs8D,EAChBp2D,SAAUx7B,KAAKu/E,wBAEjBv/E,KAAK0oF,WACH,IAAIjK,GAA2B1b,EAAQ6uB,G,CAG7C,CAEAC,eAAAA,CAEEC,EACA7iF,EACAgE,GAEA,IAAIy6E,EACJ,IACE,MAAMzsF,OAAmB5C,IAAZ4U,EAAwBA,EAAQ4jB,UAAOx4B,EASpD,OARA2B,KAAK+uF,WAAa9/E,EAClBy+E,EAAaoE,EAAW3wF,MAAMnB,KAAMiB,GACpCjB,KAAKitF,mBACHS,OACYrvF,IAAZ4U,QAA2C5U,IAAlB4U,EAAQmiB,MAC7BniB,EAAQmiB,MACR08D,EAAWt2D,UAEVkyD,C,CACP,MAAOtsF,GACP,MAAMpB,KAAK+xF,qBAAqB3wF,EAAG6R,EAAS6+E,EAAWt2D,S,CAE3D,CAEAu2D,oBAAAA,CAEE3wF,EACA6R,EACAuoB,GAYA,MAVI2iD,GAAuB/8E,SAA6B/C,IAAvB+C,EAAE2uF,mBACjC/vF,KAAKitF,mBACH7rF,EAAE2uF,sBACU1xF,IAAZ4U,QAA2C5U,IAAlB4U,EAAQmiB,MAC7BniB,EAAQmiB,MACRoG,UAGCp6B,EAAE2uF,kBAEL3uF,CACR,CAEA4wF,eAAAA,CAEEl8E,EACA7G,EACAgE,GAEA,IAAIo6E,EACJ,IACE,MAAMt4E,EAAY/U,KAAKgV,GAAG,IACoB,IAA1ChV,KAAK0Z,aAAa3E,EAAWe,IAC/B9V,KAAKypF,eACL4D,EAAgBt4E,GAEhB/U,KAAKiyF,qBAAqBn8E,EAASf,EAAW9B,E,CAEhD,MAAOi/E,GACP7E,EAAgBrtF,KAAKmyF,wBACnBr8E,EACA7G,EACAijF,E,CAUJ,OANAlyF,KAAKgtF,qBACS3uF,IAAZ4U,QAA2C5U,IAAlB4U,EAAQmiB,MAC7BniB,EAAQmiB,MACRtf,EAAQja,KACZwxF,GAEKA,CACT,CAEA4E,oBAAAA,CAEEn8E,EACAf,EACA9B,GAEA,IAAIokD,EACJ,MAAMhnB,EAAgBrwC,KAAKgV,GAAG,GAW9B,MATEqiD,OADch5D,IAAZ4U,GAAyBA,EAAQw9E,QAC7Bx9E,EAAQw9E,QAERzwF,KAAKyvB,qBAAqBiF,0BAA0B,CACxDO,SAAUnf,EACVof,OAAQngB,EACRkE,SAAUo3B,EACV7U,SAAUx7B,KAAKu/E,wBAGbv/E,KAAK0oF,WACT,IAAInK,GAAyBlnB,EAAKtiD,EAAWs7B,GAEjD,CAEA8hD,uBAAAA,CAEEr8E,EACA7G,EACAijF,GAIA,IACElyF,KAAKq2B,iBAEqB,6BAA1B67D,EAAiBr2F,MAChBmE,KAAK8oF,iBAeN,MAAMoJ,EAdN,CACA,MAAMr8B,EAAU71D,KAAKgpF,4BAAiClzE,EAAS7G,GAC/D,IACE,OAAOjP,KAAKqpF,kBAAuBvzE,EAAS+/C,E,CAC5C,MAAOu8B,GACP,MAAIA,EAAoBv2F,OAAS+iF,GAGzBsT,EAEAE,C,EAMd,CAEAC,cAAAA,GAEE,MAAMC,EAActyF,KAAKgyB,OACnBugE,GAAiB/tB,EAAAA,EAAAA,GAAMxkE,KAAKwwB,YAClC,MAAO,CACLwB,OAAQsgE,EACRE,WAAYxyF,KAAKsoF,mBACjB93D,WAAY+hE,EACZpG,UAAWnsF,KAAKmsF,UAEpB,CAEAsG,gBAAAA,CAAsCzlF,GACpChN,KAAKgyB,OAAShlB,EAASglB,OACvBhyB,KAAK6oF,iBAAiB77E,EAASwlF,YAC/BxyF,KAAKwwB,WAAaxjB,EAASwjB,UAC7B,CAEAg/D,yBAAAA,CAEEH,EACAqD,EACA7H,GAEA7qF,KAAKkrF,sBAAsB/qF,KAAK0qF,GAChC7qF,KAAKwwB,WAAWrwB,KAAKkvF,GAErBrvF,KAAK8sF,yBAAyB4F,EAChC,CAEA5J,cAAAA,GACE,OAA2C,IAApC9oF,KAAKgvF,oBAAoB/yF,MAClC,CAEAsjF,mBAAAA,GACE,MAAM8P,EAAYrvF,KAAKuqF,+BACvB,OAAOvqF,KAAK6uF,oBAAoBQ,EAClC,CAEAzE,uBAAAA,CAA6CyE,GAC3C,OAAOrvF,KAAK6uF,oBAAoBQ,EAClC,CAEOsC,cAAAA,GACL,OAAO3xF,KAAK0Z,aAAa1Z,KAAKgV,GAAG,GAAIslB,GACvC,CAEOgrB,KAAAA,GACLtlD,KAAK0uF,kBACL1uF,KAAK+uF,WAAa,EAClB/uF,KAAKgvF,oBAAsB,GAC3BhvF,KAAKgyB,OAAS,GACdhyB,KAAKwwB,WAAa,GAElBxwB,KAAKmsF,UAAY,GACjBnsF,KAAKkrF,sBAAwB,EAC/B,GCh0BI,MACJyH,MAAAA,CAA+BxhE,GAC7B,OAAOA,EAAK/uB,KAAKpC,KACnB,CAEAyyB,OAAAA,CAEExjB,EACA6G,EACA7C,GAEA,OAAOjT,KAAKgyF,gBAAgBl8E,EAAS7G,EAAKgE,EAC5C,CAEAogB,OAAAA,CAEEpkB,EACA6iF,EACA7+E,GAEA,OAAOjT,KAAK6xF,gBAAgBC,EAAY7iF,EAAKgE,EAC/C,CAEApE,MAAAA,CAEEI,EACAihF,GAEA,OAAOlwF,KAAKiwF,eAAeC,EAAmBjhF,EAChD,CAEA6nB,EAAAA,CAEE7nB,EACAuiF,GAEA,OAAOxxF,KAAKuxF,WAAWC,EAAYviF,EACrC,CAEA8gB,IAAAA,CAEE9gB,EACAihF,GAEA,OAAOlwF,KAAKgxF,aAAa/hF,EAAKihF,EAChC,CAEAjgE,UAAAA,CAEEhhB,EACAihF,GAEA,OAAOlwF,KAAKqwF,mBAAmBphF,EAAKihF,EACtC,CAEAY,OAAAA,CAEEh7E,EACA7C,GAEA,OAAOjT,KAAKgyF,gBAAgBl8E,EAAS,EAAG7C,EAC1C,CAEA2/E,QAAAA,CAEE98E,EACA7C,GAEA,OAAOjT,KAAKgyF,gBAAgBl8E,EAAS,EAAG7C,EAC1C,CAEA4/E,QAAAA,CAEE/8E,EACA7C,GAEA,OAAOjT,KAAKgyF,gBAAgBl8E,EAAS,EAAG7C,EAC1C,CAEA6/E,QAAAA,CAEEh9E,EACA7C,GAEA,OAAOjT,KAAKgyF,gBAAgBl8E,EAAS,EAAG7C,EAC1C,CAEA8/E,QAAAA,CAEEj9E,EACA7C,GAEA,OAAOjT,KAAKgyF,gBAAgBl8E,EAAS,EAAG7C,EAC1C,CAEA+/E,QAAAA,CAEEl9E,EACA7C,GAEA,OAAOjT,KAAKgyF,gBAAgBl8E,EAAS,EAAG7C,EAC1C,CAEAggF,QAAAA,CAEEn9E,EACA7C,GAEA,OAAOjT,KAAKgyF,gBAAgBl8E,EAAS,EAAG7C,EAC1C,CAEAigF,QAAAA,CAEEp9E,EACA7C,GAEA,OAAOjT,KAAKgyF,gBAAgBl8E,EAAS,EAAG7C,EAC1C,CAEAkgF,QAAAA,CAEEr9E,EACA7C,GAEA,OAAOjT,KAAKgyF,gBAAgBl8E,EAAS,EAAG7C,EAC1C,CAEAmgF,QAAAA,CAEEt9E,EACA7C,GAEA,OAAOjT,KAAKgyF,gBAAgBl8E,EAAS,EAAG7C,EAC1C,CAEAogF,OAAAA,CAEEvB,EACA7+E,GAEA,OAAOjT,KAAK6xF,gBAAgBC,EAAY,EAAG7+E,EAC7C,CAEAqgF,QAAAA,CAEExB,EACA7+E,GAEA,OAAOjT,KAAK6xF,gBAAgBC,EAAY,EAAG7+E,EAC7C,CAEAsgF,QAAAA,CAEEzB,EACA7+E,GAEA,OAAOjT,KAAK6xF,gBAAgBC,EAAY,EAAG7+E,EAC7C,CAEAugF,QAAAA,CAEE1B,EACA7+E,GAEA,OAAOjT,KAAK6xF,gBAAgBC,EAAY,EAAG7+E,EAC7C,CAEAwgF,QAAAA,CAEE3B,EACA7+E,GAEA,OAAOjT,KAAK6xF,gBAAgBC,EAAY,EAAG7+E,EAC7C,CAEAygF,QAAAA,CAEE5B,EACA7+E,GAEA,OAAOjT,KAAK6xF,gBAAgBC,EAAY,EAAG7+E,EAC7C,CAEA0gF,QAAAA,CAEE7B,EACA7+E,GAEA,OAAOjT,KAAK6xF,gBAAgBC,EAAY,EAAG7+E,EAC7C,CAEA2gF,QAAAA,CAEE9B,EACA7+E,GAEA,OAAOjT,KAAK6xF,gBAAgBC,EAAY,EAAG7+E,EAC7C,CAEA4gF,QAAAA,CAEE/B,EACA7+E,GAEA,OAAOjT,KAAK6xF,gBAAgBC,EAAY,EAAG7+E,EAC7C,CAEA6gF,QAAAA,CAEEhC,EACA7+E,GAEA,OAAOjT,KAAK6xF,gBAAgBC,EAAY,EAAG7+E,EAC7C,CAEAuhE,MAAAA,CAEE0b,GAEA,OAAOlwF,KAAKiwF,eAAeC,EAAmB,EAChD,CAEA6D,OAAAA,CAEE7D,GAEA,OAAOlwF,KAAKiwF,eAAeC,EAAmB,EAChD,CAEA8D,OAAAA,CAEE9D,GAEA,OAAOlwF,KAAKiwF,eAAeC,EAAmB,EAChD,CAEA+D,OAAAA,CAEE/D,GAEA,OAAOlwF,KAAKiwF,eAAeC,EAAmB,EAChD,CAEAgE,OAAAA,CAEEhE,GAEA,OAAOlwF,KAAKiwF,eAAeC,EAAmB,EAChD,CAEAiE,OAAAA,CAEEjE,GAEA,OAAOlwF,KAAKiwF,eAAeC,EAAmB,EAChD,CAEAkE,OAAAA,CAEElE,GAEA,OAAOlwF,KAAKiwF,eAAeC,EAAmB,EAChD,CAEAmE,OAAAA,CAEEnE,GAEA,OAAOlwF,KAAKiwF,eAAeC,EAAmB,EAChD,CAEAoE,OAAAA,CAEEpE,GAEA,OAAOlwF,KAAKiwF,eAAeC,EAAmB,EAChD,CAEAqE,OAAAA,CAEErE,GAEA,OAAOlwF,KAAKiwF,eAAeC,EAAmB,EAChD,CAEAsE,EAAAA,CAEEhD,GAEA,OAAOxxF,KAAKuxF,WAAWC,EAAY,EACrC,CAEAiD,GAAAA,CAEEjD,GAEA,OAAOxxF,KAAKuxF,WAAWC,EAAY,EACrC,CAEAkD,GAAAA,CAEElD,GAEA,OAAOxxF,KAAKuxF,WAAWC,EAAY,EACrC,CAEAmD,GAAAA,CAEEnD,GAEA,OAAOxxF,KAAKuxF,WAAWC,EAAY,EACrC,CAEAoD,GAAAA,CAEEpD,GAEA,OAAOxxF,KAAKuxF,WAAWC,EAAY,EACrC,CAEAqD,GAAAA,CAEErD,GAEA,OAAOxxF,KAAKuxF,WAAWC,EAAY,EACrC,CAEAsD,GAAAA,CAEEtD,GAEA,OAAOxxF,KAAKuxF,WAAWC,EAAY,EACrC,CAEAuD,GAAAA,CAEEvD,GAEA,OAAOxxF,KAAKuxF,WAAWC,EAAY,EACrC,CAEAwD,GAAAA,CAEExD,GAEA,OAAOxxF,KAAKuxF,WAAWC,EAAY,EACrC,CAEAyD,GAAAA,CAEEzD,GAEA,OAAOxxF,KAAKuxF,WAAWC,EAAY,EACrC,CAEA0D,IAAAA,CAEEhF,GAEAlwF,KAAKgxF,aAAa,EAAGd,EACvB,CAEAiF,KAAAA,CAEEjF,GAEAlwF,KAAKgxF,aAAa,EAAGd,EACvB,CAEAkF,KAAAA,CAEElF,GAEAlwF,KAAKgxF,aAAa,EAAGd,EACvB,CAEAmF,KAAAA,CAEEnF,GAEAlwF,KAAKgxF,aAAa,EAAGd,EACvB,CAEAoF,KAAAA,CAEEpF,GAEAlwF,KAAKgxF,aAAa,EAAGd,EACvB,CAEAqF,KAAAA,CAEErF,GAEAlwF,KAAKgxF,aAAa,EAAGd,EACvB,CAEAsF,KAAAA,CAEEtF,GAEAlwF,KAAKgxF,aAAa,EAAGd,EACvB,CAEAuF,KAAAA,CAEEvF,GAEAlwF,KAAKgxF,aAAa,EAAGd,EACvB,CAEAwF,KAAAA,CAEExF,GAEAlwF,KAAKgxF,aAAa,EAAGd,EACvB,CAEAyF,KAAAA,CAEEzF,GAEAlwF,KAAKgxF,aAAa,EAAGd,EACvB,CAEA0F,QAAAA,CAAmC3iF,GACjCjT,KAAKmxF,qBAAqB,EAAGl+E,EAC/B,CAEA4iF,SAAAA,CAAoC5iF,GAClCjT,KAAKmxF,qBAAqB,EAAGl+E,EAC/B,CAEA6iF,SAAAA,CAAoC7iF,GAClCjT,KAAKmxF,qBAAqB,EAAGl+E,EAC/B,CAEA8iF,SAAAA,CAAoC9iF,GAClCjT,KAAKmxF,qBAAqB,EAAGl+E,EAC/B,CAEA+iF,SAAAA,CAAoC/iF,GAClCjT,KAAKmxF,qBAAqB,EAAGl+E,EAC/B,CAEAgjF,SAAAA,CAAoChjF,GAClCjT,KAAKmxF,qBAAqB,EAAGl+E,EAC/B,CAEAijF,SAAAA,CAAoCjjF,GAClCjT,KAAKmxF,qBAAqB,EAAGl+E,EAC/B,CAEAkjF,SAAAA,CAAoCljF,GAClCjT,KAAKmxF,qBAAqB,EAAGl+E,EAC/B,CAEAmjF,SAAAA,CAAoCnjF,GAClCjT,KAAKmxF,qBAAqB,EAAGl+E,EAC/B,CAEAojF,SAAAA,CAAoCpjF,GAClCjT,KAAKmxF,qBAAqB,EAAGl+E,EAC/B,CAEAqjF,YAAAA,CAEEpG,GAEAlwF,KAAKqwF,mBAAmB,EAAGH,EAC7B,CAEAqG,aAAAA,CAEErG,GAEA,OAAOlwF,KAAKqwF,mBAAmB,EAAGH,EACpC,CAEAsG,aAAAA,CAEEtG,GAEAlwF,KAAKqwF,mBAAmB,EAAGH,EAC7B,CAEAuG,aAAAA,CAEEvG,GAEAlwF,KAAKqwF,mBAAmB,EAAGH,EAC7B,CAEAwG,aAAAA,CAEExG,GAEAlwF,KAAKqwF,mBAAmB,EAAGH,EAC7B,CAEAyG,aAAAA,CAEEzG,GAEAlwF,KAAKqwF,mBAAmB,EAAGH,EAC7B,CAEA0G,aAAAA,CAEE1G,GAEAlwF,KAAKqwF,mBAAmB,EAAGH,EAC7B,CAEA2G,aAAAA,CAEE3G,GAEAlwF,KAAKqwF,mBAAmB,EAAGH,EAC7B,CAEA4G,aAAAA,CAEE5G,GAEAlwF,KAAKqwF,mBAAmB,EAAGH,EAC7B,CAEA6G,aAAAA,CAEE7G,GAEAlwF,KAAKqwF,mBAAmB,EAAGH,EAC7B,CAEA8G,gBAAAA,CAEE/jF,GAEAjT,KAAK2wF,2BAA2B,EAAG19E,EACrC,CAEAgkF,iBAAAA,CAEEhkF,GAEAjT,KAAK2wF,2BAA2B,EAAG19E,EACrC,CAEAikF,iBAAAA,CAEEjkF,GAEAjT,KAAK2wF,2BAA2B,EAAG19E,EACrC,CAEAkkF,iBAAAA,CAEElkF,GAEAjT,KAAK2wF,2BAA2B,EAAG19E,EACrC,CAEAmkF,iBAAAA,CAEEnkF,GAEAjT,KAAK2wF,2BAA2B,EAAG19E,EACrC,CAEAokF,iBAAAA,CAEEpkF,GAEAjT,KAAK2wF,2BAA2B,EAAG19E,EACrC,CAEAqkF,iBAAAA,CAEErkF,GAEAjT,KAAK2wF,2BAA2B,EAAG19E,EACrC,CAEAskF,iBAAAA,CAEEtkF,GAEAjT,KAAK2wF,2BAA2B,EAAG19E,EACrC,CAEAukF,iBAAAA,CAEEvkF,GAEAjT,KAAK2wF,2BAA2B,EAAG19E,EACrC,CAEAwkF,iBAAAA,CAEExkF,GAEAjT,KAAK2wF,2BAA2B,EAAG19E,EACrC,CAEA0jB,IAAAA,CAEE96B,EACAu2B,GAC4C,IAA5CrgB,EAAA3T,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAyB8mF,GAEzB,GAAI52C,GAAStuC,KAAK2lF,kBAAmB9pF,GAAO,CAC1C,MAMM0F,EAAQ,CACZ4J,QANA2iE,GAAqCuB,4BAA4B,CAC/Dt2D,aAAcld,EACdyzE,YAAatvE,KAAK3D,YAKpBsP,KAAMikE,GAA0BoL,oBAChCx/C,SAAU3/B,GAEZmE,KAAKw0B,iBAAiBr0B,KAAKoB,E,CAG7BvB,KAAK2lF,kBAAkBxlF,KAAKtE,GAE5B,MAAM67F,EAAqB13F,KAAKovF,WAAWvzF,EAAMu2B,EAAgBrgB,GAEjE,OADC/R,KAAanE,GAAQ67F,EACfA,CACT,CAEAC,aAAAA,CAEE97F,EACAs1B,GAC4C,IAA5Cpf,EAAA3T,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAyB8mF,GAEzB,MAAM0S,EhBtaJ,SACJp8D,EACAmqD,EACAtpF,GAEA,MAAM21B,EAAS,GACf,IAAI+wC,EAaJ,OAXKz0B,GAASq3C,EAAmBnqD,KAC/BunC,EACE,kCAAAp9D,OAAkC61B,EAAQ,8CAAA71B,OAA6CtJ,EAAS,2DAElG21B,EAAO7xB,KAAK,CACVgL,QAAS43D,EACTp3D,KAAMikE,GAA0BioB,sBAChCr8D,SAAUA,KAIPxJ,CACT,CgBkZiD8lE,CAC3Cj8F,EACAmE,KAAK2lF,kBACL3lF,KAAK3D,WAEP2D,KAAKw0B,iBAAmBx0B,KAAKw0B,iBAAiB7uB,OAAOiyF,GAErD,MAAMF,EAAqB13F,KAAKovF,WAAWvzF,EAAMs1B,EAAMpf,GAEvD,OADC/R,KAAanE,GAAQ67F,EACfA,CACT,CAEAK,SAAAA,CAEEhQ,EACA9mF,GAEA,OAAO,WAELjB,KAAKgvF,oBAAoB7uF,KAAK,GAC9B,MAAM63F,EAAWh4F,KAAKqyF,iBACtB,IAGE,OAFAtK,EAAY5mF,MAAMnB,KAAMiB,IAEjB,C,CACP,MAAOG,GACP,GAAI+8E,GAAuB/8E,GACzB,OAAO,EAEP,MAAMA,C,CAER,QACApB,KAAKyyF,iBAAiBuF,GACtBh4F,KAAKgvF,oBAAoBj1E,K,CAE7B,CACF,CAGOylE,kBAAAA,GACL,OAAOx/E,KAAK+lF,oBACd,CAEOkS,4BAAAA,GACL,OvDhZ6BC,GuDgZLngF,EAAAA,EAAAA,GAAO/X,KAAK+lF,uBvD/Y/Bv3E,EAAAA,EAAAA,GAAI0pF,EAAUhnC,GADjB,IAA2BgnC,CuDiZ/B,GCvrBI,MAIJhR,gBAAAA,CAAiBn1E,GACf/R,KAAKm4F,QAAU,GACfn4F,KAAKyvB,sBAAuBzZ,EAAAA,EAAAA,GAAIjE,EAAQ,wBACnCA,EAAO0d,qBACRwwD,GAAsBxwD,oBAC5B,CAEAi5D,UAAAA,CAEEnnF,GAEA,GAAI48E,GAAuB58E,GAMzB,OALAA,EAAMpD,QAAU,CACdwyE,UAAW3wE,KAAKsrF,4BAChB8M,qBAAqB5zB,EAAAA,EAAAA,GAAMxkE,KAAKkrF,wBAElClrF,KAAKm4F,QAAQh4F,KAAKoB,GACXA,EAEP,MAAMb,MACJ,8DAGN,CAEA,UAAIsxB,GACF,OAAOwyC,EAAAA,EAAAA,GAAMxkE,KAAKm4F,QACpB,CAEA,UAAInmE,CAAOqmE,GACTr4F,KAAKm4F,QAAUE,CACjB,CAGA7H,uBAAAA,CAEE5kF,EACAwI,EACAkkF,GAEA,MAAM98D,EAAWx7B,KAAKu/E,sBAQhBgZ,EAN+BxjB,GACnCnpE,EAFkB5L,KAAKw/E,qBAAqBhkD,GAI5CpnB,EACApU,KAAKmU,cAE8C,GAC/CqkF,EAAe,GACrB,IAAK,IAAIj4F,EAAI,EAAGA,GAAKP,KAAKmU,aAAc5T,IACtCi4F,EAAar4F,KAAKH,KAAKgV,GAAGzU,IAE5B,MAAM82D,EAAMr3D,KAAKyvB,qBAAqBqF,sBAAsB,CAC1D44C,uBAAwB6qB,EACxBrjE,OAAQsjE,EACRv/E,SAAUjZ,KAAKgV,GAAG,GAClB+3D,sBAAuBurB,EACvB98D,SAAUA,IAGZ,MAAMx7B,KAAK0oF,WAAW,IAAIhK,GAAmBrnB,EAAKr3D,KAAKgV,GAAG,GAAIhV,KAAKgV,GAAG,IACxE,CAGA08E,mBAAAA,CAEE9lF,EACA6sF,GAEA,MAAMj9D,EAAWx7B,KAAKu/E,sBAGhBmZ,EAA+B5jB,GACnClpE,EAHkB5L,KAAKw/E,qBAAqBhkD,GAK5Cx7B,KAAKmU,cAGDqkF,EAAe,GACrB,IAAK,IAAIj4F,EAAI,EAAGA,GAAKP,KAAKmU,aAAc5T,IACtCi4F,EAAar4F,KAAKH,KAAKgV,GAAGzU,IAE5B,MAAM8vC,EAAgBrwC,KAAKgV,GAAG,GAExB+tD,EAAS/iE,KAAKyvB,qBAAqBoF,wBAAwB,CAC/Di4C,oBAAqB4rB,EACrBxjE,OAAQsjE,EACRv/E,SAAUo3B,EACV08B,sBAAuB0rB,EACvBj9D,SAAUx7B,KAAKu/E,wBAGjB,MAAMv/E,KAAK0oF,WACT,IAAIlK,GAAqBzb,EAAQ/iE,KAAKgV,GAAG,GAAIq7B,GAEjD,GC7GI,MACJm3C,iBAAAA,GAAqB,CAEdmR,oBAAAA,CAELC,EACAC,GAEA,MAAMC,EAAgB94F,KAAK+lF,qBAAqB6S,GAEhD,IAAIj8B,EAAAA,GAAAA,GAAYm8B,GACd,MAAMp4F,MAAM,UAADiF,OAAWizF,EAAa,uCAGrC,OAAOnmB,GACL,CAACqmB,GACDD,EACA74F,KAAK0Z,aACL1Z,KAAKmU,aAET,CAIOi1E,yBAAAA,CAELF,GAEA,MAAM6P,EAAcvoF,GAAM04E,EAAYvY,WAEhCqoB,EADkBh5F,KAAKw/E,qBACSuZ,GAKtC,OAJ+B,IAAIhoB,GACjCioB,EACA9P,GACApzB,cAEJ,GRsCI,MAIJ2xB,gBAAAA,CAAsC11E,GACpC/R,KAAKmkF,mBAAqB,GAC1BnkF,KAAK02B,iBAAkB,CACzB,CAEAgvD,eAAAA,GACE1lF,KAAK02B,iBAAkB,EAEvB12B,KAAKkmE,WAAW,mBAAoB,KAUlC,IAAK,IAAI3lE,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,MAAM0O,EAAM1O,EAAI,EAAIA,EAAI,GACxBP,KAAK,UAAD2F,OAAWsJ,IAAsB,SAAUgqF,EAAMC,GACnD,OAAOl5F,KAAKm5F,sBAAsBF,EAAM14F,EAAG24F,EAC7C,EACAl5F,KAAK,UAAD2F,OAAWsJ,IAAsB,SAAUgqF,EAAMC,GACnD,OAAOl5F,KAAKo5F,sBAAsBH,EAAM14F,EAAG24F,EAC7C,EACAl5F,KAAK,SAAD2F,OAAUsJ,IAAqB,SAAUgqF,GAC3C,OAAOj5F,KAAKq5F,qBAAqBJ,EAAM14F,EACzC,EACAP,KAAK,KAAD2F,OAAMsJ,IAAiB,SAAUgqF,GACnC,OAAOj5F,KAAKs5F,iBAAiBL,EAAM14F,EACrC,EACAP,KAAK,OAAD2F,OAAQsJ,IAAmB,SAAUgqF,GACvCj5F,KAAKu5F,mBAAmBh5F,EAAG04F,EAC7B,EACAj5F,KAAK,WAAD2F,OAAYsJ,IAAuB,SAAUgqF,GAC/Cj5F,KAAKw5F,2BAA2Bj5F,EAAG04F,EACrC,EACAj5F,KAAK,eAAD2F,OAAgBsJ,IAA2B,SAAUgqF,GACvDj5F,KAAKy5F,yBAAyBl5F,EAAG04F,EACnC,EACAj5F,KAAK,mBAAD2F,OAAoBsJ,IAA+B,SAAUgqF,GAC/Dj5F,KAAK05F,iCAAiCn5F,EAAG04F,EAC3C,C,CAIFj5F,KAAI,QAAc,SAAUiP,EAAKgqF,EAAMC,GACrC,OAAOl5F,KAAKm5F,sBAAsBF,EAAMhqF,EAAKiqF,EAC/C,EACAl5F,KAAI,QAAc,SAAUiP,EAAKgqF,EAAMC,GACrC,OAAOl5F,KAAKo5F,sBAAsBH,EAAMhqF,EAAKiqF,EAC/C,EACAl5F,KAAI,OAAa,SAAUiP,EAAKgqF,GAC9B,OAAOj5F,KAAKq5F,qBAAqBJ,EAAMhqF,EACzC,EACAjP,KAAI,GAAS,SAAUiP,EAAKgqF,GAC1B,OAAOj5F,KAAKs5F,iBAAiBL,EAAMhqF,EACrC,EACAjP,KAAI,KAAW,SAAUiP,EAAKgqF,GAC5Bj5F,KAAKu5F,mBAAmBtqF,EAAKgqF,EAC/B,EACAj5F,KAAI,WAAiB,SAAUiP,EAAKgqF,GAClCj5F,KAAKy5F,yBAAyBxqF,EAAKgqF,EACrC,EAEAj5F,KAAK2yF,OAAS3yF,KAAK25F,cACnB35F,KAAK+3F,UAAY/3F,KAAK45F,iBACtB55F,KAAKgV,GAAKhV,KAAK65F,WAEnB,CAEA7T,gBAAAA,GACEhmF,KAAK02B,iBAAkB,EAKvB12B,KAAKkmE,WAAW,6BAA8B,KAC5C,MAAM+gB,EAAYjnF,KAElB,IAAK,IAAIO,EAAI,EAAGA,EAAI,GAAIA,IAAK,CAC3B,MAAM0O,EAAM1O,EAAI,EAAIA,EAAI,UACjB0mF,EAAK,UAADthF,OAAWsJ,WACfg4E,EAAK,UAADthF,OAAWsJ,WACfg4E,EAAK,SAADthF,OAAUsJ,WACdg4E,EAAK,KAADthF,OAAMsJ,WACVg4E,EAAK,OAADthF,OAAQsJ,WACZg4E,EAAK,WAADthF,OAAYsJ,WAChBg4E,EAAK,eAADthF,OAAgBsJ,WACpBg4E,EAAK,mBAADthF,OAAoBsJ,G,QAG1Bg4E,EAAI,eACJA,EAAI,eACJA,EAAI,cACJA,EAAI,UACJA,EAAI,YACJA,EAAI,kBAEJA,EAAK0L,cACL1L,EAAK8Q,iBACL9Q,EAAKjyE,IAEhB,CAKA2kF,aAAAA,CAAsCxoE,GACpC,CAIFyoE,gBAAAA,CACE7R,EACA9mF,GAEA,MAAO,KAAM,CACf,CAIA44F,SAAAA,CAAUrL,GAGR,OAAOzJ,EACT,CAEAe,kBAAAA,CAAmBjqF,EAAcu3E,GAC/B,IACE,MAAM0mB,EAAkB,IAAIhpC,EAAK,CAAEriD,WAAY,GAAI5S,KAAMA,IAKzD,OAJAi+F,EAAgBj+F,KAAOA,EACvBmE,KAAKmkF,mBAAmBhkF,KAAK25F,GAC7B1mB,EAAIhxE,KAAKpC,MACTA,KAAKmkF,mBAAmBpqE,MACjB+/E,C,CACP,MAAOC,GACP,IAA2C,IAAvCA,EAAcjV,qBAChB,IACEiV,EAAc5uF,QACZ4uF,EAAc5uF,QAAd4uF,yJ,CAGF,MAAOC,GAEP,MAAMD,C,CAGV,MAAMA,C,CAEV,CAGAV,oBAAAA,CAEEnJ,EACAtkF,GAEA,OAAOg4E,GAAWxhF,KAAKpC,KAAM4O,EAAQshF,EAAmBtkF,EAC1D,CAEA6tF,wBAAAA,CAEE7tF,EACAskF,GAEAtM,GAAWxhF,KAAKpC,KAAMyP,EAAqBygF,EAAmBtkF,EAChE,CAEA8tF,gCAAAA,CAEE9tF,EACAqH,GAEA2wE,GAAWxhF,KACTpC,KACA6P,EACAoD,EACArH,EACA03E,GAEJ,CAEAiW,kBAAAA,CAEE3tF,EACAskF,GAEAtM,GAAWxhF,KAAKpC,KAAMkP,EAAYghF,EAAmBtkF,EACvD,CAEA4tF,0BAAAA,CAEE5tF,EACAqH,GAEA2wE,GAAWxhF,KACTpC,KACAsP,EACA2D,EACArH,EACA03E,GAEJ,CAEAgW,gBAAAA,CAEE9H,EACA5lF,GAEA,OAAO44E,GAAapiF,KAAKpC,KAAMwxF,EAAY5lF,EAC7C,CAEAwtF,qBAAAA,CAEEtH,EACAlmF,EACAqH,GAGA,GADA+wE,GAAuBp4E,IAClBkmF,IAA8C,KAAhC97E,EAAAA,EAAAA,GAAI87E,EAAY,YAAuB,CACxD,MAAMvwF,EAAa,IAAIb,MACrB,WAAAiF,OAAWk/E,GAAaj5E,GAAW,2EAAAjG,OACiBhD,KAAKC,UACrDkvF,GACD,KAAG,8BAAAnsF,OAEK3F,KAAKmkF,mBAAmB,GAAItoF,KACrC,MAGJ,MADA0F,EAAMujF,sBAAuB,EACvBvjF,C,CAGR,MAAM0iF,GAAgBC,EAAAA,GAAAA,GAAKlkF,KAAKmkF,oBAC1B3oD,EAAWs2D,EAAWt2D,SACtBy+D,EAAkB,IAAIrsF,EAAY,CACtCqB,IAAKrD,EACLylD,gBAAiB71B,EACjBlb,MAAc,OAAPrN,QAAO,IAAPA,OAAO,EAAPA,EAASmiB,MAEhBrnB,oBAAgB1P,IAIlB,OAFA4lF,EAASx1E,WAAWtO,KAAK85F,GAElBj6F,KAAKilF,UACRtB,GACKN,EACX,CAEA8V,qBAAAA,CAEErjF,EACAlK,EACAqH,GAGA,GADA+wE,GAAuBp4E,IAClBg5D,GAAoB9uD,GAAU,CACjC,MAAMvU,EAAa,IAAIb,MACrB,WAAAiF,OAAWk/E,GAAaj5E,GAAW,uEAAAjG,OACahD,KAAKC,UACjDkT,GACD,KAAG,8BAAAnQ,OAEK3F,KAAKmkF,mBAAmB,GAAItoF,KACrC,MAGJ,MADA0F,EAAMujF,sBAAuB,EACvBvjF,C,CAER,MAAM0iF,GAAgBC,EAAAA,GAAAA,GAAKlkF,KAAKmkF,oBAC1B8V,EAAkB,IAAIxsF,EAAS,CACnCwB,IAAKrD,EACL+B,aAAcmI,EACdwK,MAAc,OAAPrN,QAAO,IAAPA,OAAO,EAAPA,EAASmiB,QAIlB,OAFA6uD,EAASx1E,WAAWtO,KAAK85F,GAElBvW,EACT,GS1WI,MAKJgE,qBAAAA,CAAsB31E,GACpB,IAAIiE,EAAAA,EAAAA,GAAIjE,EAAQ,iBAAkB,CAChC,MAAMmoF,EAAoBnoF,EAAO4zD,cAC3Bw0B,EAA6C,kBAAtBD,EAC7Bl6F,KAAKsmE,kBAAoB6zB,EACbD,EACRzzB,IACJzmE,KAAK2lE,cAAgBw0B,EACjBD,EAAoB,EACnBA,C,MAELl6F,KAAKsmE,kBAAoB,EACzBtmE,KAAK2lE,cAAgBsa,GAAsBta,cAG7C3lE,KAAKqmE,iBAAmB,CAC1B,CAEAH,UAAAA,CAAmCC,EAAmBC,GAGpD,IAA2B,IAAvBpmE,KAAK2lE,cAAwB,CAC/B3lE,KAAKqmE,kBACL,MAAM3oE,EAAS,IAAI0C,MAAMJ,KAAKqmE,gBAAkB,GAAG3iE,KAAK,MACpD1D,KAAKqmE,gBAAkBrmE,KAAKsmE,mBAC9BhlE,QAAQ8R,IAAI,GAADzN,OAAIjI,EAAM,YAAAiI,OAAQwgE,EAAS,MAExC,MAAM,KAAEvC,EAAI,MAAE9kE,GAAU0kE,GAAM4C,GAExBG,EAAc3C,EAAO,GAAKtiE,QAAQ4hC,KAAO5hC,QAAQ8R,IAKvD,OAJIpT,KAAKqmE,gBAAkBrmE,KAAKsmE,mBAC9BC,EAAY,GAAD5gE,OAAIjI,EAAM,SAAAiI,OAAQwgE,EAAS,YAAAxgE,OAAWi+D,EAAI,OAEvD5jE,KAAKqmE,kBACEvnE,C,CAEP,OAAOsnE,GAEX,IPnDU3xD,QAAS2lF,IACjB,MAAMC,EAAYD,EAASl1F,UAC3BhG,OAAOyuD,oBAAoB0sC,GAAW5lF,QAAS6lF,IAC7C,GAAiB,gBAAbA,EACF,OAGF,MAAMC,EAAqBr7F,OAAOuuD,yBAChC4sC,EACAC,GAIAC,IACCA,EAAmBt1F,KAAOs1F,EAAmBrtF,KAE9ChO,OAAOC,eACLkmF,GAAYngF,UACZo1F,EACAC,GAGFlV,GAAYngF,UAAUo1F,GAAYF,EAASl1F,UAAUo1F,OD6RvD,MAAO/jE,WAA8B+uD,GACzCpqF,WAAAA,CACEkgD,GACqD,IAArDrpC,EAAA3T,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAgC6hF,GAEhC,MAAMua,GAAch2B,EAAAA,EAAAA,GAAMzyD,GAC1ByoF,EAAYvV,WAAY,EACxB9pF,MAAMigD,EAAiBo/C,EACzB,E,mCS/SF,QAJA,SAAgB17F,EAAO+oD,GACrB,OAAO/oD,EAAQ+oD,CACjB,C,uFCMI4yC,GAAez/F,EAAG,cAAcC,EAAAA,GAIlCC,WAAAA,GACEC,MAAM,CAAC,MAAO,YAChB,IAJEC,EAAAA,EAAAA,IAAMJ,EAAO,mBAAkBA,GAQ/B0/F,GAAiBn/F,EAAG,cAAcC,EAAAA,GAIpCC,kBAAAA,CAAmBC,EAAMC,EAAOC,GAC9B,GAAkB,sBAAdF,EAAKG,KAGT,OAAOF,EAAMI,QAAQ,KAAM,IAAI2iD,MACjC,IAPEtjD,EAAAA,EAAAA,IAAMG,EAAO,qBAAoBA,GAWjCo/F,EAAY,CACd58F,OAAQ,CACNC,cAA8B5C,EAAAA,EAAAA,IAAO,IAAM,IAAIq/F,EAAmB,gBAClEx8F,gBAAgC7C,EAAAA,EAAAA,IAAO,IAAM,IAAIs/F,EAAqB,oBAG1E,SAASE,IAA6C,IAA3Bz8F,EAAOC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGE,EAAAA,EACnC,MAAMC,GAASC,EAAAA,EAAAA,KACbC,EAAAA,EAAAA,GAA8BN,GAC9BO,EAAAA,IAEIm8F,GAAMr8F,EAAAA,EAAAA,KACVG,EAAAA,EAAAA,GAAwB,CAAEJ,WAC1Bu8F,EAAAA,GACAH,GAGF,OADAp8F,EAAOM,gBAAgB3B,SAAS29F,GACzB,CAAEt8F,SAAQs8F,MACnB,EACAz/F,EAAAA,EAAAA,IAAOw/F,EAAmB,oB,kBCzDpB,SAAUG,EAAGv9D,GACjB,OAAOA,EAAKt6B,WAAW,EACzB,CAEM,SAAU83F,EAAev9F,EAAeyP,GACxC9M,MAAMrB,QAAQtB,GAChBA,EAAKgX,QAAQ,SAAUwmF,GACrB/tF,EAAI/M,KAAK86F,EACX,GAEA/tF,EAAI/M,KAAK1C,EAEb,CAEM,SAAUy9F,EACdC,EACAC,GAEA,IAAyB,IAArBD,EAAQC,GACV,KAAM,kBAAoBA,EAGTD,EAAQC,GAC3BD,EAAQC,IAAW,CACrB,CAEM,SAAUC,EAA0BxnE,GAExC,QAAYx1B,IAARw1B,EACF,MAAMnzB,MAAM,2CAEd,OAAO,CACT,CAGM,SAAU46F,IACd,MAAM56F,MAAM,0CACd,CAEM,SAAU66F,EAAY1nE,GAC1B,MAAuB,cAAhBA,EAAU,IACnB,C,yBCzCO,MAAM2nE,EAA4B,GACzC,IAAK,IAAIj7F,EAAIw6F,EAAG,KAAMx6F,GAAKw6F,EAAG,KAAMx6F,IAClCi7F,EAAgBr7F,KAAKI,GAGhB,MAAMk7F,EAA0B,CAACV,EAAG,MAAMp1F,OAAO61F,GACxD,IAAK,IAAIj7F,EAAIw6F,EAAG,KAAMx6F,GAAKw6F,EAAG,KAAMx6F,IAClCk7F,EAAct7F,KAAKI,GAGrB,IAAK,IAAIA,EAAIw6F,EAAG,KAAMx6F,GAAKw6F,EAAG,KAAMx6F,IAClCk7F,EAAct7F,KAAKI,GAId,MAAMm7F,EAA4B,CACvCX,EAAG,KACHA,EAAG,MACHA,EAAG,MACHA,EAAG,MACHA,EAAG,MACHA,EAAG,MACHA,EAAG,MACHA,EAAG,QACHA,EAAG,UACHA,EAAG,UACHA,EAAG,UACHA,EAAG,UACHA,EAAG,UACHA,EAAG,UACHA,EAAG,UACHA,EAAG,UACHA,EAAG,UACHA,EAAG,UACHA,EAAG,UACHA,EAAG,UACHA,EAAG,UACHA,EAAG,UACHA,EAAG,UACHA,EAAG,UACHA,EAAG,UACHA,EAAG,WCZCY,EAAkB,cAClBC,EAAiB,QACjBC,EAAuB,QAIvB,MAAO92C,EAAb7pD,WAAAA,GACY,KAAA+T,IAAc,EACd,KAAAtT,MAAgB,GAChB,KAAA+9B,SAAmB,CA+xB/B,CA7xBYoiE,SAAAA,GACR,MAAO,CACL7sF,IAAKjP,KAAKiP,IACVtT,MAAOqE,KAAKrE,MACZ+9B,SAAU15B,KAAK05B,SAEnB,CAEUqiE,YAAAA,CAAa/uF,GAKrBhN,KAAKiP,IAAMjC,EAASiC,IACpBjP,KAAKrE,MAAQqR,EAASrR,MACtBqE,KAAK05B,SAAW1sB,EAAS0sB,QAC3B,CAEO0sB,OAAAA,CAAQzqD,GAEbqE,KAAKiP,IAAM,EACXjP,KAAKrE,MAAQA,EACbqE,KAAK05B,SAAW,EAEhB15B,KAAKg8F,YAAY,KACjB,MAAMl9F,EAAQkB,KAAKi8F,cACnBj8F,KAAKg8F,YAAY,KAEjB,MAAM90C,EAAqB,CACzBv7C,KAAM,QACNm6C,IAAK,CAAEC,MAAO/lD,KAAKiP,IAAKF,IAAKpT,EAAMM,QACnCgkE,QAAQ,EACR9H,YAAY,EACZ+jC,WAAW,EACXj1C,SAAS,EACTsT,QAAQ,GAGV,KAAOv6D,KAAKm8F,gBACV,OAAQn8F,KAAKo8F,WACX,IAAK,IACHlB,EAAQh0C,EAAO,UACf,MACF,IAAK,IACHg0C,EAAQh0C,EAAO,cACf,MACF,IAAK,IACHg0C,EAAQh0C,EAAO,aACf,MACF,IAAK,IACHg0C,EAAQh0C,EAAO,WACf,MACF,IAAK,IACHg0C,EAAQh0C,EAAO,UAKrB,GAAIlnD,KAAKiP,MAAQjP,KAAKrE,MAAMM,OAC1B,MAAMyE,MAAM,oBAAsBV,KAAKrE,MAAMK,UAAUgE,KAAKiP,MAE9D,MAAO,CACLtD,KAAM,UACNu7C,MAAOA,EACPpoD,MAAOA,EACPgnD,IAAK9lD,KAAK8lD,IAAI,GAElB,CAEUm2C,WAAAA,GACR,MAAM1tF,EAAO,GACPw3C,EAAQ/lD,KAAKiP,IAInB,IAFAV,EAAKpO,KAAKH,KAAKk4E,eAEY,MAApBl4E,KAAKq8F,YACVr8F,KAAKg8F,YAAY,KACjBztF,EAAKpO,KAAKH,KAAKk4E,eAGjB,MAAO,CAAEvsE,KAAM,cAAe7M,MAAOyP,EAAMu3C,IAAK9lD,KAAK8lD,IAAIC,GAC3D,CAEUmyB,WAAAA,GACR,MAAM7f,EAAQ,GACRtS,EAAQ/lD,KAAKiP,IAEnB,KAAOjP,KAAKs8F,UACVjkC,EAAMl4D,KAAKH,KAAKs4D,QAGlB,MAAO,CAAE3sD,KAAM,cAAe7M,MAAOu5D,EAAOvS,IAAK9lD,KAAK8lD,IAAIC,GAC5D,CAEUuS,IAAAA,GACR,OAAIt4D,KAAKu8F,cACAv8F,KAAKw8F,YAELx8F,KAAKuN,MAEhB,CAEUivF,SAAAA,GACR,MAAMz2C,EAAQ/lD,KAAKiP,IACnB,OAAQjP,KAAKo8F,WACX,IAAK,IACH,MAAO,CACLzwF,KAAM,cACNm6C,IAAK9lD,KAAK8lD,IAAIC,IAElB,IAAK,IACH,MAAO,CAAEp6C,KAAM,YAAam6C,IAAK9lD,KAAK8lD,IAAIC,IAE5C,IAAK,KACH,OAAQ/lD,KAAKo8F,WACX,IAAK,IACH,MAAO,CACLzwF,KAAM,eACNm6C,IAAK9lD,KAAK8lD,IAAIC,IAElB,IAAK,IACH,MAAO,CACLp6C,KAAM,kBACNm6C,IAAK9lD,KAAK8lD,IAAIC,IAIpB,MAAMrlD,MAAM,4BAEd,IAAK,IAGH,IAAIiL,EACJ,OAHA3L,KAAKg8F,YAAY,KAGTh8F,KAAKo8F,WACX,IAAK,IACHzwF,EAAO,YACP,MACF,IAAK,IACHA,EAAO,oBAGX0vF,EAAc1vF,GAEd,MAAMswF,EAAcj8F,KAAKi8F,cAIzB,OAFAj8F,KAAKg8F,YAAY,KAEV,CACLrwF,KAAMA,EACN7M,MAAOm9F,EACPn2C,IAAK9lD,KAAK8lD,IAAIC,IAIpB,OAAOu1C,GACT,CAEU51C,UAAAA,GACuB,IAE3Bt6C,EAFJqxF,EAAAr+F,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,IAAAA,UAAA,GAGA,MAAM2nD,EAAQ/lD,KAAKiP,IACnB,OAAQjP,KAAKo8F,WACX,IAAK,IACHhxF,EAAQ,CACN8tD,QAAS,EACTwjC,OAAQj2B,KAEV,MACF,IAAK,IACHr7D,EAAQ,CACN8tD,QAAS,EACTwjC,OAAQj2B,KAEV,MACF,IAAK,IACHr7D,EAAQ,CACN8tD,QAAS,EACTwjC,OAAQ,GAEV,MACF,IAAK,IACH,MAAMxjC,EAAUl5D,KAAK28F,uBACrB,OAAQ38F,KAAKo8F,WACX,IAAK,IACHhxF,EAAQ,CACN8tD,QAASA,EACTwjC,OAAQxjC,GAEV,MACF,IAAK,IACH,IAAIwjC,EACA18F,KAAK48F,WACPF,EAAS18F,KAAK28F,uBACdvxF,EAAQ,CACN8tD,QAASA,EACTwjC,OAAQA,IAGVtxF,EAAQ,CACN8tD,QAASA,EACTwjC,OAAQj2B,KAGZzmE,KAAKg8F,YAAY,KAKrB,IAAuB,IAAnBS,QAAqCp+F,IAAV+M,EAC7B,OAEFiwF,EAAcjwF,GAMlB,IAAuB,IAAnBqxF,QAAqCp+F,IAAV+M,EAK/B,OAAIiwF,EAAcjwF,IACS,MAArBpL,KAAKq8F,SAAS,IAChBr8F,KAAKg8F,YAAY,KACjB5wF,EAAMyxF,QAAS,GAEfzxF,EAAMyxF,QAAS,EAGjBzxF,EAAMO,KAAO,aACbP,EAAM06C,IAAM9lD,KAAK8lD,IAAIC,GACd36C,QAVT,CAYF,CAEUmC,IAAAA,GACR,IAAIA,EACJ,MAAMw4C,EAAQ/lD,KAAKiP,IACnB,OAAQjP,KAAKq8F,YACX,IAAK,IACH9uF,EAAOvN,KAAK88F,SACZ,MACF,IAAK,KACHvvF,EAAOvN,KAAK+8F,aACZ,MACF,IAAK,IACHxvF,EAAOvN,KAAKg9F,iBACZ,MACF,IAAK,IACHzvF,EAAOvN,KAAKu5B,QAShB,YALal7B,IAATkP,GAAsBvN,KAAKi9F,uBAC7B1vF,EAAOvN,KAAKk9F,oBAIV7B,EAAoB9tF,IACtBA,EAAKu4C,IAAM9lD,KAAK8lD,IAAIC,GAEhB/lD,KAAKm9F,iBACP5vF,EAAKm4C,WAAa1lD,KAAK0lD,cAGlBn4C,GAIF+tF,GACT,CAEUwB,MAAAA,GAER,OADA98F,KAAKg8F,YAAY,KACV,CACLrwF,KAAM,MACN6sD,YAAY,EACZ15D,MAAO,CAACi8F,EAAG,MAAOA,EAAG,MAAOA,EAAG,UAAWA,EAAG,WAEjD,CAEUgC,UAAAA,GAGR,OAFA/8F,KAAKg8F,YAAY,MAETh8F,KAAKq8F,YACX,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACH,OAAOr8F,KAAKo9F,oBACd,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACH,OAAOp9F,KAAKq9F,uBACd,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACH,OAAOr9F,KAAKs9F,oBACd,IAAK,IACH,OAAOt9F,KAAKu9F,0BACd,IAAK,IACH,OAAOv9F,KAAKw9F,mBACd,IAAK,IACH,OAAOx9F,KAAKy9F,wBACd,IAAK,IACH,OAAOz9F,KAAK09F,kCACd,QACE,OAAO19F,KAAK29F,qBAElB,CAEUP,iBAAAA,GAGR,MAAO,CAAEzxF,KAAM,qBAAsB7M,MAFvBkB,KAAK49F,kBAGrB,CAEUP,oBAAAA,GACR,IAAInwF,EACAsrD,GAAa,EACjB,OAAQx4D,KAAKo8F,WACX,IAAK,IACHlvF,EAAMsuF,EACN,MACF,IAAK,IACHtuF,EAAMsuF,EACNhjC,GAAa,EACb,MACF,IAAK,IACHtrD,EAAMwuF,EACN,MACF,IAAK,IACHxuF,EAAMwuF,EACNljC,GAAa,EACb,MACF,IAAK,IACHtrD,EAAMuuF,EACN,MACF,IAAK,IACHvuF,EAAMuuF,EACNjjC,GAAa,EAKjB,OAAI6iC,EAAcnuF,GACT,CAAEvB,KAAM,MAAO7M,MAAOoO,EAAKsrD,WAAYA,GAGzC8iC,GACT,CAEUgC,iBAAAA,GACR,IAAIO,EACJ,OAAQ79F,KAAKo8F,WACX,IAAK,IACHyB,EAAa9C,EAAG,MAChB,MACF,IAAK,IACH8C,EAAa9C,EAAG,MAChB,MACF,IAAK,IACH8C,EAAa9C,EAAG,MAChB,MACF,IAAK,IACH8C,EAAa9C,EAAG,MAChB,MACF,IAAK,IACH8C,EAAa9C,EAAG,MAKpB,OAAIM,EAAcwC,GACT,CAAElyF,KAAM,YAAa7M,MAAO++F,GAG9BvC,GACT,CAEUiC,uBAAAA,GACRv9F,KAAKg8F,YAAY,KACjB,MAAMv1C,EAASzmD,KAAKo8F,UACpB,IAAgC,IAA5B,WAAWp2F,KAAKygD,GAClB,MAAM/lD,MAAM,YAId,MAAO,CAAEiL,KAAM,YAAa7M,MADT2nD,EAAOC,cAAcxjD,WAAW,GAAK,GAE1D,CAEUs6F,gBAAAA,GAIR,OADAx9F,KAAKg8F,YAAY,KACV,CAAErwF,KAAM,YAAa7M,MAAOi8F,EAAG,MACxC,CAEU0C,qBAAAA,GAER,OADAz9F,KAAKg8F,YAAY,KACVh8F,KAAK89F,eAAe,EAC7B,CAEUJ,+BAAAA,GAER,OADA19F,KAAKg8F,YAAY,KACVh8F,KAAK89F,eAAe,EAC7B,CAEUH,kBAAAA,GAIR,MAAO,CAAEhyF,KAAM,YAAa7M,MAAOi8F,EADf/6F,KAAKo8F,WAE3B,CAEU2B,yBAAAA,GACR,OAAQ/9F,KAAKq8F,YAEX,IAAK,KAEL,IAAK,KAEL,IAAK,SAEL,IAAK,SAEL,IAAK,KAEL,IAAK,IACH,MAAM37F,MAAM,OACd,QAEE,MAAO,CAAEiL,KAAM,YAAa7M,MAAOi8F,EADlB/6F,KAAKo8F,YAG5B,CAEUY,cAAAA,GACR,MAAM9vF,EAA0B,GAChC,IAAIsrD,GAAa,EAOjB,IANAx4D,KAAKg8F,YAAY,KACQ,MAArBh8F,KAAKq8F,SAAS,KAChBr8F,KAAKg8F,YAAY,KACjBxjC,GAAa,GAGRx4D,KAAKg+F,eAAe,CACzB,MAAMv3F,EAAOzG,KAAKi+F,YACOx3F,EAAKkF,KAC9B,GAAI4vF,EAAY90F,IAASzG,KAAKk+F,cAAe,CAC3Cl+F,KAAKg8F,YAAY,KACjB,MAAMriF,EAAK3Z,KAAKi+F,YACOtkF,EAAGhO,KAG1B,GAAI4vF,EAAY5hF,GAAK,CACnB,GAAIA,EAAG7a,MAAQ2H,EAAK3H,MAClB,MAAM4B,MAAM,yCAEdwM,EAAI/M,KAAK,CAAEsG,KAAMA,EAAK3H,MAAO6a,GAAIA,EAAG7a,O,MAGpCk8F,EAAYv0F,EAAK3H,MAAOoO,GACxBA,EAAI/M,KAAK46F,EAAG,MACZC,EAAYrhF,EAAG7a,MAAOoO,E,MAGxB8tF,EAAYv0F,EAAK3H,MAAOoO,E,CAM5B,OAFAlN,KAAKg8F,YAAY,KAEV,CAAErwF,KAAM,MAAO6sD,WAAYA,EAAY15D,MAAOoO,EACvD,CAEU+wF,SAAAA,GACR,OAAQj+F,KAAKq8F,YAEX,IAAK,IAEL,IAAK,KAEL,IAAK,KAEL,IAAK,SAEL,IAAK,SACH,MAAM37F,MAAM,OACd,IAAK,KACH,OAAOV,KAAKm+F,cACd,QACE,OAAOn+F,KAAK+9F,4BAElB,CAEUI,WAAAA,GAER,OADAn+F,KAAKg8F,YAAY,MACTh8F,KAAKq8F,YAGX,IAAK,IAEH,OADAr8F,KAAKg8F,YAAY,KACV,CAAErwF,KAAM,YAAa7M,MAAOi8F,EAAG,OACxC,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACH,OAAO/6F,KAAKq9F,uBACd,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACH,OAAOr9F,KAAKs9F,oBACd,IAAK,IACH,OAAOt9F,KAAKu9F,0BACd,IAAK,IACH,OAAOv9F,KAAKw9F,mBACd,IAAK,IACH,OAAOx9F,KAAKy9F,wBACd,IAAK,IACH,OAAOz9F,KAAK09F,kCACd,QACE,OAAO19F,KAAK29F,qBAElB,CAEUpkE,KAAAA,GACR,IAAI6kE,GAAY,EAEhB,GADAp+F,KAAKg8F,YAAY,KAEV,MADCh8F,KAAKq8F,SAAS,GAElBr8F,KAAKg8F,YAAY,KACjBh8F,KAAKg8F,YAAY,KACjBoC,GAAY,OAGZp+F,KAAK05B,WAGT,MAAM56B,EAAQkB,KAAKi8F,cACnBj8F,KAAKg8F,YAAY,KAEjB,MAAMqC,EAA+B,CACnC1yF,KAAM,QACNyyF,UAAWA,EACXt/F,MAAOA,GAOT,OAJIs/F,IACFC,EAAc,IAAIr+F,KAAK05B,UAGlB2kE,CACT,CAEUT,eAAAA,GACR,IAAI97E,EAAS9hB,KAAKo8F,UAIlB,IAA0C,IAAtCP,EAAqB71F,KAAK8b,GAC5B,MAAMphB,MAAM,gCAGd,KAAOk7F,EAAe51F,KAAKhG,KAAKq8F,SAAS,KACvCv6E,GAAU9hB,KAAKo8F,UAGjB,OAAOz+F,SAASmkB,EAAQ,GAC1B,CAEU66E,oBAAAA,GACR,IAAI76E,EAAS9hB,KAAKo8F,UAClB,IAAoC,IAAhCR,EAAe51F,KAAK8b,GACtB,MAAMphB,MAAM,wBAGd,KAAOk7F,EAAe51F,KAAKhG,KAAKq8F,SAAS,KACvCv6E,GAAU9hB,KAAKo8F,UAGjB,OAAOz+F,SAASmkB,EAAQ,GAC1B,CAEUo7E,gBAAAA,GACR,MAAMoB,EAAWt+F,KAAKo8F,UACtB,OAAQkC,GAEN,IAAK,KAEL,IAAK,KAEL,IAAK,SAEL,IAAK,SAEL,IAAK,IAEL,IAAK,IAEL,IAAK,KAEL,IAAK,IAEL,IAAK,IAEL,IAAK,IAEL,IAAK,IAEL,IAAK,IAEL,IAAK,IAEL,IAAK,IAEL,IAAK,IAEH,MAAM59F,MAAM,OACd,QACE,MAAO,CAAEiL,KAAM,YAAa7M,MAAOi8F,EAAGuD,IAE5C,CACUnC,YAAAA,GACR,OAAQn8F,KAAKq8F,SAAS,IACpB,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACH,OAAO,EACT,QACE,OAAO,EAEb,CAEU6B,WAAAA,GACR,MAA2B,MAApBl+F,KAAKq8F,YAAsBr8F,KAAKg+F,YAAY,EACrD,CAEUpB,OAAAA,GACR,OAAOhB,EAAe51F,KAAKhG,KAAKq8F,SAAS,GAC3C,CAEU2B,WAAAA,GAAuB,IAAXxP,EAAOpwF,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAC9B,OAAQ4B,KAAKq8F,SAAS7N,IACpB,IAAK,IACL,IAAK,KACL,IAAK,KACL,IAAK,SACL,IAAK,SACH,OAAO,EACT,QACE,OAAO,EAEb,CAEU8N,MAAAA,GACR,OAAOt8F,KAAKu+F,UAAYv+F,KAAKu8F,aAC/B,CAEUgC,MAAAA,GACR,GAAIv+F,KAAKi9F,qBACP,OAAO,EAGT,OAAQj9F,KAAKq8F,SAAS,IACpB,IAAK,IACL,IAAK,KACL,IAAK,IAEL,IAAK,IACH,OAAO,EACT,QACE,OAAO,EAEb,CAEUE,WAAAA,GACR,OAAQv8F,KAAKq8F,SAAS,IACpB,IAAK,IACL,IAAK,IACH,OAAO,EAET,IAAK,KACH,OAAQr8F,KAAKq8F,SAAS,IACpB,IAAK,IACL,IAAK,IACH,OAAO,EACT,QACE,OAAO,EAGb,IAAK,IACH,MACuB,MAArBr8F,KAAKq8F,SAAS,KACQ,MAArBr8F,KAAKq8F,SAAS,IAAmC,MAArBr8F,KAAKq8F,SAAS,IAE/C,QACE,OAAO,EAEb,CAEUc,YAAAA,GACR,MAAMqB,EAAYx+F,KAAK87F,YACvB,IACE,YAAiCz9F,IAA1B2B,KAAK0lD,YAAW,E,CACvB,MAAOtkD,GACP,OAAO,C,CACP,QACApB,KAAK+7F,aAAayC,E,CAEtB,CAEUvB,kBAAAA,GACR,OAAQj9F,KAAKq8F,YACX,IAAK,IACL,IAAK,IACL,IAAK,KACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,IACL,IAAK,KACL,IAAK,KACL,IAAK,SACL,IAAK,SACH,OAAO,EACT,QACE,OAAO,EAEb,CAEUyB,cAAAA,CAAeW,GACvB,IAAIC,EAAY,GAChB,IAAK,IAAIn+F,EAAI,EAAGA,EAAIk+F,EAASl+F,IAAK,CAChC,MAAMo+F,EAAU3+F,KAAKo8F,UACrB,IAAsC,IAAlCT,EAAgB31F,KAAK24F,GACvB,MAAMj+F,MAAM,iCAEdg+F,GAAaC,C,CAGf,MAAO,CAAEhzF,KAAM,YAAa7M,MADXnB,SAAS+gG,EAAW,IAEvC,CAEUrC,QAAAA,GAAoB,IAAX7N,EAAOpwF,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAC3B,OAAO4B,KAAKrE,MAAMqE,KAAKiP,IAAMu/E,EAC/B,CAEU4N,OAAAA,GACR,MAAMkC,EAAWt+F,KAAKq8F,SAAS,GAE/B,OADAr8F,KAAKg8F,iBAAY39F,GACVigG,CACT,CAEUtC,WAAAA,CAAYx+D,GACpB,QAAan/B,IAATm/B,GAAsBx9B,KAAKrE,MAAMqE,KAAKiP,OAASuuB,EACjD,MAAM98B,MACJ,cACE88B,EACA,iBACAx9B,KAAKrE,MAAMqE,KAAKiP,KAChB,gBACAjP,KAAKiP,KAIX,GAAIjP,KAAKiP,KAAOjP,KAAKrE,MAAMM,OACzB,MAAMyE,MAAM,2BAEdV,KAAKiP,KACP,CAEU62C,GAAAA,CAAIC,GACZ,MAAO,CAAEA,MAAOA,EAAOh3C,IAAK/O,KAAKiP,IACnC,ECvzBI,MAAOg2C,EACJe,aAAAA,CAAcpoD,GACnB,IAAK,MAAM8K,KAAO9K,EAAM,CACtB,MAAMuwB,EAASvwB,EAAa8K,GAExB9K,EAAKuH,eAAeuD,UACHrK,IAAf8vB,EAAMxiB,KACR3L,KAAKmmD,MAAMh4B,GACF/tB,MAAMrB,QAAQovB,IACvBA,EAAM1Z,QAASmqF,IACb5+F,KAAKmmD,MAAMy4C,IACV5+F,M,CAIX,CAEOmmD,KAAAA,CAAMvoD,GACX,OAAQA,EAAK+N,MACX,IAAK,UACH3L,KAAK6+F,aAAajhG,GAClB,MACF,IAAK,QACHoC,KAAK8+F,WAAWlhG,GAChB,MACF,IAAK,cACHoC,KAAK++F,iBAAiBnhG,GACtB,MACF,IAAK,cACHoC,KAAK4xD,iBAAiBh0D,GACtB,MACF,IAAK,cACHoC,KAAK2/D,iBAAiB/hE,GACtB,MACF,IAAK,YACHoC,KAAKm/D,eAAevhE,GACpB,MACF,IAAK,eACHoC,KAAKg/F,kBAAkBphG,GACvB,MACF,IAAK,kBACHoC,KAAKi/F,qBAAqBrhG,GAC1B,MACF,IAAK,YACHoC,KAAK+5D,eAAen8D,GACpB,MACF,IAAK,oBACHoC,KAAKg6D,uBAAuBp8D,GAC5B,MACF,IAAK,YACHoC,KAAK2lD,eAAe/nD,GACpB,MACF,IAAK,MACHoC,KAAK6lD,SAASjoD,GACd,MACF,IAAK,QACHoC,KAAKylD,WAAW7nD,GAChB,MACF,IAAK,qBACHoC,KAAKk/F,wBAAwBthG,GAC7B,MACF,IAAK,aACHoC,KAAKm/F,gBAAgBvhG,GAIzBoC,KAAKgmD,cAAcpoD,EACrB,CAEOihG,YAAAA,CAAajhG,GAA4B,CAEzCkhG,UAAAA,CAAWlhG,GAA0B,CAErCmhG,gBAAAA,CAAiBnhG,GAA0B,CAE3Cg0D,gBAAAA,CAAiBh0D,GAA0B,CAG3C+hE,gBAAAA,CAAiB/hE,GAAwB,CAEzCuhE,cAAAA,CAAevhE,GAAwB,CAEvCohG,iBAAAA,CAAkBphG,GAAwB,CAE1CqhG,oBAAAA,CAAqBrhG,GAAwB,CAE7Cm8D,cAAAA,CAAen8D,GAAwB,CAEvCo8D,sBAAAA,CAAuBp8D,GAAwB,CAG/C+nD,cAAAA,CAAe/nD,GAAwB,CAEvCioD,QAAAA,CAASjoD,GAAkB,CAE3B6nD,UAAAA,CAAW7nD,GAAoB,CAE/BshG,uBAAAA,CAAwBthG,GAAiC,CAEzDuhG,eAAAA,CAAgBvhG,GAAyB,E,6FCpCtCwhG,E,sBA5DN,SAAUh9C,EAAUxkD,GACtB,OAAO,IAAImxD,EAAAA,GAAenxD,EAAMwvB,IACxBs1B,EAAAA,EAAAA,IAAmBt1B,GACZA,EAAQ/D,QAER,GAEZ,CAAE2lC,aAAa,GACtB,CAYM,SAAUlqB,EAAY3W,EAAgBpG,GACxC,KAAOoG,EAAM5B,WAET,IADA4B,EAAQA,EAAM5B,aACAxE,EACV,OAAO,EAGf,OAAO,CACX,CAEM,SAAUsE,EAAaxV,GAGzB,MAAO,CACHxL,MAAO,CACHE,UAAWsL,EAAM+rC,YAAe,EAChCt3C,KAAMuL,EAAMgK,UAAa,GAE7B9R,IAAK,CACDxD,UAAWsL,EAAMy5B,UACjBhlC,KAAMuL,EAAMiK,QAAW,GAGnC,CAIM,SAAU6kB,EAAkB/nC,GAC9B,IAAKA,EACD,OAEJ,MAAM,OAAEitB,EAAM,IAAE9b,EAAG,MAAE3D,GAAUxN,EAC/B,MAAO,CACHwN,QACAyf,SACA9b,MACA9S,OAAQ8S,EAAM8b,EAEtB,CA8BM,SAAUqkC,EAAQ9jD,EAAcuO,GAClC,MAAM0lF,EApBJ,SAAuBj0F,EAAcuO,GACvC,GAAIvO,EAAM2D,IAAIzD,KAAOqO,EAAGtO,MAAMC,MAASF,EAAM2D,IAAIzD,OAASqO,EAAGtO,MAAMC,MAAQF,EAAM2D,IAAIxD,WAAaoO,EAAGtO,MAAME,UACvG,OAAO6zF,EAAgBE,OACpB,GAAIl0F,EAAMC,MAAMC,KAAOqO,EAAG5K,IAAIzD,MAASF,EAAMC,MAAMC,OAASqO,EAAG5K,IAAIzD,MAAQF,EAAMC,MAAME,WAAaoO,EAAG5K,IAAIxD,UAC9G,OAAO6zF,EAAgBG,MAE3B,MAAMC,EAAcp0F,EAAMC,MAAMC,KAAOqO,EAAGtO,MAAMC,MAASF,EAAMC,MAAMC,OAASqO,EAAGtO,MAAMC,MAAQF,EAAMC,MAAME,WAAaoO,EAAGtO,MAAME,UAC3Hk0F,EAAYr0F,EAAM2D,IAAIzD,KAAOqO,EAAG5K,IAAIzD,MAASF,EAAM2D,IAAIzD,OAASqO,EAAG5K,IAAIzD,MAAQF,EAAM2D,IAAIxD,WAAaoO,EAAG5K,IAAIxD,UACnH,OAAIi0F,GAAeC,EACRL,EAAgBM,OAChBF,EACAJ,EAAgBO,YAChBF,EACAL,EAAgBQ,aAEhBR,EAAgBS,OAE/B,CAGuBC,CAAa10F,EAAOuO,GACvC,OAAO0lF,EAAaD,EAAgBG,KACxC,EA/BA,SAAYH,GACRA,EAAAA,EAAA,mBACAA,EAAAA,EAAA,iBACAA,EAAAA,EAAA,+BACAA,EAAAA,EAAA,6BACAA,EAAAA,EAAA,mBACAA,EAAAA,EAAA,oBACH,CAPD,CAAYA,IAAAA,EAAe,KAmCpB,MAAMl7C,EAAoB,ilQAsB3B,SAAU3D,EAAgBjtB,EAA8BysE,GAC1D,GAAIzsE,EAAS,CACT,MAAMra,EA8FR,SAA0Brb,GAA4B,IAAbqvB,IAAM7uB,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,KAAAA,UAAA,GACjD,KAAOR,EAAK2uB,WAAW,CACnB,MAAMxE,EAASnqB,EAAK2uB,UACpB,IAAIhkB,EAAQwf,EAAOsB,QAAQ5jB,QAAQ7H,GACnC,KAAO2K,EAAQ,GAAG,CACdA,IACA,MAAM0Q,EAAW8O,EAAOsB,QAAQ9gB,GAChC,GAAI0kB,IAAWhU,EAASgU,OACpB,OAAOhU,CAEf,CACArb,EAAOmqB,CACX,CACA,MACJ,CA5GyBi4E,CAAgB1sE,GAAS,GAC1C,GAAIra,GAAYgnF,EAAchnF,EAAU8mF,GACpC,OAAO9mF,EAEX,IAAIupC,EAAAA,EAAAA,IAAclvB,GAAU,CAIxB,IAAK,IAAI/yB,EADQ+yB,EAAQjK,QAAQ62E,UAAU9+F,IAAMA,EAAE6rB,QAC3B,EAAG1sB,GAAK,EAAGA,IAAK,CACpC,MAAM4tB,EAAQmF,EAAQjK,QAAQ9oB,GAC9B,GAAI0/F,EAAc9xE,EAAO4xE,GACrB,OAAO5xE,CAEf,CACJ,CACJ,CAEJ,CAEM,SAAU8xE,EAAc3sE,EAAkBysE,GAC5C,OAAOp9C,EAAAA,EAAAA,IAAcrvB,IAAYysE,EAAazxD,SAAShb,EAAQrnB,UAAUpQ,KAC7E,C,kDC3HA,QAPA,SAAmBiD,GACjB,IAAIkD,GAASm+F,EAAAA,EAAAA,GAASrhG,GAClBshG,EAAYp+F,EAAS,EAEzB,OAAOA,IAAWA,EAAUo+F,EAAYp+F,EAASo+F,EAAYp+F,EAAU,CACzE,C,yGCWM,MAAOuiD,EAAbrpD,WAAAA,GAIc,KAAAmsB,YAAkC,EAmHhD,CAjHIizB,WAAAA,CAAYtjB,EAAkB/jB,GAC1B,MAAMotF,GAAiBhpE,EAAAA,EAAAA,KAAOF,EAAAA,EAAAA,IAAqBH,GAAS,IACtDspE,EAA8BtgG,KAAKugG,oBAAoBF,GACvD5zE,EAAsBzsB,KAAKwgG,mBAAmBH,EAAgBC,EAAgBrtF,GAYpF,OAVAqtF,EAAe7rF,QAAQgsF,IACnB,MAAMr6C,EAAUq6C,EAAcjvC,QACP,kBAAZpL,GAAwBA,GAAW,SAAUA,IAAWE,EAAAA,EAAAA,IAAaF,GAC5E35B,EAAOG,QAAQ6zE,GAEfh0E,EAAOtsB,KAAKsgG,KAKbh0E,CACX,CAGAuuB,iBAAAA,CAAkBv3B,GACd,MAAO,CAAE4D,YAAarnB,KAAK0gG,iBAC/B,CAEUA,cAAAA,GACN,MAAMr5E,EAAc,IAAIrnB,KAAKqnB,aAE7B,OADArnB,KAAKqnB,YAAc,GACZA,CACX,CAEUk5E,mBAAAA,CAAoBh0F,GAC1B,OAAOA,EAAMyD,OAAO4oB,EAAAA,IAAgB5oB,OAAO5O,IAAMA,EAAE2E,UAC9CyI,IAAI2lB,GAAYn0B,KAAK2gG,mBAAmBxsE,IAAWwhB,SAC5D,CAEUgrD,kBAAAA,CAAmBxsE,GACzB,MAAMoxB,GAAQvB,EAAAA,EAAAA,GAAc7vB,GACtBiyB,EAAUpmD,KAAK4gG,sBAAsBr7C,GAASvlD,KAAK6gG,qBAAqBt7C,GAASA,EACjFt5C,EAAuB,CACzBpQ,KAAMs4B,EAASt4B,KACf21D,QAASpL,GASb,MAPuB,oBAAZA,IACPn6C,EAAUgxD,aAAc,GAExB9oC,EAASlH,SAEThhB,EAAUwwD,OAAQnW,EAAAA,EAAAA,IAAaf,GAASr2B,EAAAA,GAAMwtC,QAAU,UAErDzwD,CACX,CAEU20F,qBAAAA,CAAsBr7C,GAC5B,SAAIA,EAAM2B,MAAM5Y,SAAS,OAAQiX,EAAM2B,MAAM5Y,SAAS,UAG3CiX,EAAMh8C,OAAO+kC,SAAS,SAAUiX,EAAMh8C,OAAO+kC,SAAS,OAMrE,CAEUuyD,oBAAAA,CAAqBt7C,GAC3B,MAAMu7C,EAAc,IAAIziD,OAAOkH,EAAOA,EAAM2B,MAAQ,KACpD,MAAO,CAACzjC,EAAMoH,KACVi2E,EAAYv2F,UAAYsgB,EAExB,OADmBi2E,EAAY3kG,KAAKsnB,GAG5C,CAEU+8E,kBAAAA,CAAmBj0F,EAA6B+zF,EAA6BrtF,GACnF,OAAO1G,EAEFyD,OAAOsnB,EAAAA,IACPle,QAAQ1d,IAAQyrC,EAAAA,EAAAA,IAAkBzrC,GAAMsU,OAAOgjB,EAAAA,KAC/C+tE,SAAS3/F,GAAKA,EAAEtC,OAAO62C,UAEvBqrD,KAAK,CAAC79F,EAAGyE,IAAMA,EAAE9I,MAAM7C,OAASkH,EAAErE,MAAM7C,QACxCuS,IAAIqpB,GAAW73B,KAAKihG,kBAAkBppE,EAASyoE,EAAgBp6E,QAAe,OAAPjT,QAAO,IAAPA,OAAO,EAAPA,EAASs0B,kBACzF,CAEU05D,iBAAAA,CAAkBppE,EAAkByoE,EAA6B/4D,GACvE,MAAM25D,EAAiBlhG,KAAKmhG,oBAAoBtpE,EAAS0P,GACnDt7B,EAAuB,CACzBpQ,KAAMg8B,EAAQ/4B,MACd0yD,QAAS0vC,EACTrkC,WAAY78D,KAAKohG,cAAcvpE,EAASyoE,IAO5C,MAJ8B,oBAAnBY,IACPj1F,EAAUgxD,aAAc,GAGrBhxD,CACX,CAEUk1F,mBAAAA,CAAoBtpE,EAAkB0P,GAC5C,OAAOA,EACH,IAAI8W,QAAOmI,EAAAA,EAAAA,IAA0B3uB,EAAQ/4B,QAC7C+4B,EAAQ/4B,KAChB,CAEUsiG,aAAAA,CAAcvpE,EAAkByoE,GACtC,OAAOA,EAAe9rF,OAAO,CAAC6sF,EAAyBxqF,KACnD,MAAMuvC,EAAe,OAALvvC,QAAK,IAALA,OAAK,EAALA,EAAO26C,QAIvB,OAHW,OAAPpL,QAAO,IAAPA,OAAO,EAAPA,EAAS78C,UAAUo9C,EAAAA,EAAAA,IAAe,IAAMP,EAAQ78C,OAAS,IAAKsuB,EAAQ/4B,QACtEuiG,EAAWlhG,KAAK0W,GAEbwqF,GACR,GACP,E,qFCjJAC,GAAkBtmG,EAAG,cAAcC,EAAAA,GAIrCC,WAAAA,GACEC,MAAM,CAAC,UACT,IAJEC,EAAAA,EAAAA,IAAMJ,EAAO,sBAAqBA,GAQlCumG,EAAe,CACjBxjG,OAAQ,CACNC,cAA8B5C,EAAAA,EAAAA,IAAO,IAAM,IAAIkmG,EAAsB,gBACrErjG,gBAAgC7C,EAAAA,EAAAA,IAAO,IAAM,IAAI4O,EAAAA,GAAwB,oBAG7E,SAASw3F,IAAgD,IAA3BrjG,EAAOC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGE,EAAAA,EACtC,MAAMC,GAASC,EAAAA,EAAAA,KACbC,EAAAA,EAAAA,GAA8BN,GAC9BO,EAAAA,IAEI+iG,GAASjjG,EAAAA,EAAAA,KACbG,EAAAA,EAAAA,GAAwB,CAAEJ,WAC1BmjG,EAAAA,GACAH,GAGF,OADAhjG,EAAOM,gBAAgB3B,SAASukG,GACzB,CAAEljG,SAAQkjG,SACnB,EACArmG,EAAAA,EAAAA,IAAOomG,EAAsB,uB,wECtB7B,QAbA,SAAoBG,GAClB,OAAO,SAASt5F,EAAY0C,EAAWynD,GACrC,IAAIovC,EAAW1iG,OAAOmJ,GACtB,KAAKG,EAAAA,EAAAA,GAAYH,GAAa,CAC5B,IAAIC,GAAW+J,EAAAA,EAAAA,GAAatH,EAAW,GACvC1C,GAAa2P,EAAAA,EAAAA,GAAK3P,GAClB0C,EAAY,SAASrC,GAAO,OAAOJ,EAASs5F,EAASl5F,GAAMA,EAAKk5F,EAAW,CAC7E,CACA,IAAIr5F,EAAQo5F,EAAct5F,EAAY0C,EAAWynD,GACjD,OAAOjqD,GAAS,EAAIq5F,EAASt5F,EAAWD,EAAWE,GAASA,QAASlK,CACvE,CACF,E,0BCjBIk0D,EAAYznC,KAAKC,ICoCrB,QAFW82E,EDGX,SAAmBx/F,EAAO0I,EAAWynD,GACnC,IAAIv2D,EAAkB,MAAToG,EAAgB,EAAIA,EAAMpG,OACvC,IAAKA,EACH,OAAQ,EAEV,IAAIsM,EAAqB,MAAbiqD,EAAoB,GAAI3C,EAAAA,EAAAA,GAAU2C,GAI9C,OAHIjqD,EAAQ,IACVA,EAAQgqD,EAAUt2D,EAASsM,EAAO,KAE7Bu5F,EAAAA,EAAAA,GAAcz/F,GAAOgQ,EAAAA,EAAAA,GAAatH,EAAW,GAAIxC,EAC1D,E,mCEpBM,MAAOw5F,EAET1jE,QAAAA,GACI,MAAM,IAAI39B,MAAM,+BACpB,CAEA,mBAAMg5C,GACF,MAAO,EACX,EAIG,MAAMp7C,EAAkB,CAC3B2/B,mBAAoBA,IAAM,IAAI8jE,E,gBClClC,SAASpiF,EAAO7gB,GACZ,MAAwB,kBAAVA,GAAsBA,aAAiByI,MACzD,CAcA,SAASlF,EAAMvD,GACX,OAAOsB,MAAMrB,QAAQD,EACzB,CAxBAI,OAAOC,eAAeC,EAAS,aAAc,CAAEN,OAAO,IACtDM,EAAQ4iG,YAAc5iG,EAAQiD,MAAQjD,EAAQoqB,KAAOpqB,EAAQmC,MAAQnC,EAAQ0iB,OAAS1iB,EAAQugB,OAASvgB,EAAQojB,aAAU,EAIzHpjB,EAAQojB,QAHR,SAAiB1jB,GACb,OAAiB,IAAVA,IAA4B,IAAVA,CAC7B,EAKAM,EAAQugB,OAASA,EAIjBvgB,EAAQ0iB,OAHR,SAAgBhjB,GACZ,MAAwB,kBAAVA,GAAsBA,aAAiBogB,MACzD,EAKA9f,EAAQmC,MAHR,SAAezC,GACX,OAAOA,aAAiB4B,KAC5B,EAKAtB,EAAQoqB,KAHR,SAAc1qB,GACV,MAAwB,oBAAVA,CAClB,EAKAM,EAAQiD,MAAQA,EAIhBjD,EAAQ4iG,YAHR,SAAqBljG,GACjB,OAAOuD,EAAMvD,IAAUA,EAAMukB,MAAM4+E,GAAQtiF,EAAOsiF,GACtD,C,kBC3BA7iG,EAAQ,GAA0BA,EAAQ,QAAoB,EAC9D,MAAMG,EAAQC,EAAQ,OAChB4f,EAAK5f,EAAQ,OACb0iG,EAAW1iG,EAAQ,MACzB,IAAI28B,GACJ,SAAWA,GACPA,EAAkBx8B,KAAOT,OAAO0mE,OAAO,CACnCnpC,yBAAyB,EACzB0a,wBAAyB+qD,EAAS5iG,MAAMK,OAE5Cw8B,EAAkBgmE,UAAYjjG,OAAO0mE,OAAO,CACxCnpC,yBAAyB,EACzB0a,wBAAyB+qD,EAAS5iG,MAAMK,OAQ5Cw8B,EAAkBtpB,GANlB,SAAY/T,GACR,MAAMqgB,EAAYrgB,EAClB,OAAOqgB,IAAcA,IAAcgd,EAAkBx8B,MAC9Cwf,IAAcgd,EAAkBgmE,WAC/B/iF,EAAGoD,QAAQrD,EAAUsd,4BAA8Btd,EAAUg4B,wBACzE,CAEH,CAhBD,CAgBGhb,IAAsB/8B,EAAQ,GAAoB+8B,EAAoB,CAAC,IAC1E,MAAMimE,EAAgBljG,OAAO0mE,OAAO,SAAU9lE,EAAU3B,GACpD,MAAMuQ,GAAS,EAAInP,EAAM8B,WAAWmiE,MAAMhnC,WAAW18B,EAAS7C,KAAKkB,GAAU,GAC7E,MAAO,CAAEuB,OAAAA,GAAYgP,EAAOhP,SAAW,EAC3C,GACA,MAAM2iG,EACFnnG,WAAAA,GACI8E,KAAKsiG,cAAe,CACxB,CACA5gD,MAAAA,GACS1hD,KAAKsiG,eACNtiG,KAAKsiG,cAAe,EAChBtiG,KAAKuiG,WACLviG,KAAKuiG,SAASpgG,UAAK9D,GACnB2B,KAAKN,WAGjB,CACA,2BAAI+8B,GACA,OAAOz8B,KAAKsiG,YAChB,CACA,2BAAInrD,GACA,OAAIn3C,KAAKsiG,aACEF,GAENpiG,KAAKuiG,WACNviG,KAAKuiG,SAAW,IAAIL,EAAS7iG,SAE1BW,KAAKuiG,SAAS7gG,MACzB,CACAhC,OAAAA,GACQM,KAAKuiG,WACLviG,KAAKuiG,SAAS7iG,UACdM,KAAKuiG,cAAWlkG,EAExB,EAiCJe,EAAQ,GA/BR,MACI,SAAIyX,GAMA,OALK7W,KAAKwiG,SAGNxiG,KAAKwiG,OAAS,IAAIH,GAEfriG,KAAKwiG,MAChB,CACA9gD,MAAAA,GACS1hD,KAAKwiG,OAONxiG,KAAKwiG,OAAO9gD,SAHZ1hD,KAAKwiG,OAASrmE,EAAkBgmE,SAKxC,CACAziG,OAAAA,GACSM,KAAKwiG,OAIDxiG,KAAKwiG,kBAAkBH,GAE5BriG,KAAKwiG,OAAO9iG,UAJZM,KAAKwiG,OAASrmE,EAAkBx8B,IAMxC,E,qFC5EA8iG,GAAoBznG,EAAG,cAAcC,EAAAA,GAIvCC,WAAAA,GACEC,MAAM,CAAC,YACT,IAJEC,EAAAA,EAAAA,IAAMJ,EAAO,wBAAuBA,GAQpC0nG,EAAiB,CACnB3kG,OAAQ,CACNC,cAA8B5C,EAAAA,EAAAA,IAAO,IAAM,IAAIqnG,EAAwB,gBACvExkG,gBAAgC7C,EAAAA,EAAAA,IAAO,IAAM,IAAI4O,EAAAA,GAAwB,oBAG7E,SAAS24F,IAAkD,IAA3BxkG,EAAOC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGE,EAAAA,EACxC,MAAMC,GAASC,EAAAA,EAAAA,KACbC,EAAAA,EAAAA,GAA8BN,GAC9BO,EAAAA,IAEIkkG,GAAWpkG,EAAAA,EAAAA,KACfG,EAAAA,EAAAA,GAAwB,CAAEJ,WAC1BskG,EAAAA,GACAH,GAGF,OADAnkG,EAAOM,gBAAgB3B,SAAS0lG,GACzB,CAAErkG,SAAQqkG,WACnB,EACAxnG,EAAAA,EAAAA,IAAOunG,EAAwB,yB,wNC/B/B,MAAMG,EAAgF,CAClFnnE,QAASA,OACTxM,iBAAkBA,KAAA,CACdoY,iBAAiB,EACjB0F,eAAgB,CAAC,YACjBzpB,WAAY,aAIdu/E,EAAkG,CACpG7xE,cAAeA,IAAM,IAAI+mC,EAAAA,IAoBvB,SAAU+qC,EAAoBC,G,MAChC,MAAMzmG,EAlBV,WACI,MAAM+B,GAASC,EAAAA,EAAAA,KACXC,EAAAA,EAAAA,GAA8BH,EAAAA,GAC9BykG,GAEE/rE,GAAUx4B,EAAAA,EAAAA,KACZG,EAAAA,EAAAA,GAAwB,CAAEJ,WAC1BukG,GAGJ,OADAvkG,EAAOM,gBAAgB3B,SAAS85B,GACzBA,CACX,CAOqBksE,GACXp2E,EAAUtwB,EAASioD,WAAWE,eAAe/Z,YAAYq4D,GAE/D,OADAzmG,EAAS+B,OAAOw/B,UAAU4B,uBAAuBlB,UAAU3R,EAAS5S,EAAAA,EAAIxV,MAAM,YAADiB,OAAyB,QAAZwN,EAAA2Z,EAAQjxB,YAAI,IAAAsX,EAAAA,EAAI,UAAS,cAC5G2Z,CACX,C,oCClDIq2E,EAAYjkG,OAAOC,eACnB/D,EAASA,CAAC0Q,EAAQhN,IAAUqkG,EAAUr3F,EAAQ,OAAQ,CAAEhN,QAAOgjF,cAAc,IAI7EshB,EAAY,YACZC,EAAe,eAInBjoG,EAHA,SAAwBqC,GACtB,OAAOmjC,GAAW6nB,WAAWhrD,EAAM4lG,EACrC,EACuB,kBACvB,IAAIC,EAAO,OACPC,EAAS,SAIbnoG,EAHA,SAAkBqC,GAChB,OAAOmjC,GAAW6nB,WAAWhrD,EAAM8lG,EACrC,EACiB,YACjB,IAAIC,EAAW,WACXC,EAAgB,gBAChBC,EAAoB,oBACpBC,EAAS,SAIbvoG,EAHA,SAAkBqC,GAChB,OAAOmjC,GAAW6nB,WAAWhrD,EAAMkmG,EACrC,EACiB,YACjB,IAAIC,EAAQ,QACRC,EAAO,OACPC,EAAQ,QACRlB,EAAW,WAIfxnG,EAHA,SAAoBqC,GAClB,OAAOmjC,GAAW6nB,WAAWhrD,EAAMmlG,EACrC,EACmB,cACnB,IAAIn4C,EAAQ,QACR+D,EAAO,OAIXpzD,EAHA,SAAgBqC,GACd,OAAOmjC,GAAW6nB,WAAWhrD,EAAM+wD,EACrC,EACe,UACf,IAAIu1C,EAAO,OACPC,EAAW,WACXC,EAAQ,QAIZ7oG,EAHA,SAAiBqC,GACf,OAAOmjC,GAAW6nB,WAAWhrD,EAAMwmG,EACrC,EACgB,WAChB,IAAIr1F,EAAS,SACT6yF,EAAS,SAIbrmG,EAHA,SAAkBqC,GAChB,OAAOmjC,GAAW6nB,WAAWhrD,EAAMgkG,EACrC,EACiB,YACjB,IAAIyC,EAAc,cAIlB9oG,EAHA,SAAuBqC,GACrB,OAAOmjC,GAAW6nB,WAAWhrD,EAAMymG,EACrC,EACsB,iBACtB,IAAIrJ,EAAM,MAIVz/F,EAHA,SAAeqC,GACb,OAAOmjC,GAAW6nB,WAAWhrD,EAAMo9F,EACrC,EACc,SACd,IAAIsJ,EAAa,aAIjB/oG,EAHA,SAAsBqC,GACpB,OAAOmjC,GAAW6nB,WAAWhrD,EAAM0mG,EACrC,EACqB,gBACrB,IAAIj6F,EAAQ,QACRk6F,EAAU,UACVrnG,EAAU,UAId3B,EAHA,SAAmBqC,GACjB,OAAOmjC,GAAW6nB,WAAWhrD,EAAMV,EACrC,EACkB,aAClB,IAgWIsnG,EAEAC,EAEAC,EAEAC,EAEAC,EAEAC,EAEAC,EA5WAC,EAAa,aACbC,GAAY,YACZC,GAAO,OACPC,GAAU,UACVC,IAAoBhqG,EAAG,cAAc2wD,EAAAA,GAIvCC,WAAAA,GACE,MAAO,CAACy3C,EAAcC,EAAMC,EAAQC,EAAUC,EAAeC,EAAmBC,EAAQC,EAAOiB,GAAWhB,EAAMC,EAAOlB,EAAUn4C,EAAO+D,EAAMu1C,EAAMC,EAAUc,GAAMb,EAAOr1F,EAAQ6yF,EAAQyC,EAAarJ,EAAKsJ,EAAYj6F,EAAO66F,GAASX,EAAShB,EAAWrmG,EAAS6nG,EACxQ,CACA/4C,gBAAAA,CAAiB3d,EAAS4d,GACxB,OAAQ5d,GACN,KAAKq1D,EACL,KAAKC,EACL,KAAKC,EACL,KAAKE,EACL,KAAKM,EACH,OAAOjkG,KAAKypC,UAAU25D,EAAWt3C,GAEnC,KAAK+4C,GACH,OAAO7kG,KAAKypC,UAAUm5D,EAAU92C,GAElC,KAAKg5C,GACL,KAAKC,GACH,OAAO/kG,KAAKypC,UAAUs6D,EAAMj4C,GAE9B,QACE,OAAO,EAGb,CACA1oB,gBAAAA,CAAiB7B,GACf,MAAMwqB,EAAc,GAAHpmD,OAAM47B,EAAQhV,UAAUnwB,MAAK,KAAAuJ,OAAI47B,EAAQ1jC,UAC1D,GACO,eADCkuD,EAEJ,OAAOu3C,EAGP,MAAM,IAAI5iG,MAAM,GAADiF,OAAIomD,EAAW,iCAGpC,CACAC,eAAAA,CAAgBrgD,GACd,OAAQA,GACN,KAAK03F,EACH,MAAO,CACLxnG,KAAMwnG,EACNp3C,WAAY,CACV,CAAEpwD,KAAM,YACR,CAAEA,KAAM,YACR,CAAEA,KAAM,QAASqwD,aAAc,IAC/B,CAAErwD,KAAM,SAAUqwD,aAAc,IAChC,CAAErwD,KAAM,YAAaqwD,aAAc,IACnC,CAAErwD,KAAM,WAAYqwD,aAAc,IAClC,CAAErwD,KAAM,WAId,KAAKynG,EACH,MAAO,CACLznG,KAAMynG,EACNr3C,WAAY,CACV,CAAEpwD,KAAM,SACR,CAAEA,KAAM,UAId,KAAK0nG,EACH,MAAO,CACL1nG,KAAM0nG,EACNt3C,WAAY,CACV,CAAEpwD,KAAM,QACR,CAAEA,KAAM,WAId,KAAK2nG,EACH,MAAO,CACL3nG,KAAM2nG,EACNv3C,WAAY,CACV,CAAEpwD,KAAM,YAId,KAAK4nG,EACH,MAAO,CACL5nG,KAAM4nG,EACNx3C,WAAY,CACV,CAAEpwD,KAAM,MACR,CAAEA,KAAM,UACR,CAAEA,KAAM,OAAQqwD,aAAc,MAIpC,KAAKw3C,EACH,MAAO,CACL7nG,KAAM6nG,EACNz3C,WAAY,CACV,CAAEpwD,KAAM,aACR,CAAEA,KAAM,eAId,KAAK8nG,EACH,MAAO,CACL9nG,KAAM8nG,EACN13C,WAAY,CACV,CAAEpwD,KAAM,MACR,CAAEA,KAAM,WACR,CAAEA,KAAM,OAAQqwD,aAAc,IAC9B,CAAErwD,KAAM,UAId,KAAK+nG,EACH,MAAO,CACL/nG,KAAM+nG,EACN33C,WAAY,CACV,CAAEpwD,KAAM,UAAWqwD,aAAc,IACjC,CAAErwD,KAAM,SACR,CAAEA,KAAM,UAId,KAAKgoG,EACH,MAAO,CACLhoG,KAAMgoG,EACN53C,WAAY,CACV,CAAEpwD,KAAM,UACR,CAAEA,KAAM,WAAYqwD,cAAc,GAClC,CAAErwD,KAAM,SACR,CAAEA,KAAM,UAAWqwD,cAAc,GACjC,CAAErwD,KAAM,UACR,CAAEA,KAAM,WAAYqwD,cAAc,GAClC,CAAErwD,KAAM,SACR,CAAEA,KAAM,UAAWqwD,cAAc,GACjC,CAAErwD,KAAM,WAId,KAAKioG,EACH,MAAO,CACLjoG,KAAMioG,EACN73C,WAAY,CACV,CAAEpwD,KAAM,QACR,CAAEA,KAAM,WAId,KAAK+mG,EACH,MAAO,CACL/mG,KAAM+mG,EACN32C,WAAY,CACV,CAAEpwD,KAAM,YACR,CAAEA,KAAM,YACR,CAAEA,KAAM,aAAcqwD,aAAc,IACpC,CAAErwD,KAAM,WAId,KAAK4uD,EACH,MAAO,CACL5uD,KAAM4uD,EACNwB,WAAY,CACV,CAAEpwD,KAAM,QACR,CAAEA,KAAM,MACR,CAAEA,KAAM,MACR,CAAEA,KAAM,WAId,KAAK2yD,EACH,MAAO,CACL3yD,KAAM2yD,EACNvC,WAAY,CACV,CAAEpwD,KAAM,YACR,CAAEA,KAAM,YACR,CAAEA,KAAM,WAId,KAAKkoG,EACH,MAAO,CACLloG,KAAMkoG,EACN93C,WAAY,CACV,CAAEpwD,KAAM,iBACR,CAAEA,KAAM,UAId,KAAKmoG,EACH,MAAO,CACLnoG,KAAMmoG,EACN/3C,WAAY,CACV,CAAEpwD,KAAM,MACR,CAAEA,KAAM,QAId,KAAKooG,EACH,MAAO,CACLpoG,KAAMooG,EACNh4C,WAAY,CACV,CAAEpwD,KAAM,UACR,CAAEA,KAAM,MACR,CAAEA,KAAM,OAAQqwD,aAAc,IAC9B,CAAErwD,KAAM,UAId,KAAK+S,EACH,MAAO,CACL/S,KAAM+S,EACNq9C,WAAY,CACV,CAAEpwD,KAAM,QACR,CAAEA,KAAM,QAASqwD,cAAc,KAIrC,KAAKu1C,EACH,MAAO,CACL5lG,KAAM4lG,EACNx1C,WAAY,CACV,CAAEpwD,KAAM,YACR,CAAEA,KAAM,YACR,CAAEA,KAAM,SAAUqwD,aAAc,IAChC,CAAErwD,KAAM,WAId,KAAKqoG,EACH,MAAO,CACLroG,KAAMqoG,EACNj4C,WAAY,CACV,CAAEpwD,KAAM,QACR,CAAEA,KAAM,OACR,CAAEA,KAAM,SACR,CAAEA,KAAM,WAId,KAAKg/F,EACH,MAAO,CACLh/F,KAAMg/F,EACN5uC,WAAY,CACV,CAAEpwD,KAAM,YACR,CAAEA,KAAM,YACR,CAAEA,KAAM,WAAYqwD,aAAc,IAClC,CAAErwD,KAAM,WAAYqwD,cAAc,GAClC,CAAErwD,KAAM,WAId,KAAKsoG,EACH,MAAO,CACLtoG,KAAMsoG,EACNl4C,WAAY,CACV,CAAEpwD,KAAM,SACR,CAAEA,KAAM,WAId,KAAKqO,EACH,MAAO,CACLrO,KAAMqO,EACN+hD,WAAY,CACV,CAAEpwD,KAAM,YACR,CAAEA,KAAM,YACR,CAAEA,KAAM,OAAQqwD,aAAc,IAC9B,CAAErwD,KAAM,SAAUqwD,aAAc,IAChC,CAAErwD,KAAM,UAAWqwD,aAAc,IACjC,CAAErwD,KAAM,WAId,KAAKuoG,EACH,MAAO,CACLvoG,KAAMuoG,EACNn4C,WAAY,CACV,CAAEpwD,KAAM,QACR,CAAEA,KAAM,YACR,CAAEA,KAAM,MACR,CAAEA,KAAM,MACR,CAAEA,KAAM,WAId,KAAKkB,EACH,MAAO,CACLlB,KAAMkB,EACNkvD,WAAY,CACV,CAAEpwD,KAAM,YACR,CAAEA,KAAM,YACR,CAAEA,KAAM,SACR,CAAEA,KAAM,cAAeqwD,aAAc,MAI3C,KAAK04C,EACH,MAAO,CACL/oG,KAAM+oG,EACN34C,WAAY,CACV,CAAEpwD,KAAM,UACR,CAAEA,KAAM,UAId,KAAKgpG,GACH,MAAO,CACLhpG,KAAMgpG,GACN54C,WAAY,CACV,CAAEpwD,KAAM,YACR,CAAEA,KAAM,YACR,CAAEA,KAAM,OACR,CAAEA,KAAM,aAAcqwD,aAAc,IACpC,CAAErwD,KAAM,WAId,KAAKipG,GACH,MAAO,CACLjpG,KAAMipG,GACN74C,WAAY,CACV,CAAEpwD,KAAM,iBACR,CAAEA,KAAM,QACR,CAAEA,KAAM,WAId,KAAKkpG,GACH,MAAO,CACLlpG,KAAMkpG,GACN94C,WAAY,CACV,CAAEpwD,KAAM,iBACR,CAAEA,KAAM,UAId,QACE,MAAO,CACLA,KAAM8P,EACNsgD,WAAY,IAIpB,GApVE7wD,EAAMJ,EAAO,wBAAuBA,GAsVpC4lC,GAAa,IAAIokE,GAKjBC,GAA8B7pG,EAAO,IAAuB,OAAjBipG,QAAiB,IAAjBA,EAAAA,EAAsBA,EAAoBrB,EAAoB,gkJAA+jJ,eAExqJkC,GAAgC9pG,EAAO,IAAyB,OAAnBkpG,QAAmB,IAAnBA,EAAAA,EAAwBA,EAAsBtB,EAAoB,yoLAAwoL,iBAEvvLmC,GAA6B/pG,EAAO,IAAsB,OAAhBmpG,QAAgB,IAAhBA,EAAAA,EAAqBA,EAAmBvB,EAAoB,0tKAAytK,cAE/zKoC,GAAsChqG,EAAO,IAA+B,OAAzBopG,QAAyB,IAAzBA,EAAAA,EAA8BA,EAA4BxB,EAAoB,62WAA42W,uBAE7+WqC,GAAkCjqG,EAAO,IAA2B,OAArBqpG,QAAqB,IAArBA,EAAAA,EAA0BA,EAAwBzB,EAAoB,orVAAmrV,mBAExyVsC,GAA+BlqG,EAAO,IAAwB,OAAlBspG,QAAkB,IAAlBA,EAAAA,EAAuBA,EAAqB1B,EAAoB,4rXAA2rX,gBAEvyXuC,GAAiCnqG,EAAO,IAA0B,OAApBupG,QAAoB,IAApBA,EAAAA,EAAyBA,EAAuB3B,EAAoB,46RAA26R,kBAG7hSwC,GAAuB,CACzBhiF,WAAY,OACZypB,eAAgB,CAAC,OAAQ,YACzB1F,iBAAiB,EACjBnY,KAAM,cAEJq2E,GAAyB,CAC3BjiF,WAAY,SACZypB,eAAgB,CAAC,OAAQ,YACzB1F,iBAAiB,EACjBnY,KAAM,cAEJs2E,GAAsB,CACxBliF,WAAY,MACZypB,eAAgB,CAAC,OAAQ,YACzB1F,iBAAiB,EACjBnY,KAAM,cAEJu2E,GAA+B,CACjCniF,WAAY,eACZypB,eAAgB,CAAC,OAAQ,YACzB1F,iBAAiB,EACjBnY,KAAM,cAEJw2E,GAA2B,CAC7BpiF,WAAY,WACZypB,eAAgB,CAAC,OAAQ,YACzB1F,iBAAiB,EACjBnY,KAAM,cAEJy2E,GAAwB,CAC1BriF,WAAY,QACZypB,eAAgB,CAAC,OAAQ,YACzB1F,iBAAiB,EACjBnY,KAAM,cAEJ02E,GAA0B,CAC5BtiF,WAAY,UACZypB,eAAgB,CAAC,OAAQ,YACzB1F,iBAAiB,EACjBnY,KAAM,cAEJ1wB,GAA+B,CACjCwyB,cAA+B91B,EAAO,IAAM,IAAI4pG,GAAwB,kBAEtEv2C,GAAsB,CACxB9yB,QAAyBvgC,EAAO,IAAM6pG,KAAe,WACrD91E,iBAAkC/zB,EAAO,IAAMoqG,GAAsB,oBACrEznG,OAAQ,CAAC,GAEP2jG,GAAwB,CAC1B/lE,QAAyBvgC,EAAO,IAAM8pG,KAAiB,WACvD/1E,iBAAkC/zB,EAAO,IAAMqqG,GAAwB,oBACvE1nG,OAAQ,CAAC,GAEP+8F,GAAqB,CACvBn/D,QAAyBvgC,EAAO,IAAM+pG,KAAc,WACpDh2E,iBAAkC/zB,EAAO,IAAMsqG,GAAqB,oBACpE3nG,OAAQ,CAAC,GAEPgoG,GAA8B,CAChCpqE,QAAyBvgC,EAAO,IAAMgqG,KAAuB,WAC7Dj2E,iBAAkC/zB,EAAO,IAAMuqG,GAA8B,oBAC7E5nG,OAAQ,CAAC,GAEP8kG,GAA0B,CAC5BlnE,QAAyBvgC,EAAO,IAAMiqG,KAAmB,WACzDl2E,iBAAkC/zB,EAAO,IAAMwqG,GAA0B,oBACzE7nG,OAAQ,CAAC,GAEPoM,GAAuB,CACzBwxB,QAAyBvgC,EAAO,IAAMkqG,KAAgB,WACtDn2E,iBAAkC/zB,EAAO,IAAMyqG,GAAuB,oBACtE9nG,OAAQ,CAAC,GAEPa,GAAyB,CAC3B+8B,QAAyBvgC,EAAO,IAAMmqG,KAAkB,WACxDp2E,iBAAkC/zB,EAAO,IAAM0qG,GAAyB,oBACxE/nG,OAAQ,CAAC,GAYPioG,GAAe,CACjBC,UAN4B,6CAO5BC,UAN4B,4BAO5BC,MANe,yBAQb3qG,IAA6BD,EAAG,cAAc+oD,EAAAA,EAIhD8hD,YAAAA,CAAa1qG,EAAMC,EAAO23B,GACxB,IAAIx0B,EAAQkB,KAAKqmG,mBAAmB3qG,EAAMC,EAAO23B,GAIjD,YAHc,IAAVx0B,IACFA,EAAQkB,KAAKvE,mBAAmBC,EAAMC,EAAO23B,SAEjC,IAAVx0B,EACK3D,MAAMirG,aAAa1qG,EAAMC,EAAO23B,GAElCx0B,CACT,CACAunG,kBAAAA,CAAmB3qG,EAAMC,EAAOC,GAC9B,MAAM2pD,EAAQygD,GAAatqG,EAAKG,MAChC,QAAc,IAAV0pD,EACF,OAEF,MAAMrpD,EAAQqpD,EAAMppD,KAAKR,GACzB,OAAc,OAAVO,OAGa,IAAbA,EAAM,GACDA,EAAM,GAAGwiD,OAAO3iD,QAAQ,cAAe,UAE/B,IAAbG,EAAM,GACDA,EAAM,GAAGH,QAAQ,SAAU,IAAIA,QAAQ,SAAU,IAAIA,QAAQ,cAAe,KAAKA,QAAQ,eAAgB,WADlH,OANA,CAUF,GA5BEX,EAAMG,EAAO,iCAAgCA,GA8B7CyO,IAEA5O,EAFoB+B,EAAG,cAAc3B,GAIvCC,kBAAAA,CAAmB6qG,EAAOC,EAAQ3qG,GAElC,GAJe,wBAAuBuB,GASpClC,IAA2BurG,EAAG,cAAcjiD,EAAAA,EAI9CrpD,WAAAA,CAAYurG,GACVtrG,QACA6E,KAAKymG,SAAW,IAAI7wF,IAAI6wF,EAC1B,CACAjG,kBAAAA,CAAmBj0F,EAAO+zF,EAAgBrtF,GACxC,MAAMsnC,EAAap/C,MAAMqlG,mBAAmBj0F,EAAO+zF,EAAgBrtF,GAMnE,OALAsnC,EAAW9lC,QAASxI,IACdjM,KAAKymG,SAASzwF,IAAI/J,EAAUpQ,YAA+B,IAAtBoQ,EAAUulD,UACjDvlD,EAAUulD,QAAU,IAAInT,OAAOpyC,EAAUulD,QAAQprD,WAAa,yBAG3Dm0C,CACT,GAdEn/C,EAAMorG,EAAO,+BAA8BA,GAkB3CprG,EAFkBsrG,EAAG,cAAczrG,KAEtB,qB,kFCpiBjB,QALA,SAAaoN,EAAYC,GAEvB,QADWvJ,EAAAA,EAAAA,GAAQsJ,GAAc6nD,EAAAA,EAAWy2C,EAAAA,GAChCt+F,GAAYgK,EAAAA,EAAAA,GAAa/J,EAAU,GACjD,C,iFCkNM,MAAOqmD,EAITzzD,WAAAA,CAAY0rG,EAAkBC,GAC1B7mG,KAAK4mG,QAAUA,EACf5mG,KAAK6mG,OAASA,CAClB,CAEA3gE,QAAAA,GACI,MAAMA,EAAW,CACbj1B,MAAOjR,KAAK4mG,UACZt2F,KAAMA,IAAMtQ,KAAK6mG,OAAO3gE,EAASj1B,OACjC,CAAC7L,OAAO8gC,UAAW,IAAMA,GAE7B,OAAOA,CACX,CAEA,CAAC9gC,OAAO8gC,YACJ,OAAOlmC,KAAKkmC,UAChB,CAEA1kC,OAAAA,GACI,MAAM0kC,EAAWlmC,KAAKkmC,WACtB,OAAOhgB,QAAQggB,EAAS51B,OAAO2wC,KACnC,CAEA3yB,KAAAA,GACI,MAAM4X,EAAWlmC,KAAKkmC,WACtB,IAAI5X,EAAQ,EACRhe,EAAO41B,EAAS51B,OACpB,MAAQA,EAAK2wC,MACT3yB,IACAhe,EAAO41B,EAAS51B,OAEpB,OAAOge,CACX,CAEAqnB,OAAAA,GACI,MAAM3zC,EAAc,GACdkkC,EAAWlmC,KAAKkmC,WACtB,IAAI51B,EACJ,GACIA,EAAO41B,EAAS51B,YACGjS,IAAfiS,EAAKxR,OACLkD,EAAO7B,KAAKmQ,EAAKxR,cAEfwR,EAAK2wC,MACf,OAAOj/C,CACX,CAEAszC,KAAAA,GACI,OAAO,IAAI1/B,IAAI5V,KACnB,CAEA8mG,KAAAA,CAAoBC,EAAqBC,GACrC,MAAMC,EAAcjnG,KAAKwO,IAAI4e,GAAmB,CAC5C25E,EAAQA,EAAM35E,GAAWA,EACzB45E,EAAUA,EAAQ55E,GAAWA,IAEjC,OAAO,IAAIxgB,IAAIq6F,EACnB,CAEA7gG,QAAAA,GACI,OAAOpG,KAAK0D,MAChB,CAEAiC,MAAAA,CAAWkiD,GACP,OAAO,IAAI8G,EACP,KAAM,CAAGn+C,MAAOxQ,KAAK4mG,UAAWM,WAAW,EAAOhhE,SAAU2hB,EAAMziD,OAAO8gC,cACzEj1B,IACI,IAAIjP,EACJ,IAAKiP,EAAMi2F,UAAW,CAClB,GAEI,GADAllG,EAAShC,KAAK6mG,OAAO51F,EAAMT,QACtBxO,EAAOi/C,KACR,OAAOj/C,SAELA,EAAOi/C,MACjBhwC,EAAMi2F,WAAY,CACtB,CACA,GAEI,GADAllG,EAASiP,EAAMi1B,SAAS51B,QACnBtO,EAAOi/C,KACR,OAAOj/C,SAELA,EAAOi/C,MACjB,OAAO6N,GAGnB,CAEAprD,IAAAA,GAAoB,IAAf6L,EAASnR,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,IACb,MAAM8nC,EAAWlmC,KAAKkmC,WACtB,IACIlkC,EADAlD,EAAQ,GAERqoG,GAAe,EACnB,GACInlG,EAASkkC,EAAS51B,OACbtO,EAAOi/C,OACJkmD,IACAroG,GAASyQ,GAEbzQ,GAASsH,EAASpE,EAAOlD,QAE7BqoG,GAAe,SACTnlG,EAAOi/C,MACjB,OAAOniD,CACX,CAEA2G,OAAAA,CAAQ2hG,GAA+B,IAAb50C,EAASp0D,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EAClC,MAAM8nC,EAAWlmC,KAAKkmC,WACtB,IAAI39B,EAAQ,EACR+H,EAAO41B,EAAS51B,OACpB,MAAQA,EAAK2wC,MAAM,CACf,GAAI14C,GAASiqD,GAAaliD,EAAKxR,QAAUsoG,EACrC,OAAO7+F,EAEX+H,EAAO41B,EAAS51B,OAChB/H,GACJ,CACA,OAAQ,CACZ,CAeA8a,KAAAA,CAAMtY,GACF,MAAMm7B,EAAWlmC,KAAKkmC,WACtB,IAAI51B,EAAO41B,EAAS51B,OACpB,MAAQA,EAAK2wC,MAAM,CACf,IAAKl2C,EAAUuF,EAAKxR,OAChB,OAAO,EAEXwR,EAAO41B,EAAS51B,MACpB,CACA,OAAO,CACX,CAEA8+B,IAAAA,CAAKrkC,GACD,MAAMm7B,EAAWlmC,KAAKkmC,WACtB,IAAI51B,EAAO41B,EAAS51B,OACpB,MAAQA,EAAK2wC,MAAM,CACf,GAAIl2C,EAAUuF,EAAKxR,OACf,OAAO,EAEXwR,EAAO41B,EAAS51B,MACpB,CACA,OAAO,CACX,CAEAmE,OAAAA,CAAQwxB,GACJ,MAAMC,EAAWlmC,KAAKkmC,WACtB,IAAI39B,EAAQ,EACR+H,EAAO41B,EAAS51B,OACpB,MAAQA,EAAK2wC,MACThb,EAAW31B,EAAKxR,MAAOyJ,GACvB+H,EAAO41B,EAAS51B,OAChB/H,GAER,CAEAiG,GAAAA,CAAOy3B,GACH,OAAO,IAAI0oB,EACP3uD,KAAK4mG,QACJ31F,IACG,MAAM,KAAEgwC,EAAI,MAAEniD,GAAUkB,KAAK6mG,OAAO51F,GACpC,OAAIgwC,EACO6N,EAEA,CAAE7N,MAAM,EAAOniD,MAAOmnC,EAAWnnC,KAIxD,CAKAkR,MAAAA,CAAOjF,GACH,OAAO,IAAI4jD,EACP3uD,KAAK4mG,QACL31F,IACI,IAAIjP,EACJ,GAEI,GADAA,EAAShC,KAAK6mG,OAAO51F,IAChBjP,EAAOi/C,MAAQl2C,EAAU/I,EAAOlD,OACjC,OAAOkD,SAELA,EAAOi/C,MACjB,OAAO6N,GAGnB,CAEAjlB,WAAAA,GACI,OAAO7pC,KAAKgQ,OAAO5O,QAAW/C,IAAN+C,GAAyB,OAANA,EAC/C,CAIAoT,MAAAA,CAAUyxB,EAA0DohE,GAChE,MAAMnhE,EAAWlmC,KAAKkmC,WACtB,IAAImM,EAAmCg1D,EACnC/2F,EAAO41B,EAAS51B,OACpB,MAAQA,EAAK2wC,MAEL5O,OADkBh0C,IAAlBg0C,EACgB/hC,EAAKxR,MAELmnC,EAAWoM,EAAe/hC,EAAKxR,OAEnDwR,EAAO41B,EAAS51B,OAEpB,OAAO+hC,CACX,CAIAi1D,WAAAA,CAAerhE,EAA0DohE,GACrE,OAAOrnG,KAAKunG,gBAAgBvnG,KAAKkmC,WAAYD,EAAYohE,EAC7D,CAEUE,eAAAA,CAAmBrhE,EAAuBD,EAA0DohE,GAC1G,MAAM/2F,EAAO41B,EAAS51B,OACtB,GAAIA,EAAK2wC,KACL,OAAOomD,EAEX,MAAMh1D,EAAgBryC,KAAKunG,gBAAgBrhE,EAAUD,EAAYohE,GACjE,YAAsBhpG,IAAlBg0C,EACO/hC,EAAKxR,MAETmnC,EAAWoM,EAAe/hC,EAAKxR,MAC1C,CAIA2oC,IAAAA,CAAK18B,GACD,MAAMm7B,EAAWlmC,KAAKkmC,WACtB,IAAI51B,EAAO41B,EAAS51B,OACpB,MAAQA,EAAK2wC,MAAM,CACf,GAAIl2C,EAAUuF,EAAKxR,OACf,OAAOwR,EAAKxR,MAEhBwR,EAAO41B,EAAS51B,MACpB,CAEJ,CAEA4vF,SAAAA,CAAUn1F,GACN,MAAMm7B,EAAWlmC,KAAKkmC,WACtB,IAAI39B,EAAQ,EACR+H,EAAO41B,EAAS51B,OACpB,MAAQA,EAAK2wC,MAAM,CACf,GAAIl2C,EAAUuF,EAAKxR,OACf,OAAOyJ,EAEX+H,EAAO41B,EAAS51B,OAChB/H,GACJ,CACA,OAAQ,CACZ,CAEA+lC,QAAAA,CAAS84D,GACL,MAAMlhE,EAAWlmC,KAAKkmC,WACtB,IAAI51B,EAAO41B,EAAS51B,OACpB,MAAQA,EAAK2wC,MAAM,CACf,GAAI3wC,EAAKxR,QAAUsoG,EACf,OAAO,EAEX92F,EAAO41B,EAAS51B,MACpB,CACA,OAAO,CACX,CAEA8I,OAAAA,CAAW6sB,GAEP,OAAO,IAAI0oB,EACP,KAAM,CAAG3uD,KAAMA,KAAK4mG,YACnB31F,IACG,EAAG,CACC,GAAIA,EAAMi1B,SAAU,CAChB,MAAM51B,EAAOW,EAAMi1B,SAAS51B,OAC5B,IAAIA,EAAK2wC,KAGL,OAAO3wC,EAFPW,EAAMi1B,cAAW7nC,CAIzB,CACA,MAAM,KAAE4iD,EAAI,MAAEniD,GAAUkB,KAAK6mG,OAAO51F,EAAMjR,MAC1C,IAAKihD,EAAM,CACP,MAAMumD,EAASvhE,EAAWnnC,GAC1B,IAAI2oG,EAAWD,GAGX,MAAO,CAAEvmD,MAAM,EAAOniD,MAAO0oG,GAF7Bv2F,EAAMi1B,SAAWshE,EAAOpiG,OAAO8gC,WAIvC,CACJ,OAASj1B,EAAMi1B,UACf,OAAO4oB,GAGnB,CAEA3oB,IAAAA,CAA2BuhE,GAIvB,QAHcrpG,IAAVqpG,IACAA,EAAQ,GAERA,GAAS,EACT,OAAO1nG,KAEX,MAAMq3B,EAASqwE,EAAQ,EAAI1nG,KAAKmmC,KAAKuhE,EAAQ,GAAoC1nG,KAEjF,OAAO,IAAI2uD,EACP,KAAM,CAAG3uD,KAAMq3B,EAAOuvE,YACrB31F,IACG,EAAG,CACC,GAAIA,EAAMi1B,SAAU,CAChB,MAAM51B,EAAOW,EAAMi1B,SAAS51B,OAC5B,IAAIA,EAAK2wC,KAGL,OAAO3wC,EAFPW,EAAMi1B,cAAW7nC,CAIzB,CACA,MAAM,KAAE4iD,EAAI,MAAEniD,GAAUu4B,EAAOwvE,OAAO51F,EAAMjR,MAC5C,IAAKihD,EAAM,CACP,IAAIwmD,EAAW3oG,GAGX,MAAO,CAAEmiD,MAAM,EAAOniD,MAAOA,GAF7BmS,EAAMi1B,SAAWpnC,EAAMsG,OAAO8gC,WAItC,CACJ,OAASj1B,EAAMi1B,UACf,OAAO4oB,GAGnB,CAEA64C,IAAAA,GACI,MACM3lG,EADWhC,KAAKkmC,WACE51B,OACxB,IAAItO,EAAOi/C,KAGX,OAAOj/C,EAAOlD,KAClB,CAEA8oG,IAAAA,GAAkB,IAAbC,EAASzpG,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAG,EACb,OAAO,IAAIuwD,EACP,KACI,MAAM19C,EAAQjR,KAAK4mG,UACnB,IAAK,IAAIrmG,EAAI,EAAGA,EAAIsnG,EAAWtnG,IAAK,CAEhC,GADaP,KAAK6mG,OAAO51F,GAChBgwC,KACL,OAAOhwC,CAEf,CACA,OAAOA,GAEXjR,KAAK6mG,OAEb,CAEAiB,KAAAA,CAAMC,GACF,OAAO,IAAIp5C,EACP,KAAM,CAAG98C,KAAM,EAAGZ,MAAOjR,KAAK4mG,YAC9B31F,IACIA,EAAMY,OACFZ,EAAMY,KAAOk2F,EACNj5C,EAEJ9uD,KAAK6mG,OAAO51F,EAAMA,QAGrC,CAEA8vF,QAAAA,CAAkBiH,GACd,OAAO,IAAIr5C,EACP,KAAM,CAAGzhD,IAAK,IAAI0I,IAAgBqyF,cAAejoG,KAAK4mG,YACtD31F,IACI,IAAIjP,EACJ,GAEI,GADAA,EAAShC,KAAK6mG,OAAO51F,EAAMg3F,gBACtBjmG,EAAOi/C,KAAM,CACd,MAAMniD,EAAQkpG,EAAKA,EAAGhmG,EAAOlD,OAASkD,EAAOlD,MAC7C,IAAKmS,EAAM/D,IAAI8I,IAAIlX,GAEf,OADAmS,EAAM/D,IAAIrN,IAAIf,GACPkD,CAEf,SACMA,EAAOi/C,MACjB,OAAO6N,GAGnB,CAEAo5C,OAAAA,CAAiBrgD,EAAoBn/C,GACjC,MAAMy/F,EAAc,IAAIvyF,IACxB,IAAK,MAAMnY,KAAQoqD,EAAO,CACtB,MAAM/oD,EAAQ4J,EAAMA,EAAIjL,GAAQA,EAChC0qG,EAAYtoG,IAAIf,EACpB,CACA,OAAOkB,KAAKgQ,OAAO5O,IACf,MAAMgnG,EAAS1/F,EAAMA,EAAItH,GAAKA,EAC9B,OAAQ+mG,EAAYnyF,IAAIoyF,IAEhC,EAGJ,SAAShiG,EAAS3I,GACd,MAAoB,kBAATA,EACAA,EAES,qBAATA,EACA,YAG2B,oBAA1BA,EAAa2I,SAEb3I,EAAa2I,WAElBlH,OAAOgG,UAAUkB,SAAShE,KAAK3E,EAC1C,CAEA,SAASgqG,EAAc5zE,GACnB,QAASA,GAAwD,oBAAzCA,EAAoBzuB,OAAO8gC,SACvD,CAMO,MAAMmiE,EAA4B,IAAI15C,EAA2B,OAAiB,IAAMG,GAKlFA,EAA+C5vD,OAAO0mE,OAAO,CAAE3kB,MAAM,EAAMniD,WAAOT,IAKzF,SAAUg5B,IAA2D,QAAAr2B,EAAA5C,UAAAnC,OAA9CqsG,EAA8C,IAAAloG,MAAAY,GAAAE,EAAA,EAAAA,EAAAF,EAAAE,IAA9ConG,EAA8CpnG,GAAA9C,UAAA8C,GACvE,GAA2B,IAAvBonG,EAAYrsG,OAAc,CAC1B,MAAMoM,EAAaigG,EAAY,GAC/B,GAAIjgG,aAAsBsmD,EACtB,OAAOtmD,EAEX,GAAIo/F,EAAWp/F,GACX,OAAO,IAAIsmD,EACP,IAAMtmD,EAAWjD,OAAO8gC,YACvBA,GAAaA,EAAS51B,QAG/B,GAAiC,kBAAtBjI,EAAWpM,OAClB,OAAO,IAAI0yD,EACP,KAAM,CAAGpmD,MAAO,IACf0I,GACOA,EAAM1I,MAAQF,EAAWpM,OAClB,CAAEglD,MAAM,EAAOniD,MAAOuJ,EAAW4I,EAAM1I,UAEvCumD,EAK3B,CACA,OAAIw5C,EAAYrsG,OAAS,EAEd,IAAI0yD,EACP,KAAM,CAAG45C,UAAW,EAAGC,SAAU,IAChCv3F,IACG,EAAG,CACC,GAAIA,EAAMi1B,SAAU,CAChB,MAAM51B,EAAOW,EAAMi1B,SAAS51B,OAC5B,IAAKA,EAAK2wC,KACN,OAAO3wC,EAEXW,EAAMi1B,cAAW7nC,CACrB,CACA,GAAI4S,EAAM5O,MAAO,CACb,GAAI4O,EAAMu3F,SAAWv3F,EAAM5O,MAAMpG,OAC7B,MAAO,CAAEglD,MAAM,EAAOniD,MAAOmS,EAAM5O,MAAM4O,EAAMu3F,aAEnDv3F,EAAM5O,WAAQhE,EACd4S,EAAMu3F,SAAW,CACrB,CACA,GAAIv3F,EAAMs3F,UAAYD,EAAYrsG,OAAQ,CACtC,MAAMoM,EAAaigG,EAAYr3F,EAAMs3F,aACjCd,EAAWp/F,GACX4I,EAAMi1B,SAAW79B,EAAWjD,OAAO8gC,YAC5B79B,GAA2C,kBAAtBA,EAAWpM,SACvCgV,EAAM5O,MAAQgG,EAEtB,CACJ,OAAS4I,EAAMi1B,UAAYj1B,EAAM5O,OAAS4O,EAAMs3F,UAAYD,EAAYrsG,QACxE,OAAO6yD,IAIZu5C,CACX,CAyBM,MAAOt5C,UACDJ,EAGRzzD,WAAAA,CAAYqJ,EAASgiB,EAAoCtT,GACrD9X,MACI,KAAM,CACFstG,WAAkB,OAAPx1F,QAAO,IAAPA,OAAO,EAAPA,EAAS+7C,aAAc,CAAC,CAACzqD,GAAMa,OAAO8gC,aAAe,CAAC3f,EAAShiB,GAAMa,OAAO8gC,aACvFwiE,QAAQ,IAEZz3F,IAKI,IAJIA,EAAMy3F,SACNz3F,EAAMw3F,UAAU1uF,MAChB9I,EAAMy3F,QAAS,GAEZz3F,EAAMw3F,UAAUxsG,OAAS,GAAG,CAC/B,MACMqU,EADWW,EAAMw3F,UAAUx3F,EAAMw3F,UAAUxsG,OAAS,GACpCqU,OACtB,IAAIA,EAAK2wC,KAIL,OADAhwC,EAAMw3F,UAAUtoG,KAAKomB,EAASjW,EAAKxR,OAAOsG,OAAO8gC,aAC1C51B,EAHPW,EAAMw3F,UAAU1uF,KAKxB,CACA,OAAO+0C,GAGnB,CAES5oB,QAAAA,GACL,MAAMA,EAAW,CACbj1B,MAAOjR,KAAK4mG,UACZt2F,KAAMA,IAAMtQ,KAAK6mG,OAAO3gE,EAASj1B,OACjC03F,MAAOA,KACHziE,EAASj1B,MAAMy3F,QAAS,GAE5B,CAACtjG,OAAO8gC,UAAW,IAAMA,GAE7B,OAAOA,CACX,EAME,IAAWJ,GAAjB,SAAiBA,GAKGA,EAAAC,IAAhB,SAAoB1O,GAChB,OAAOA,EAAO7iB,OAAO,CAACrR,EAAGyE,IAAMzE,EAAIyE,EAAG,EAC1C,EAKgBk+B,EAAA8iE,QAAhB,SAAwBvxE,GACpB,OAAOA,EAAO7iB,OAAO,CAACrR,EAAGyE,IAAMzE,EAAIyE,EAAG,EAC1C,EAKgBk+B,EAAA1tB,IAAhB,SAAoBif,GAChB,OAAOA,EAAO7iB,OAAO,CAACrR,EAAGyE,IAAMkjB,KAAK1S,IAAIjV,EAAGyE,GAC/C,EAKgBk+B,EAAA/a,IAAhB,SAAoBsM,GAChB,OAAOA,EAAO7iB,OAAO,CAACrR,EAAGyE,IAAMkjB,KAAKC,IAAI5nB,EAAGyE,GAC/C,CAEH,CA9BD,CAAiBk+B,IAAAA,EAAS,I,6DC9yB1B,QAJA,SAAiBz9B,EAAYC,GAC3B,OAAOuB,EAAAA,EAAAA,IAAY2E,EAAAA,EAAAA,GAAInG,EAAYC,GAAW,EAChD,C,qNCWM,SAAU6uB,EAAqBH,EAAsB6xE,GACvD,MAAMnxE,EAAY,IAAI9hB,IAChBkzF,EArBJ,SAAuB9xE,GACzB,OAAOA,EAAQzqB,MAAMk7B,KAAKrmC,GAAK62D,EAAAA,GAAiB72D,IAAMA,EAAE2P,MAC5D,CAmBsBg4F,CAAa/xE,GAC/B,IAAK8xE,EACD,OAAO,IAAIlzF,IAAIohB,EAAQzqB,OAG3B,MAAMy8F,EAAe,CAACF,GAA+BnjG,OAnBnD,SAAyBqxB,GAC3B,OAAOA,EAAQzqB,MAAMyD,OAAQ5O,GAA6B62D,EAAAA,GAAmB72D,IAAMA,EAAE6rB,OACzF,CAiBgEg8E,CAAejyE,IAC3E,IAAK,MAAMt7B,KAAQstG,EACfE,EAAQxtG,EAAMg8B,EAAWmxE,GAG7B,MAAMt8F,EAAQ,IAAIqJ,IAClB,IAAK,MAAMla,KAAQs7B,EAAQzqB,OACnBmrB,EAAU1hB,IAAIta,EAAKG,OAAUo8D,EAAAA,GAAmBv8D,IAASA,EAAKuxB,SAC9D1gB,EAAM1M,IAAInE,GAGlB,OAAO6Q,CACX,CAEA,SAAS28F,EAAQxtG,EAAwBytG,EAAyBN,GAC9DM,EAAWtpG,IAAInE,EAAKG,OACpBsrC,EAAAA,EAAAA,IAAkBzrC,GAAM+Y,QAAQ7W,IAC5B,GAAIq6D,EAAAA,GAAer6D,IAAUirG,GAAgB5wC,EAAAA,GAAuBr6D,GAAQ,CACxE,MAAMwrG,EAAUxrG,EAAKlC,KAAK48B,IACtB8wE,IAAYD,EAAWnzF,IAAIozF,EAAQvtG,OACnCqtG,EAAQE,EAASD,EAAYN,EAErC,GAER,CAUM,SAAUQ,EAA0BpuE,GACtC,GAAIA,EAAS9G,SACT,OAAO8G,EAAS9G,SACb,GAAI8G,EAAStvB,KAAK2sB,IAAK,CAC1B,MAAMgxE,EAAgBnuE,EAAmBF,EAAStvB,KAAK2sB,KACvD,OAAoB,OAAbgxE,QAAa,IAAbA,OAAa,EAAbA,EAAen1E,QAC1B,CAEJ,CAOM,SAAU2vB,EAAkB5oB,GAC9B,OAAOA,EAAajO,UAAWq5B,EAAAA,EAAAA,IAAatC,EAAc9oB,GAC9D,CAQM,SAAUkR,EAAqBxuC,EAA2BC,GAC5D,OAAKD,GAASC,EAGP0rG,EAA6B3rG,EAAMC,EAAUD,EAAKkvB,SAAS,GAFvD,EAGf,CAWM,SAAU2W,EAAoB7lC,EAA2BC,EAA8B0K,GACzF,IAAK3K,IAASC,EACV,OAEJ,MAAM6uB,EAAQ68E,EAA6B3rG,EAAMC,EAAUD,EAAKkvB,SAAS,GACzE,OAAqB,IAAjBJ,EAAMzwB,OAQHywB,EAJHnkB,OADUlK,IAAVkK,EACQuiB,KAAKC,IAAI,EAAGD,KAAK1S,IAAI7P,EAAOmkB,EAAMzwB,OAAS,IAE3C,QANZ,CASJ,CAEA,SAASstG,EAA6B3rG,EAAeC,EAAkBuvB,EAA8B5c,GACjG,IAAKA,EAAO,CACR,MAAMg5F,GAAcx1E,EAAAA,EAAAA,IAAmBp2B,EAAKouB,cAAeisC,EAAAA,IAC3D,GAAIuxC,GAAeA,EAAY39E,UAAYhuB,EACvC,MAAO,CAACD,EAEhB,CACA,OAAI8kD,EAAAA,EAAAA,IAAmB9kD,IAASA,EAAKkvB,UAAYM,EACtCxvB,EAAKyrB,QAAQjQ,QAAQhY,GAAKmoG,EAA6BnoG,EAAGvD,EAAUuvB,GAAS,IAEjF,EACX,CAwBM,SAAU6jB,EAAmBrzC,EAA2Bi6B,EAAiBtvB,GAC3E,IAAK3K,EACD,OAEJ,MAAM8uB,EAAQ+8E,EAA4B7rG,EAAMi6B,EAAa,OAAJj6B,QAAI,IAAJA,OAAI,EAAJA,EAAMkvB,SAC/D,OAAqB,IAAjBJ,EAAMzwB,OAQHywB,EAJHnkB,OADUlK,IAAVkK,EACQuiB,KAAKC,IAAI,EAAGD,KAAK1S,IAAI7P,EAAOmkB,EAAMzwB,OAAS,IAE3C,QANZ,CASJ,CAEM,SAAUwtG,EAA4B7rG,EAAei6B,EAAiBzK,GACxE,GAAIxvB,EAAKkvB,UAAYM,EACjB,MAAO,GAEX,GAAI6qC,EAAAA,GAAcr6D,EAAKouB,gBAAkBpuB,EAAKouB,cAAcltB,QAAU+4B,EAClE,MAAO,CAACj6B,GAEZ,MAAM8rG,GAAetnD,EAAAA,EAAAA,IAAUxkD,GAAMsoC,WACrC,IAAIlkC,EACJ,MAAM2nG,EAA0B,GAChC,GAEI,GADA3nG,EAAS0nG,EAAap5F,QACjBtO,EAAOi/C,KAAM,CACd,MAAM2oD,EAAY5nG,EAAOlD,MACrB8qG,EAAU98E,UAAYM,EAClB6qC,EAAAA,GAAc2xC,EAAU59E,gBAAkB49E,EAAU59E,cAAcltB,QAAU+4B,GAC5E8xE,EAAaxpG,KAAKypG,GAGtBF,EAAaf,OAErB,SACM3mG,EAAOi/C,MACjB,OAAO0oD,CACX,CAQM,SAAUjlE,EAAepR,G,MAC3B,MAAMxG,EAAUwG,EAAQxG,QAGxB,KAAOA,KAA6B,QAAjB3Z,EAAAmgB,EAAQ/G,iBAAS,IAAApZ,OAAA,EAAAA,EAAE2Z,UAAS,CAC3C,MAAM8F,GAAaoB,EAAAA,EAAAA,IAAmBV,EAAQtH,cAAeisC,EAAAA,IAC7D,GAAIrlC,EACA,OAAOA,EAEXU,EAAUA,EAAQ/G,SACtB,CAEJ,CAOM,SAAU4O,EAAmBxvB,GAC/B,IAAIk+F,EAAqBl+F,EAazB,OAZIssD,EAAAA,GAAmB4xC,KAEf5xC,EAAAA,GAAa4xC,EAAUtuE,YAEvBsuE,EAAYA,EAAUtuE,WAAWA,WAC1B08B,EAAAA,GAAiB4xC,EAAUtuE,YAElCsuE,EAAYA,EAAUtuE,YAEtB/vB,EAAAA,EAAAA,GAAkBq+F,EAAUtuE,aAG7BuuE,EAA2Bn+F,EAAMk+F,EAAW,IAAIj9F,IAC3D,CAEA,SAASk9F,EAA2Bn+F,EAAwBk+F,EAAoBzhE,G,MAE5E,SAAS2hE,EAAGnsG,EAAeosG,GACvB,IAAIC,EAOJ,OANyBj2E,EAAAA,EAAAA,IAAmBp2B,EAAMq6D,EAAAA,MAG9CgyC,EAAkBH,EAA2BE,EAASA,EAAS5hE,IAEnEA,EAAMl7B,IAAIvB,EAAMs+F,GACTA,CACX,CAEA,GAAI7hE,EAAMpyB,IAAIrK,GACV,OAAOy8B,EAAMnjC,IAAI0G,GAErBy8B,EAAMl7B,IAAIvB,OAAMtN,GAChB,IAAK,MAAMT,KAAQupC,EAAAA,EAAAA,IAAkB0iE,GAAY,CAC7C,GAAI5xC,EAAAA,GAAiBr6D,IAAwC,SAA/BA,EAAKiuB,QAAQvkB,cAEvC,OADA8gC,EAAMl7B,IAAIvB,EAAM/N,GACTA,EACJ,GAAIq6D,EAAAA,GAAer6D,IAASq6D,EAAAA,GAAiBr6D,EAAKlC,KAAK48B,KAC1D,OAAOyxE,EAAGnsG,EAAMA,EAAKlC,KAAK48B,KACvB,GAAI2/B,EAAAA,GAAiBr6D,KAAqB,QAAZuV,EAAAvV,EAAKssG,eAAO,IAAA/2F,OAAA,EAAAA,EAAEmlB,KAC/C,OAAOyxE,EAAGnsG,EAAMA,EAAKssG,QAAQ5xE,IAErC,CAEJ,CA6CM,SAAU7G,EAAe/1B,GAC3B,OAAOyuG,EAAuBzuG,EAAM,IAAIka,IAC5C,CAEA,SAASu0F,EAAuBzuG,EAAsB0uG,GAClD,GAAIA,EAAQp0F,IAAIta,GACZ,OAAO,EAEP0uG,EAAQvqG,IAAInE,GAEhB,IAAK,MAAMkC,KAAQupC,EAAAA,EAAAA,IAAkBzrC,GACjC,GAAIu8D,EAAAA,GAAer6D,GAAO,CACtB,IAAKA,EAAKlC,KAAK48B,IAEX,OAAO,EAEX,GAAI2/B,EAAAA,GAAiBr6D,EAAKlC,KAAK48B,OAAS6xE,EAAuBvsG,EAAKlC,KAAK48B,IAAK8xE,GAC1E,OAAO,CAEf,KAAO,IAAInyC,EAAAA,GAAiBr6D,GACxB,OAAO,EACJ,GAAIq6D,EAAAA,GAAar6D,GACpB,OAAO,CACX,CAEJ,OAAOsoB,QAAQxqB,EAAK+S,WACxB,CAsCM,SAAUkjB,EAAoBj2B,GAChC,GAAIA,EAAK2uG,aACL,OAAO3uG,EAAK2uG,aAAaxuG,KACtB,GAAIH,EAAK4uG,SACZ,OAAO5uG,EAAK4uG,SACT,GAAI5uG,EAAK6uG,WAAY,CACxB,MAAMP,EAAUtuG,EAAK6uG,WAAWjyE,IAChC,GAAI0xE,EAAS,CAET,GAAI/xC,EAAAA,GAAiB+xC,GACjB,OAAOA,EAAQnuG,KACZ,GAAIo8D,EAAAA,GAAgB+xC,IAAY/xC,EAAAA,GAAW+xC,GAC9C,OAAOA,EAAQnuG,IAEvB,CACJ,CAEJ,CAEM,SAAUo8B,EAAYtsB,G,MACxB,GAAIssD,EAAAA,GAAiBtsD,GACjB,OAAO8lB,EAAe9lB,GAAQA,EAAK9P,KAAgC,QAAzBsX,EAAAwe,EAAoBhmB,UAAK,IAAAwH,EAAAA,EAAIxH,EAAK9P,KACzE,GAAIo8D,EAAAA,GAAgBtsD,IAASssD,EAAAA,GAAWtsD,IAASssD,EAAAA,GAAiBtsD,GACrE,OAAOA,EAAK9P,KACT,GAAIo8D,EAAAA,GAAatsD,GAAO,CAC3B,MAAMqsB,EAUR,SAAwBpE,G,MAC1B,GAAIA,EAAOy2E,aACP,OAAOz2E,EAAOy2E,aAAaxuG,KACxB,GAAe,QAAXsX,EAAAygB,EAAOjoB,YAAI,IAAAwH,OAAA,EAAAA,EAAEmlB,IACpB,OAAOL,EAAYrE,EAAOjoB,KAAK2sB,KAEnC,MACJ,CAjB2BkyE,CAAc7+F,GACjC,GAAIqsB,EACA,OAAOA,CAEf,MAAO,GAAIigC,EAAAA,GAAmBtsD,GAC1B,OAAOA,EAAK9P,KAEhB,MAAM,IAAI6E,MAAM,kCACpB,CAiCM,SAAU+pG,EAAY/uG,G,UACxB,OAAIu8D,EAAAA,GAAmBv8D,GACG,QAAfyxB,EAAS,QAATha,EAAAzX,EAAKiQ,YAAI,IAAAwH,OAAA,EAAAA,EAAEtX,YAAI,IAAAsxB,EAAAA,EAAI,SAEM,QAAzBue,EAAA/Z,EAAoBj2B,UAAK,IAAAgwC,EAAAA,EAAIhwC,EAAKG,IAEjD,CAEM,SAAUmoD,EAAc9oB,GAC1B,MAAMgsB,EAAe,CACjBlkD,GAAG,EACHzC,GAAG,EACHuD,GAAG,GAEDyF,EAASmhG,EAAuBxvE,EAAazsB,WAAYy4C,GACzDyjD,EAAWzrG,OAAOo1B,QAAQ4yB,GAAOl3C,OAAOglB,IAAA,IAAE,CAAEl2B,GAAMk2B,EAAA,OAAKl2B,IAAO0P,IAAI6mB,IAAA,IAAEx5B,GAAKw5B,EAAA,OAAKx5B,IAAM6H,KAAK,IAC/F,OAAO,IAAI26C,OAAO90C,EAAQohG,EAC9B,CAGA,MAAMC,EAAW,SAASrhG,OAQ1B,SAASmhG,EAAuBt9E,EAA8B85B,GAC1D,GAAI+Q,EAAAA,GAA2B7qC,GAC3B,OA2CGy9E,GAD0Bl7E,EA1CMvC,GA2CHnb,SAASzD,IAAIpN,GAAKspG,EAAuBtpG,IAAIsC,KAAK,KAAM,CACxF62B,YAAa5K,EAAa4K,YAC1BzjB,UAAW6Y,EAAa7Y,YA5CrB,GAAImhD,EAAAA,GAAoB7qC,GAC3B,OAgDGy9E,GADmBtxE,EA/CMnM,GAgDHnb,SAASzD,IAAIpN,GAAKspG,EAAuBtpG,IAAIsC,KAAK,IAAK,CAChF62B,YAAahB,EAAMgB,YACnBzjB,UAAWyiB,EAAMziB,YAjDd,GAAImhD,EAAAA,GAAqB7qC,GAC5B,OAkER,SAA+BhiB,GAC3B,GAAIA,EAAM6C,MACN,OAAO48F,EAAgB,IAADllG,OAAKmlG,EAAe1/F,EAAM4C,MAAK,KAAArI,OAAImlG,EAAe1/F,EAAM6C,OAAM,KAAK,CACrFssB,YAAanvB,EAAMmvB,YACnBzjB,UAAW1L,EAAM0L,UACjBkjB,MAAM,IAGd,OAAO6wE,EAAgBC,EAAe1/F,EAAM4C,MAAO,CAC/CusB,YAAanvB,EAAMmvB,YACnBzjB,UAAW1L,EAAM0L,UACjBkjB,MAAM,GAEd,CA/Ee+wE,CAAsB39E,GAC1B,GAAI6qC,EAAAA,GAAuB7qC,GAAU,CACxC,MAAM1xB,EAAO0xB,EAAQ1xB,KAAK48B,IAC1B,IAAK58B,EACD,MAAM,IAAIgF,MAAM,2BAEpB,OAAOmqG,EAAgBH,EAAuBhvG,EAAK+S,YAAa,CAC5D8rB,YAAanN,EAAQmN,YACrBzjB,UAAWsW,EAAQtW,WAE3B,CAAO,GAAImhD,EAAAA,GAAmB7qC,GAC1B,OAiDGy9E,EAAgB,MAADllG,OAAO+kG,GADLp0C,EAhDMlpC,GAiD6B+G,UAAS,KAAAxuB,OAAIilG,EAAQ,MAAM,CAClFrwE,YAAa+7B,EAAO/7B,YACpBzjB,UAAWw/C,EAAOx/C,YAlDf,GAAImhD,EAAAA,GAAiB7qC,GACxB,OAuCmB49E,EAvCM59E,EAwCtBy9E,EAAgB,GAADllG,OAAIilG,EAAQ,MAAAjlG,OAAK+kG,EAAuBM,EAAM72E,WAAa,CAC7EoG,YAAaywE,EAAMzwE,YACnBzjB,UAAWk0F,EAAMl0F,YAzCd,GAAImhD,EAAAA,GAAiB7qC,GAAU,CAClC,MAAM69E,EAAY79E,EAAQm4B,MAAMniD,YAAY,KACtCmG,EAAS6jB,EAAQm4B,MAAMvpD,UAAU,EAAGivG,GACpCC,EAAa99E,EAAQm4B,MAAMvpD,UAAUivG,EAAY,GAMvD,OALI/jD,IACAA,EAAM3mD,EAAI2qG,EAAW58D,SAAS,KAC9B4Y,EAAMlkD,EAAIkoG,EAAW58D,SAAS,KAC9B4Y,EAAMpjD,EAAIonG,EAAW58D,SAAS,MAE3Bu8D,EAAgBthG,EAAQ,CAC3BgxB,YAAanN,EAAQmN,YACrBzjB,UAAWsW,EAAQtW,UACnBkjB,MAAM,GAEd,CAAO,GAAIi+B,EAAAA,GAAe7qC,GACtB,OAAOy9E,EAAgBD,EAAU,CAC7BrwE,YAAanN,EAAQmN,YACrBzjB,UAAWsW,EAAQtW,YAGvB,MAAM,IAAIpW,MAAM,6BAADiF,OAAqC,OAAPynB,QAAO,IAAPA,OAAO,EAAPA,EAAShxB,QAkB9D,IAA2B4uG,EAOC10C,EAdE/8B,EAPO5J,CAFrC,CA6CA,SAASm7E,EAAejzE,GACpB,OAAOumB,EAAAA,EAAAA,IAAavmB,EAAQ/4B,MAChC,CAEA,SAAS+rG,EAAgBtlD,EAAetyC,G,MAQpC,QAHqB,IAAjBA,EAAQ+mB,MAAkB/mB,EAAQ6D,aAClCyuC,EAAQ,IAAH5/C,OAAwB,QAAjBwN,EAAAF,EAAQ6D,iBAAS,IAAA3D,EAAAA,EAAI,IAAExN,OAAG4/C,EAAK,MAE3CtyC,EAAQsnB,YACD,GAAP50B,OAAU4/C,GAAK5/C,OAAGsN,EAAQsnB,aAEvBgrB,CACX,C,mHCvgBI4lD,EAAU,CAAC,EACXC,EAAe,CACjB56D,MAAsBp1C,EAAAA,EAAAA,IAAO6gC,UAC3B,MAAQsyB,mBAAoB88C,SAA8B,+BACpDttG,EAASstG,IAAsB78C,KAAKzwD,OAAO2yB,cACjDy6E,EAAQ36D,KAAOzyC,GACd,QACHutG,QAAwBlwG,EAAAA,EAAAA,IAAO6gC,UAC7B,MAAQulE,qBAAsB+J,SAAgC,gCACxDxtG,EAASwtG,IAAwB9J,OAAO1jG,OAAO2yB,cACrDy6E,EAAQG,OAASvtG,GAChB,UACHytG,KAAqBpwG,EAAAA,EAAAA,IAAO6gC,UAC1B,MAAQ2+D,kBAAmB6Q,SAA6B,gCAClD1tG,EAAS0tG,IAAqB5Q,IAAI98F,OAAO2yB,cAC/Cy6E,EAAQK,IAAMztG,GACb,OACH2tG,cAA8BtwG,EAAAA,EAAAA,IAAO6gC,UACnC,MAAQ0vE,2BAA4BC,SAAsC,gCACpE7tG,EAAS6tG,IAA8BvI,aAAatlG,OAAO2yB,cACjEy6E,EAAQO,aAAe3tG,GACtB,gBACH8tG,UAA0BzwG,EAAAA,EAAAA,IAAO6gC,UAC/B,MAAQ0mE,uBAAwBmJ,SAAkC,gCAC5D/tG,EAAS+tG,IAA0BlJ,SAAS7kG,OAAO2yB,cACzDy6E,EAAQU,SAAW9tG,GAClB,YACHguG,OAAuB3wG,EAAAA,EAAAA,IAAO6gC,UAC5B,MAAQhyB,oBAAqB+hG,SAA+B,gCACtDjuG,EAASiuG,IAAuB9hG,MAAMnM,OAAO2yB,cACnDy6E,EAAQY,MAAQhuG,GACf,SACHkuG,SAAyB7wG,EAAAA,EAAAA,IAAO6gC,UAC9B,MAAQ/9B,sBAAuBguG,SAAiC,gCAC1DnuG,EAASmuG,IAAyBnvG,QAAQgB,OAAO2yB,cACvDy6E,EAAQc,QAAUluG,GACjB,YAELk+B,eAAev3B,EAAMynG,EAAa1oF,GAChC,MAAMwsD,EAAcm7B,EAAae,GACjC,IAAKl8B,EACH,MAAM,IAAIvvE,MAAM,yBAADiF,OAA0BwmG,IAEtChB,EAAQgB,UACLl8B,IAER,MACMjuE,EADSmpG,EAAQgB,GACDznG,MAAM+e,GAC5B,GAAIzhB,EAAO+vB,YAAY91B,OAAS,GAAK+F,EAAOmwB,aAAal2B,OAAS,EAChE,MAAM,IAAImwG,EAAkBpqG,GAE9B,OAAOA,EAAOlD,KAChB,EACA1D,EAAAA,EAAAA,IAAOsJ,EAAO,SACd,IAAI0nG,GAAiBpxG,EAAG,cAAc0F,MACpCxF,WAAAA,CAAY8G,GACV,MAAM+vB,EAAc/vB,EAAO+vB,YAAYvjB,IAAK8jB,GAAQA,EAAInnB,SAASzH,KAAK,MAChEyuB,EAAenwB,EAAOmwB,aAAa3jB,IAAK8jB,GAAQA,EAAInnB,SAASzH,KAAK,MACxEvI,MAAM,mBAADwK,OAAoBosB,EAAW,KAAApsB,OAAIwsB,IACxCnyB,KAAKgC,OAASA,CAChB,IAEE5G,EAAAA,EAAAA,IAAMJ,EAAO,qBAAoBA,E,kDCpGrC,QAnBA,SAAsBqH,EAAOiG,EAAUiuD,GAIrC,IAHA,IAAIhuD,GAAS,EACTtM,EAASoG,EAAMpG,SAEVsM,EAAQtM,GAAQ,CACvB,IAAI6C,EAAQuD,EAAMkG,GACd2Q,EAAU5Q,EAASxJ,GAEvB,GAAe,MAAXoa,SAAiC7a,IAAb04D,EACf79C,IAAYA,KAAY0uC,EAAAA,EAAAA,GAAS1uC,GAClCq9C,EAAWr9C,EAAS69C,IAE1B,IAAIA,EAAW79C,EACXlX,EAASlD,CAEjB,CACA,OAAOkD,CACT,C,uFCZIqqG,GAAwBrxG,EAAG,cAAcC,EAAAA,GAI3CC,WAAAA,GACEC,MAAM,CAAC,gBACT,IAJEC,EAAAA,EAAAA,IAAMJ,EAAO,4BAA2BA,GAQxCsxG,GAA0B/wG,EAAG,cAAcC,EAAAA,GAI7CC,kBAAAA,CAAmBC,EAAMC,EAAOC,GAC9B,MAAkB,cAAdF,EAAKG,KACAF,EAAMI,QAAQ,QAAS,IAAI2iD,OACX,mBAAdhjD,EAAKG,KACPF,EAAMI,QAAQ,SAAU,IACR,eAAdL,EAAKG,KACPF,EAAMI,QAAQ,SAAU,IAAI2iD,YAD9B,CAIT,IAXEtjD,EAAAA,EAAAA,IAAMG,EAAO,8BAA6BA,GAe1CgxG,EAAqB,CACvBxuG,OAAQ,CACNC,cAA8B5C,EAAAA,EAAAA,IAAO,IAAM,IAAIixG,EAA4B,gBAC3EpuG,gBAAgC7C,EAAAA,EAAAA,IAAO,IAAM,IAAIkxG,EAA8B,oBAGnF,SAASX,IAAsD,IAA3BxtG,EAAOC,UAAAnC,OAAA,QAAAoC,IAAAD,UAAA,GAAAA,UAAA,GAAGE,EAAAA,EAC5C,MAAMC,GAASC,EAAAA,EAAAA,KACbC,EAAAA,EAAAA,GAA8BN,GAC9BO,EAAAA,IAEI2kG,GAAe7kG,EAAAA,EAAAA,KACnBG,EAAAA,EAAAA,GAAwB,CAAEJ,WAC1BwnG,EAAAA,GACAwG,GAGF,OADAhuG,EAAOM,gBAAgB3B,SAASmmG,GACzB,CAAE9kG,SAAQ8kG,eACnB,EACAjoG,EAAAA,EAAAA,IAAOuwG,EAA4B,6B,uCCNlB1tG,E,sBAlCX,MAAOqmD,EAETrxB,OAAAA,CAAQt3B,EAAe23B,GACnB,IAAIzH,EAAuCyH,EAAQtH,cAInD,IAHIkI,EAAAA,EAAAA,IAAiBrI,KACjBA,GAAUw9E,EAAAA,EAAAA,IAA0Bx9E,KAEpCuM,EAAAA,EAAAA,IAAWvM,GAAU,CACrB,MAAMnwB,EAAOmwB,EAAQnwB,KAAK48B,IAC1B,IAAK58B,EACD,MAAM,IAAIgF,MAAM,2CAEpB,OAAOV,KAAKomG,aAAa1qG,EAAMC,EAAO23B,EAC1C,CACA,OAAO33B,CACX,CAGUyqG,YAAAA,CAAa1qG,EAAoBC,EAAe23B,G,MACtD,OAAQ53B,EAAKG,KAAK6qD,eACd,IAAK,MAAO,OAAOzoD,EAAeuuG,WAAW7wG,GAC7C,IAAK,SAAU,OAAOsC,EAAewuG,cAAc9wG,GACnD,IAAK,KAAM,OAAOsC,EAAeyuG,UAAU/wG,GAE/C,OAAyB,QAAjBwX,GAAAs3F,EAAAA,EAAAA,IAAY/uG,UAAK,IAAAyX,OAAA,EAAAA,EAAE7L,eACvB,IAAK,SAAU,OAAOrJ,EAAe0uG,cAAchxG,GACnD,IAAK,UAAW,OAAOsC,EAAe2uG,eAAejxG,GACrD,IAAK,SAAU,OAAOsC,EAAe4uG,cAAclxG,GACnD,IAAK,OAAQ,OAAOsC,EAAe6uG,YAAYnxG,GAC/C,QAAS,OAAOA,EAExB,GAGJ,SAAiBsC,GAgBb,SAAS8uG,EAAuBvvE,GAC5B,OAAQA,GACJ,IAAK,IAAK,MAAO,KACjB,IAAK,IAAK,MAAO,KACjB,IAAK,IAAK,MAAO,KACjB,IAAK,IAAK,MAAO,KACjB,IAAK,IAAK,MAAO,KACjB,IAAK,IAAK,MAAO,KACjB,IAAK,IAAK,MAAO,KACjB,QAAS,OAAOA,EAExB,CAzBgBv/B,EAAAwuG,cAAhB,SAA8B9wG,GAC1B,IAAIqG,EAAS,GACb,IAAK,IAAIzB,EAAI,EAAGA,EAAI5E,EAAMM,OAAS,EAAGsE,IAAK,CACvC,MAAMqD,EAAIjI,EAAMwL,OAAO5G,GACvB,GAAU,OAANqD,EAAY,CAEZ5B,GAAU+qG,EADCpxG,EAAMwL,SAAS5G,GAE9B,MACIyB,GAAU4B,CAElB,CACA,OAAO5B,CACX,EAegB/D,EAAAyuG,UAAhB,SAA0B/wG,GACtB,MAAwB,MAApBA,EAAMwL,OAAO,GACNxL,EAAMK,UAAU,GAEhBL,CAEf,EAEgBsC,EAAAuuG,WAAhB,SAA2B7wG,GACvB,OAAOgC,SAAShC,EACpB,EAEgBsC,EAAA4uG,cAAhB,SAA8BlxG,GAC1B,OAAOqxG,OAAOrxG,EAClB,EAEgBsC,EAAA6uG,YAAhB,SAA4BnxG,GACxB,OAAO,IAAI8nE,KAAK9nE,EACpB,EAEgBsC,EAAA0uG,cAAhB,SAA8BhxG,GAC1B,OAAOujB,OAAOvjB,EAClB,EAEgBsC,EAAA2uG,eAAhB,SAA+BjxG,GAC3B,MAA+B,SAAxBA,EAAM2L,aACjB,CAEH,CAzDD,CAAiBrJ,IAAAA,EAAc,I","sources":["../node_modules/.pnpm/@mermaid-js+parser@0.6.2/node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-XRWGC2XP.mjs","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isString.js","../node_modules/.pnpm/vscode-jsonrpc@8.2.0/node_modules/vscode-jsonrpc/lib/common/events.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/min.js","../LIB/node_modules/path-browserify/index.js","../LIB/webpack/bootstrap","../LIB/webpack/runtime/define property getters","../LIB/webpack/runtime/hasOwnProperty shorthand","../LIB/webpack/runtime/make namespace object","../LIB/src/platform.ts","../LIB/src/uri.ts","../LIB/src/utils.ts","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseMap.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseHas.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/has.js","../node_modules/.pnpm/vscode-jsonrpc@8.2.0/node_modules/vscode-jsonrpc/lib/common/ral.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/defaults.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/flatten.js","../node_modules/.pnpm/@mermaid-js+parser@0.6.2/node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-WFRQ32O7.mjs","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseSet.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_basePickBy.js","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/errors.ts","../node_modules/.pnpm/chevrotain-allstar@0.3.1_chevrotain@11.0.3/node_modules/chevrotain-allstar/src/atn.ts","../node_modules/.pnpm/chevrotain-allstar@0.3.1_chevrotain@11.0.3/node_modules/chevrotain-allstar/src/dfa.ts","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/uniqBy.js","../node_modules/.pnpm/chevrotain-allstar@0.3.1_chevrotain@11.0.3/node_modules/chevrotain-allstar/src/all-star-lookahead.ts","../node_modules/.pnpm/vscode-languageserver-types@3.17.5/node_modules/vscode-languageserver-types/lib/esm/main.js","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/cst-node-builder.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/langium-parser.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/parser-builder-base.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/langium-parser-builder.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/promise-utils.ts","../node_modules/.pnpm/vscode-languageserver-textdocument@1.0.12/node_modules/vscode-languageserver-textdocument/lib/esm/main.js","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/documents.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/references/linker.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/references/name-provider.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/uri-utils.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/references/references.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/collections.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/references/scope-computation.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/references/scope.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/caching.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/references/scope-provider.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/serializer/json-serializer.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/service-registry.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/validation/validation-registry.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/validation/document-validator.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/ast-descriptions.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/ast-node-locator.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/disposable.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/configuration.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/document-builder.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/index-manager.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/workspace-manager.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/lexer.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/documentation/jsdoc.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/documentation/documentation-provider.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/documentation/comment-provider.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/async-parser.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/workspace-lock.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/serializer/hydrator.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/default-module.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/languages/grammar-config.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/completion-parser-builder.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/regexp-utils.ts","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/clone.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_trimmedEndIndex.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseTrim.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/toNumber.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/toFinite.js","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/languages/generated/ast.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/dependency-injection.ts","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/last.js","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/syntax-tree.ts","../node_modules/.pnpm/@mermaid-js+parser@0.6.2/node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-T44TD3VJ.mjs","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/ast-utils.ts","../node_modules/.pnpm/@chevrotain+utils@11.0.3/node_modules/@chevrotain/utils/src/to-fast-properties.ts","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseSlice.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/drop.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/assign.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/pickBy.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseIsRegExp.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/isRegExp.js","../node_modules/.pnpm/@chevrotain+gast@11.0.3/node_modules/@chevrotain/gast/src/model.ts","../node_modules/.pnpm/@chevrotain+gast@11.0.3/node_modules/@chevrotain/gast/src/visitor.ts","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseSome.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/some.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/includes.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_arrayEvery.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseEvery.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/every.js","../node_modules/.pnpm/@chevrotain+gast@11.0.3/node_modules/@chevrotain/gast/src/helpers.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/rest.ts","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/uniq.js","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/first.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/constants.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/follow.ts","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/negate.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/reject.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/indexOf.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseDifference.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/difference.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/compact.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/head.js","../node_modules/.pnpm/@chevrotain+utils@11.0.3/node_modules/@chevrotain/utils/src/print.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/scan/reg_exp_parser.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/scan/reg_exp.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/scan/lexer.ts","../node_modules/.pnpm/@chevrotain+utils@11.0.3/node_modules/@chevrotain/utils/src/timer.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/scan/tokens.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/scan/lexer_errors_public.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/scan/lexer_public.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/scan/tokens_public.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/errors_public.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/resolver.ts","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_arrayAggregator.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseAggregator.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_createAggregator.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/groupBy.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/dropRight.js","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/interpreter.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/lookahead.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/checks.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/gast/gast_resolver_public.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/exceptions_public.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/recoverable.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/keys.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/grammar/llk_lookahead.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/looksahead.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/cst/cst.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/lang/lang_extensions.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/cst/cst_visitor.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/gast_recorder.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/parser.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/utils/apply_mixins.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/tree_builder.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/lexer_adapter.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/recognizer_engine.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/recognizer_api.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/error_handler.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/context_assist.ts","../node_modules/.pnpm/chevrotain@11.0.3/node_modules/chevrotain/src/parse/parser/traits/perf_tracer.ts","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseLt.js","../node_modules/.pnpm/@mermaid-js+parser@0.6.2/node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-WFWHJNB7.mjs","../node_modules/.pnpm/@chevrotain+regexp-to-ast@11.0.3/node_modules/@chevrotain/regexp-to-ast/src/utils.ts","../node_modules/.pnpm/@chevrotain+regexp-to-ast@11.0.3/node_modules/@chevrotain/regexp-to-ast/src/character-classes.ts","../node_modules/.pnpm/@chevrotain+regexp-to-ast@11.0.3/node_modules/@chevrotain/regexp-to-ast/src/regexp-parser.ts","../node_modules/.pnpm/@chevrotain+regexp-to-ast@11.0.3/node_modules/@chevrotain/regexp-to-ast/src/base-regexp-visitor.ts","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/cst-utils.ts","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/toInteger.js","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/token-builder.ts","../node_modules/.pnpm/@mermaid-js+parser@0.6.2/node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-KMC2YHZD.mjs","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_createFind.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/findIndex.js","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/find.js","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/workspace/file-system-provider.ts","../node_modules/.pnpm/vscode-jsonrpc@8.2.0/node_modules/vscode-jsonrpc/lib/common/is.js","../node_modules/.pnpm/vscode-jsonrpc@8.2.0/node_modules/vscode-jsonrpc/lib/common/cancellation.js","../node_modules/.pnpm/@mermaid-js+parser@0.6.2/node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-BN7GFLIU.mjs","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/grammar-loader.ts","../node_modules/.pnpm/@mermaid-js+parser@0.6.2/node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-4KMFLZZN.mjs","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/map.js","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/stream.ts","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/flatMap.js","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/utils/grammar-utils.ts","../node_modules/.pnpm/@mermaid-js+parser@0.6.2/node_modules/@mermaid-js/parser/dist/mermaid-parser.core.mjs","../node_modules/.pnpm/lodash-es@4.17.21/node_modules/lodash-es/_baseExtremum.js","../node_modules/.pnpm/@mermaid-js+parser@0.6.2/node_modules/@mermaid-js/parser/dist/chunks/mermaid-parser.core/chunk-JEIROHC2.mjs","../node_modules/.pnpm/langium@3.3.1/node_modules/langium/src/parser/value-converter.ts"],"sourcesContent":["import {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  MermaidGeneratedSharedModule,\n  TreemapGeneratedModule,\n  __name\n} from \"./chunk-4KMFLZZN.mjs\";\n\n// src/language/treemap/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/treemap/tokenBuilder.ts\nvar TreemapTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"TreemapTokenBuilder\");\n  }\n  constructor() {\n    super([\"treemap\"]);\n  }\n};\n\n// src/language/treemap/valueConverter.ts\nvar classDefRegex = /classDef\\s+([A-Z_a-z]\\w+)(?:\\s+([^\\n\\r;]*))?;?/;\nvar TreemapValueConverter = class extends AbstractMermaidValueConverter {\n  static {\n    __name(this, \"TreemapValueConverter\");\n  }\n  runCustomConverter(rule, input, _cstNode) {\n    if (rule.name === \"NUMBER2\") {\n      return parseFloat(input.replace(/,/g, \"\"));\n    } else if (rule.name === \"SEPARATOR\") {\n      return input.substring(1, input.length - 1);\n    } else if (rule.name === \"STRING2\") {\n      return input.substring(1, input.length - 1);\n    } else if (rule.name === \"INDENTATION\") {\n      return input.length;\n    } else if (rule.name === \"ClassDef\") {\n      if (typeof input !== \"string\") {\n        return input;\n      }\n      const match = classDefRegex.exec(input);\n      if (match) {\n        return {\n          $type: \"ClassDefStatement\",\n          className: match[1],\n          styleText: match[2] || void 0\n        };\n      }\n    }\n    return void 0;\n  }\n};\n\n// src/language/treemap/treemap-validator.ts\nfunction registerValidationChecks(services) {\n  const validator = services.validation.TreemapValidator;\n  const registry = services.validation.ValidationRegistry;\n  if (registry) {\n    const checks = {\n      Treemap: validator.checkSingleRoot.bind(validator)\n      // Remove unused validation for TreemapRow\n    };\n    registry.register(checks, validator);\n  }\n}\n__name(registerValidationChecks, \"registerValidationChecks\");\nvar TreemapValidator = class {\n  static {\n    __name(this, \"TreemapValidator\");\n  }\n  /**\n   * Validates that a treemap has only one root node.\n   * A root node is defined as a node that has no indentation.\n   */\n  checkSingleRoot(doc, accept) {\n    let rootNodeIndentation;\n    for (const row of doc.TreemapRows) {\n      if (!row.item) {\n        continue;\n      }\n      if (rootNodeIndentation === void 0 && // Check if this is a root node (no indentation)\n      row.indent === void 0) {\n        rootNodeIndentation = 0;\n      } else if (row.indent === void 0) {\n        accept(\"error\", \"Multiple root nodes are not allowed in a treemap.\", {\n          node: row,\n          property: \"item\"\n        });\n      } else if (rootNodeIndentation !== void 0 && rootNodeIndentation >= parseInt(row.indent, 10)) {\n        accept(\"error\", \"Multiple root nodes are not allowed in a treemap.\", {\n          node: row,\n          property: \"item\"\n        });\n      }\n    }\n  }\n};\n\n// src/language/treemap/module.ts\nvar TreemapModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new TreemapTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new TreemapValueConverter(), \"ValueConverter\")\n  },\n  validation: {\n    TreemapValidator: /* @__PURE__ */ __name(() => new TreemapValidator(), \"TreemapValidator\")\n  }\n};\nfunction createTreemapServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Treemap = inject(\n    createDefaultCoreModule({ shared }),\n    TreemapGeneratedModule,\n    TreemapModule\n  );\n  shared.ServiceRegistry.register(Treemap);\n  registerValidationChecks(Treemap);\n  return { shared, Treemap };\n}\n__name(createTreemapServices, \"createTreemapServices\");\n\nexport {\n  TreemapModule,\n  createTreemapServices\n};\n","import baseGetTag from './_baseGetTag.js';\nimport isArray from './isArray.js';\nimport isObjectLike from './isObjectLike.js';\n\n/** `Object#toString` result references. */\nvar stringTag = '[object String]';\n\n/**\n * Checks if `value` is classified as a `String` primitive or object.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a string, else `false`.\n * @example\n *\n * _.isString('abc');\n * // => true\n *\n * _.isString(1);\n * // => false\n */\nfunction isString(value) {\n  return typeof value == 'string' ||\n    (!isArray(value) && isObjectLike(value) && baseGetTag(value) == stringTag);\n}\n\nexport default isString;\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Emitter = exports.Event = void 0;\nconst ral_1 = require(\"./ral\");\nvar Event;\n(function (Event) {\n    const _disposable = { dispose() { } };\n    Event.None = function () { return _disposable; };\n})(Event || (exports.Event = Event = {}));\nclass CallbackList {\n    add(callback, context = null, bucket) {\n        if (!this._callbacks) {\n            this._callbacks = [];\n            this._contexts = [];\n        }\n        this._callbacks.push(callback);\n        this._contexts.push(context);\n        if (Array.isArray(bucket)) {\n            bucket.push({ dispose: () => this.remove(callback, context) });\n        }\n    }\n    remove(callback, context = null) {\n        if (!this._callbacks) {\n            return;\n        }\n        let foundCallbackWithDifferentContext = false;\n        for (let i = 0, len = this._callbacks.length; i < len; i++) {\n            if (this._callbacks[i] === callback) {\n                if (this._contexts[i] === context) {\n                    // callback & context match => remove it\n                    this._callbacks.splice(i, 1);\n                    this._contexts.splice(i, 1);\n                    return;\n                }\n                else {\n                    foundCallbackWithDifferentContext = true;\n                }\n            }\n        }\n        if (foundCallbackWithDifferentContext) {\n            throw new Error('When adding a listener with a context, you should remove it with the same context');\n        }\n    }\n    invoke(...args) {\n        if (!this._callbacks) {\n            return [];\n        }\n        const ret = [], callbacks = this._callbacks.slice(0), contexts = this._contexts.slice(0);\n        for (let i = 0, len = callbacks.length; i < len; i++) {\n            try {\n                ret.push(callbacks[i].apply(contexts[i], args));\n            }\n            catch (e) {\n                // eslint-disable-next-line no-console\n                (0, ral_1.default)().console.error(e);\n            }\n        }\n        return ret;\n    }\n    isEmpty() {\n        return !this._callbacks || this._callbacks.length === 0;\n    }\n    dispose() {\n        this._callbacks = undefined;\n        this._contexts = undefined;\n    }\n}\nclass Emitter {\n    constructor(_options) {\n        this._options = _options;\n    }\n    /**\n     * For the public to allow to subscribe\n     * to events from this Emitter\n     */\n    get event() {\n        if (!this._event) {\n            this._event = (listener, thisArgs, disposables) => {\n                if (!this._callbacks) {\n                    this._callbacks = new CallbackList();\n                }\n                if (this._options && this._options.onFirstListenerAdd && this._callbacks.isEmpty()) {\n                    this._options.onFirstListenerAdd(this);\n                }\n                this._callbacks.add(listener, thisArgs);\n                const result = {\n                    dispose: () => {\n                        if (!this._callbacks) {\n                            // disposable is disposed after emitter is disposed.\n                            return;\n                        }\n                        this._callbacks.remove(listener, thisArgs);\n                        result.dispose = Emitter._noop;\n                        if (this._options && this._options.onLastListenerRemove && this._callbacks.isEmpty()) {\n                            this._options.onLastListenerRemove(this);\n                        }\n                    }\n                };\n                if (Array.isArray(disposables)) {\n                    disposables.push(result);\n                }\n                return result;\n            };\n        }\n        return this._event;\n    }\n    /**\n     * To be kept private to fire an event to\n     * subscribers\n     */\n    fire(event) {\n        if (this._callbacks) {\n            this._callbacks.invoke.call(this._callbacks, event);\n        }\n    }\n    dispose() {\n        if (this._callbacks) {\n            this._callbacks.dispose();\n            this._callbacks = undefined;\n        }\n    }\n}\nexports.Emitter = Emitter;\nEmitter._noop = function () { };\n","import baseExtremum from './_baseExtremum.js';\nimport baseLt from './_baseLt.js';\nimport identity from './identity.js';\n\n/**\n * Computes the minimum value of `array`. If `array` is empty or falsey,\n * `undefined` is returned.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Math\n * @param {Array} array The array to iterate over.\n * @returns {*} Returns the minimum value.\n * @example\n *\n * _.min([4, 2, 8, 6]);\n * // => 2\n *\n * _.min([]);\n * // => undefined\n */\nfunction min(array) {\n  return (array && array.length)\n    ? baseExtremum(array, identity, baseLt)\n    : undefined;\n}\n\nexport default min;\n","// 'path' module extracted from Node.js v8.11.1 (only the posix part)\n// transplited with Babel\n\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\nfunction assertPath(path) {\n  if (typeof path !== 'string') {\n    throw new TypeError('Path must be a string. Received ' + JSON.stringify(path));\n  }\n}\n\n// Resolves . and .. elements in a path with directory names\nfunction normalizeStringPosix(path, allowAboveRoot) {\n  var res = '';\n  var lastSegmentLength = 0;\n  var lastSlash = -1;\n  var dots = 0;\n  var code;\n  for (var i = 0; i <= path.length; ++i) {\n    if (i < path.length)\n      code = path.charCodeAt(i);\n    else if (code === 47 /*/*/)\n      break;\n    else\n      code = 47 /*/*/;\n    if (code === 47 /*/*/) {\n      if (lastSlash === i - 1 || dots === 1) {\n        // NOOP\n      } else if (lastSlash !== i - 1 && dots === 2) {\n        if (res.length < 2 || lastSegmentLength !== 2 || res.charCodeAt(res.length - 1) !== 46 /*.*/ || res.charCodeAt(res.length - 2) !== 46 /*.*/) {\n          if (res.length > 2) {\n            var lastSlashIndex = res.lastIndexOf('/');\n            if (lastSlashIndex !== res.length - 1) {\n              if (lastSlashIndex === -1) {\n                res = '';\n                lastSegmentLength = 0;\n              } else {\n                res = res.slice(0, lastSlashIndex);\n                lastSegmentLength = res.length - 1 - res.lastIndexOf('/');\n              }\n              lastSlash = i;\n              dots = 0;\n              continue;\n            }\n          } else if (res.length === 2 || res.length === 1) {\n            res = '';\n            lastSegmentLength = 0;\n            lastSlash = i;\n            dots = 0;\n            continue;\n          }\n        }\n        if (allowAboveRoot) {\n          if (res.length > 0)\n            res += '/..';\n          else\n            res = '..';\n          lastSegmentLength = 2;\n        }\n      } else {\n        if (res.length > 0)\n          res += '/' + path.slice(lastSlash + 1, i);\n        else\n          res = path.slice(lastSlash + 1, i);\n        lastSegmentLength = i - lastSlash - 1;\n      }\n      lastSlash = i;\n      dots = 0;\n    } else if (code === 46 /*.*/ && dots !== -1) {\n      ++dots;\n    } else {\n      dots = -1;\n    }\n  }\n  return res;\n}\n\nfunction _format(sep, pathObject) {\n  var dir = pathObject.dir || pathObject.root;\n  var base = pathObject.base || (pathObject.name || '') + (pathObject.ext || '');\n  if (!dir) {\n    return base;\n  }\n  if (dir === pathObject.root) {\n    return dir + base;\n  }\n  return dir + sep + base;\n}\n\nvar posix = {\n  // path.resolve([from ...], to)\n  resolve: function resolve() {\n    var resolvedPath = '';\n    var resolvedAbsolute = false;\n    var cwd;\n\n    for (var i = arguments.length - 1; i >= -1 && !resolvedAbsolute; i--) {\n      var path;\n      if (i >= 0)\n        path = arguments[i];\n      else {\n        if (cwd === undefined)\n          cwd = process.cwd();\n        path = cwd;\n      }\n\n      assertPath(path);\n\n      // Skip empty entries\n      if (path.length === 0) {\n        continue;\n      }\n\n      resolvedPath = path + '/' + resolvedPath;\n      resolvedAbsolute = path.charCodeAt(0) === 47 /*/*/;\n    }\n\n    // At this point the path should be resolved to a full absolute path, but\n    // handle relative paths to be safe (might happen when process.cwd() fails)\n\n    // Normalize the path\n    resolvedPath = normalizeStringPosix(resolvedPath, !resolvedAbsolute);\n\n    if (resolvedAbsolute) {\n      if (resolvedPath.length > 0)\n        return '/' + resolvedPath;\n      else\n        return '/';\n    } else if (resolvedPath.length > 0) {\n      return resolvedPath;\n    } else {\n      return '.';\n    }\n  },\n\n  normalize: function normalize(path) {\n    assertPath(path);\n\n    if (path.length === 0) return '.';\n\n    var isAbsolute = path.charCodeAt(0) === 47 /*/*/;\n    var trailingSeparator = path.charCodeAt(path.length - 1) === 47 /*/*/;\n\n    // Normalize the path\n    path = normalizeStringPosix(path, !isAbsolute);\n\n    if (path.length === 0 && !isAbsolute) path = '.';\n    if (path.length > 0 && trailingSeparator) path += '/';\n\n    if (isAbsolute) return '/' + path;\n    return path;\n  },\n\n  isAbsolute: function isAbsolute(path) {\n    assertPath(path);\n    return path.length > 0 && path.charCodeAt(0) === 47 /*/*/;\n  },\n\n  join: function join() {\n    if (arguments.length === 0)\n      return '.';\n    var joined;\n    for (var i = 0; i < arguments.length; ++i) {\n      var arg = arguments[i];\n      assertPath(arg);\n      if (arg.length > 0) {\n        if (joined === undefined)\n          joined = arg;\n        else\n          joined += '/' + arg;\n      }\n    }\n    if (joined === undefined)\n      return '.';\n    return posix.normalize(joined);\n  },\n\n  relative: function relative(from, to) {\n    assertPath(from);\n    assertPath(to);\n\n    if (from === to) return '';\n\n    from = posix.resolve(from);\n    to = posix.resolve(to);\n\n    if (from === to) return '';\n\n    // Trim any leading backslashes\n    var fromStart = 1;\n    for (; fromStart < from.length; ++fromStart) {\n      if (from.charCodeAt(fromStart) !== 47 /*/*/)\n        break;\n    }\n    var fromEnd = from.length;\n    var fromLen = fromEnd - fromStart;\n\n    // Trim any leading backslashes\n    var toStart = 1;\n    for (; toStart < to.length; ++toStart) {\n      if (to.charCodeAt(toStart) !== 47 /*/*/)\n        break;\n    }\n    var toEnd = to.length;\n    var toLen = toEnd - toStart;\n\n    // Compare paths to find the longest common path from root\n    var length = fromLen < toLen ? fromLen : toLen;\n    var lastCommonSep = -1;\n    var i = 0;\n    for (; i <= length; ++i) {\n      if (i === length) {\n        if (toLen > length) {\n          if (to.charCodeAt(toStart + i) === 47 /*/*/) {\n            // We get here if `from` is the exact base path for `to`.\n            // For example: from='/foo/bar'; to='/foo/bar/baz'\n            return to.slice(toStart + i + 1);\n          } else if (i === 0) {\n            // We get here if `from` is the root\n            // For example: from='/'; to='/foo'\n            return to.slice(toStart + i);\n          }\n        } else if (fromLen > length) {\n          if (from.charCodeAt(fromStart + i) === 47 /*/*/) {\n            // We get here if `to` is the exact base path for `from`.\n            // For example: from='/foo/bar/baz'; to='/foo/bar'\n            lastCommonSep = i;\n          } else if (i === 0) {\n            // We get here if `to` is the root.\n            // For example: from='/foo'; to='/'\n            lastCommonSep = 0;\n          }\n        }\n        break;\n      }\n      var fromCode = from.charCodeAt(fromStart + i);\n      var toCode = to.charCodeAt(toStart + i);\n      if (fromCode !== toCode)\n        break;\n      else if (fromCode === 47 /*/*/)\n        lastCommonSep = i;\n    }\n\n    var out = '';\n    // Generate the relative path based on the path difference between `to`\n    // and `from`\n    for (i = fromStart + lastCommonSep + 1; i <= fromEnd; ++i) {\n      if (i === fromEnd || from.charCodeAt(i) === 47 /*/*/) {\n        if (out.length === 0)\n          out += '..';\n        else\n          out += '/..';\n      }\n    }\n\n    // Lastly, append the rest of the destination (`to`) path that comes after\n    // the common path parts\n    if (out.length > 0)\n      return out + to.slice(toStart + lastCommonSep);\n    else {\n      toStart += lastCommonSep;\n      if (to.charCodeAt(toStart) === 47 /*/*/)\n        ++toStart;\n      return to.slice(toStart);\n    }\n  },\n\n  _makeLong: function _makeLong(path) {\n    return path;\n  },\n\n  dirname: function dirname(path) {\n    assertPath(path);\n    if (path.length === 0) return '.';\n    var code = path.charCodeAt(0);\n    var hasRoot = code === 47 /*/*/;\n    var end = -1;\n    var matchedSlash = true;\n    for (var i = path.length - 1; i >= 1; --i) {\n      code = path.charCodeAt(i);\n      if (code === 47 /*/*/) {\n          if (!matchedSlash) {\n            end = i;\n            break;\n          }\n        } else {\n        // We saw the first non-path separator\n        matchedSlash = false;\n      }\n    }\n\n    if (end === -1) return hasRoot ? '/' : '.';\n    if (hasRoot && end === 1) return '//';\n    return path.slice(0, end);\n  },\n\n  basename: function basename(path, ext) {\n    if (ext !== undefined && typeof ext !== 'string') throw new TypeError('\"ext\" argument must be a string');\n    assertPath(path);\n\n    var start = 0;\n    var end = -1;\n    var matchedSlash = true;\n    var i;\n\n    if (ext !== undefined && ext.length > 0 && ext.length <= path.length) {\n      if (ext.length === path.length && ext === path) return '';\n      var extIdx = ext.length - 1;\n      var firstNonSlashEnd = -1;\n      for (i = path.length - 1; i >= 0; --i) {\n        var code = path.charCodeAt(i);\n        if (code === 47 /*/*/) {\n            // If we reached a path separator that was not part of a set of path\n            // separators at the end of the string, stop now\n            if (!matchedSlash) {\n              start = i + 1;\n              break;\n            }\n          } else {\n          if (firstNonSlashEnd === -1) {\n            // We saw the first non-path separator, remember this index in case\n            // we need it if the extension ends up not matching\n            matchedSlash = false;\n            firstNonSlashEnd = i + 1;\n          }\n          if (extIdx >= 0) {\n            // Try to match the explicit extension\n            if (code === ext.charCodeAt(extIdx)) {\n              if (--extIdx === -1) {\n                // We matched the extension, so mark this as the end of our path\n                // component\n                end = i;\n              }\n            } else {\n              // Extension does not match, so our result is the entire path\n              // component\n              extIdx = -1;\n              end = firstNonSlashEnd;\n            }\n          }\n        }\n      }\n\n      if (start === end) end = firstNonSlashEnd;else if (end === -1) end = path.length;\n      return path.slice(start, end);\n    } else {\n      for (i = path.length - 1; i >= 0; --i) {\n        if (path.charCodeAt(i) === 47 /*/*/) {\n            // If we reached a path separator that was not part of a set of path\n            // separators at the end of the string, stop now\n            if (!matchedSlash) {\n              start = i + 1;\n              break;\n            }\n          } else if (end === -1) {\n          // We saw the first non-path separator, mark this as the end of our\n          // path component\n          matchedSlash = false;\n          end = i + 1;\n        }\n      }\n\n      if (end === -1) return '';\n      return path.slice(start, end);\n    }\n  },\n\n  extname: function extname(path) {\n    assertPath(path);\n    var startDot = -1;\n    var startPart = 0;\n    var end = -1;\n    var matchedSlash = true;\n    // Track the state of characters (if any) we see before our first dot and\n    // after any path separator we find\n    var preDotState = 0;\n    for (var i = path.length - 1; i >= 0; --i) {\n      var code = path.charCodeAt(i);\n      if (code === 47 /*/*/) {\n          // If we reached a path separator that was not part of a set of path\n          // separators at the end of the string, stop now\n          if (!matchedSlash) {\n            startPart = i + 1;\n            break;\n          }\n          continue;\n        }\n      if (end === -1) {\n        // We saw the first non-path separator, mark this as the end of our\n        // extension\n        matchedSlash = false;\n        end = i + 1;\n      }\n      if (code === 46 /*.*/) {\n          // If this is our first dot, mark it as the start of our extension\n          if (startDot === -1)\n            startDot = i;\n          else if (preDotState !== 1)\n            preDotState = 1;\n      } else if (startDot !== -1) {\n        // We saw a non-dot and non-path separator before our dot, so we should\n        // have a good chance at having a non-empty extension\n        preDotState = -1;\n      }\n    }\n\n    if (startDot === -1 || end === -1 ||\n        // We saw a non-dot character immediately before the dot\n        preDotState === 0 ||\n        // The (right-most) trimmed path component is exactly '..'\n        preDotState === 1 && startDot === end - 1 && startDot === startPart + 1) {\n      return '';\n    }\n    return path.slice(startDot, end);\n  },\n\n  format: function format(pathObject) {\n    if (pathObject === null || typeof pathObject !== 'object') {\n      throw new TypeError('The \"pathObject\" argument must be of type Object. Received type ' + typeof pathObject);\n    }\n    return _format('/', pathObject);\n  },\n\n  parse: function parse(path) {\n    assertPath(path);\n\n    var ret = { root: '', dir: '', base: '', ext: '', name: '' };\n    if (path.length === 0) return ret;\n    var code = path.charCodeAt(0);\n    var isAbsolute = code === 47 /*/*/;\n    var start;\n    if (isAbsolute) {\n      ret.root = '/';\n      start = 1;\n    } else {\n      start = 0;\n    }\n    var startDot = -1;\n    var startPart = 0;\n    var end = -1;\n    var matchedSlash = true;\n    var i = path.length - 1;\n\n    // Track the state of characters (if any) we see before our first dot and\n    // after any path separator we find\n    var preDotState = 0;\n\n    // Get non-dir info\n    for (; i >= start; --i) {\n      code = path.charCodeAt(i);\n      if (code === 47 /*/*/) {\n          // If we reached a path separator that was not part of a set of path\n          // separators at the end of the string, stop now\n          if (!matchedSlash) {\n            startPart = i + 1;\n            break;\n          }\n          continue;\n        }\n      if (end === -1) {\n        // We saw the first non-path separator, mark this as the end of our\n        // extension\n        matchedSlash = false;\n        end = i + 1;\n      }\n      if (code === 46 /*.*/) {\n          // If this is our first dot, mark it as the start of our extension\n          if (startDot === -1) startDot = i;else if (preDotState !== 1) preDotState = 1;\n        } else if (startDot !== -1) {\n        // We saw a non-dot and non-path separator before our dot, so we should\n        // have a good chance at having a non-empty extension\n        preDotState = -1;\n      }\n    }\n\n    if (startDot === -1 || end === -1 ||\n    // We saw a non-dot character immediately before the dot\n    preDotState === 0 ||\n    // The (right-most) trimmed path component is exactly '..'\n    preDotState === 1 && startDot === end - 1 && startDot === startPart + 1) {\n      if (end !== -1) {\n        if (startPart === 0 && isAbsolute) ret.base = ret.name = path.slice(1, end);else ret.base = ret.name = path.slice(startPart, end);\n      }\n    } else {\n      if (startPart === 0 && isAbsolute) {\n        ret.name = path.slice(1, startDot);\n        ret.base = path.slice(1, end);\n      } else {\n        ret.name = path.slice(startPart, startDot);\n        ret.base = path.slice(startPart, end);\n      }\n      ret.ext = path.slice(startDot, end);\n    }\n\n    if (startPart > 0) ret.dir = path.slice(0, startPart - 1);else if (isAbsolute) ret.dir = '/';\n\n    return ret;\n  },\n\n  sep: '/',\n  delimiter: ':',\n  win32: null,\n  posix: null\n};\n\nposix.posix = posix;\n\nmodule.exports = posix;\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n'use strict';\n\n// !!!!!\n// SEE https://github.com/microsoft/vscode/blob/master/src/vs/base/common/platform.ts\n// !!!!!\n\ndeclare const process: { platform: 'win32' };\ndeclare const navigator: { userAgent: string };\n\nexport let isWindows: boolean;\n\nif (typeof process === 'object') {\n\tisWindows = process.platform === 'win32';\n} else if (typeof navigator === 'object') {\n\tlet userAgent = navigator.userAgent;\n\tisWindows = userAgent.indexOf('Windows') >= 0;\n}\n","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n'use strict';\n\nimport { CharCode } from './charCode'\nimport { isWindows } from './platform';\n\nconst _schemePattern = /^\\w[\\w\\d+.-]*$/;\nconst _singleSlashStart = /^\\//;\nconst _doubleSlashStart = /^\\/\\//;\n\nfunction _validateUri(ret: URI, _strict?: boolean): void {\n\n\t// scheme, must be set\n\tif (!ret.scheme && _strict) {\n\t\tthrow new Error(`[UriError]: Scheme is missing: {scheme: \"\", authority: \"${ret.authority}\", path: \"${ret.path}\", query: \"${ret.query}\", fragment: \"${ret.fragment}\"}`);\n\t}\n\n\t// scheme, https://tools.ietf.org/html/rfc3986#section-3.1\n\t// ALPHA *( ALPHA / DIGIT / \"+\" / \"-\" / \".\" )\n\tif (ret.scheme && !_schemePattern.test(ret.scheme)) {\n\t\tthrow new Error('[UriError]: Scheme contains illegal characters.');\n\t}\n\n\t// path, http://tools.ietf.org/html/rfc3986#section-3.3\n\t// If a URI contains an authority component, then the path component\n\t// must either be empty or begin with a slash (\"/\") character.  If a URI\n\t// does not contain an authority component, then the path cannot begin\n\t// with two slash characters (\"//\").\n\tif (ret.path) {\n\t\tif (ret.authority) {\n\t\t\tif (!_singleSlashStart.test(ret.path)) {\n\t\t\t\tthrow new Error('[UriError]: If a URI contains an authority component, then the path component must either be empty or begin with a slash (\"/\") character');\n\t\t\t}\n\t\t} else {\n\t\t\tif (_doubleSlashStart.test(ret.path)) {\n\t\t\t\tthrow new Error('[UriError]: If a URI does not contain an authority component, then the path cannot begin with two slash characters (\"//\")');\n\t\t\t}\n\t\t}\n\t}\n}\n\n// for a while we allowed uris *without* schemes and this is the migration\n// for them, e.g. an uri without scheme and without strict-mode warns and falls\n// back to the file-scheme. that should cause the least carnage and still be a\n// clear warning\nfunction _schemeFix(scheme: string, _strict: boolean): string {\n\tif (!scheme && !_strict) {\n\t\treturn 'file';\n\t}\n\treturn scheme;\n}\n\n// implements a bit of https://tools.ietf.org/html/rfc3986#section-5\nfunction _referenceResolution(scheme: string, path: string): string {\n\n\t// the slash-character is our 'default base' as we don't\n\t// support constructing URIs relative to other URIs. This\n\t// also means that we alter and potentially break paths.\n\t// see https://tools.ietf.org/html/rfc3986#section-5.1.4\n\tswitch (scheme) {\n\t\tcase 'https':\n\t\tcase 'http':\n\t\tcase 'file':\n\t\t\tif (!path) {\n\t\t\t\tpath = _slash;\n\t\t\t} else if (path[0] !== _slash) {\n\t\t\t\tpath = _slash + path;\n\t\t\t}\n\t\t\tbreak;\n\t}\n\treturn path;\n}\n\nconst _empty = '';\nconst _slash = '/';\nconst _regexp = /^(([^:/?#]+?):)?(\\/\\/([^/?#]*))?([^?#]*)(\\?([^#]*))?(#(.*))?/;\n\n/**\n * Uniform Resource Identifier (URI) http://tools.ietf.org/html/rfc3986.\n * This class is a simple parser which creates the basic component parts\n * (http://tools.ietf.org/html/rfc3986#section-3) with minimal validation\n * and encoding.\n *\n * ```txt\n *       foo://example.com:8042/over/there?name=ferret#nose\n *       \\_/   \\______________/\\_________/ \\_________/ \\__/\n *        |           |            |            |        |\n *     scheme     authority       path        query   fragment\n *        |   _____________________|__\n *       / \\ /                        \\\n *       urn:example:animal:ferret:nose\n * ```\n */\nexport class URI implements UriComponents {\n\n\tstatic isUri(thing: any): thing is URI {\n\t\tif (thing instanceof URI) {\n\t\t\treturn true;\n\t\t}\n\t\tif (!thing) {\n\t\t\treturn false;\n\t\t}\n\t\treturn typeof (<URI>thing).authority === 'string'\n\t\t\t&& typeof (<URI>thing).fragment === 'string'\n\t\t\t&& typeof (<URI>thing).path === 'string'\n\t\t\t&& typeof (<URI>thing).query === 'string'\n\t\t\t&& typeof (<URI>thing).scheme === 'string'\n\t\t\t&& typeof (<URI>thing).fsPath === 'string'\n\t\t\t&& typeof (<URI>thing).with === 'function'\n\t\t\t&& typeof (<URI>thing).toString === 'function';\n\t}\n\n\t/**\n\t * scheme is the 'http' part of 'http://www.example.com/some/path?query#fragment'.\n\t * The part before the first colon.\n\t */\n\treadonly scheme: string;\n\n\t/**\n\t * authority is the 'www.example.com' part of 'http://www.example.com/some/path?query#fragment'.\n\t * The part between the first double slashes and the next slash.\n\t */\n\treadonly authority: string;\n\n\t/**\n\t * path is the '/some/path' part of 'http://www.example.com/some/path?query#fragment'.\n\t */\n\treadonly path: string;\n\n\t/**\n\t * query is the 'query' part of 'http://www.example.com/some/path?query#fragment'.\n\t */\n\treadonly query: string;\n\n\t/**\n\t * fragment is the 'fragment' part of 'http://www.example.com/some/path?query#fragment'.\n\t */\n\treadonly fragment: string;\n\n\t/**\n\t * @internal\n\t */\n\tprotected constructor(scheme: string, authority?: string, path?: string, query?: string, fragment?: string, _strict?: boolean);\n\n\t/**\n\t * @internal\n\t */\n\tprotected constructor(components: UriComponents);\n\n\t/**\n\t * @internal\n\t */\n\tprotected constructor(schemeOrData: string | UriComponents, authority?: string, path?: string, query?: string, fragment?: string, _strict: boolean = false) {\n\n\t\tif (typeof schemeOrData === 'object') {\n\t\t\tthis.scheme = schemeOrData.scheme || _empty;\n\t\t\tthis.authority = schemeOrData.authority || _empty;\n\t\t\tthis.path = schemeOrData.path || _empty;\n\t\t\tthis.query = schemeOrData.query || _empty;\n\t\t\tthis.fragment = schemeOrData.fragment || _empty;\n\t\t\t// no validation because it's this URI\n\t\t\t// that creates uri components.\n\t\t\t// _validateUri(this);\n\t\t} else {\n\t\t\tthis.scheme = _schemeFix(schemeOrData, _strict);\n\t\t\tthis.authority = authority || _empty;\n\t\t\tthis.path = _referenceResolution(this.scheme, path || _empty);\n\t\t\tthis.query = query || _empty;\n\t\t\tthis.fragment = fragment || _empty;\n\n\t\t\t_validateUri(this, _strict);\n\t\t}\n\t}\n\n\t// ---- filesystem path -----------------------\n\n\t/**\n\t * Returns a string representing the corresponding file system path of this URI.\n\t * Will handle UNC paths, normalizes windows drive letters to lower-case, and uses the\n\t * platform specific path separator.\n\t *\n\t * * Will *not* validate the path for invalid characters and semantics.\n\t * * Will *not* look at the scheme of this URI.\n\t * * The result shall *not* be used for display purposes but for accessing a file on disk.\n\t *\n\t *\n\t * The *difference* to `URI#path` is the use of the platform specific separator and the handling\n\t * of UNC paths. See the below sample of a file-uri with an authority (UNC path).\n\t *\n\t * ```ts\n\t\tconst u = URI.parse('file://server/c$/folder/file.txt')\n\t\tu.authority === 'server'\n\t\tu.path === '/shares/c$/file.txt'\n\t\tu.fsPath === '\\\\server\\c$\\folder\\file.txt'\n\t```\n\t *\n\t * Using `URI#path` to read a file (using fs-apis) would not be enough because parts of the path,\n\t * namely the server name, would be missing. Therefore `URI#fsPath` exists - it's sugar to ease working\n\t * with URIs that represent files on disk (`file` scheme).\n\t */\n\tget fsPath(): string {\n\t\t// if (this.scheme !== 'file') {\n\t\t// \tconsole.warn(`[UriError] calling fsPath with scheme ${this.scheme}`);\n\t\t// }\n\t\treturn uriToFsPath(this, false);\n\t}\n\n\t// ---- modify to new -------------------------\n\n\twith(change: { scheme?: string; authority?: string | null; path?: string | null; query?: string | null; fragment?: string | null }): URI {\n\n\t\tif (!change) {\n\t\t\treturn this;\n\t\t}\n\n\t\tlet { scheme, authority, path, query, fragment } = change;\n\t\tif (scheme === undefined) {\n\t\t\tscheme = this.scheme;\n\t\t} else if (scheme === null) {\n\t\t\tscheme = _empty;\n\t\t}\n\t\tif (authority === undefined) {\n\t\t\tauthority = this.authority;\n\t\t} else if (authority === null) {\n\t\t\tauthority = _empty;\n\t\t}\n\t\tif (path === undefined) {\n\t\t\tpath = this.path;\n\t\t} else if (path === null) {\n\t\t\tpath = _empty;\n\t\t}\n\t\tif (query === undefined) {\n\t\t\tquery = this.query;\n\t\t} else if (query === null) {\n\t\t\tquery = _empty;\n\t\t}\n\t\tif (fragment === undefined) {\n\t\t\tfragment = this.fragment;\n\t\t} else if (fragment === null) {\n\t\t\tfragment = _empty;\n\t\t}\n\n\t\tif (scheme === this.scheme\n\t\t\t&& authority === this.authority\n\t\t\t&& path === this.path\n\t\t\t&& query === this.query\n\t\t\t&& fragment === this.fragment) {\n\n\t\t\treturn this;\n\t\t}\n\n\t\treturn new Uri(scheme, authority, path, query, fragment);\n\t}\n\n\t// ---- parse & validate ------------------------\n\n\t/**\n\t * Creates a new URI from a string, e.g. `http://www.example.com/some/path`,\n\t * `file:///usr/home`, or `scheme:with/path`.\n\t *\n\t * @param value A string which represents an URI (see `URI#toString`).\n\t */\n\tstatic parse(value: string, _strict: boolean = false): URI {\n\t\tconst match = _regexp.exec(value);\n\t\tif (!match) {\n\t\t\treturn new Uri(_empty, _empty, _empty, _empty, _empty);\n\t\t}\n\t\treturn new Uri(\n\t\t\tmatch[2] || _empty,\n\t\t\tpercentDecode(match[4] || _empty),\n\t\t\tpercentDecode(match[5] || _empty),\n\t\t\tpercentDecode(match[7] || _empty),\n\t\t\tpercentDecode(match[9] || _empty),\n\t\t\t_strict\n\t\t);\n\t}\n\n\t/**\n\t * Creates a new URI from a file system path, e.g. `c:\\my\\files`,\n\t * `/usr/home`, or `\\\\server\\share\\some\\path`.\n\t *\n\t * The *difference* between `URI#parse` and `URI#file` is that the latter treats the argument\n\t * as path, not as stringified-uri. E.g. `URI.file(path)` is **not the same as**\n\t * `URI.parse('file://' + path)` because the path might contain characters that are\n\t * interpreted (# and ?). See the following sample:\n\t * ```ts\n\tconst good = URI.file('/coding/c#/project1');\n\tgood.scheme === 'file';\n\tgood.path === '/coding/c#/project1';\n\tgood.fragment === '';\n\tconst bad = URI.parse('file://' + '/coding/c#/project1');\n\tbad.scheme === 'file';\n\tbad.path === '/coding/c'; // path is now broken\n\tbad.fragment === '/project1';\n\t```\n\t *\n\t * @param path A file system path (see `URI#fsPath`)\n\t */\n\tstatic file(path: string): URI {\n\n\t\tlet authority = _empty;\n\n\t\t// normalize to fwd-slashes on windows,\n\t\t// on other systems bwd-slashes are valid\n\t\t// filename character, eg /f\\oo/ba\\r.txt\n\t\tif (isWindows) {\n\t\t\tpath = path.replace(/\\\\/g, _slash);\n\t\t}\n\n\t\t// check for authority as used in UNC shares\n\t\t// or use the path as given\n\t\tif (path[0] === _slash && path[1] === _slash) {\n\t\t\tconst idx = path.indexOf(_slash, 2);\n\t\t\tif (idx === -1) {\n\t\t\t\tauthority = path.substring(2);\n\t\t\t\tpath = _slash;\n\t\t\t} else {\n\t\t\t\tauthority = path.substring(2, idx);\n\t\t\t\tpath = path.substring(idx) || _slash;\n\t\t\t}\n\t\t}\n\n\t\treturn new Uri('file', authority, path, _empty, _empty);\n\t}\n\n\tstatic from(components: { scheme: string; authority?: string; path?: string; query?: string; fragment?: string }): URI {\n\t\tconst result = new Uri(\n\t\t\tcomponents.scheme,\n\t\t\tcomponents.authority,\n\t\t\tcomponents.path,\n\t\t\tcomponents.query,\n\t\t\tcomponents.fragment,\n\t\t);\n\t\t_validateUri(result, true);\n\t\treturn result;\n\t}\n\n\t// ---- printing/externalize ---------------------------\n\n\t/**\n\t * Creates a string representation for this URI. It's guaranteed that calling\n\t * `URI.parse` with the result of this function creates an URI which is equal\n\t * to this URI.\n\t *\n\t * * The result shall *not* be used for display purposes but for externalization or transport.\n\t * * The result will be encoded using the percentage encoding and encoding happens mostly\n\t * ignore the scheme-specific encoding rules.\n\t *\n\t * @param skipEncoding Do not encode the result, default is `false`\n\t */\n\ttoString(skipEncoding: boolean = false): string {\n\t\treturn _asFormatted(this, skipEncoding);\n\t}\n\n\ttoJSON(): UriComponents {\n\t\treturn this;\n\t}\n\n\tstatic revive(data: UriComponents | URI): URI;\n\tstatic revive(data: UriComponents | URI | undefined): URI | undefined;\n\tstatic revive(data: UriComponents | URI | null): URI | null;\n\tstatic revive(data: UriComponents | URI | undefined | null): URI | undefined | null;\n\tstatic revive(data: UriComponents | URI | undefined | null): URI | undefined | null {\n\t\tif (!data) {\n\t\t\treturn <any>data;\n\t\t} else if (data instanceof URI) {\n\t\t\treturn data;\n\t\t} else {\n\t\t\tconst result = new Uri(data);\n\t\t\tresult._formatted = (<UriState>data).external;\n\t\t\tresult._fsPath = (<UriState>data)._sep === _pathSepMarker ? (<UriState>data).fsPath : null;\n\t\t\treturn result;\n\t\t}\n\t}\n}\n\nexport interface UriComponents {\n\tscheme: string;\n\tauthority: string;\n\tpath: string;\n\tquery: string;\n\tfragment: string;\n}\n\ninterface UriState extends UriComponents {\n\t$mid: number;\n\texternal: string;\n\tfsPath: string;\n\t_sep: 1 | undefined;\n}\n\nconst _pathSepMarker = isWindows ? 1 : undefined;\n\n// This class exists so that URI is compatible with vscode.Uri (API).\nclass Uri extends URI {\n\n\t_formatted: string | null = null;\n\t_fsPath: string | null = null;\n\n\toverride get fsPath(): string {\n\t\tif (!this._fsPath) {\n\t\t\tthis._fsPath = uriToFsPath(this, false);\n\t\t}\n\t\treturn this._fsPath;\n\t}\n\n\toverride toString(skipEncoding: boolean = false): string {\n\t\tif (!skipEncoding) {\n\t\t\tif (!this._formatted) {\n\t\t\t\tthis._formatted = _asFormatted(this, false);\n\t\t\t}\n\t\t\treturn this._formatted;\n\t\t} else {\n\t\t\t// we don't cache that\n\t\t\treturn _asFormatted(this, true);\n\t\t}\n\t}\n\n\toverride toJSON(): UriComponents {\n\t\tconst res = <UriState>{\n\t\t\t$mid: 1\n\t\t};\n\t\t// cached state\n\t\tif (this._fsPath) {\n\t\t\tres.fsPath = this._fsPath;\n\t\t\tres._sep = _pathSepMarker;\n\t\t}\n\t\tif (this._formatted) {\n\t\t\tres.external = this._formatted;\n\t\t}\n\t\t// uri components\n\t\tif (this.path) {\n\t\t\tres.path = this.path;\n\t\t}\n\t\tif (this.scheme) {\n\t\t\tres.scheme = this.scheme;\n\t\t}\n\t\tif (this.authority) {\n\t\t\tres.authority = this.authority;\n\t\t}\n\t\tif (this.query) {\n\t\t\tres.query = this.query;\n\t\t}\n\t\tif (this.fragment) {\n\t\t\tres.fragment = this.fragment;\n\t\t}\n\t\treturn res;\n\t}\n}\n\n// reserved characters: https://tools.ietf.org/html/rfc3986#section-2.2\nconst encodeTable: { [ch: number]: string } = {\n\t[CharCode.Colon]: '%3A', // gen-delims\n\t[CharCode.Slash]: '%2F',\n\t[CharCode.QuestionMark]: '%3F',\n\t[CharCode.Hash]: '%23',\n\t[CharCode.OpenSquareBracket]: '%5B',\n\t[CharCode.CloseSquareBracket]: '%5D',\n\t[CharCode.AtSign]: '%40',\n\n\t[CharCode.ExclamationMark]: '%21', // sub-delims\n\t[CharCode.DollarSign]: '%24',\n\t[CharCode.Ampersand]: '%26',\n\t[CharCode.SingleQuote]: '%27',\n\t[CharCode.OpenParen]: '%28',\n\t[CharCode.CloseParen]: '%29',\n\t[CharCode.Asterisk]: '%2A',\n\t[CharCode.Plus]: '%2B',\n\t[CharCode.Comma]: '%2C',\n\t[CharCode.Semicolon]: '%3B',\n\t[CharCode.Equals]: '%3D',\n\n\t[CharCode.Space]: '%20',\n};\n\nfunction encodeURIComponentFast(uriComponent: string, isPath: boolean, isAuthority: boolean): string {\n\tlet res: string | undefined = undefined;\n\tlet nativeEncodePos = -1;\n\n\tfor (let pos = 0; pos < uriComponent.length; pos++) {\n\t\tconst code = uriComponent.charCodeAt(pos);\n\n\t\t// unreserved characters: https://tools.ietf.org/html/rfc3986#section-2.3\n\t\tif (\n\t\t\t(code >= CharCode.a && code <= CharCode.z)\n\t\t\t|| (code >= CharCode.A && code <= CharCode.Z)\n\t\t\t|| (code >= CharCode.Digit0 && code <= CharCode.Digit9)\n\t\t\t|| code === CharCode.Dash\n\t\t\t|| code === CharCode.Period\n\t\t\t|| code === CharCode.Underline\n\t\t\t|| code === CharCode.Tilde\n\t\t\t|| (isPath && code === CharCode.Slash)\n\t\t\t|| (isAuthority && code === CharCode.OpenSquareBracket)\n\t\t\t|| (isAuthority && code === CharCode.CloseSquareBracket)\n\t\t\t|| (isAuthority && code === CharCode.Colon)\n\t\t) {\n\t\t\t// check if we are delaying native encode\n\t\t\tif (nativeEncodePos !== -1) {\n\t\t\t\tres += encodeURIComponent(uriComponent.substring(nativeEncodePos, pos));\n\t\t\t\tnativeEncodePos = -1;\n\t\t\t}\n\t\t\t// check if we write into a new string (by default we try to return the param)\n\t\t\tif (res !== undefined) {\n\t\t\t\tres += uriComponent.charAt(pos);\n\t\t\t}\n\n\t\t} else {\n\t\t\t// encoding needed, we need to allocate a new string\n\t\t\tif (res === undefined) {\n\t\t\t\tres = uriComponent.substr(0, pos);\n\t\t\t}\n\n\t\t\t// check with default table first\n\t\t\tconst escaped = encodeTable[code];\n\t\t\tif (escaped !== undefined) {\n\n\t\t\t\t// check if we are delaying native encode\n\t\t\t\tif (nativeEncodePos !== -1) {\n\t\t\t\t\tres += encodeURIComponent(uriComponent.substring(nativeEncodePos, pos));\n\t\t\t\t\tnativeEncodePos = -1;\n\t\t\t\t}\n\n\t\t\t\t// append escaped variant to result\n\t\t\t\tres += escaped;\n\n\t\t\t} else if (nativeEncodePos === -1) {\n\t\t\t\t// use native encode only when needed\n\t\t\t\tnativeEncodePos = pos;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (nativeEncodePos !== -1) {\n\t\tres += encodeURIComponent(uriComponent.substring(nativeEncodePos));\n\t}\n\n\treturn res !== undefined ? res : uriComponent;\n}\n\nfunction encodeURIComponentMinimal(path: string): string {\n\tlet res: string | undefined = undefined;\n\tfor (let pos = 0; pos < path.length; pos++) {\n\t\tconst code = path.charCodeAt(pos);\n\t\tif (code === CharCode.Hash || code === CharCode.QuestionMark) {\n\t\t\tif (res === undefined) {\n\t\t\t\tres = path.substr(0, pos);\n\t\t\t}\n\t\t\tres += encodeTable[code];\n\t\t} else {\n\t\t\tif (res !== undefined) {\n\t\t\t\tres += path[pos];\n\t\t\t}\n\t\t}\n\t}\n\treturn res !== undefined ? res : path;\n}\n\n/**\n * Compute `fsPath` for the given uri\n */\nexport function uriToFsPath(uri: URI, keepDriveLetterCasing: boolean): string {\n\n\tlet value: string;\n\tif (uri.authority && uri.path.length > 1 && uri.scheme === 'file') {\n\t\t// unc path: file://shares/c$/far/boo\n\t\tvalue = `//${uri.authority}${uri.path}`;\n\t} else if (\n\t\turi.path.charCodeAt(0) === CharCode.Slash\n\t\t&& (uri.path.charCodeAt(1) >= CharCode.A && uri.path.charCodeAt(1) <= CharCode.Z || uri.path.charCodeAt(1) >= CharCode.a && uri.path.charCodeAt(1) <= CharCode.z)\n\t\t&& uri.path.charCodeAt(2) === CharCode.Colon\n\t) {\n\t\tif (!keepDriveLetterCasing) {\n\t\t\t// windows drive letter: file:///c:/far/boo\n\t\t\tvalue = uri.path[1].toLowerCase() + uri.path.substr(2);\n\t\t} else {\n\t\t\tvalue = uri.path.substr(1);\n\t\t}\n\t} else {\n\t\t// other path\n\t\tvalue = uri.path;\n\t}\n\tif (isWindows) {\n\t\tvalue = value.replace(/\\//g, '\\\\');\n\t}\n\treturn value;\n}\n\n/**\n * Create the external version of a uri\n */\nfunction _asFormatted(uri: URI, skipEncoding: boolean): string {\n\n\tconst encoder = !skipEncoding\n\t\t? encodeURIComponentFast\n\t\t: encodeURIComponentMinimal;\n\n\tlet res = '';\n\tlet { scheme, authority, path, query, fragment } = uri;\n\tif (scheme) {\n\t\tres += scheme;\n\t\tres += ':';\n\t}\n\tif (authority || scheme === 'file') {\n\t\tres += _slash;\n\t\tres += _slash;\n\t}\n\tif (authority) {\n\t\tlet idx = authority.indexOf('@');\n\t\tif (idx !== -1) {\n\t\t\t// <user>@<auth>\n\t\t\tconst userinfo = authority.substr(0, idx);\n\t\t\tauthority = authority.substr(idx + 1);\n\t\t\tidx = userinfo.lastIndexOf(':');\n\t\t\tif (idx === -1) {\n\t\t\t\tres += encoder(userinfo, false, false);\n\t\t\t} else {\n\t\t\t\t// <user>:<pass>@<auth>\n\t\t\t\tres += encoder(userinfo.substr(0, idx), false, false);\n\t\t\t\tres += ':';\n\t\t\t\tres += encoder(userinfo.substr(idx + 1), false, true);\n\t\t\t}\n\t\t\tres += '@';\n\t\t}\n\t\tauthority = authority.toLowerCase();\n\t\tidx = authority.lastIndexOf(':');\n\t\tif (idx === -1) {\n\t\t\tres += encoder(authority, false, true);\n\t\t} else {\n\t\t\t// <auth>:<port>\n\t\t\tres += encoder(authority.substr(0, idx), false, true);\n\t\t\tres += authority.substr(idx);\n\t\t}\n\t}\n\tif (path) {\n\t\t// lower-case windows drive letters in /C:/fff or C:/fff\n\t\tif (path.length >= 3 && path.charCodeAt(0) === CharCode.Slash && path.charCodeAt(2) === CharCode.Colon) {\n\t\t\tconst code = path.charCodeAt(1);\n\t\t\tif (code >= CharCode.A && code <= CharCode.Z) {\n\t\t\t\tpath = `/${String.fromCharCode(code + 32)}:${path.substr(3)}`; // \"/c:\".length === 3\n\t\t\t}\n\t\t} else if (path.length >= 2 && path.charCodeAt(1) === CharCode.Colon) {\n\t\t\tconst code = path.charCodeAt(0);\n\t\t\tif (code >= CharCode.A && code <= CharCode.Z) {\n\t\t\t\tpath = `${String.fromCharCode(code + 32)}:${path.substr(2)}`; // \"/c:\".length === 3\n\t\t\t}\n\t\t}\n\t\t// encode the rest of the path\n\t\tres += encoder(path, true, false);\n\t}\n\tif (query) {\n\t\tres += '?';\n\t\tres += encoder(query, false, false);\n\t}\n\tif (fragment) {\n\t\tres += '#';\n\t\tres += !skipEncoding ? encodeURIComponentFast(fragment, false, false) : fragment;\n\t}\n\treturn res;\n}\n\n// --- decode\n\nfunction decodeURIComponentGraceful(str: string): string {\n\ttry {\n\t\treturn decodeURIComponent(str);\n\t} catch {\n\t\tif (str.length > 3) {\n\t\t\treturn str.substr(0, 3) + decodeURIComponentGraceful(str.substr(3));\n\t\t} else {\n\t\t\treturn str;\n\t\t}\n\t}\n}\n\nconst _rEncodedAsHex = /(%[0-9A-Za-z][0-9A-Za-z])+/g;\n\nfunction percentDecode(str: string): string {\n\tif (!str.match(_rEncodedAsHex)) {\n\t\treturn str;\n\t}\n\treturn str.replace(_rEncodedAsHex, (match) => decodeURIComponentGraceful(match));\n}\n\n/**\n * Mapped-type that replaces all occurrences of URI with UriComponents\n */\nexport type UriDto<T> = { [K in keyof T]: T[K] extends URI\n\t? UriComponents\n\t: UriDto<T[K]> };\n","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\n'use strict';\n\nimport { CharCode } from './charCode';\nimport { URI } from './uri';\nimport * as nodePath from 'path';\n\nconst posixPath = nodePath.posix || nodePath;\nconst slash = '/';\n\nexport namespace Utils {\n\n    /**\n     * Joins one or more input paths to the path of URI. \n     * '/' is used as the directory separation character. \n     * \n     * The resolved path will be normalized. That means:\n     *  - all '..' and '.' segments are resolved.\n     *  - multiple, sequential occurences of '/' are replaced by a single instance of '/'.\n     *  - trailing separators are preserved.\n     * \n     * @param uri The input URI.\n     * @param paths The paths to be joined with the path of URI.\n     * @returns A URI with the joined path. All other properties of the URI (scheme, authority, query, fragments, ...) will be taken from the input URI.\n     */\n    export function joinPath(uri: URI, ...paths: string[]): URI {\n        return uri.with({ path: posixPath.join(uri.path, ...paths) });\n    }\n\n\n    /**\n     * Resolves one or more paths against the path of a URI. \n     * '/' is used as the directory separation character. \n     * \n     * The resolved path will be normalized. That means:\n     *  - all '..' and '.' segments are resolved. \n     *  - multiple, sequential occurences of '/' are replaced by a single instance of '/'.\n     *  - trailing separators are removed.\n     * \n     * @param uri The input URI.\n     * @param paths The paths to resolve against the path of URI.\n     * @returns A URI with the resolved path. All other properties of the URI (scheme, authority, query, fragments, ...) will be taken from the input URI.\n     */\n    export function resolvePath(uri: URI, ...paths: string[]): URI {\n        let path = uri.path; \n        let slashAdded = false;\n        if (path[0] !== slash) {\n            path = slash + path; // make the path abstract: for posixPath.resolve the first segments has to be absolute or cwd is used.\n            slashAdded = true;\n        }\n        let resolvedPath = posixPath.resolve(path, ...paths);\n        if (slashAdded && resolvedPath[0] === slash && !uri.authority) {\n            resolvedPath = resolvedPath.substring(1);\n        }\n        return uri.with({ path: resolvedPath });\n    }\n\n    /**\n     * Returns a URI where the path is the directory name of the input uri, similar to the Unix dirname command. \n     * In the path, '/' is recognized as the directory separation character. Trailing directory separators are ignored.\n     * The orignal URI is returned if the URIs path is empty or does not contain any path segments.\n     * \n     * @param uri The input URI.\n     * @return The last segment of the URIs path.\n     */\n    export function dirname(uri: URI): URI {\n        if (uri.path.length === 0 || uri.path === slash) {\n            return uri;\n        }\n        let path = posixPath.dirname(uri.path);\n        if (path.length === 1 && path.charCodeAt(0) === CharCode.Period) {\n            path = '';\n        }\n        return uri.with({ path });\n    }\n\n    /**\n     * Returns the last segment of the path of a URI, similar to the Unix basename command. \n     * In the path, '/' is recognized as the directory separation character. Trailing directory separators are ignored.\n     * The empty string is returned if the URIs path is empty or does not contain any path segments.\n     * \n     * @param uri The input URI.\n     * @return The base name of the URIs path.\n     */\n    export function basename(uri: URI): string {\n        return posixPath.basename(uri.path);\n    }\n\n    /**\n     * Returns the extension name of the path of a URI, similar to the Unix extname command. \n     * In the path, '/' is recognized as the directory separation character. Trailing directory separators are ignored.\n     * The empty string is returned if the URIs path is empty or does not contain any path segments.\n     * \n     * @param uri The input URI.\n     * @return The extension name of the URIs path.\n     */\n    export function extname(uri: URI): string {\n        return posixPath.extname(uri.path);\n    }\n}","import baseEach from './_baseEach.js';\nimport isArrayLike from './isArrayLike.js';\n\n/**\n * The base implementation of `_.map` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns the new mapped array.\n */\nfunction baseMap(collection, iteratee) {\n  var index = -1,\n      result = isArrayLike(collection) ? Array(collection.length) : [];\n\n  baseEach(collection, function(value, key, collection) {\n    result[++index] = iteratee(value, key, collection);\n  });\n  return result;\n}\n\nexport default baseMap;\n","/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * The base implementation of `_.has` without support for deep paths.\n *\n * @private\n * @param {Object} [object] The object to query.\n * @param {Array|string} key The key to check.\n * @returns {boolean} Returns `true` if `key` exists, else `false`.\n */\nfunction baseHas(object, key) {\n  return object != null && hasOwnProperty.call(object, key);\n}\n\nexport default baseHas;\n","import baseHas from './_baseHas.js';\nimport hasPath from './_hasPath.js';\n\n/**\n * Checks if `path` is a direct property of `object`.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The object to query.\n * @param {Array|string} path The path to check.\n * @returns {boolean} Returns `true` if `path` exists, else `false`.\n * @example\n *\n * var object = { 'a': { 'b': 2 } };\n * var other = _.create({ 'a': _.create({ 'b': 2 }) });\n *\n * _.has(object, 'a');\n * // => true\n *\n * _.has(object, 'a.b');\n * // => true\n *\n * _.has(object, ['a', 'b']);\n * // => true\n *\n * _.has(other, 'a');\n * // => false\n */\nfunction has(object, path) {\n  return object != null && hasPath(object, path, baseHas);\n}\n\nexport default has;\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nlet _ral;\nfunction RAL() {\n    if (_ral === undefined) {\n        throw new Error(`No runtime abstraction layer installed`);\n    }\n    return _ral;\n}\n(function (RAL) {\n    function install(ral) {\n        if (ral === undefined) {\n            throw new Error(`No runtime abstraction layer provided`);\n        }\n        _ral = ral;\n    }\n    RAL.install = install;\n})(RAL || (RAL = {}));\nexports.default = RAL;\n","import baseRest from './_baseRest.js';\nimport eq from './eq.js';\nimport isIterateeCall from './_isIterateeCall.js';\nimport keysIn from './keysIn.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Assigns own and inherited enumerable string keyed properties of source\n * objects to the destination object for all destination properties that\n * resolve to `undefined`. Source objects are applied from left to right.\n * Once a property is set, additional values of the same property are ignored.\n *\n * **Note:** This method mutates `object`.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The destination object.\n * @param {...Object} [sources] The source objects.\n * @returns {Object} Returns `object`.\n * @see _.defaultsDeep\n * @example\n *\n * _.defaults({ 'a': 1 }, { 'b': 2 }, { 'a': 3 });\n * // => { 'a': 1, 'b': 2 }\n */\nvar defaults = baseRest(function(object, sources) {\n  object = Object(object);\n\n  var index = -1;\n  var length = sources.length;\n  var guard = length > 2 ? sources[2] : undefined;\n\n  if (guard && isIterateeCall(sources[0], sources[1], guard)) {\n    length = 1;\n  }\n\n  while (++index < length) {\n    var source = sources[index];\n    var props = keysIn(source);\n    var propsIndex = -1;\n    var propsLength = props.length;\n\n    while (++propsIndex < propsLength) {\n      var key = props[propsIndex];\n      var value = object[key];\n\n      if (value === undefined ||\n          (eq(value, objectProto[key]) && !hasOwnProperty.call(object, key))) {\n        object[key] = source[key];\n      }\n    }\n  }\n\n  return object;\n});\n\nexport default defaults;\n","import baseFlatten from './_baseFlatten.js';\n\n/**\n * Flattens `array` a single level deep.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to flatten.\n * @returns {Array} Returns the new flattened array.\n * @example\n *\n * _.flatten([1, [2, [3, [4]], 5]]);\n * // => [1, 2, [3, [4]], 5]\n */\nfunction flatten(array) {\n  var length = array == null ? 0 : array.length;\n  return length ? baseFlatten(array, 1) : [];\n}\n\nexport default flatten;\n","import {\n  AbstractMermaidTokenBuilder,\n  CommonValueConverter,\n  MermaidGeneratedSharedModule,\n  RadarGeneratedModule,\n  __name\n} from \"./chunk-4KMFLZZN.mjs\";\n\n// src/language/radar/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/radar/tokenBuilder.ts\nvar RadarTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"RadarTokenBuilder\");\n  }\n  constructor() {\n    super([\"radar-beta\"]);\n  }\n};\n\n// src/language/radar/module.ts\nvar RadarModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new RadarTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new CommonValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createRadarServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Radar = inject(\n    createDefaultCoreModule({ shared }),\n    RadarGeneratedModule,\n    RadarModule\n  );\n  shared.ServiceRegistry.register(Radar);\n  return { shared, Radar };\n}\n__name(createRadarServices, \"createRadarServices\");\n\nexport {\n  RadarModule,\n  createRadarServices\n};\n","import assignValue from './_assignValue.js';\nimport castPath from './_castPath.js';\nimport isIndex from './_isIndex.js';\nimport isObject from './isObject.js';\nimport toKey from './_toKey.js';\n\n/**\n * The base implementation of `_.set`.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {Array|string} path The path of the property to set.\n * @param {*} value The value to set.\n * @param {Function} [customizer] The function to customize path creation.\n * @returns {Object} Returns `object`.\n */\nfunction baseSet(object, path, value, customizer) {\n  if (!isObject(object)) {\n    return object;\n  }\n  path = castPath(path, object);\n\n  var index = -1,\n      length = path.length,\n      lastIndex = length - 1,\n      nested = object;\n\n  while (nested != null && ++index < length) {\n    var key = toKey(path[index]),\n        newValue = value;\n\n    if (key === '__proto__' || key === 'constructor' || key === 'prototype') {\n      return object;\n    }\n\n    if (index != lastIndex) {\n      var objValue = nested[key];\n      newValue = customizer ? customizer(objValue, key, nested) : undefined;\n      if (newValue === undefined) {\n        newValue = isObject(objValue)\n          ? objValue\n          : (isIndex(path[index + 1]) ? [] : {});\n      }\n    }\n    assignValue(nested, key, newValue);\n    nested = nested[key];\n  }\n  return object;\n}\n\nexport default baseSet;\n","import baseGet from './_baseGet.js';\nimport baseSet from './_baseSet.js';\nimport castPath from './_castPath.js';\n\n/**\n * The base implementation of  `_.pickBy` without support for iteratee shorthands.\n *\n * @private\n * @param {Object} object The source object.\n * @param {string[]} paths The property paths to pick.\n * @param {Function} predicate The function invoked per property.\n * @returns {Object} Returns the new object.\n */\nfunction basePickBy(object, paths, predicate) {\n  var index = -1,\n      length = paths.length,\n      result = {};\n\n  while (++index < length) {\n    var path = paths[index],\n        value = baseGet(object, path);\n\n    if (predicate(value, path)) {\n      baseSet(result, castPath(path, object), value);\n    }\n  }\n  return result;\n}\n\nexport default basePickBy;\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { CstNode } from '../syntax-tree.js';\r\n\r\nexport class ErrorWithLocation extends Error {\r\n    constructor(node: CstNode | undefined, message: string) {\r\n        super(node ? `${message} at ${node.range.start.line}:${node.range.start.character}` : message);\r\n    }\r\n}\r\n\r\nexport function assertUnreachable(_: never): never {\r\n    throw new Error('Error! The input value was not handled.');\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport map from \"lodash-es/map.js\"\r\nimport filter from \"lodash-es/filter.js\"\r\nimport {\r\n    IProduction,\r\n    IProductionWithOccurrence,\r\n    TokenType,\r\n    Alternation,\r\n    NonTerminal,\r\n    Rule,\r\n    Option,\r\n    RepetitionMandatory,\r\n    Repetition,\r\n    Terminal,\r\n    Alternative,\r\n    RepetitionWithSeparator,\r\n    RepetitionMandatoryWithSeparator,\r\n    LookaheadProductionType\r\n} from \"chevrotain\"\r\n\r\nexport function buildATNKey(rule: Rule, type: LookaheadProductionType, occurrence: number): string {\r\n    return `${rule.name}_${type}_${occurrence}`;\r\n}\r\n\r\nexport interface ATN {\r\n    decisionMap: Record<string, DecisionState>\r\n    states: ATNState[]\r\n    decisionStates: DecisionState[]\r\n    ruleToStartState: Map<Rule, RuleStartState>\r\n    ruleToStopState: Map<Rule, RuleStopState>\r\n}\r\n\r\nexport const ATN_INVALID_TYPE = 0\r\nexport const ATN_BASIC = 1\r\nexport const ATN_RULE_START = 2\r\nexport const ATN_PLUS_BLOCK_START = 4\r\nexport const ATN_STAR_BLOCK_START = 5\r\n// Currently unused as the ATN is not used for lexing\r\nexport const ATN_TOKEN_START = 6\r\nexport const ATN_RULE_STOP = 7\r\nexport const ATN_BLOCK_END = 8\r\nexport const ATN_STAR_LOOP_BACK = 9\r\nexport const ATN_STAR_LOOP_ENTRY = 10\r\nexport const ATN_PLUS_LOOP_BACK = 11\r\nexport const ATN_LOOP_END = 12\r\n\r\nexport type ATNState =\r\n    | BasicState\r\n    | BasicBlockStartState\r\n    | PlusBlockStartState\r\n    | PlusLoopbackState\r\n    | StarBlockStartState\r\n    | StarLoopbackState\r\n    | StarLoopEntryState\r\n    | BlockEndState\r\n    | RuleStartState\r\n    | RuleStopState\r\n    | LoopEndState\r\n\r\nexport interface ATNBaseState {\r\n    atn: ATN\r\n    production: IProductionWithOccurrence\r\n    stateNumber: number\r\n    rule: Rule\r\n    epsilonOnlyTransitions: boolean\r\n    transitions: Transition[]\r\n    nextTokenWithinRule: number[]\r\n}\r\n\r\nexport interface BasicState extends ATNBaseState {\r\n    type: typeof ATN_BASIC\r\n}\r\n\r\nexport interface BlockStartState extends DecisionState {\r\n    end: BlockEndState\r\n}\r\n\r\nexport interface BasicBlockStartState extends BlockStartState {\r\n    type: typeof ATN_BASIC\r\n}\r\n\r\nexport interface PlusBlockStartState extends BlockStartState {\r\n    loopback: PlusLoopbackState\r\n    type: typeof ATN_PLUS_BLOCK_START\r\n}\r\n\r\nexport interface PlusLoopbackState extends DecisionState {\r\n    type: typeof ATN_PLUS_LOOP_BACK\r\n}\r\n\r\nexport interface StarBlockStartState extends BlockStartState {\r\n    type: typeof ATN_STAR_BLOCK_START\r\n}\r\n\r\nexport interface StarLoopbackState extends ATNBaseState {\r\n    type: typeof ATN_STAR_LOOP_BACK\r\n}\r\n\r\nexport interface StarLoopEntryState extends DecisionState {\r\n    loopback: StarLoopbackState\r\n    type: typeof ATN_STAR_LOOP_ENTRY\r\n}\r\n\r\nexport interface BlockEndState extends ATNBaseState {\r\n    start: BlockStartState\r\n    type: typeof ATN_BLOCK_END\r\n}\r\n\r\nexport interface DecisionState extends ATNBaseState {\r\n    decision: number\r\n}\r\n\r\nexport interface LoopEndState extends ATNBaseState {\r\n    loopback: ATNState\r\n    type: typeof ATN_LOOP_END\r\n}\r\n\r\nexport interface RuleStartState extends ATNBaseState {\r\n    stop: RuleStopState\r\n    type: typeof ATN_RULE_START\r\n}\r\n\r\nexport interface RuleStopState extends ATNBaseState {\r\n    type: typeof ATN_RULE_STOP\r\n}\r\n\r\nexport interface Transition {\r\n    target: ATNState\r\n    isEpsilon(): boolean\r\n}\r\n\r\nexport abstract class AbstractTransition implements Transition {\r\n    target: ATNState\r\n\r\n    constructor(target: ATNState) {\r\n        this.target = target\r\n    }\r\n\r\n    isEpsilon() {\r\n        return false\r\n    }\r\n}\r\n\r\nexport class AtomTransition extends AbstractTransition {\r\n    tokenType: TokenType\r\n\r\n    constructor(target: ATNState, tokenType: TokenType) {\r\n        super(target)\r\n        this.tokenType = tokenType\r\n    }\r\n}\r\n\r\nexport class EpsilonTransition extends AbstractTransition {\r\n    constructor(target: ATNState) {\r\n        super(target)\r\n    }\r\n\r\n    isEpsilon() {\r\n        return true\r\n    }\r\n}\r\n\r\nexport class RuleTransition extends AbstractTransition {\r\n    rule: Rule\r\n    followState: ATNState\r\n\r\n    constructor(ruleStart: RuleStartState, rule: Rule, followState: ATNState) {\r\n        super(ruleStart)\r\n        this.rule = rule\r\n        this.followState = followState\r\n    }\r\n\r\n    isEpsilon() {\r\n        return true\r\n    }\r\n}\r\n\r\ninterface ATNHandle {\r\n    left: ATNState\r\n    right: ATNState\r\n}\r\n\r\nexport function createATN(rules: Rule[]): ATN {\r\n    const atn: ATN = {\r\n        decisionMap: {},\r\n        decisionStates: [],\r\n        ruleToStartState: new Map(),\r\n        ruleToStopState: new Map(),\r\n        states: []\r\n    }\r\n    createRuleStartAndStopATNStates(atn, rules)\r\n    const ruleLength = rules.length\r\n    for (let i = 0; i < ruleLength; i++) {\r\n        const rule = rules[i]\r\n        const ruleBlock = block(atn, rule, rule)\r\n        if (ruleBlock === undefined) {\r\n            continue\r\n        }\r\n        buildRuleHandle(atn, rule, ruleBlock)\r\n    }\r\n    return atn\r\n}\r\n\r\nfunction createRuleStartAndStopATNStates(atn: ATN, rules: Rule[]): void {\r\n    const ruleLength = rules.length\r\n    for (let i = 0; i < ruleLength; i++) {\r\n        const rule = rules[i]\r\n        const start = newState<RuleStartState>(atn, rule, undefined, {\r\n            type: ATN_RULE_START\r\n        })\r\n        const stop = newState<RuleStopState>(atn, rule, undefined, {\r\n            type: ATN_RULE_STOP\r\n        })\r\n        start.stop = stop\r\n        atn.ruleToStartState.set(rule, start)\r\n        atn.ruleToStopState.set(rule, stop)\r\n    }\r\n}\r\n\r\nfunction atom(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    production: IProduction\r\n): ATNHandle | undefined {\r\n    if (production instanceof Terminal) {\r\n        return tokenRef(atn, rule, production.terminalType, production)\r\n    } else if (production instanceof NonTerminal) {\r\n        return ruleRef(atn, rule, production)\r\n    } else if (production instanceof Alternation) {\r\n        return alternation(atn, rule, production)\r\n    } else if (production instanceof Option) {\r\n        return option(atn, rule, production)\r\n    } else if (production instanceof Repetition) {\r\n        return repetition(atn, rule, production)\r\n    } else if (production instanceof RepetitionWithSeparator) {\r\n        return repetitionSep(atn, rule, production)\r\n    } else if (production instanceof RepetitionMandatory) {\r\n        return repetitionMandatory(atn, rule, production)\r\n    } else if (production instanceof RepetitionMandatoryWithSeparator) {\r\n        return repetitionMandatorySep(atn, rule, production)\r\n    } else {\r\n        return block(atn, rule, production as Alternative)\r\n    }\r\n}\r\n\r\nfunction repetition(atn: ATN, rule: Rule, repetition: Repetition): ATNHandle {\r\n    const starState = newState<StarBlockStartState>(atn, rule, repetition, {\r\n        type: ATN_STAR_BLOCK_START\r\n    })\r\n    defineDecisionState(atn, starState)\r\n    const handle = makeAlts(\r\n        atn,\r\n        rule,\r\n        starState,\r\n        repetition,\r\n        block(atn, rule, repetition)\r\n    )\r\n    return star(atn, rule, repetition, handle)\r\n}\r\n\r\nfunction repetitionSep(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    repetition: RepetitionWithSeparator\r\n): ATNHandle {\r\n    const starState = newState<StarBlockStartState>(atn, rule, repetition, {\r\n        type: ATN_STAR_BLOCK_START\r\n    })\r\n    defineDecisionState(atn, starState)\r\n    const handle = makeAlts(\r\n        atn,\r\n        rule,\r\n        starState,\r\n        repetition,\r\n        block(atn, rule, repetition)\r\n    )\r\n    const sep = tokenRef(atn, rule, repetition.separator, repetition)\r\n    return star(atn, rule, repetition, handle, sep)\r\n}\r\n\r\nfunction repetitionMandatory(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    repetition: RepetitionMandatory\r\n): ATNHandle {\r\n    const plusState = newState<PlusBlockStartState>(atn, rule, repetition, {\r\n        type: ATN_PLUS_BLOCK_START\r\n    })\r\n    defineDecisionState(atn, plusState)\r\n    const handle = makeAlts(\r\n        atn,\r\n        rule,\r\n        plusState,\r\n        repetition,\r\n        block(atn, rule, repetition)\r\n    )\r\n    return plus(atn, rule, repetition, handle)\r\n}\r\n\r\nfunction repetitionMandatorySep(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    repetition: RepetitionMandatoryWithSeparator\r\n): ATNHandle {\r\n    const plusState = newState<PlusBlockStartState>(atn, rule, repetition, {\r\n        type: ATN_PLUS_BLOCK_START\r\n    })\r\n    defineDecisionState(atn, plusState)\r\n    const handle = makeAlts(\r\n        atn,\r\n        rule,\r\n        plusState,\r\n        repetition,\r\n        block(atn, rule, repetition)\r\n    )\r\n    const sep = tokenRef(atn, rule, repetition.separator, repetition)\r\n    return plus(atn, rule, repetition, handle, sep)\r\n}\r\n\r\nfunction alternation(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    alternation: Alternation\r\n): ATNHandle {\r\n    const start = newState<BasicBlockStartState>(atn, rule, alternation, {\r\n        type: ATN_BASIC\r\n    })\r\n    defineDecisionState(atn, start)\r\n    const alts = map(alternation.definition, (e) => atom(atn, rule, e))\r\n    const handle = makeAlts(atn, rule, start, alternation, ...alts)\r\n    return handle\r\n}\r\n\r\nfunction option(atn: ATN, rule: Rule, option: Option): ATNHandle {\r\n    const start = newState<BasicBlockStartState>(atn, rule, option, {\r\n        type: ATN_BASIC\r\n    })\r\n    defineDecisionState(atn, start)\r\n    const handle = makeAlts(atn, rule, start, option, block(atn, rule, option))\r\n    return optional(atn, rule, option, handle)\r\n}\r\n\r\nfunction block(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    block: { definition: IProduction[] }\r\n): ATNHandle | undefined {\r\n    const handles = filter(\r\n        map(block.definition, (e) => atom(atn, rule, e)),\r\n        (e) => e !== undefined\r\n    ) as ATNHandle[]\r\n    if (handles.length === 1) {\r\n        return handles[0]\r\n    } else if (handles.length === 0) {\r\n        return undefined\r\n    } else {\r\n        return makeBlock(atn, handles)\r\n    }\r\n}\r\n\r\nfunction plus(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    plus: IProductionWithOccurrence,\r\n    handle: ATNHandle,\r\n    sep?: ATNHandle\r\n): ATNHandle {\r\n    const blkStart = handle.left as PlusBlockStartState\r\n    const blkEnd = handle.right\r\n\r\n    const loop = newState<PlusLoopbackState>(atn, rule, plus, {\r\n        type: ATN_PLUS_LOOP_BACK\r\n    })\r\n    defineDecisionState(atn, loop)\r\n    const end = newState<LoopEndState>(atn, rule, plus, {\r\n        type: ATN_LOOP_END\r\n    })\r\n    blkStart.loopback = loop\r\n    end.loopback = loop\r\n    atn.decisionMap[buildATNKey(rule, sep ? 'RepetitionMandatoryWithSeparator' : 'RepetitionMandatory', plus.idx)] = loop;\r\n    epsilon(blkEnd, loop) // block can see loop back\r\n\r\n    // Depending on whether we have a separator we put the exit transition at index 1 or 0\r\n    // This influences the chosen option in the lookahead DFA\r\n    if (sep === undefined) {\r\n        epsilon(loop, blkStart) // loop back to start\r\n        epsilon(loop, end) // exit\r\n    } else {\r\n        epsilon(loop, end) // exit\r\n        // loop back to start with separator\r\n        epsilon(loop, sep.left)\r\n        epsilon(sep.right, blkStart)\r\n    }\r\n\r\n    return {\r\n        left: blkStart,\r\n        right: end\r\n    }\r\n}\r\n\r\nfunction star(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    star: IProductionWithOccurrence,\r\n    handle: ATNHandle,\r\n    sep?: ATNHandle\r\n): ATNHandle {\r\n    const start = handle.left\r\n    const end = handle.right\r\n\r\n    const entry = newState<StarLoopEntryState>(atn, rule, star, {\r\n        type: ATN_STAR_LOOP_ENTRY\r\n    })\r\n    defineDecisionState(atn, entry)\r\n    const loopEnd = newState<LoopEndState>(atn, rule, star, {\r\n        type: ATN_LOOP_END\r\n    })\r\n    const loop = newState<StarLoopbackState>(atn, rule, star, {\r\n        type: ATN_STAR_LOOP_BACK\r\n    })\r\n    entry.loopback = loop\r\n    loopEnd.loopback = loop\r\n\r\n    epsilon(entry, start) // loop enter edge (alt 2)\r\n    epsilon(entry, loopEnd) // bypass loop edge (alt 1)\r\n    epsilon(end, loop) // block end hits loop back\r\n\r\n    if (sep !== undefined) {\r\n        epsilon(loop, loopEnd) // end loop\r\n        // loop back to start of handle using separator\r\n        epsilon(loop, sep.left)\r\n        epsilon(sep.right, start)\r\n    } else {\r\n        epsilon(loop, entry) // loop back to entry/exit decision\r\n    }\r\n\r\n    atn.decisionMap[buildATNKey(rule, sep ? 'RepetitionWithSeparator' : 'Repetition', star.idx)] = entry;\r\n    return {\r\n        left: entry,\r\n        right: loopEnd\r\n    }\r\n}\r\n\r\nfunction optional(atn: ATN, rule: Rule, optional: Option, handle: ATNHandle): ATNHandle {\r\n    const start = handle.left as DecisionState\r\n    const end = handle.right\r\n\r\n    epsilon(start, end)\r\n\r\n    atn.decisionMap[buildATNKey(rule, 'Option', optional.idx)] = start;\r\n    return handle\r\n}\r\n\r\nfunction defineDecisionState(atn: ATN, state: DecisionState): number {\r\n    atn.decisionStates.push(state)\r\n    state.decision = atn.decisionStates.length - 1\r\n    return state.decision\r\n}\r\n\r\nfunction makeAlts(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    start: BlockStartState,\r\n    production: IProductionWithOccurrence,\r\n    ...alts: (ATNHandle | undefined)[]\r\n): ATNHandle {\r\n    const end = newState<BlockEndState>(atn, rule, production, {\r\n        type: ATN_BLOCK_END,\r\n        start\r\n    })\r\n    start.end = end\r\n    for (const alt of alts) {\r\n        if (alt !== undefined) {\r\n            // hook alts up to decision block\r\n            epsilon(start, alt.left)\r\n            epsilon(alt.right, end)\r\n        } else {\r\n            epsilon(start, end)\r\n        }\r\n    }\r\n\r\n    const handle: ATNHandle = {\r\n        left: start as ATNState,\r\n        right: end\r\n    }\r\n    atn.decisionMap[buildATNKey(rule, getProdType(production), production.idx)] = start\r\n    return handle\r\n}\r\n\r\nfunction getProdType(production: IProduction): LookaheadProductionType {\r\n    if (production instanceof Alternation) {\r\n        return 'Alternation';\r\n    } else if (production instanceof Option) {\r\n        return 'Option';\r\n    } else if (production instanceof Repetition) {\r\n        return 'Repetition';\r\n    } else if (production instanceof RepetitionWithSeparator) {\r\n        return 'RepetitionWithSeparator';\r\n    } else if (production instanceof RepetitionMandatory) {\r\n        return 'RepetitionMandatory';\r\n    } else if (production instanceof RepetitionMandatoryWithSeparator) {\r\n        return 'RepetitionMandatoryWithSeparator';\r\n    } else {\r\n        throw new Error('Invalid production type encountered');\r\n    }\r\n}\r\n\r\nfunction makeBlock(atn: ATN, alts: ATNHandle[]): ATNHandle {\r\n    const altsLength = alts.length\r\n    for (let i = 0; i < altsLength - 1; i++) {\r\n        const handle = alts[i]\r\n        let transition: Transition | undefined\r\n        if (handle.left.transitions.length === 1) {\r\n            transition = handle.left.transitions[0]\r\n        }\r\n        const isRuleTransition = transition instanceof RuleTransition\r\n        const ruleTransition = transition as RuleTransition\r\n        const next = alts[i + 1].left\r\n        if (\r\n            handle.left.type === ATN_BASIC &&\r\n            handle.right.type === ATN_BASIC &&\r\n            transition !== undefined &&\r\n            ((isRuleTransition && ruleTransition.followState === handle.right) ||\r\n                transition.target === handle.right)\r\n        ) {\r\n            // we can avoid epsilon edge to next element\r\n            if (isRuleTransition) {\r\n                ruleTransition.followState = next\r\n            } else {\r\n                transition.target = next\r\n            }\r\n            removeState(atn, handle.right) // we skipped over this state\r\n        } else {\r\n            // need epsilon if previous block's right end node is complex\r\n            epsilon(handle.right, next)\r\n        }\r\n    }\r\n\r\n    const first = alts[0]\r\n    const last = alts[altsLength - 1]\r\n    return {\r\n        left: first.left,\r\n        right: last.right\r\n    }\r\n}\r\n\r\nfunction tokenRef(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    tokenType: TokenType,\r\n    production: IProductionWithOccurrence\r\n): ATNHandle {\r\n    const left = newState<BasicState>(atn, rule, production, {\r\n        type: ATN_BASIC\r\n    })\r\n    const right = newState<BasicState>(atn, rule, production, {\r\n        type: ATN_BASIC\r\n    })\r\n    addTransition(left, new AtomTransition(right, tokenType))\r\n    return {\r\n        left,\r\n        right\r\n    }\r\n}\r\n\r\nfunction ruleRef(\r\n    atn: ATN,\r\n    currentRule: Rule,\r\n    nonTerminal: NonTerminal\r\n): ATNHandle {\r\n    const rule = nonTerminal.referencedRule\r\n    const start = atn.ruleToStartState.get(rule)!\r\n    const left = newState<BasicBlockStartState>(atn, currentRule, nonTerminal, {\r\n        type: ATN_BASIC\r\n    })\r\n    const right = newState<BasicBlockStartState>(atn, currentRule, nonTerminal, {\r\n        type: ATN_BASIC\r\n    })\r\n\r\n    const call = new RuleTransition(start, rule, right)\r\n    addTransition(left, call)\r\n\r\n    return {\r\n        left,\r\n        right\r\n    }\r\n}\r\n\r\nfunction buildRuleHandle(atn: ATN, rule: Rule, block: ATNHandle): ATNHandle {\r\n    const start = atn.ruleToStartState.get(rule)!\r\n    epsilon(start, block.left)\r\n    const stop = atn.ruleToStopState.get(rule)!\r\n    epsilon(block.right, stop)\r\n    const handle: ATNHandle = {\r\n        left: start,\r\n        right: stop\r\n    }\r\n    return handle\r\n}\r\n\r\nfunction epsilon(a: ATNBaseState, b: ATNBaseState): void {\r\n    const transition = new EpsilonTransition(b as ATNState)\r\n    addTransition(a, transition)\r\n}\r\n\r\nfunction newState<T extends ATNState>(\r\n    atn: ATN,\r\n    rule: Rule,\r\n    production: IProductionWithOccurrence | undefined,\r\n    partial: Partial<T>\r\n): T {\r\n    const t: T = {\r\n        atn,\r\n        production,\r\n        epsilonOnlyTransitions: false,\r\n        rule,\r\n        transitions: [],\r\n        nextTokenWithinRule: [],\r\n        stateNumber: atn.states.length,\r\n        ...partial\r\n    } as unknown as T\r\n    atn.states.push(t)\r\n    return t\r\n}\r\n\r\nfunction addTransition(state: ATNBaseState, transition: Transition) {\r\n    // A single ATN state can only contain epsilon transitions or non-epsilon transitions\r\n    // Because they are never mixed, only setting the property for the first transition is fine\r\n    if (state.transitions.length === 0) {\r\n        state.epsilonOnlyTransitions = transition.isEpsilon()\r\n    }\r\n    state.transitions.push(transition)\r\n}\r\n\r\nfunction removeState(atn: ATN, state: ATNState): void {\r\n    atn.states.splice(atn.states.indexOf(state), 1)\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport map from \"lodash-es/map.js\"\r\nimport { ATNState, DecisionState } from \"./atn.js\"\r\n\r\nexport interface DFA {\r\n  start?: DFAState\r\n  states: Record<string, DFAState>\r\n  decision: number\r\n  atnStartState: DecisionState\r\n}\r\n\r\nexport interface DFAState {\r\n  configs: ATNConfigSet\r\n  edges: Record<number, DFAState>\r\n  isAcceptState: boolean\r\n  prediction: number\r\n}\r\n\r\nexport const DFA_ERROR = {} as DFAState\r\n\r\nexport interface ATNConfig {\r\n  state: ATNState\r\n  alt: number\r\n  stack: ATNState[]\r\n}\r\n\r\nexport class ATNConfigSet {\r\n  private map: Record<string, number> = {}\r\n  private configs: ATNConfig[] = []\r\n\r\n  uniqueAlt: number | undefined\r\n\r\n  get size(): number {\r\n    return this.configs.length\r\n  }\r\n\r\n  finalize(): void {\r\n    // Empties the map to free up memory\r\n    this.map = {}\r\n  }\r\n\r\n  add(config: ATNConfig): void {\r\n    const key = getATNConfigKey(config)\r\n    // Only add configs which don't exist in our map already\r\n    // While this does not influence the actual algorithm, adding them anyway would massively increase memory consumption\r\n    if (!(key in this.map)) {\r\n      this.map[key] = this.configs.length\r\n      this.configs.push(config)\r\n    }\r\n  }\r\n\r\n  get elements(): readonly ATNConfig[] {\r\n    return this.configs\r\n  }\r\n\r\n  get alts(): number[] {\r\n    return map(this.configs, (e) => e.alt)\r\n  }\r\n\r\n  get key(): string {\r\n    let value = \"\"\r\n    for (const k in this.map) {\r\n      value += k + \":\"\r\n    }\r\n    return value\r\n  }\r\n}\r\n\r\nexport function getATNConfigKey(config: ATNConfig, alt = true) {\r\n  return `${alt ? `a${config.alt}` : \"\"}s${\r\n    config.state.stateNumber\r\n  }:${config.stack.map((e) => e.stateNumber.toString()).join(\"_\")}`\r\n}\r\n","import baseIteratee from './_baseIteratee.js';\nimport baseUniq from './_baseUniq.js';\n\n/**\n * This method is like `_.uniq` except that it accepts `iteratee` which is\n * invoked for each element in `array` to generate the criterion by which\n * uniqueness is computed. The order of result values is determined by the\n * order they occur in the array. The iteratee is invoked with one argument:\n * (value).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {Function} [iteratee=_.identity] The iteratee invoked per element.\n * @returns {Array} Returns the new duplicate free array.\n * @example\n *\n * _.uniqBy([2.1, 1.2, 2.3], Math.floor);\n * // => [2.1, 1.2]\n *\n * // The `_.property` iteratee shorthand.\n * _.uniqBy([{ 'x': 1 }, { 'x': 2 }, { 'x': 1 }], 'x');\n * // => [{ 'x': 1 }, { 'x': 2 }]\n */\nfunction uniqBy(array, iteratee) {\n  return (array && array.length) ? baseUniq(array, baseIteratee(iteratee, 2)) : [];\n}\n\nexport default uniqBy;\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport {\r\n    IToken,\r\n    TokenType,\r\n    tokenMatcher,\r\n    tokenLabel,\r\n    Rule,\r\n    IProductionWithOccurrence,\r\n    NonTerminal,\r\n    Alternation,\r\n    Option,\r\n    RepetitionMandatory,\r\n    RepetitionMandatoryWithSeparator,\r\n    RepetitionWithSeparator,\r\n    Repetition,\r\n    Terminal,\r\n    BaseParser,\r\n    LLkLookaheadStrategy,\r\n    ILookaheadValidationError,\r\n    IOrAlt,\r\n    getLookaheadPaths,\r\n    OptionalProductionType\r\n} from \"chevrotain\";\r\nimport {\r\n    ATN,\r\n    ATNState,\r\n    ATN_RULE_STOP,\r\n    AtomTransition,\r\n    buildATNKey,\r\n    createATN,\r\n    DecisionState,\r\n    EpsilonTransition,\r\n    RuleTransition,\r\n    Transition\r\n} from \"./atn.js\";\r\nimport {\r\n    ATNConfig,\r\n    ATNConfigSet,\r\n    DFA,\r\n    DFAState,\r\n    DFA_ERROR,\r\n    getATNConfigKey\r\n} from \"./dfa.js\";\r\nimport min from \"lodash-es/min.js\";\r\nimport flatMap from \"lodash-es/flatMap.js\";\r\nimport uniqBy from \"lodash-es/uniqBy.js\";\r\nimport map from \"lodash-es/map.js\";\r\nimport flatten from \"lodash-es/flatten.js\";\r\nimport forEach from \"lodash-es/forEach.js\";\r\nimport isEmpty from \"lodash-es/isEmpty.js\";\r\nimport reduce from \"lodash-es/reduce.js\";\r\n\r\ntype DFACache = (predicateSet: PredicateSet) => DFA\r\n\r\nexport type AmbiguityReport = (message: string) => void;\r\n\r\nfunction createDFACache(startState: DecisionState, decision: number): DFACache {\r\n    const map: Record<string, DFA | undefined> = {}\r\n    return (predicateSet) => {\r\n        const key = predicateSet.toString()\r\n        let existing = map[key]\r\n        if (existing !== undefined) {\r\n            return existing\r\n        } else {\r\n            existing = {\r\n                atnStartState: startState,\r\n                decision,\r\n                states: {}\r\n            }\r\n            map[key] = existing\r\n            return existing\r\n        }\r\n    }\r\n}\r\n\r\nclass PredicateSet {\r\n    private predicates: boolean[] = []\r\n\r\n    is(index: number): boolean {\r\n        return index >= this.predicates.length || this.predicates[index]\r\n    }\r\n\r\n    set(index: number, value: boolean) {\r\n        this.predicates[index] = value\r\n    }\r\n\r\n    toString(): string {\r\n        let value = \"\"\r\n        const size = this.predicates.length\r\n        for (let i = 0; i < size; i++) {\r\n            value += this.predicates[i] === true ? \"1\" : \"0\"\r\n        }\r\n        return value\r\n    }\r\n}\r\n\r\ninterface AdaptivePredictError {\r\n    tokenPath: IToken[]\r\n    possibleTokenTypes: TokenType[]\r\n    actualToken: IToken\r\n}\r\n\r\nconst EMPTY_PREDICATES = new PredicateSet()\r\n\r\nexport interface LLStarLookaheadOptions {\r\n    logging?: AmbiguityReport\r\n}\r\n\r\nexport class LLStarLookaheadStrategy extends LLkLookaheadStrategy {\r\n\r\n    private atn: ATN;\r\n    private dfas: DFACache[];\r\n    private logging: AmbiguityReport;\r\n\r\n    constructor(options?: LLStarLookaheadOptions) {\r\n        super();\r\n        this.logging = options?.logging ?? ((message) => console.log(message));\r\n    }\r\n\r\n    override initialize(options: { rules: Rule[] }): void {\r\n        this.atn = createATN(options.rules);\r\n        this.dfas = initATNSimulator(this.atn);\r\n    }\r\n\r\n    override validateAmbiguousAlternationAlternatives(): ILookaheadValidationError[] {\r\n        return [];\r\n    }\r\n\r\n    override validateEmptyOrAlternatives(): ILookaheadValidationError[] {\r\n        return [];\r\n    }\r\n\r\n    override buildLookaheadForAlternation(options: {\r\n        prodOccurrence: number;\r\n        rule: Rule;\r\n        maxLookahead: number;\r\n        hasPredicates: boolean;\r\n        dynamicTokensEnabled: boolean\r\n    }): (this: BaseParser, orAlts?: IOrAlt<any>[] | undefined) => number | undefined {\r\n        const { prodOccurrence, rule, hasPredicates, dynamicTokensEnabled } = options;\r\n        const dfas = this.dfas;\r\n        const logging = this.logging;\r\n        const key = buildATNKey(rule, 'Alternation', prodOccurrence);\r\n        const decisionState = this.atn.decisionMap[key];\r\n        const decisionIndex = decisionState.decision;\r\n        const partialAlts: (TokenType | undefined)[][] = map(\r\n            getLookaheadPaths({\r\n                maxLookahead: 1,\r\n                occurrence: prodOccurrence,\r\n                prodType: \"Alternation\",\r\n                rule: rule\r\n            }),\r\n            (currAlt) => map(currAlt, (path) => path[0])\r\n        )\r\n\r\n        if (isLL1Sequence(partialAlts, false) && !dynamicTokensEnabled) {\r\n            const choiceToAlt = reduce(\r\n                partialAlts,\r\n                (result, currAlt, idx) => {\r\n                    forEach(currAlt, (currTokType) => {\r\n                        if (currTokType) {\r\n                            result[currTokType.tokenTypeIdx!] = idx\r\n                            forEach(currTokType.categoryMatches!, (currExtendingType) => {\r\n                                result[currExtendingType] = idx\r\n                            })\r\n                        }\r\n                    })\r\n                    return result\r\n                },\r\n                {} as Record<number, number>\r\n            )\r\n\r\n            if (hasPredicates) {\r\n                return function (this: BaseParser, orAlts) {\r\n                    const nextToken = this.LA(1)\r\n                    const prediction: number | undefined = choiceToAlt[nextToken.tokenTypeIdx]\r\n                    if (orAlts !== undefined && prediction !== undefined) {\r\n                        const gate = orAlts[prediction]?.GATE\r\n                        if (gate !== undefined && gate.call(this) === false) {\r\n                            return undefined;\r\n                        }\r\n                    }\r\n                    return prediction\r\n                }\r\n            } else {\r\n                return function (this: BaseParser): number | undefined {\r\n                    const nextToken = this.LA(1)\r\n                    return choiceToAlt[nextToken.tokenTypeIdx];\r\n                }\r\n            }\r\n        } else if (hasPredicates) {\r\n            return function (this: BaseParser, orAlts) {\r\n                const predicates = new PredicateSet()\r\n                const length = orAlts === undefined ? 0 : orAlts.length\r\n                for (let i = 0; i < length; i++) {\r\n                    const gate = orAlts?.[i].GATE\r\n                    predicates.set(i, gate === undefined || gate.call(this))\r\n                }\r\n                const result = adaptivePredict.call(this, dfas, decisionIndex, predicates, logging);\r\n                return typeof result === 'number' ? result : undefined;\r\n            }\r\n        } else {\r\n            return function (this: BaseParser) {\r\n                const result = adaptivePredict.call(this, dfas, decisionIndex, EMPTY_PREDICATES, logging);\r\n                return typeof result === 'number' ? result : undefined;\r\n            }\r\n        }\r\n    }\r\n\r\n    override buildLookaheadForOptional(options: {\r\n        prodOccurrence: number;\r\n        prodType: OptionalProductionType;\r\n        rule: Rule;\r\n        maxLookahead: number;\r\n        dynamicTokensEnabled: boolean\r\n    }): (this: BaseParser) => boolean {\r\n        const { prodOccurrence, rule, prodType, dynamicTokensEnabled } = options;\r\n        const dfas = this.dfas;\r\n        const logging = this.logging;\r\n        const key = buildATNKey(rule, prodType, prodOccurrence);\r\n        const decisionState = this.atn.decisionMap[key];\r\n        const decisionIndex = decisionState.decision;\r\n        const alts = map(\r\n            getLookaheadPaths({\r\n                maxLookahead: 1,\r\n                occurrence: prodOccurrence,\r\n                prodType,\r\n                rule\r\n            }),\r\n            (e) => {\r\n              return map(e, (g) => g[0])\r\n            }\r\n          )\r\n        \r\n          if (isLL1Sequence(alts) && alts[0][0] && !dynamicTokensEnabled) {\r\n            const alt = alts[0]\r\n            const singleTokensTypes = flatten(alt)\r\n        \r\n            if (\r\n              singleTokensTypes.length === 1 &&\r\n              isEmpty(singleTokensTypes[0].categoryMatches)\r\n            ) {\r\n              const expectedTokenType = singleTokensTypes[0]\r\n              const expectedTokenUniqueKey = expectedTokenType.tokenTypeIdx\r\n        \r\n              return function (this: BaseParser): boolean {\r\n                return this.LA(1).tokenTypeIdx === expectedTokenUniqueKey\r\n              }\r\n            } else {\r\n              const choiceToAlt = reduce(\r\n                singleTokensTypes,\r\n                (result, currTokType) => {\r\n                  if (currTokType !== undefined) {\r\n                    result[currTokType.tokenTypeIdx!] = true\r\n                    forEach(currTokType.categoryMatches, (currExtendingType) => {\r\n                      result[currExtendingType] = true\r\n                    })\r\n                  }\r\n                  return result\r\n                },\r\n                {} as Record<number, boolean>\r\n              )\r\n        \r\n              return function (this: BaseParser): boolean {\r\n                const nextToken = this.LA(1)\r\n                return choiceToAlt[nextToken.tokenTypeIdx] === true\r\n              }\r\n            }\r\n          }\r\n          return function (this: BaseParser) {\r\n            const result = adaptivePredict.call(this, dfas, decisionIndex, EMPTY_PREDICATES, logging)\r\n              return typeof result === \"object\" ? false : result === 0;\r\n          }\r\n    }\r\n\r\n}\r\n\r\nfunction isLL1Sequence(sequences: (TokenType | undefined)[][], allowEmpty = true): boolean {\r\n    const fullSet = new Set<number>()\r\n\r\n    for (const alt of sequences) {\r\n        const altSet = new Set<number>()\r\n        for (const tokType of alt) {\r\n            if (tokType === undefined) {\r\n                if (allowEmpty) {\r\n                    // Epsilon production encountered\r\n                    break\r\n                } else {\r\n                    return false;\r\n                }\r\n            }\r\n            const indices = [tokType.tokenTypeIdx!].concat(tokType.categoryMatches!)\r\n            for (const index of indices) {\r\n                if (fullSet.has(index)) {\r\n                    if (!altSet.has(index)) {\r\n                        return false\r\n                    }\r\n                } else {\r\n                    fullSet.add(index)\r\n                    altSet.add(index)\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return true\r\n}\r\n\r\nfunction initATNSimulator(atn: ATN): DFACache[] {\r\n    const decisionLength = atn.decisionStates.length\r\n    const decisionToDFA: DFACache[] = Array(decisionLength)\r\n    for (let i = 0; i < decisionLength; i++) {\r\n        decisionToDFA[i] = createDFACache(atn.decisionStates[i], i)\r\n    }\r\n    return decisionToDFA;\r\n}\r\n\r\nfunction adaptivePredict(\r\n    this: BaseParser,\r\n    dfaCaches: DFACache[],\r\n    decision: number,\r\n    predicateSet: PredicateSet,\r\n    logging: AmbiguityReport\r\n): number | AdaptivePredictError {\r\n    const dfa = dfaCaches[decision](predicateSet)\r\n    let start = dfa.start\r\n    if (start === undefined) {\r\n        const closure = computeStartState(dfa.atnStartState as ATNState)\r\n        start = addDFAState(dfa, newDFAState(closure))\r\n        dfa.start = start\r\n    }\r\n\r\n    const alt = performLookahead.apply(this, [dfa, start, predicateSet, logging])\r\n    return alt\r\n}\r\n\r\nfunction performLookahead(\r\n    this: BaseParser,\r\n    dfa: DFA,\r\n    s0: DFAState,\r\n    predicateSet: PredicateSet,\r\n    logging: AmbiguityReport\r\n): number | AdaptivePredictError {\r\n    let previousD = s0\r\n\r\n    let i = 1\r\n    const path: IToken[] = []\r\n    let t = this.LA(i++)\r\n\r\n    while (true) {\r\n        let d = getExistingTargetState(previousD, t)\r\n        if (d === undefined) {\r\n            d = computeLookaheadTarget.apply(this, [dfa, previousD, t, i, predicateSet, logging])\r\n        }\r\n\r\n        if (d === DFA_ERROR) {\r\n            return buildAdaptivePredictError(path, previousD, t)\r\n        }\r\n\r\n        if (d.isAcceptState === true) {\r\n            return d.prediction\r\n        }\r\n\r\n        previousD = d\r\n        path.push(t)\r\n        t = this.LA(i++)\r\n    }\r\n}\r\n\r\nfunction computeLookaheadTarget(\r\n    this: BaseParser,\r\n    dfa: DFA,\r\n    previousD: DFAState,\r\n    token: IToken,\r\n    lookahead: number,\r\n    predicateSet: PredicateSet,\r\n    logging: AmbiguityReport\r\n): DFAState {\r\n    const reach = computeReachSet(previousD.configs, token, predicateSet)\r\n    if (reach.size === 0) {\r\n        addDFAEdge(dfa, previousD, token, DFA_ERROR)\r\n        return DFA_ERROR\r\n    }\r\n\r\n    let newState = newDFAState(reach)\r\n    const predictedAlt = getUniqueAlt(reach, predicateSet)\r\n\r\n    if (predictedAlt !== undefined) {\r\n        newState.isAcceptState = true\r\n        newState.prediction = predictedAlt\r\n        newState.configs.uniqueAlt = predictedAlt\r\n    } else if (hasConflictTerminatingPrediction(reach)) {\r\n        const prediction = min(reach.alts)!\r\n        newState.isAcceptState = true\r\n        newState.prediction = prediction\r\n        newState.configs.uniqueAlt = prediction\r\n        reportLookaheadAmbiguity.apply(this, [dfa, lookahead, reach.alts, logging])\r\n    }\r\n\r\n    newState = addDFAEdge(dfa, previousD, token, newState)\r\n    return newState\r\n}\r\n\r\nfunction reportLookaheadAmbiguity(\r\n    this: BaseParser,\r\n    dfa: DFA,\r\n    lookahead: number,\r\n    ambiguityIndices: number[],\r\n    logging: AmbiguityReport\r\n) {\r\n    const prefixPath: TokenType[] = []\r\n    for (let i = 1; i <= lookahead; i++) {\r\n        prefixPath.push(this.LA(i).tokenType)\r\n    }\r\n    const atnState = dfa.atnStartState\r\n    const topLevelRule = atnState.rule\r\n    const production = atnState.production\r\n    const message = buildAmbiguityError({\r\n        topLevelRule,\r\n        ambiguityIndices,\r\n        production,\r\n        prefixPath\r\n    })\r\n    logging(message)\r\n}\r\n\r\nfunction buildAmbiguityError(options: {\r\n    topLevelRule: Rule\r\n    prefixPath: TokenType[]\r\n    ambiguityIndices: number[]\r\n    production: IProductionWithOccurrence\r\n}): string {\r\n    const pathMsg = map(options.prefixPath, (currtok) =>\r\n        tokenLabel(currtok)\r\n    ).join(\", \")\r\n    const occurrence =\r\n        options.production.idx === 0 ? \"\" : options.production.idx\r\n    let currMessage =\r\n        `Ambiguous Alternatives Detected: <${options.ambiguityIndices.join(\r\n            \", \"\r\n        )}> in <${getProductionDslName(options.production)}${occurrence}>` +\r\n        ` inside <${options.topLevelRule.name}> Rule,\\n` +\r\n        `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n`\r\n\r\n    currMessage =\r\n        currMessage +\r\n        `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#AMBIGUOUS_ALTERNATIVES\\n` +\r\n        `For Further details.`\r\n    return currMessage\r\n}\r\n\r\nfunction getProductionDslName(prod: IProductionWithOccurrence): string {\r\n    if (prod instanceof NonTerminal) {\r\n        return \"SUBRULE\"\r\n    } else if (prod instanceof Option) {\r\n        return \"OPTION\"\r\n    } else if (prod instanceof Alternation) {\r\n        return \"OR\"\r\n    } else if (prod instanceof RepetitionMandatory) {\r\n        return \"AT_LEAST_ONE\"\r\n    } else if (prod instanceof RepetitionMandatoryWithSeparator) {\r\n        return \"AT_LEAST_ONE_SEP\"\r\n    } else if (prod instanceof RepetitionWithSeparator) {\r\n        return \"MANY_SEP\"\r\n    } else if (prod instanceof Repetition) {\r\n        return \"MANY\"\r\n    } else if (prod instanceof Terminal) {\r\n        return \"CONSUME\"\r\n    } else {\r\n        throw Error(\"non exhaustive match\")\r\n    }\r\n}\r\n\r\nfunction buildAdaptivePredictError(\r\n    path: IToken[],\r\n    previous: DFAState,\r\n    current: IToken\r\n): AdaptivePredictError {\r\n    const nextTransitions = flatMap(\r\n        previous.configs.elements,\r\n        (e) => e.state.transitions\r\n    )\r\n    const nextTokenTypes = uniqBy(\r\n        nextTransitions\r\n            .filter((e): e is AtomTransition => e instanceof AtomTransition)\r\n            .map((e) => e.tokenType),\r\n        (e) => e.tokenTypeIdx\r\n    )\r\n    return {\r\n        actualToken: current,\r\n        possibleTokenTypes: nextTokenTypes,\r\n        tokenPath: path\r\n    }\r\n}\r\n\r\nfunction getExistingTargetState(\r\n    state: DFAState,\r\n    token: IToken\r\n): DFAState | undefined {\r\n    return state.edges[token.tokenTypeIdx]\r\n}\r\n\r\nfunction computeReachSet(\r\n    configs: ATNConfigSet,\r\n    token: IToken,\r\n    predicateSet: PredicateSet\r\n): ATNConfigSet {\r\n    const intermediate = new ATNConfigSet()\r\n    const skippedStopStates: ATNConfig[] = []\r\n\r\n    for (const c of configs.elements) {\r\n        if (predicateSet.is(c.alt) === false) {\r\n            continue\r\n        }\r\n        if (c.state.type === ATN_RULE_STOP) {\r\n            skippedStopStates.push(c)\r\n            continue\r\n        }\r\n        const transitionLength = c.state.transitions.length\r\n        for (let i = 0; i < transitionLength; i++) {\r\n            const transition = c.state.transitions[i]\r\n            const target = getReachableTarget(transition, token)\r\n            if (target !== undefined) {\r\n                intermediate.add({\r\n                    state: target,\r\n                    alt: c.alt,\r\n                    stack: c.stack\r\n                })\r\n            }\r\n        }\r\n    }\r\n\r\n    let reach: ATNConfigSet | undefined\r\n\r\n    if (skippedStopStates.length === 0 && intermediate.size === 1) {\r\n        reach = intermediate\r\n    }\r\n\r\n    if (reach === undefined) {\r\n        reach = new ATNConfigSet()\r\n        for (const c of intermediate.elements) {\r\n            closure(c, reach)\r\n        }\r\n    }\r\n\r\n    if (skippedStopStates.length > 0 && !hasConfigInRuleStopState(reach)) {\r\n        for (const c of skippedStopStates) {\r\n            reach.add(c)\r\n        }\r\n    }\r\n\r\n    return reach\r\n}\r\n\r\nfunction getReachableTarget(\r\n    transition: Transition,\r\n    token: IToken\r\n): ATNState | undefined {\r\n    if (\r\n        transition instanceof AtomTransition &&\r\n        tokenMatcher(token, transition.tokenType)\r\n    ) {\r\n        return transition.target\r\n    }\r\n    return undefined\r\n}\r\n\r\nfunction getUniqueAlt(\r\n    configs: ATNConfigSet,\r\n    predicateSet: PredicateSet\r\n): number | undefined {\r\n    let alt: number | undefined\r\n    for (const c of configs.elements) {\r\n        if (predicateSet.is(c.alt) === true) {\r\n            if (alt === undefined) {\r\n                alt = c.alt\r\n            } else if (alt !== c.alt) {\r\n                return undefined\r\n            }\r\n        }\r\n    }\r\n    return alt\r\n}\r\n\r\nfunction newDFAState(closure: ATNConfigSet): DFAState {\r\n    return {\r\n        configs: closure,\r\n        edges: {},\r\n        isAcceptState: false,\r\n        prediction: -1\r\n    }\r\n}\r\n\r\nfunction addDFAEdge(\r\n    dfa: DFA,\r\n    from: DFAState,\r\n    token: IToken,\r\n    to: DFAState\r\n): DFAState {\r\n    to = addDFAState(dfa, to)\r\n    from.edges[token.tokenTypeIdx] = to\r\n    return to\r\n}\r\n\r\nfunction addDFAState(dfa: DFA, state: DFAState): DFAState {\r\n    if (state === DFA_ERROR) {\r\n        return state\r\n    }\r\n    // Repetitions have the same config set\r\n    // Therefore, storing the key of the config in a map allows us to create a loop in our DFA\r\n    const mapKey = state.configs.key\r\n    const existing = dfa.states[mapKey]\r\n    if (existing !== undefined) {\r\n        return existing\r\n    }\r\n    state.configs.finalize()\r\n    dfa.states[mapKey] = state\r\n    return state\r\n}\r\n\r\nfunction computeStartState(atnState: ATNState): ATNConfigSet {\r\n    const configs = new ATNConfigSet()\r\n\r\n    const numberOfTransitions = atnState.transitions.length\r\n    for (let i = 0; i < numberOfTransitions; i++) {\r\n        const target = atnState.transitions[i].target\r\n        const config: ATNConfig = {\r\n            state: target,\r\n            alt: i,\r\n            stack: []\r\n        }\r\n        closure(config, configs)\r\n    }\r\n\r\n    return configs\r\n}\r\n\r\nfunction closure(config: ATNConfig, configs: ATNConfigSet): void {\r\n    const p = config.state\r\n\r\n    if (p.type === ATN_RULE_STOP) {\r\n        if (config.stack.length > 0) {\r\n            const atnStack = [...config.stack]\r\n            const followState = atnStack.pop()!\r\n            const followConfig: ATNConfig = {\r\n                state: followState,\r\n                alt: config.alt,\r\n                stack: atnStack\r\n            }\r\n            closure(followConfig, configs)\r\n        } else {\r\n            // Dipping into outer context, simply add the config\r\n            // This will stop computation once every config is at the rule stop state\r\n            configs.add(config)\r\n        }\r\n        return\r\n    }\r\n\r\n    if (!p.epsilonOnlyTransitions) {\r\n        configs.add(config)\r\n    }\r\n\r\n    const transitionLength = p.transitions.length\r\n    for (let i = 0; i < transitionLength; i++) {\r\n        const transition = p.transitions[i]\r\n        const c = getEpsilonTarget(config, transition)\r\n\r\n        if (c !== undefined) {\r\n            closure(c, configs)\r\n        }\r\n    }\r\n}\r\n\r\nfunction getEpsilonTarget(\r\n    config: ATNConfig,\r\n    transition: Transition\r\n): ATNConfig | undefined {\r\n    if (transition instanceof EpsilonTransition) {\r\n        return {\r\n            state: transition.target,\r\n            alt: config.alt,\r\n            stack: config.stack\r\n        }\r\n    } else if (transition instanceof RuleTransition) {\r\n        const stack = [...config.stack, transition.followState]\r\n        return {\r\n            state: transition.target,\r\n            alt: config.alt,\r\n            stack\r\n        }\r\n    }\r\n    return undefined\r\n}\r\n\r\nfunction hasConfigInRuleStopState(configs: ATNConfigSet): boolean {\r\n    for (const c of configs.elements) {\r\n        if (c.state.type === ATN_RULE_STOP) {\r\n            return true\r\n        }\r\n    }\r\n    return false\r\n}\r\n\r\nfunction allConfigsInRuleStopStates(configs: ATNConfigSet): boolean {\r\n    for (const c of configs.elements) {\r\n        if (c.state.type !== ATN_RULE_STOP) {\r\n            return false\r\n        }\r\n    }\r\n    return true\r\n}\r\n\r\nfunction hasConflictTerminatingPrediction(configs: ATNConfigSet): boolean {\r\n    if (allConfigsInRuleStopStates(configs)) {\r\n        return true\r\n    }\r\n    const altSets = getConflictingAltSets(configs.elements)\r\n    const heuristic =\r\n        hasConflictingAltSet(altSets) && !hasStateAssociatedWithOneAlt(altSets)\r\n    return heuristic\r\n}\r\n\r\nfunction getConflictingAltSets(\r\n    configs: readonly ATNConfig[]\r\n): Map<string, Record<number, boolean>> {\r\n    const configToAlts = new Map<string, Record<number, boolean>>()\r\n    for (const c of configs) {\r\n        const key = getATNConfigKey(c, false)\r\n        let alts = configToAlts.get(key)\r\n        if (alts === undefined) {\r\n            alts = {}\r\n            configToAlts.set(key, alts)\r\n        }\r\n        alts[c.alt] = true\r\n    }\r\n    return configToAlts\r\n}\r\n\r\nfunction hasConflictingAltSet(\r\n    altSets: Map<string, Record<number, boolean>>\r\n): boolean {\r\n    for (const value of Array.from(altSets.values())) {\r\n        if (Object.keys(value).length > 1) {\r\n            return true\r\n        }\r\n    }\r\n    return false\r\n}\r\n\r\nfunction hasStateAssociatedWithOneAlt(\r\n    altSets: Map<string, Record<number, boolean>>\r\n): boolean {\r\n    for (const value of Array.from(altSets.values())) {\r\n        if (Object.keys(value).length === 1) {\r\n            return true\r\n        }\r\n    }\r\n    return false\r\n}\r\n","/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\n'use strict';\nexport var DocumentUri;\n(function (DocumentUri) {\n    function is(value) {\n        return typeof value === 'string';\n    }\n    DocumentUri.is = is;\n})(DocumentUri || (DocumentUri = {}));\nexport var URI;\n(function (URI) {\n    function is(value) {\n        return typeof value === 'string';\n    }\n    URI.is = is;\n})(URI || (URI = {}));\nexport var integer;\n(function (integer) {\n    integer.MIN_VALUE = -2147483648;\n    integer.MAX_VALUE = 2147483647;\n    function is(value) {\n        return typeof value === 'number' && integer.MIN_VALUE <= value && value <= integer.MAX_VALUE;\n    }\n    integer.is = is;\n})(integer || (integer = {}));\nexport var uinteger;\n(function (uinteger) {\n    uinteger.MIN_VALUE = 0;\n    uinteger.MAX_VALUE = 2147483647;\n    function is(value) {\n        return typeof value === 'number' && uinteger.MIN_VALUE <= value && value <= uinteger.MAX_VALUE;\n    }\n    uinteger.is = is;\n})(uinteger || (uinteger = {}));\n/**\n * The Position namespace provides helper functions to work with\n * {@link Position} literals.\n */\nexport var Position;\n(function (Position) {\n    /**\n     * Creates a new Position literal from the given line and character.\n     * @param line The position's line.\n     * @param character The position's character.\n     */\n    function create(line, character) {\n        if (line === Number.MAX_VALUE) {\n            line = uinteger.MAX_VALUE;\n        }\n        if (character === Number.MAX_VALUE) {\n            character = uinteger.MAX_VALUE;\n        }\n        return { line, character };\n    }\n    Position.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Position} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Is.uinteger(candidate.line) && Is.uinteger(candidate.character);\n    }\n    Position.is = is;\n})(Position || (Position = {}));\n/**\n * The Range namespace provides helper functions to work with\n * {@link Range} literals.\n */\nexport var Range;\n(function (Range) {\n    function create(one, two, three, four) {\n        if (Is.uinteger(one) && Is.uinteger(two) && Is.uinteger(three) && Is.uinteger(four)) {\n            return { start: Position.create(one, two), end: Position.create(three, four) };\n        }\n        else if (Position.is(one) && Position.is(two)) {\n            return { start: one, end: two };\n        }\n        else {\n            throw new Error(`Range#create called with invalid arguments[${one}, ${two}, ${three}, ${four}]`);\n        }\n    }\n    Range.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Range} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Position.is(candidate.start) && Position.is(candidate.end);\n    }\n    Range.is = is;\n})(Range || (Range = {}));\n/**\n * The Location namespace provides helper functions to work with\n * {@link Location} literals.\n */\nexport var Location;\n(function (Location) {\n    /**\n     * Creates a Location literal.\n     * @param uri The location's uri.\n     * @param range The location's range.\n     */\n    function create(uri, range) {\n        return { uri, range };\n    }\n    Location.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Location} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.range) && (Is.string(candidate.uri) || Is.undefined(candidate.uri));\n    }\n    Location.is = is;\n})(Location || (Location = {}));\n/**\n * The LocationLink namespace provides helper functions to work with\n * {@link LocationLink} literals.\n */\nexport var LocationLink;\n(function (LocationLink) {\n    /**\n     * Creates a LocationLink literal.\n     * @param targetUri The definition's uri.\n     * @param targetRange The full range of the definition.\n     * @param targetSelectionRange The span of the symbol definition at the target.\n     * @param originSelectionRange The span of the symbol being defined in the originating source file.\n     */\n    function create(targetUri, targetRange, targetSelectionRange, originSelectionRange) {\n        return { targetUri, targetRange, targetSelectionRange, originSelectionRange };\n    }\n    LocationLink.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link LocationLink} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.targetRange) && Is.string(candidate.targetUri)\n            && Range.is(candidate.targetSelectionRange)\n            && (Range.is(candidate.originSelectionRange) || Is.undefined(candidate.originSelectionRange));\n    }\n    LocationLink.is = is;\n})(LocationLink || (LocationLink = {}));\n/**\n * The Color namespace provides helper functions to work with\n * {@link Color} literals.\n */\nexport var Color;\n(function (Color) {\n    /**\n     * Creates a new Color literal.\n     */\n    function create(red, green, blue, alpha) {\n        return {\n            red,\n            green,\n            blue,\n            alpha,\n        };\n    }\n    Color.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Color} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.numberRange(candidate.red, 0, 1)\n            && Is.numberRange(candidate.green, 0, 1)\n            && Is.numberRange(candidate.blue, 0, 1)\n            && Is.numberRange(candidate.alpha, 0, 1);\n    }\n    Color.is = is;\n})(Color || (Color = {}));\n/**\n * The ColorInformation namespace provides helper functions to work with\n * {@link ColorInformation} literals.\n */\nexport var ColorInformation;\n(function (ColorInformation) {\n    /**\n     * Creates a new ColorInformation literal.\n     */\n    function create(range, color) {\n        return {\n            range,\n            color,\n        };\n    }\n    ColorInformation.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link ColorInformation} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.range) && Color.is(candidate.color);\n    }\n    ColorInformation.is = is;\n})(ColorInformation || (ColorInformation = {}));\n/**\n * The Color namespace provides helper functions to work with\n * {@link ColorPresentation} literals.\n */\nexport var ColorPresentation;\n(function (ColorPresentation) {\n    /**\n     * Creates a new ColorInformation literal.\n     */\n    function create(label, textEdit, additionalTextEdits) {\n        return {\n            label,\n            textEdit,\n            additionalTextEdits,\n        };\n    }\n    ColorPresentation.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link ColorInformation} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.string(candidate.label)\n            && (Is.undefined(candidate.textEdit) || TextEdit.is(candidate))\n            && (Is.undefined(candidate.additionalTextEdits) || Is.typedArray(candidate.additionalTextEdits, TextEdit.is));\n    }\n    ColorPresentation.is = is;\n})(ColorPresentation || (ColorPresentation = {}));\n/**\n * A set of predefined range kinds.\n */\nexport var FoldingRangeKind;\n(function (FoldingRangeKind) {\n    /**\n     * Folding range for a comment\n     */\n    FoldingRangeKind.Comment = 'comment';\n    /**\n     * Folding range for an import or include\n     */\n    FoldingRangeKind.Imports = 'imports';\n    /**\n     * Folding range for a region (e.g. `#region`)\n     */\n    FoldingRangeKind.Region = 'region';\n})(FoldingRangeKind || (FoldingRangeKind = {}));\n/**\n * The folding range namespace provides helper functions to work with\n * {@link FoldingRange} literals.\n */\nexport var FoldingRange;\n(function (FoldingRange) {\n    /**\n     * Creates a new FoldingRange literal.\n     */\n    function create(startLine, endLine, startCharacter, endCharacter, kind, collapsedText) {\n        const result = {\n            startLine,\n            endLine\n        };\n        if (Is.defined(startCharacter)) {\n            result.startCharacter = startCharacter;\n        }\n        if (Is.defined(endCharacter)) {\n            result.endCharacter = endCharacter;\n        }\n        if (Is.defined(kind)) {\n            result.kind = kind;\n        }\n        if (Is.defined(collapsedText)) {\n            result.collapsedText = collapsedText;\n        }\n        return result;\n    }\n    FoldingRange.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link FoldingRange} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.uinteger(candidate.startLine) && Is.uinteger(candidate.startLine)\n            && (Is.undefined(candidate.startCharacter) || Is.uinteger(candidate.startCharacter))\n            && (Is.undefined(candidate.endCharacter) || Is.uinteger(candidate.endCharacter))\n            && (Is.undefined(candidate.kind) || Is.string(candidate.kind));\n    }\n    FoldingRange.is = is;\n})(FoldingRange || (FoldingRange = {}));\n/**\n * The DiagnosticRelatedInformation namespace provides helper functions to work with\n * {@link DiagnosticRelatedInformation} literals.\n */\nexport var DiagnosticRelatedInformation;\n(function (DiagnosticRelatedInformation) {\n    /**\n     * Creates a new DiagnosticRelatedInformation literal.\n     */\n    function create(location, message) {\n        return {\n            location,\n            message\n        };\n    }\n    DiagnosticRelatedInformation.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link DiagnosticRelatedInformation} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Location.is(candidate.location) && Is.string(candidate.message);\n    }\n    DiagnosticRelatedInformation.is = is;\n})(DiagnosticRelatedInformation || (DiagnosticRelatedInformation = {}));\n/**\n * The diagnostic's severity.\n */\nexport var DiagnosticSeverity;\n(function (DiagnosticSeverity) {\n    /**\n     * Reports an error.\n     */\n    DiagnosticSeverity.Error = 1;\n    /**\n     * Reports a warning.\n     */\n    DiagnosticSeverity.Warning = 2;\n    /**\n     * Reports an information.\n     */\n    DiagnosticSeverity.Information = 3;\n    /**\n     * Reports a hint.\n     */\n    DiagnosticSeverity.Hint = 4;\n})(DiagnosticSeverity || (DiagnosticSeverity = {}));\n/**\n * The diagnostic tags.\n *\n * @since 3.15.0\n */\nexport var DiagnosticTag;\n(function (DiagnosticTag) {\n    /**\n     * Unused or unnecessary code.\n     *\n     * Clients are allowed to render diagnostics with this tag faded out instead of having\n     * an error squiggle.\n     */\n    DiagnosticTag.Unnecessary = 1;\n    /**\n     * Deprecated or obsolete code.\n     *\n     * Clients are allowed to rendered diagnostics with this tag strike through.\n     */\n    DiagnosticTag.Deprecated = 2;\n})(DiagnosticTag || (DiagnosticTag = {}));\n/**\n * The CodeDescription namespace provides functions to deal with descriptions for diagnostic codes.\n *\n * @since 3.16.0\n */\nexport var CodeDescription;\n(function (CodeDescription) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.string(candidate.href);\n    }\n    CodeDescription.is = is;\n})(CodeDescription || (CodeDescription = {}));\n/**\n * The Diagnostic namespace provides helper functions to work with\n * {@link Diagnostic} literals.\n */\nexport var Diagnostic;\n(function (Diagnostic) {\n    /**\n     * Creates a new Diagnostic literal.\n     */\n    function create(range, message, severity, code, source, relatedInformation) {\n        let result = { range, message };\n        if (Is.defined(severity)) {\n            result.severity = severity;\n        }\n        if (Is.defined(code)) {\n            result.code = code;\n        }\n        if (Is.defined(source)) {\n            result.source = source;\n        }\n        if (Is.defined(relatedInformation)) {\n            result.relatedInformation = relatedInformation;\n        }\n        return result;\n    }\n    Diagnostic.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Diagnostic} interface.\n     */\n    function is(value) {\n        var _a;\n        let candidate = value;\n        return Is.defined(candidate)\n            && Range.is(candidate.range)\n            && Is.string(candidate.message)\n            && (Is.number(candidate.severity) || Is.undefined(candidate.severity))\n            && (Is.integer(candidate.code) || Is.string(candidate.code) || Is.undefined(candidate.code))\n            && (Is.undefined(candidate.codeDescription) || (Is.string((_a = candidate.codeDescription) === null || _a === void 0 ? void 0 : _a.href)))\n            && (Is.string(candidate.source) || Is.undefined(candidate.source))\n            && (Is.undefined(candidate.relatedInformation) || Is.typedArray(candidate.relatedInformation, DiagnosticRelatedInformation.is));\n    }\n    Diagnostic.is = is;\n})(Diagnostic || (Diagnostic = {}));\n/**\n * The Command namespace provides helper functions to work with\n * {@link Command} literals.\n */\nexport var Command;\n(function (Command) {\n    /**\n     * Creates a new Command literal.\n     */\n    function create(title, command, ...args) {\n        let result = { title, command };\n        if (Is.defined(args) && args.length > 0) {\n            result.arguments = args;\n        }\n        return result;\n    }\n    Command.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link Command} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.title) && Is.string(candidate.command);\n    }\n    Command.is = is;\n})(Command || (Command = {}));\n/**\n * The TextEdit namespace provides helper function to create replace,\n * insert and delete edits more easily.\n */\nexport var TextEdit;\n(function (TextEdit) {\n    /**\n     * Creates a replace text edit.\n     * @param range The range of text to be replaced.\n     * @param newText The new text.\n     */\n    function replace(range, newText) {\n        return { range, newText };\n    }\n    TextEdit.replace = replace;\n    /**\n     * Creates an insert text edit.\n     * @param position The position to insert the text at.\n     * @param newText The text to be inserted.\n     */\n    function insert(position, newText) {\n        return { range: { start: position, end: position }, newText };\n    }\n    TextEdit.insert = insert;\n    /**\n     * Creates a delete text edit.\n     * @param range The range of text to be deleted.\n     */\n    function del(range) {\n        return { range, newText: '' };\n    }\n    TextEdit.del = del;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate)\n            && Is.string(candidate.newText)\n            && Range.is(candidate.range);\n    }\n    TextEdit.is = is;\n})(TextEdit || (TextEdit = {}));\nexport var ChangeAnnotation;\n(function (ChangeAnnotation) {\n    function create(label, needsConfirmation, description) {\n        const result = { label };\n        if (needsConfirmation !== undefined) {\n            result.needsConfirmation = needsConfirmation;\n        }\n        if (description !== undefined) {\n            result.description = description;\n        }\n        return result;\n    }\n    ChangeAnnotation.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Is.string(candidate.label) &&\n            (Is.boolean(candidate.needsConfirmation) || candidate.needsConfirmation === undefined) &&\n            (Is.string(candidate.description) || candidate.description === undefined);\n    }\n    ChangeAnnotation.is = is;\n})(ChangeAnnotation || (ChangeAnnotation = {}));\nexport var ChangeAnnotationIdentifier;\n(function (ChangeAnnotationIdentifier) {\n    function is(value) {\n        const candidate = value;\n        return Is.string(candidate);\n    }\n    ChangeAnnotationIdentifier.is = is;\n})(ChangeAnnotationIdentifier || (ChangeAnnotationIdentifier = {}));\nexport var AnnotatedTextEdit;\n(function (AnnotatedTextEdit) {\n    /**\n     * Creates an annotated replace text edit.\n     *\n     * @param range The range of text to be replaced.\n     * @param newText The new text.\n     * @param annotation The annotation.\n     */\n    function replace(range, newText, annotation) {\n        return { range, newText, annotationId: annotation };\n    }\n    AnnotatedTextEdit.replace = replace;\n    /**\n     * Creates an annotated insert text edit.\n     *\n     * @param position The position to insert the text at.\n     * @param newText The text to be inserted.\n     * @param annotation The annotation.\n     */\n    function insert(position, newText, annotation) {\n        return { range: { start: position, end: position }, newText, annotationId: annotation };\n    }\n    AnnotatedTextEdit.insert = insert;\n    /**\n     * Creates an annotated delete text edit.\n     *\n     * @param range The range of text to be deleted.\n     * @param annotation The annotation.\n     */\n    function del(range, annotation) {\n        return { range, newText: '', annotationId: annotation };\n    }\n    AnnotatedTextEdit.del = del;\n    function is(value) {\n        const candidate = value;\n        return TextEdit.is(candidate) && (ChangeAnnotation.is(candidate.annotationId) || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    AnnotatedTextEdit.is = is;\n})(AnnotatedTextEdit || (AnnotatedTextEdit = {}));\n/**\n * The TextDocumentEdit namespace provides helper function to create\n * an edit that manipulates a text document.\n */\nexport var TextDocumentEdit;\n(function (TextDocumentEdit) {\n    /**\n     * Creates a new `TextDocumentEdit`\n     */\n    function create(textDocument, edits) {\n        return { textDocument, edits };\n    }\n    TextDocumentEdit.create = create;\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate)\n            && OptionalVersionedTextDocumentIdentifier.is(candidate.textDocument)\n            && Array.isArray(candidate.edits);\n    }\n    TextDocumentEdit.is = is;\n})(TextDocumentEdit || (TextDocumentEdit = {}));\nexport var CreateFile;\n(function (CreateFile) {\n    function create(uri, options, annotation) {\n        let result = {\n            kind: 'create',\n            uri\n        };\n        if (options !== undefined && (options.overwrite !== undefined || options.ignoreIfExists !== undefined)) {\n            result.options = options;\n        }\n        if (annotation !== undefined) {\n            result.annotationId = annotation;\n        }\n        return result;\n    }\n    CreateFile.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && candidate.kind === 'create' && Is.string(candidate.uri) && (candidate.options === undefined ||\n            ((candidate.options.overwrite === undefined || Is.boolean(candidate.options.overwrite)) && (candidate.options.ignoreIfExists === undefined || Is.boolean(candidate.options.ignoreIfExists)))) && (candidate.annotationId === undefined || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    CreateFile.is = is;\n})(CreateFile || (CreateFile = {}));\nexport var RenameFile;\n(function (RenameFile) {\n    function create(oldUri, newUri, options, annotation) {\n        let result = {\n            kind: 'rename',\n            oldUri,\n            newUri\n        };\n        if (options !== undefined && (options.overwrite !== undefined || options.ignoreIfExists !== undefined)) {\n            result.options = options;\n        }\n        if (annotation !== undefined) {\n            result.annotationId = annotation;\n        }\n        return result;\n    }\n    RenameFile.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && candidate.kind === 'rename' && Is.string(candidate.oldUri) && Is.string(candidate.newUri) && (candidate.options === undefined ||\n            ((candidate.options.overwrite === undefined || Is.boolean(candidate.options.overwrite)) && (candidate.options.ignoreIfExists === undefined || Is.boolean(candidate.options.ignoreIfExists)))) && (candidate.annotationId === undefined || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    RenameFile.is = is;\n})(RenameFile || (RenameFile = {}));\nexport var DeleteFile;\n(function (DeleteFile) {\n    function create(uri, options, annotation) {\n        let result = {\n            kind: 'delete',\n            uri\n        };\n        if (options !== undefined && (options.recursive !== undefined || options.ignoreIfNotExists !== undefined)) {\n            result.options = options;\n        }\n        if (annotation !== undefined) {\n            result.annotationId = annotation;\n        }\n        return result;\n    }\n    DeleteFile.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && candidate.kind === 'delete' && Is.string(candidate.uri) && (candidate.options === undefined ||\n            ((candidate.options.recursive === undefined || Is.boolean(candidate.options.recursive)) && (candidate.options.ignoreIfNotExists === undefined || Is.boolean(candidate.options.ignoreIfNotExists)))) && (candidate.annotationId === undefined || ChangeAnnotationIdentifier.is(candidate.annotationId));\n    }\n    DeleteFile.is = is;\n})(DeleteFile || (DeleteFile = {}));\nexport var WorkspaceEdit;\n(function (WorkspaceEdit) {\n    function is(value) {\n        let candidate = value;\n        return candidate &&\n            (candidate.changes !== undefined || candidate.documentChanges !== undefined) &&\n            (candidate.documentChanges === undefined || candidate.documentChanges.every((change) => {\n                if (Is.string(change.kind)) {\n                    return CreateFile.is(change) || RenameFile.is(change) || DeleteFile.is(change);\n                }\n                else {\n                    return TextDocumentEdit.is(change);\n                }\n            }));\n    }\n    WorkspaceEdit.is = is;\n})(WorkspaceEdit || (WorkspaceEdit = {}));\nclass TextEditChangeImpl {\n    constructor(edits, changeAnnotations) {\n        this.edits = edits;\n        this.changeAnnotations = changeAnnotations;\n    }\n    insert(position, newText, annotation) {\n        let edit;\n        let id;\n        if (annotation === undefined) {\n            edit = TextEdit.insert(position, newText);\n        }\n        else if (ChangeAnnotationIdentifier.is(annotation)) {\n            id = annotation;\n            edit = AnnotatedTextEdit.insert(position, newText, annotation);\n        }\n        else {\n            this.assertChangeAnnotations(this.changeAnnotations);\n            id = this.changeAnnotations.manage(annotation);\n            edit = AnnotatedTextEdit.insert(position, newText, id);\n        }\n        this.edits.push(edit);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    replace(range, newText, annotation) {\n        let edit;\n        let id;\n        if (annotation === undefined) {\n            edit = TextEdit.replace(range, newText);\n        }\n        else if (ChangeAnnotationIdentifier.is(annotation)) {\n            id = annotation;\n            edit = AnnotatedTextEdit.replace(range, newText, annotation);\n        }\n        else {\n            this.assertChangeAnnotations(this.changeAnnotations);\n            id = this.changeAnnotations.manage(annotation);\n            edit = AnnotatedTextEdit.replace(range, newText, id);\n        }\n        this.edits.push(edit);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    delete(range, annotation) {\n        let edit;\n        let id;\n        if (annotation === undefined) {\n            edit = TextEdit.del(range);\n        }\n        else if (ChangeAnnotationIdentifier.is(annotation)) {\n            id = annotation;\n            edit = AnnotatedTextEdit.del(range, annotation);\n        }\n        else {\n            this.assertChangeAnnotations(this.changeAnnotations);\n            id = this.changeAnnotations.manage(annotation);\n            edit = AnnotatedTextEdit.del(range, id);\n        }\n        this.edits.push(edit);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    add(edit) {\n        this.edits.push(edit);\n    }\n    all() {\n        return this.edits;\n    }\n    clear() {\n        this.edits.splice(0, this.edits.length);\n    }\n    assertChangeAnnotations(value) {\n        if (value === undefined) {\n            throw new Error(`Text edit change is not configured to manage change annotations.`);\n        }\n    }\n}\n/**\n * A helper class\n */\nclass ChangeAnnotations {\n    constructor(annotations) {\n        this._annotations = annotations === undefined ? Object.create(null) : annotations;\n        this._counter = 0;\n        this._size = 0;\n    }\n    all() {\n        return this._annotations;\n    }\n    get size() {\n        return this._size;\n    }\n    manage(idOrAnnotation, annotation) {\n        let id;\n        if (ChangeAnnotationIdentifier.is(idOrAnnotation)) {\n            id = idOrAnnotation;\n        }\n        else {\n            id = this.nextId();\n            annotation = idOrAnnotation;\n        }\n        if (this._annotations[id] !== undefined) {\n            throw new Error(`Id ${id} is already in use.`);\n        }\n        if (annotation === undefined) {\n            throw new Error(`No annotation provided for id ${id}`);\n        }\n        this._annotations[id] = annotation;\n        this._size++;\n        return id;\n    }\n    nextId() {\n        this._counter++;\n        return this._counter.toString();\n    }\n}\n/**\n * A workspace change helps constructing changes to a workspace.\n */\nexport class WorkspaceChange {\n    constructor(workspaceEdit) {\n        this._textEditChanges = Object.create(null);\n        if (workspaceEdit !== undefined) {\n            this._workspaceEdit = workspaceEdit;\n            if (workspaceEdit.documentChanges) {\n                this._changeAnnotations = new ChangeAnnotations(workspaceEdit.changeAnnotations);\n                workspaceEdit.changeAnnotations = this._changeAnnotations.all();\n                workspaceEdit.documentChanges.forEach((change) => {\n                    if (TextDocumentEdit.is(change)) {\n                        const textEditChange = new TextEditChangeImpl(change.edits, this._changeAnnotations);\n                        this._textEditChanges[change.textDocument.uri] = textEditChange;\n                    }\n                });\n            }\n            else if (workspaceEdit.changes) {\n                Object.keys(workspaceEdit.changes).forEach((key) => {\n                    const textEditChange = new TextEditChangeImpl(workspaceEdit.changes[key]);\n                    this._textEditChanges[key] = textEditChange;\n                });\n            }\n        }\n        else {\n            this._workspaceEdit = {};\n        }\n    }\n    /**\n     * Returns the underlying {@link WorkspaceEdit} literal\n     * use to be returned from a workspace edit operation like rename.\n     */\n    get edit() {\n        this.initDocumentChanges();\n        if (this._changeAnnotations !== undefined) {\n            if (this._changeAnnotations.size === 0) {\n                this._workspaceEdit.changeAnnotations = undefined;\n            }\n            else {\n                this._workspaceEdit.changeAnnotations = this._changeAnnotations.all();\n            }\n        }\n        return this._workspaceEdit;\n    }\n    getTextEditChange(key) {\n        if (OptionalVersionedTextDocumentIdentifier.is(key)) {\n            this.initDocumentChanges();\n            if (this._workspaceEdit.documentChanges === undefined) {\n                throw new Error('Workspace edit is not configured for document changes.');\n            }\n            const textDocument = { uri: key.uri, version: key.version };\n            let result = this._textEditChanges[textDocument.uri];\n            if (!result) {\n                const edits = [];\n                const textDocumentEdit = {\n                    textDocument,\n                    edits\n                };\n                this._workspaceEdit.documentChanges.push(textDocumentEdit);\n                result = new TextEditChangeImpl(edits, this._changeAnnotations);\n                this._textEditChanges[textDocument.uri] = result;\n            }\n            return result;\n        }\n        else {\n            this.initChanges();\n            if (this._workspaceEdit.changes === undefined) {\n                throw new Error('Workspace edit is not configured for normal text edit changes.');\n            }\n            let result = this._textEditChanges[key];\n            if (!result) {\n                let edits = [];\n                this._workspaceEdit.changes[key] = edits;\n                result = new TextEditChangeImpl(edits);\n                this._textEditChanges[key] = result;\n            }\n            return result;\n        }\n    }\n    initDocumentChanges() {\n        if (this._workspaceEdit.documentChanges === undefined && this._workspaceEdit.changes === undefined) {\n            this._changeAnnotations = new ChangeAnnotations();\n            this._workspaceEdit.documentChanges = [];\n            this._workspaceEdit.changeAnnotations = this._changeAnnotations.all();\n        }\n    }\n    initChanges() {\n        if (this._workspaceEdit.documentChanges === undefined && this._workspaceEdit.changes === undefined) {\n            this._workspaceEdit.changes = Object.create(null);\n        }\n    }\n    createFile(uri, optionsOrAnnotation, options) {\n        this.initDocumentChanges();\n        if (this._workspaceEdit.documentChanges === undefined) {\n            throw new Error('Workspace edit is not configured for document changes.');\n        }\n        let annotation;\n        if (ChangeAnnotation.is(optionsOrAnnotation) || ChangeAnnotationIdentifier.is(optionsOrAnnotation)) {\n            annotation = optionsOrAnnotation;\n        }\n        else {\n            options = optionsOrAnnotation;\n        }\n        let operation;\n        let id;\n        if (annotation === undefined) {\n            operation = CreateFile.create(uri, options);\n        }\n        else {\n            id = ChangeAnnotationIdentifier.is(annotation) ? annotation : this._changeAnnotations.manage(annotation);\n            operation = CreateFile.create(uri, options, id);\n        }\n        this._workspaceEdit.documentChanges.push(operation);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    renameFile(oldUri, newUri, optionsOrAnnotation, options) {\n        this.initDocumentChanges();\n        if (this._workspaceEdit.documentChanges === undefined) {\n            throw new Error('Workspace edit is not configured for document changes.');\n        }\n        let annotation;\n        if (ChangeAnnotation.is(optionsOrAnnotation) || ChangeAnnotationIdentifier.is(optionsOrAnnotation)) {\n            annotation = optionsOrAnnotation;\n        }\n        else {\n            options = optionsOrAnnotation;\n        }\n        let operation;\n        let id;\n        if (annotation === undefined) {\n            operation = RenameFile.create(oldUri, newUri, options);\n        }\n        else {\n            id = ChangeAnnotationIdentifier.is(annotation) ? annotation : this._changeAnnotations.manage(annotation);\n            operation = RenameFile.create(oldUri, newUri, options, id);\n        }\n        this._workspaceEdit.documentChanges.push(operation);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n    deleteFile(uri, optionsOrAnnotation, options) {\n        this.initDocumentChanges();\n        if (this._workspaceEdit.documentChanges === undefined) {\n            throw new Error('Workspace edit is not configured for document changes.');\n        }\n        let annotation;\n        if (ChangeAnnotation.is(optionsOrAnnotation) || ChangeAnnotationIdentifier.is(optionsOrAnnotation)) {\n            annotation = optionsOrAnnotation;\n        }\n        else {\n            options = optionsOrAnnotation;\n        }\n        let operation;\n        let id;\n        if (annotation === undefined) {\n            operation = DeleteFile.create(uri, options);\n        }\n        else {\n            id = ChangeAnnotationIdentifier.is(annotation) ? annotation : this._changeAnnotations.manage(annotation);\n            operation = DeleteFile.create(uri, options, id);\n        }\n        this._workspaceEdit.documentChanges.push(operation);\n        if (id !== undefined) {\n            return id;\n        }\n    }\n}\n/**\n * The TextDocumentIdentifier namespace provides helper functions to work with\n * {@link TextDocumentIdentifier} literals.\n */\nexport var TextDocumentIdentifier;\n(function (TextDocumentIdentifier) {\n    /**\n     * Creates a new TextDocumentIdentifier literal.\n     * @param uri The document's uri.\n     */\n    function create(uri) {\n        return { uri };\n    }\n    TextDocumentIdentifier.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link TextDocumentIdentifier} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri);\n    }\n    TextDocumentIdentifier.is = is;\n})(TextDocumentIdentifier || (TextDocumentIdentifier = {}));\n/**\n * The VersionedTextDocumentIdentifier namespace provides helper functions to work with\n * {@link VersionedTextDocumentIdentifier} literals.\n */\nexport var VersionedTextDocumentIdentifier;\n(function (VersionedTextDocumentIdentifier) {\n    /**\n     * Creates a new VersionedTextDocumentIdentifier literal.\n     * @param uri The document's uri.\n     * @param version The document's version.\n     */\n    function create(uri, version) {\n        return { uri, version };\n    }\n    VersionedTextDocumentIdentifier.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link VersionedTextDocumentIdentifier} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && Is.integer(candidate.version);\n    }\n    VersionedTextDocumentIdentifier.is = is;\n})(VersionedTextDocumentIdentifier || (VersionedTextDocumentIdentifier = {}));\n/**\n * The OptionalVersionedTextDocumentIdentifier namespace provides helper functions to work with\n * {@link OptionalVersionedTextDocumentIdentifier} literals.\n */\nexport var OptionalVersionedTextDocumentIdentifier;\n(function (OptionalVersionedTextDocumentIdentifier) {\n    /**\n     * Creates a new OptionalVersionedTextDocumentIdentifier literal.\n     * @param uri The document's uri.\n     * @param version The document's version.\n     */\n    function create(uri, version) {\n        return { uri, version };\n    }\n    OptionalVersionedTextDocumentIdentifier.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link OptionalVersionedTextDocumentIdentifier} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && (candidate.version === null || Is.integer(candidate.version));\n    }\n    OptionalVersionedTextDocumentIdentifier.is = is;\n})(OptionalVersionedTextDocumentIdentifier || (OptionalVersionedTextDocumentIdentifier = {}));\n/**\n * The TextDocumentItem namespace provides helper functions to work with\n * {@link TextDocumentItem} literals.\n */\nexport var TextDocumentItem;\n(function (TextDocumentItem) {\n    /**\n     * Creates a new TextDocumentItem literal.\n     * @param uri The document's uri.\n     * @param languageId The document's language identifier.\n     * @param version The document's version number.\n     * @param text The document's text.\n     */\n    function create(uri, languageId, version, text) {\n        return { uri, languageId, version, text };\n    }\n    TextDocumentItem.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link TextDocumentItem} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && Is.string(candidate.languageId) && Is.integer(candidate.version) && Is.string(candidate.text);\n    }\n    TextDocumentItem.is = is;\n})(TextDocumentItem || (TextDocumentItem = {}));\n/**\n * Describes the content type that a client supports in various\n * result literals like `Hover`, `ParameterInfo` or `CompletionItem`.\n *\n * Please note that `MarkupKinds` must not start with a `$`. This kinds\n * are reserved for internal usage.\n */\nexport var MarkupKind;\n(function (MarkupKind) {\n    /**\n     * Plain text is supported as a content format\n     */\n    MarkupKind.PlainText = 'plaintext';\n    /**\n     * Markdown is supported as a content format\n     */\n    MarkupKind.Markdown = 'markdown';\n    /**\n     * Checks whether the given value is a value of the {@link MarkupKind} type.\n     */\n    function is(value) {\n        const candidate = value;\n        return candidate === MarkupKind.PlainText || candidate === MarkupKind.Markdown;\n    }\n    MarkupKind.is = is;\n})(MarkupKind || (MarkupKind = {}));\nexport var MarkupContent;\n(function (MarkupContent) {\n    /**\n     * Checks whether the given value conforms to the {@link MarkupContent} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(value) && MarkupKind.is(candidate.kind) && Is.string(candidate.value);\n    }\n    MarkupContent.is = is;\n})(MarkupContent || (MarkupContent = {}));\n/**\n * The kind of a completion entry.\n */\nexport var CompletionItemKind;\n(function (CompletionItemKind) {\n    CompletionItemKind.Text = 1;\n    CompletionItemKind.Method = 2;\n    CompletionItemKind.Function = 3;\n    CompletionItemKind.Constructor = 4;\n    CompletionItemKind.Field = 5;\n    CompletionItemKind.Variable = 6;\n    CompletionItemKind.Class = 7;\n    CompletionItemKind.Interface = 8;\n    CompletionItemKind.Module = 9;\n    CompletionItemKind.Property = 10;\n    CompletionItemKind.Unit = 11;\n    CompletionItemKind.Value = 12;\n    CompletionItemKind.Enum = 13;\n    CompletionItemKind.Keyword = 14;\n    CompletionItemKind.Snippet = 15;\n    CompletionItemKind.Color = 16;\n    CompletionItemKind.File = 17;\n    CompletionItemKind.Reference = 18;\n    CompletionItemKind.Folder = 19;\n    CompletionItemKind.EnumMember = 20;\n    CompletionItemKind.Constant = 21;\n    CompletionItemKind.Struct = 22;\n    CompletionItemKind.Event = 23;\n    CompletionItemKind.Operator = 24;\n    CompletionItemKind.TypeParameter = 25;\n})(CompletionItemKind || (CompletionItemKind = {}));\n/**\n * Defines whether the insert text in a completion item should be interpreted as\n * plain text or a snippet.\n */\nexport var InsertTextFormat;\n(function (InsertTextFormat) {\n    /**\n     * The primary text to be inserted is treated as a plain string.\n     */\n    InsertTextFormat.PlainText = 1;\n    /**\n     * The primary text to be inserted is treated as a snippet.\n     *\n     * A snippet can define tab stops and placeholders with `$1`, `$2`\n     * and `${3:foo}`. `$0` defines the final tab stop, it defaults to\n     * the end of the snippet. Placeholders with equal identifiers are linked,\n     * that is typing in one will update others too.\n     *\n     * See also: https://microsoft.github.io/language-server-protocol/specifications/specification-current/#snippet_syntax\n     */\n    InsertTextFormat.Snippet = 2;\n})(InsertTextFormat || (InsertTextFormat = {}));\n/**\n * Completion item tags are extra annotations that tweak the rendering of a completion\n * item.\n *\n * @since 3.15.0\n */\nexport var CompletionItemTag;\n(function (CompletionItemTag) {\n    /**\n     * Render a completion as obsolete, usually using a strike-out.\n     */\n    CompletionItemTag.Deprecated = 1;\n})(CompletionItemTag || (CompletionItemTag = {}));\n/**\n * The InsertReplaceEdit namespace provides functions to deal with insert / replace edits.\n *\n * @since 3.16.0\n */\nexport var InsertReplaceEdit;\n(function (InsertReplaceEdit) {\n    /**\n     * Creates a new insert / replace edit\n     */\n    function create(newText, insert, replace) {\n        return { newText, insert, replace };\n    }\n    InsertReplaceEdit.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link InsertReplaceEdit} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return candidate && Is.string(candidate.newText) && Range.is(candidate.insert) && Range.is(candidate.replace);\n    }\n    InsertReplaceEdit.is = is;\n})(InsertReplaceEdit || (InsertReplaceEdit = {}));\n/**\n * How whitespace and indentation is handled during completion\n * item insertion.\n *\n * @since 3.16.0\n */\nexport var InsertTextMode;\n(function (InsertTextMode) {\n    /**\n     * The insertion or replace strings is taken as it is. If the\n     * value is multi line the lines below the cursor will be\n     * inserted using the indentation defined in the string value.\n     * The client will not apply any kind of adjustments to the\n     * string.\n     */\n    InsertTextMode.asIs = 1;\n    /**\n     * The editor adjusts leading whitespace of new lines so that\n     * they match the indentation up to the cursor of the line for\n     * which the item is accepted.\n     *\n     * Consider a line like this: <2tabs><cursor><3tabs>foo. Accepting a\n     * multi line completion item is indented using 2 tabs and all\n     * following lines inserted will be indented using 2 tabs as well.\n     */\n    InsertTextMode.adjustIndentation = 2;\n})(InsertTextMode || (InsertTextMode = {}));\nexport var CompletionItemLabelDetails;\n(function (CompletionItemLabelDetails) {\n    function is(value) {\n        const candidate = value;\n        return candidate && (Is.string(candidate.detail) || candidate.detail === undefined) &&\n            (Is.string(candidate.description) || candidate.description === undefined);\n    }\n    CompletionItemLabelDetails.is = is;\n})(CompletionItemLabelDetails || (CompletionItemLabelDetails = {}));\n/**\n * The CompletionItem namespace provides functions to deal with\n * completion items.\n */\nexport var CompletionItem;\n(function (CompletionItem) {\n    /**\n     * Create a completion item and seed it with a label.\n     * @param label The completion item's label\n     */\n    function create(label) {\n        return { label };\n    }\n    CompletionItem.create = create;\n})(CompletionItem || (CompletionItem = {}));\n/**\n * The CompletionList namespace provides functions to deal with\n * completion lists.\n */\nexport var CompletionList;\n(function (CompletionList) {\n    /**\n     * Creates a new completion list.\n     *\n     * @param items The completion items.\n     * @param isIncomplete The list is not complete.\n     */\n    function create(items, isIncomplete) {\n        return { items: items ? items : [], isIncomplete: !!isIncomplete };\n    }\n    CompletionList.create = create;\n})(CompletionList || (CompletionList = {}));\nexport var MarkedString;\n(function (MarkedString) {\n    /**\n     * Creates a marked string from plain text.\n     *\n     * @param plainText The plain text.\n     */\n    function fromPlainText(plainText) {\n        return plainText.replace(/[\\\\`*_{}[\\]()#+\\-.!]/g, '\\\\$&'); // escape markdown syntax tokens: http://daringfireball.net/projects/markdown/syntax#backslash\n    }\n    MarkedString.fromPlainText = fromPlainText;\n    /**\n     * Checks whether the given value conforms to the {@link MarkedString} type.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.string(candidate) || (Is.objectLiteral(candidate) && Is.string(candidate.language) && Is.string(candidate.value));\n    }\n    MarkedString.is = is;\n})(MarkedString || (MarkedString = {}));\nexport var Hover;\n(function (Hover) {\n    /**\n     * Checks whether the given value conforms to the {@link Hover} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return !!candidate && Is.objectLiteral(candidate) && (MarkupContent.is(candidate.contents) ||\n            MarkedString.is(candidate.contents) ||\n            Is.typedArray(candidate.contents, MarkedString.is)) && (value.range === undefined || Range.is(value.range));\n    }\n    Hover.is = is;\n})(Hover || (Hover = {}));\n/**\n * The ParameterInformation namespace provides helper functions to work with\n * {@link ParameterInformation} literals.\n */\nexport var ParameterInformation;\n(function (ParameterInformation) {\n    /**\n     * Creates a new parameter information literal.\n     *\n     * @param label A label string.\n     * @param documentation A doc string.\n     */\n    function create(label, documentation) {\n        return documentation ? { label, documentation } : { label };\n    }\n    ParameterInformation.create = create;\n})(ParameterInformation || (ParameterInformation = {}));\n/**\n * The SignatureInformation namespace provides helper functions to work with\n * {@link SignatureInformation} literals.\n */\nexport var SignatureInformation;\n(function (SignatureInformation) {\n    function create(label, documentation, ...parameters) {\n        let result = { label };\n        if (Is.defined(documentation)) {\n            result.documentation = documentation;\n        }\n        if (Is.defined(parameters)) {\n            result.parameters = parameters;\n        }\n        else {\n            result.parameters = [];\n        }\n        return result;\n    }\n    SignatureInformation.create = create;\n})(SignatureInformation || (SignatureInformation = {}));\n/**\n * A document highlight kind.\n */\nexport var DocumentHighlightKind;\n(function (DocumentHighlightKind) {\n    /**\n     * A textual occurrence.\n     */\n    DocumentHighlightKind.Text = 1;\n    /**\n     * Read-access of a symbol, like reading a variable.\n     */\n    DocumentHighlightKind.Read = 2;\n    /**\n     * Write-access of a symbol, like writing to a variable.\n     */\n    DocumentHighlightKind.Write = 3;\n})(DocumentHighlightKind || (DocumentHighlightKind = {}));\n/**\n * DocumentHighlight namespace to provide helper functions to work with\n * {@link DocumentHighlight} literals.\n */\nexport var DocumentHighlight;\n(function (DocumentHighlight) {\n    /**\n     * Create a DocumentHighlight object.\n     * @param range The range the highlight applies to.\n     * @param kind The highlight kind\n     */\n    function create(range, kind) {\n        let result = { range };\n        if (Is.number(kind)) {\n            result.kind = kind;\n        }\n        return result;\n    }\n    DocumentHighlight.create = create;\n})(DocumentHighlight || (DocumentHighlight = {}));\n/**\n * A symbol kind.\n */\nexport var SymbolKind;\n(function (SymbolKind) {\n    SymbolKind.File = 1;\n    SymbolKind.Module = 2;\n    SymbolKind.Namespace = 3;\n    SymbolKind.Package = 4;\n    SymbolKind.Class = 5;\n    SymbolKind.Method = 6;\n    SymbolKind.Property = 7;\n    SymbolKind.Field = 8;\n    SymbolKind.Constructor = 9;\n    SymbolKind.Enum = 10;\n    SymbolKind.Interface = 11;\n    SymbolKind.Function = 12;\n    SymbolKind.Variable = 13;\n    SymbolKind.Constant = 14;\n    SymbolKind.String = 15;\n    SymbolKind.Number = 16;\n    SymbolKind.Boolean = 17;\n    SymbolKind.Array = 18;\n    SymbolKind.Object = 19;\n    SymbolKind.Key = 20;\n    SymbolKind.Null = 21;\n    SymbolKind.EnumMember = 22;\n    SymbolKind.Struct = 23;\n    SymbolKind.Event = 24;\n    SymbolKind.Operator = 25;\n    SymbolKind.TypeParameter = 26;\n})(SymbolKind || (SymbolKind = {}));\n/**\n * Symbol tags are extra annotations that tweak the rendering of a symbol.\n *\n * @since 3.16\n */\nexport var SymbolTag;\n(function (SymbolTag) {\n    /**\n     * Render a symbol as obsolete, usually using a strike-out.\n     */\n    SymbolTag.Deprecated = 1;\n})(SymbolTag || (SymbolTag = {}));\nexport var SymbolInformation;\n(function (SymbolInformation) {\n    /**\n     * Creates a new symbol information literal.\n     *\n     * @param name The name of the symbol.\n     * @param kind The kind of the symbol.\n     * @param range The range of the location of the symbol.\n     * @param uri The resource of the location of symbol.\n     * @param containerName The name of the symbol containing the symbol.\n     */\n    function create(name, kind, range, uri, containerName) {\n        let result = {\n            name,\n            kind,\n            location: { uri, range }\n        };\n        if (containerName) {\n            result.containerName = containerName;\n        }\n        return result;\n    }\n    SymbolInformation.create = create;\n})(SymbolInformation || (SymbolInformation = {}));\nexport var WorkspaceSymbol;\n(function (WorkspaceSymbol) {\n    /**\n     * Create a new workspace symbol.\n     *\n     * @param name The name of the symbol.\n     * @param kind The kind of the symbol.\n     * @param uri The resource of the location of the symbol.\n     * @param range An options range of the location.\n     * @returns A WorkspaceSymbol.\n     */\n    function create(name, kind, uri, range) {\n        return range !== undefined\n            ? { name, kind, location: { uri, range } }\n            : { name, kind, location: { uri } };\n    }\n    WorkspaceSymbol.create = create;\n})(WorkspaceSymbol || (WorkspaceSymbol = {}));\nexport var DocumentSymbol;\n(function (DocumentSymbol) {\n    /**\n     * Creates a new symbol information literal.\n     *\n     * @param name The name of the symbol.\n     * @param detail The detail of the symbol.\n     * @param kind The kind of the symbol.\n     * @param range The range of the symbol.\n     * @param selectionRange The selectionRange of the symbol.\n     * @param children Children of the symbol.\n     */\n    function create(name, detail, kind, range, selectionRange, children) {\n        let result = {\n            name,\n            detail,\n            kind,\n            range,\n            selectionRange\n        };\n        if (children !== undefined) {\n            result.children = children;\n        }\n        return result;\n    }\n    DocumentSymbol.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link DocumentSymbol} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return candidate &&\n            Is.string(candidate.name) && Is.number(candidate.kind) &&\n            Range.is(candidate.range) && Range.is(candidate.selectionRange) &&\n            (candidate.detail === undefined || Is.string(candidate.detail)) &&\n            (candidate.deprecated === undefined || Is.boolean(candidate.deprecated)) &&\n            (candidate.children === undefined || Array.isArray(candidate.children)) &&\n            (candidate.tags === undefined || Array.isArray(candidate.tags));\n    }\n    DocumentSymbol.is = is;\n})(DocumentSymbol || (DocumentSymbol = {}));\n/**\n * A set of predefined code action kinds\n */\nexport var CodeActionKind;\n(function (CodeActionKind) {\n    /**\n     * Empty kind.\n     */\n    CodeActionKind.Empty = '';\n    /**\n     * Base kind for quickfix actions: 'quickfix'\n     */\n    CodeActionKind.QuickFix = 'quickfix';\n    /**\n     * Base kind for refactoring actions: 'refactor'\n     */\n    CodeActionKind.Refactor = 'refactor';\n    /**\n     * Base kind for refactoring extraction actions: 'refactor.extract'\n     *\n     * Example extract actions:\n     *\n     * - Extract method\n     * - Extract function\n     * - Extract variable\n     * - Extract interface from class\n     * - ...\n     */\n    CodeActionKind.RefactorExtract = 'refactor.extract';\n    /**\n     * Base kind for refactoring inline actions: 'refactor.inline'\n     *\n     * Example inline actions:\n     *\n     * - Inline function\n     * - Inline variable\n     * - Inline constant\n     * - ...\n     */\n    CodeActionKind.RefactorInline = 'refactor.inline';\n    /**\n     * Base kind for refactoring rewrite actions: 'refactor.rewrite'\n     *\n     * Example rewrite actions:\n     *\n     * - Convert JavaScript function to class\n     * - Add or remove parameter\n     * - Encapsulate field\n     * - Make method static\n     * - Move method to base class\n     * - ...\n     */\n    CodeActionKind.RefactorRewrite = 'refactor.rewrite';\n    /**\n     * Base kind for source actions: `source`\n     *\n     * Source code actions apply to the entire file.\n     */\n    CodeActionKind.Source = 'source';\n    /**\n     * Base kind for an organize imports source action: `source.organizeImports`\n     */\n    CodeActionKind.SourceOrganizeImports = 'source.organizeImports';\n    /**\n     * Base kind for auto-fix source actions: `source.fixAll`.\n     *\n     * Fix all actions automatically fix errors that have a clear fix that do not require user input.\n     * They should not suppress errors or perform unsafe fixes such as generating new types or classes.\n     *\n     * @since 3.15.0\n     */\n    CodeActionKind.SourceFixAll = 'source.fixAll';\n})(CodeActionKind || (CodeActionKind = {}));\n/**\n * The reason why code actions were requested.\n *\n * @since 3.17.0\n */\nexport var CodeActionTriggerKind;\n(function (CodeActionTriggerKind) {\n    /**\n     * Code actions were explicitly requested by the user or by an extension.\n     */\n    CodeActionTriggerKind.Invoked = 1;\n    /**\n     * Code actions were requested automatically.\n     *\n     * This typically happens when current selection in a file changes, but can\n     * also be triggered when file content changes.\n     */\n    CodeActionTriggerKind.Automatic = 2;\n})(CodeActionTriggerKind || (CodeActionTriggerKind = {}));\n/**\n * The CodeActionContext namespace provides helper functions to work with\n * {@link CodeActionContext} literals.\n */\nexport var CodeActionContext;\n(function (CodeActionContext) {\n    /**\n     * Creates a new CodeActionContext literal.\n     */\n    function create(diagnostics, only, triggerKind) {\n        let result = { diagnostics };\n        if (only !== undefined && only !== null) {\n            result.only = only;\n        }\n        if (triggerKind !== undefined && triggerKind !== null) {\n            result.triggerKind = triggerKind;\n        }\n        return result;\n    }\n    CodeActionContext.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link CodeActionContext} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.typedArray(candidate.diagnostics, Diagnostic.is)\n            && (candidate.only === undefined || Is.typedArray(candidate.only, Is.string))\n            && (candidate.triggerKind === undefined || candidate.triggerKind === CodeActionTriggerKind.Invoked || candidate.triggerKind === CodeActionTriggerKind.Automatic);\n    }\n    CodeActionContext.is = is;\n})(CodeActionContext || (CodeActionContext = {}));\nexport var CodeAction;\n(function (CodeAction) {\n    function create(title, kindOrCommandOrEdit, kind) {\n        let result = { title };\n        let checkKind = true;\n        if (typeof kindOrCommandOrEdit === 'string') {\n            checkKind = false;\n            result.kind = kindOrCommandOrEdit;\n        }\n        else if (Command.is(kindOrCommandOrEdit)) {\n            result.command = kindOrCommandOrEdit;\n        }\n        else {\n            result.edit = kindOrCommandOrEdit;\n        }\n        if (checkKind && kind !== undefined) {\n            result.kind = kind;\n        }\n        return result;\n    }\n    CodeAction.create = create;\n    function is(value) {\n        let candidate = value;\n        return candidate && Is.string(candidate.title) &&\n            (candidate.diagnostics === undefined || Is.typedArray(candidate.diagnostics, Diagnostic.is)) &&\n            (candidate.kind === undefined || Is.string(candidate.kind)) &&\n            (candidate.edit !== undefined || candidate.command !== undefined) &&\n            (candidate.command === undefined || Command.is(candidate.command)) &&\n            (candidate.isPreferred === undefined || Is.boolean(candidate.isPreferred)) &&\n            (candidate.edit === undefined || WorkspaceEdit.is(candidate.edit));\n    }\n    CodeAction.is = is;\n})(CodeAction || (CodeAction = {}));\n/**\n * The CodeLens namespace provides helper functions to work with\n * {@link CodeLens} literals.\n */\nexport var CodeLens;\n(function (CodeLens) {\n    /**\n     * Creates a new CodeLens literal.\n     */\n    function create(range, data) {\n        let result = { range };\n        if (Is.defined(data)) {\n            result.data = data;\n        }\n        return result;\n    }\n    CodeLens.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link CodeLens} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Range.is(candidate.range) && (Is.undefined(candidate.command) || Command.is(candidate.command));\n    }\n    CodeLens.is = is;\n})(CodeLens || (CodeLens = {}));\n/**\n * The FormattingOptions namespace provides helper functions to work with\n * {@link FormattingOptions} literals.\n */\nexport var FormattingOptions;\n(function (FormattingOptions) {\n    /**\n     * Creates a new FormattingOptions literal.\n     */\n    function create(tabSize, insertSpaces) {\n        return { tabSize, insertSpaces };\n    }\n    FormattingOptions.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link FormattingOptions} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.uinteger(candidate.tabSize) && Is.boolean(candidate.insertSpaces);\n    }\n    FormattingOptions.is = is;\n})(FormattingOptions || (FormattingOptions = {}));\n/**\n * The DocumentLink namespace provides helper functions to work with\n * {@link DocumentLink} literals.\n */\nexport var DocumentLink;\n(function (DocumentLink) {\n    /**\n     * Creates a new DocumentLink literal.\n     */\n    function create(range, target, data) {\n        return { range, target, data };\n    }\n    DocumentLink.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link DocumentLink} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Range.is(candidate.range) && (Is.undefined(candidate.target) || Is.string(candidate.target));\n    }\n    DocumentLink.is = is;\n})(DocumentLink || (DocumentLink = {}));\n/**\n * The SelectionRange namespace provides helper function to work with\n * SelectionRange literals.\n */\nexport var SelectionRange;\n(function (SelectionRange) {\n    /**\n     * Creates a new SelectionRange\n     * @param range the range.\n     * @param parent an optional parent.\n     */\n    function create(range, parent) {\n        return { range, parent };\n    }\n    SelectionRange.create = create;\n    function is(value) {\n        let candidate = value;\n        return Is.objectLiteral(candidate) && Range.is(candidate.range) && (candidate.parent === undefined || SelectionRange.is(candidate.parent));\n    }\n    SelectionRange.is = is;\n})(SelectionRange || (SelectionRange = {}));\n/**\n * A set of predefined token types. This set is not fixed\n * an clients can specify additional token types via the\n * corresponding client capabilities.\n *\n * @since 3.16.0\n */\nexport var SemanticTokenTypes;\n(function (SemanticTokenTypes) {\n    SemanticTokenTypes[\"namespace\"] = \"namespace\";\n    /**\n     * Represents a generic type. Acts as a fallback for types which can't be mapped to\n     * a specific type like class or enum.\n     */\n    SemanticTokenTypes[\"type\"] = \"type\";\n    SemanticTokenTypes[\"class\"] = \"class\";\n    SemanticTokenTypes[\"enum\"] = \"enum\";\n    SemanticTokenTypes[\"interface\"] = \"interface\";\n    SemanticTokenTypes[\"struct\"] = \"struct\";\n    SemanticTokenTypes[\"typeParameter\"] = \"typeParameter\";\n    SemanticTokenTypes[\"parameter\"] = \"parameter\";\n    SemanticTokenTypes[\"variable\"] = \"variable\";\n    SemanticTokenTypes[\"property\"] = \"property\";\n    SemanticTokenTypes[\"enumMember\"] = \"enumMember\";\n    SemanticTokenTypes[\"event\"] = \"event\";\n    SemanticTokenTypes[\"function\"] = \"function\";\n    SemanticTokenTypes[\"method\"] = \"method\";\n    SemanticTokenTypes[\"macro\"] = \"macro\";\n    SemanticTokenTypes[\"keyword\"] = \"keyword\";\n    SemanticTokenTypes[\"modifier\"] = \"modifier\";\n    SemanticTokenTypes[\"comment\"] = \"comment\";\n    SemanticTokenTypes[\"string\"] = \"string\";\n    SemanticTokenTypes[\"number\"] = \"number\";\n    SemanticTokenTypes[\"regexp\"] = \"regexp\";\n    SemanticTokenTypes[\"operator\"] = \"operator\";\n    /**\n     * @since 3.17.0\n     */\n    SemanticTokenTypes[\"decorator\"] = \"decorator\";\n})(SemanticTokenTypes || (SemanticTokenTypes = {}));\n/**\n * A set of predefined token modifiers. This set is not fixed\n * an clients can specify additional token types via the\n * corresponding client capabilities.\n *\n * @since 3.16.0\n */\nexport var SemanticTokenModifiers;\n(function (SemanticTokenModifiers) {\n    SemanticTokenModifiers[\"declaration\"] = \"declaration\";\n    SemanticTokenModifiers[\"definition\"] = \"definition\";\n    SemanticTokenModifiers[\"readonly\"] = \"readonly\";\n    SemanticTokenModifiers[\"static\"] = \"static\";\n    SemanticTokenModifiers[\"deprecated\"] = \"deprecated\";\n    SemanticTokenModifiers[\"abstract\"] = \"abstract\";\n    SemanticTokenModifiers[\"async\"] = \"async\";\n    SemanticTokenModifiers[\"modification\"] = \"modification\";\n    SemanticTokenModifiers[\"documentation\"] = \"documentation\";\n    SemanticTokenModifiers[\"defaultLibrary\"] = \"defaultLibrary\";\n})(SemanticTokenModifiers || (SemanticTokenModifiers = {}));\n/**\n * @since 3.16.0\n */\nexport var SemanticTokens;\n(function (SemanticTokens) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && (candidate.resultId === undefined || typeof candidate.resultId === 'string') &&\n            Array.isArray(candidate.data) && (candidate.data.length === 0 || typeof candidate.data[0] === 'number');\n    }\n    SemanticTokens.is = is;\n})(SemanticTokens || (SemanticTokens = {}));\n/**\n * The InlineValueText namespace provides functions to deal with InlineValueTexts.\n *\n * @since 3.17.0\n */\nexport var InlineValueText;\n(function (InlineValueText) {\n    /**\n     * Creates a new InlineValueText literal.\n     */\n    function create(range, text) {\n        return { range, text };\n    }\n    InlineValueText.create = create;\n    function is(value) {\n        const candidate = value;\n        return candidate !== undefined && candidate !== null && Range.is(candidate.range) && Is.string(candidate.text);\n    }\n    InlineValueText.is = is;\n})(InlineValueText || (InlineValueText = {}));\n/**\n * The InlineValueVariableLookup namespace provides functions to deal with InlineValueVariableLookups.\n *\n * @since 3.17.0\n */\nexport var InlineValueVariableLookup;\n(function (InlineValueVariableLookup) {\n    /**\n     * Creates a new InlineValueText literal.\n     */\n    function create(range, variableName, caseSensitiveLookup) {\n        return { range, variableName, caseSensitiveLookup };\n    }\n    InlineValueVariableLookup.create = create;\n    function is(value) {\n        const candidate = value;\n        return candidate !== undefined && candidate !== null && Range.is(candidate.range) && Is.boolean(candidate.caseSensitiveLookup)\n            && (Is.string(candidate.variableName) || candidate.variableName === undefined);\n    }\n    InlineValueVariableLookup.is = is;\n})(InlineValueVariableLookup || (InlineValueVariableLookup = {}));\n/**\n * The InlineValueEvaluatableExpression namespace provides functions to deal with InlineValueEvaluatableExpression.\n *\n * @since 3.17.0\n */\nexport var InlineValueEvaluatableExpression;\n(function (InlineValueEvaluatableExpression) {\n    /**\n     * Creates a new InlineValueEvaluatableExpression literal.\n     */\n    function create(range, expression) {\n        return { range, expression };\n    }\n    InlineValueEvaluatableExpression.create = create;\n    function is(value) {\n        const candidate = value;\n        return candidate !== undefined && candidate !== null && Range.is(candidate.range)\n            && (Is.string(candidate.expression) || candidate.expression === undefined);\n    }\n    InlineValueEvaluatableExpression.is = is;\n})(InlineValueEvaluatableExpression || (InlineValueEvaluatableExpression = {}));\n/**\n * The InlineValueContext namespace provides helper functions to work with\n * {@link InlineValueContext} literals.\n *\n * @since 3.17.0\n */\nexport var InlineValueContext;\n(function (InlineValueContext) {\n    /**\n     * Creates a new InlineValueContext literal.\n     */\n    function create(frameId, stoppedLocation) {\n        return { frameId, stoppedLocation };\n    }\n    InlineValueContext.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link InlineValueContext} interface.\n     */\n    function is(value) {\n        const candidate = value;\n        return Is.defined(candidate) && Range.is(value.stoppedLocation);\n    }\n    InlineValueContext.is = is;\n})(InlineValueContext || (InlineValueContext = {}));\n/**\n * Inlay hint kinds.\n *\n * @since 3.17.0\n */\nexport var InlayHintKind;\n(function (InlayHintKind) {\n    /**\n     * An inlay hint that for a type annotation.\n     */\n    InlayHintKind.Type = 1;\n    /**\n     * An inlay hint that is for a parameter.\n     */\n    InlayHintKind.Parameter = 2;\n    function is(value) {\n        return value === 1 || value === 2;\n    }\n    InlayHintKind.is = is;\n})(InlayHintKind || (InlayHintKind = {}));\nexport var InlayHintLabelPart;\n(function (InlayHintLabelPart) {\n    function create(value) {\n        return { value };\n    }\n    InlayHintLabelPart.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate)\n            && (candidate.tooltip === undefined || Is.string(candidate.tooltip) || MarkupContent.is(candidate.tooltip))\n            && (candidate.location === undefined || Location.is(candidate.location))\n            && (candidate.command === undefined || Command.is(candidate.command));\n    }\n    InlayHintLabelPart.is = is;\n})(InlayHintLabelPart || (InlayHintLabelPart = {}));\nexport var InlayHint;\n(function (InlayHint) {\n    function create(position, label, kind) {\n        const result = { position, label };\n        if (kind !== undefined) {\n            result.kind = kind;\n        }\n        return result;\n    }\n    InlayHint.create = create;\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && Position.is(candidate.position)\n            && (Is.string(candidate.label) || Is.typedArray(candidate.label, InlayHintLabelPart.is))\n            && (candidate.kind === undefined || InlayHintKind.is(candidate.kind))\n            && (candidate.textEdits === undefined) || Is.typedArray(candidate.textEdits, TextEdit.is)\n            && (candidate.tooltip === undefined || Is.string(candidate.tooltip) || MarkupContent.is(candidate.tooltip))\n            && (candidate.paddingLeft === undefined || Is.boolean(candidate.paddingLeft))\n            && (candidate.paddingRight === undefined || Is.boolean(candidate.paddingRight));\n    }\n    InlayHint.is = is;\n})(InlayHint || (InlayHint = {}));\nexport var StringValue;\n(function (StringValue) {\n    function createSnippet(value) {\n        return { kind: 'snippet', value };\n    }\n    StringValue.createSnippet = createSnippet;\n})(StringValue || (StringValue = {}));\nexport var InlineCompletionItem;\n(function (InlineCompletionItem) {\n    function create(insertText, filterText, range, command) {\n        return { insertText, filterText, range, command };\n    }\n    InlineCompletionItem.create = create;\n})(InlineCompletionItem || (InlineCompletionItem = {}));\nexport var InlineCompletionList;\n(function (InlineCompletionList) {\n    function create(items) {\n        return { items };\n    }\n    InlineCompletionList.create = create;\n})(InlineCompletionList || (InlineCompletionList = {}));\n/**\n * Describes how an {@link InlineCompletionItemProvider inline completion provider} was triggered.\n *\n * @since 3.18.0\n * @proposed\n */\nexport var InlineCompletionTriggerKind;\n(function (InlineCompletionTriggerKind) {\n    /**\n     * Completion was triggered explicitly by a user gesture.\n     */\n    InlineCompletionTriggerKind.Invoked = 0;\n    /**\n     * Completion was triggered automatically while editing.\n     */\n    InlineCompletionTriggerKind.Automatic = 1;\n})(InlineCompletionTriggerKind || (InlineCompletionTriggerKind = {}));\nexport var SelectedCompletionInfo;\n(function (SelectedCompletionInfo) {\n    function create(range, text) {\n        return { range, text };\n    }\n    SelectedCompletionInfo.create = create;\n})(SelectedCompletionInfo || (SelectedCompletionInfo = {}));\nexport var InlineCompletionContext;\n(function (InlineCompletionContext) {\n    function create(triggerKind, selectedCompletionInfo) {\n        return { triggerKind, selectedCompletionInfo };\n    }\n    InlineCompletionContext.create = create;\n})(InlineCompletionContext || (InlineCompletionContext = {}));\nexport var WorkspaceFolder;\n(function (WorkspaceFolder) {\n    function is(value) {\n        const candidate = value;\n        return Is.objectLiteral(candidate) && URI.is(candidate.uri) && Is.string(candidate.name);\n    }\n    WorkspaceFolder.is = is;\n})(WorkspaceFolder || (WorkspaceFolder = {}));\nexport const EOL = ['\\n', '\\r\\n', '\\r'];\n/**\n * @deprecated Use the text document from the new vscode-languageserver-textdocument package.\n */\nexport var TextDocument;\n(function (TextDocument) {\n    /**\n     * Creates a new ITextDocument literal from the given uri and content.\n     * @param uri The document's uri.\n     * @param languageId The document's language Id.\n     * @param version The document's version.\n     * @param content The document's content.\n     */\n    function create(uri, languageId, version, content) {\n        return new FullTextDocument(uri, languageId, version, content);\n    }\n    TextDocument.create = create;\n    /**\n     * Checks whether the given literal conforms to the {@link ITextDocument} interface.\n     */\n    function is(value) {\n        let candidate = value;\n        return Is.defined(candidate) && Is.string(candidate.uri) && (Is.undefined(candidate.languageId) || Is.string(candidate.languageId)) && Is.uinteger(candidate.lineCount)\n            && Is.func(candidate.getText) && Is.func(candidate.positionAt) && Is.func(candidate.offsetAt) ? true : false;\n    }\n    TextDocument.is = is;\n    function applyEdits(document, edits) {\n        let text = document.getText();\n        let sortedEdits = mergeSort(edits, (a, b) => {\n            let diff = a.range.start.line - b.range.start.line;\n            if (diff === 0) {\n                return a.range.start.character - b.range.start.character;\n            }\n            return diff;\n        });\n        let lastModifiedOffset = text.length;\n        for (let i = sortedEdits.length - 1; i >= 0; i--) {\n            let e = sortedEdits[i];\n            let startOffset = document.offsetAt(e.range.start);\n            let endOffset = document.offsetAt(e.range.end);\n            if (endOffset <= lastModifiedOffset) {\n                text = text.substring(0, startOffset) + e.newText + text.substring(endOffset, text.length);\n            }\n            else {\n                throw new Error('Overlapping edit');\n            }\n            lastModifiedOffset = startOffset;\n        }\n        return text;\n    }\n    TextDocument.applyEdits = applyEdits;\n    function mergeSort(data, compare) {\n        if (data.length <= 1) {\n            // sorted\n            return data;\n        }\n        const p = (data.length / 2) | 0;\n        const left = data.slice(0, p);\n        const right = data.slice(p);\n        mergeSort(left, compare);\n        mergeSort(right, compare);\n        let leftIdx = 0;\n        let rightIdx = 0;\n        let i = 0;\n        while (leftIdx < left.length && rightIdx < right.length) {\n            let ret = compare(left[leftIdx], right[rightIdx]);\n            if (ret <= 0) {\n                // smaller_equal -> take left to preserve order\n                data[i++] = left[leftIdx++];\n            }\n            else {\n                // greater -> take right\n                data[i++] = right[rightIdx++];\n            }\n        }\n        while (leftIdx < left.length) {\n            data[i++] = left[leftIdx++];\n        }\n        while (rightIdx < right.length) {\n            data[i++] = right[rightIdx++];\n        }\n        return data;\n    }\n})(TextDocument || (TextDocument = {}));\n/**\n * @deprecated Use the text document from the new vscode-languageserver-textdocument package.\n */\nclass FullTextDocument {\n    constructor(uri, languageId, version, content) {\n        this._uri = uri;\n        this._languageId = languageId;\n        this._version = version;\n        this._content = content;\n        this._lineOffsets = undefined;\n    }\n    get uri() {\n        return this._uri;\n    }\n    get languageId() {\n        return this._languageId;\n    }\n    get version() {\n        return this._version;\n    }\n    getText(range) {\n        if (range) {\n            let start = this.offsetAt(range.start);\n            let end = this.offsetAt(range.end);\n            return this._content.substring(start, end);\n        }\n        return this._content;\n    }\n    update(event, version) {\n        this._content = event.text;\n        this._version = version;\n        this._lineOffsets = undefined;\n    }\n    getLineOffsets() {\n        if (this._lineOffsets === undefined) {\n            let lineOffsets = [];\n            let text = this._content;\n            let isLineStart = true;\n            for (let i = 0; i < text.length; i++) {\n                if (isLineStart) {\n                    lineOffsets.push(i);\n                    isLineStart = false;\n                }\n                let ch = text.charAt(i);\n                isLineStart = (ch === '\\r' || ch === '\\n');\n                if (ch === '\\r' && i + 1 < text.length && text.charAt(i + 1) === '\\n') {\n                    i++;\n                }\n            }\n            if (isLineStart && text.length > 0) {\n                lineOffsets.push(text.length);\n            }\n            this._lineOffsets = lineOffsets;\n        }\n        return this._lineOffsets;\n    }\n    positionAt(offset) {\n        offset = Math.max(Math.min(offset, this._content.length), 0);\n        let lineOffsets = this.getLineOffsets();\n        let low = 0, high = lineOffsets.length;\n        if (high === 0) {\n            return Position.create(0, offset);\n        }\n        while (low < high) {\n            let mid = Math.floor((low + high) / 2);\n            if (lineOffsets[mid] > offset) {\n                high = mid;\n            }\n            else {\n                low = mid + 1;\n            }\n        }\n        // low is the least x for which the line offset is larger than the current offset\n        // or array.length if no line offset is larger than the current offset\n        let line = low - 1;\n        return Position.create(line, offset - lineOffsets[line]);\n    }\n    offsetAt(position) {\n        let lineOffsets = this.getLineOffsets();\n        if (position.line >= lineOffsets.length) {\n            return this._content.length;\n        }\n        else if (position.line < 0) {\n            return 0;\n        }\n        let lineOffset = lineOffsets[position.line];\n        let nextLineOffset = (position.line + 1 < lineOffsets.length) ? lineOffsets[position.line + 1] : this._content.length;\n        return Math.max(Math.min(lineOffset + position.character, nextLineOffset), lineOffset);\n    }\n    get lineCount() {\n        return this.getLineOffsets().length;\n    }\n}\nvar Is;\n(function (Is) {\n    const toString = Object.prototype.toString;\n    function defined(value) {\n        return typeof value !== 'undefined';\n    }\n    Is.defined = defined;\n    function undefined(value) {\n        return typeof value === 'undefined';\n    }\n    Is.undefined = undefined;\n    function boolean(value) {\n        return value === true || value === false;\n    }\n    Is.boolean = boolean;\n    function string(value) {\n        return toString.call(value) === '[object String]';\n    }\n    Is.string = string;\n    function number(value) {\n        return toString.call(value) === '[object Number]';\n    }\n    Is.number = number;\n    function numberRange(value, min, max) {\n        return toString.call(value) === '[object Number]' && min <= value && value <= max;\n    }\n    Is.numberRange = numberRange;\n    function integer(value) {\n        return toString.call(value) === '[object Number]' && -2147483648 <= value && value <= 2147483647;\n    }\n    Is.integer = integer;\n    function uinteger(value) {\n        return toString.call(value) === '[object Number]' && 0 <= value && value <= 2147483647;\n    }\n    Is.uinteger = uinteger;\n    function func(value) {\n        return toString.call(value) === '[object Function]';\n    }\n    Is.func = func;\n    function objectLiteral(value) {\n        // Strictly speaking class instances pass this check as well. Since the LSP\n        // doesn't use classes we ignore this for now. If we do we need to add something\n        // like this: `Object.getPrototypeOf(Object.getPrototypeOf(x)) === null`\n        return value !== null && typeof value === 'object';\n    }\n    Is.objectLiteral = objectLiteral;\n    function typedArray(value, check) {\n        return Array.isArray(value) && value.every(check);\n    }\n    Is.typedArray = typedArray;\n})(Is || (Is = {}));\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { IToken, TokenType } from 'chevrotain';\r\nimport type { Range } from 'vscode-languageserver-types';\r\nimport type { AbstractElement } from '../languages/generated/ast.js';\r\nimport type { AstNode, CompositeCstNode, CstNode, LeafCstNode, RootCstNode } from '../syntax-tree.js';\r\nimport { Position } from 'vscode-languageserver-types';\r\nimport { tokenToRange } from '../utils/cst-utils.js';\r\n\r\nexport class CstNodeBuilder {\r\n\r\n    private rootNode!: RootCstNodeImpl;\r\n    private nodeStack: CompositeCstNodeImpl[] = [];\r\n\r\n    get current(): CompositeCstNodeImpl {\r\n        return this.nodeStack[this.nodeStack.length - 1] ?? this.rootNode;\r\n    }\r\n\r\n    buildRootNode(input: string): RootCstNode {\r\n        this.rootNode = new RootCstNodeImpl(input);\r\n        this.rootNode.root = this.rootNode;\r\n        this.nodeStack = [this.rootNode];\r\n        return this.rootNode;\r\n    }\r\n\r\n    buildCompositeNode(feature: AbstractElement): CompositeCstNode {\r\n        const compositeNode = new CompositeCstNodeImpl();\r\n        compositeNode.grammarSource = feature;\r\n        compositeNode.root = this.rootNode;\r\n        this.current.content.push(compositeNode);\r\n        this.nodeStack.push(compositeNode);\r\n        return compositeNode;\r\n    }\r\n\r\n    buildLeafNode(token: IToken, feature?: AbstractElement): LeafCstNode {\r\n        const leafNode = new LeafCstNodeImpl(token.startOffset, token.image.length, tokenToRange(token), token.tokenType, !feature);\r\n        leafNode.grammarSource = feature;\r\n        leafNode.root = this.rootNode;\r\n        this.current.content.push(leafNode);\r\n        return leafNode;\r\n    }\r\n\r\n    removeNode(node: CstNode): void {\r\n        const parent = node.container;\r\n        if (parent) {\r\n            const index = parent.content.indexOf(node);\r\n            if (index >= 0) {\r\n                parent.content.splice(index, 1);\r\n            }\r\n        }\r\n    }\r\n\r\n    addHiddenNodes(tokens: IToken[]): void {\r\n        const nodes: LeafCstNode[] = [];\r\n        for (const token of tokens) {\r\n            const leafNode = new LeafCstNodeImpl(token.startOffset, token.image.length, tokenToRange(token), token.tokenType, true);\r\n            leafNode.root = this.rootNode;\r\n            nodes.push(leafNode);\r\n        }\r\n        let current: CompositeCstNode = this.current;\r\n        let added = false;\r\n        // If we are within a composite node, we add the hidden nodes to the content\r\n        if (current.content.length > 0) {\r\n            current.content.push(...nodes);\r\n            return;\r\n        }\r\n        // Otherwise we are at a newly created node\r\n        // Instead of adding the hidden nodes here, we search for the first parent node with content\r\n        while (current.container) {\r\n            const index = current.container.content.indexOf(current);\r\n            if (index > 0) {\r\n                // Add the hidden nodes before the current node\r\n                current.container.content.splice(index, 0, ...nodes);\r\n                added = true;\r\n                break;\r\n            }\r\n            current = current.container;\r\n        }\r\n        // If we arrive at the root node, we add the hidden nodes at the beginning\r\n        // This is the case if the hidden nodes are the first nodes in the tree\r\n        if (!added) {\r\n            this.rootNode.content.unshift(...nodes);\r\n        }\r\n    }\r\n\r\n    construct(item: { $type: string | symbol | undefined, $cstNode: CstNode }): void {\r\n        const current: CstNode = this.current;\r\n        // The specified item could be a datatype ($type is symbol) or a fragment ($type is undefined)\r\n        // Only if the $type is a string, we actually assign the element\r\n        if (typeof item.$type === 'string') {\r\n            this.current.astNode = <AstNode>item;\r\n        }\r\n        item.$cstNode = current;\r\n        const node = this.nodeStack.pop();\r\n        // Empty composite nodes are not valid\r\n        // Simply remove the node from the tree\r\n        if (node?.content.length === 0) {\r\n            this.removeNode(node);\r\n        }\r\n    }\r\n}\r\n\r\nexport abstract class AbstractCstNode implements CstNode {\r\n    abstract get offset(): number;\r\n    abstract get length(): number;\r\n    abstract get end(): number;\r\n    abstract get range(): Range;\r\n\r\n    container?: CompositeCstNode;\r\n    grammarSource?: AbstractElement;\r\n    root: RootCstNode;\r\n    private _astNode?: AstNode;\r\n\r\n    /** @deprecated use `container` instead. */\r\n    get parent(): CompositeCstNode | undefined {\r\n        return this.container;\r\n    }\r\n\r\n    /** @deprecated use `grammarSource` instead. */\r\n    get feature(): AbstractElement | undefined {\r\n        return this.grammarSource;\r\n    }\r\n\r\n    get hidden(): boolean {\r\n        return false;\r\n    }\r\n\r\n    get astNode(): AstNode {\r\n        const node = typeof this._astNode?.$type === 'string' ? this._astNode : this.container?.astNode;\r\n        if (!node) {\r\n            throw new Error('This node has no associated AST element');\r\n        }\r\n        return node;\r\n    }\r\n\r\n    set astNode(value: AstNode | undefined) {\r\n        this._astNode = value;\r\n    }\r\n\r\n    /** @deprecated use `astNode` instead. */\r\n    get element(): AstNode {\r\n        return this.astNode;\r\n    }\r\n\r\n    get text(): string {\r\n        return this.root.fullText.substring(this.offset, this.end);\r\n    }\r\n}\r\n\r\nexport class LeafCstNodeImpl extends AbstractCstNode implements LeafCstNode {\r\n    get offset(): number {\r\n        return this._offset;\r\n    }\r\n\r\n    get length(): number {\r\n        return this._length;\r\n    }\r\n\r\n    get end(): number {\r\n        return this._offset + this._length;\r\n    }\r\n\r\n    override get hidden(): boolean {\r\n        return this._hidden;\r\n    }\r\n\r\n    get tokenType(): TokenType {\r\n        return this._tokenType;\r\n    }\r\n\r\n    get range(): Range {\r\n        return this._range;\r\n    }\r\n\r\n    private _hidden: boolean;\r\n    private _offset: number;\r\n    private _length: number;\r\n    private _range: Range;\r\n    private _tokenType: TokenType;\r\n\r\n    constructor(offset: number, length: number, range: Range, tokenType: TokenType, hidden = false) {\r\n        super();\r\n        this._hidden = hidden;\r\n        this._offset = offset;\r\n        this._tokenType = tokenType;\r\n        this._length = length;\r\n        this._range = range;\r\n    }\r\n}\r\n\r\nexport class CompositeCstNodeImpl extends AbstractCstNode implements CompositeCstNode {\r\n    readonly content: CstNode[] = new CstNodeContainer(this);\r\n    private _rangeCache?: Range;\r\n\r\n    /** @deprecated use `content` instead. */\r\n    get children(): CstNode[] {\r\n        return this.content;\r\n    }\r\n\r\n    get offset(): number {\r\n        return this.firstNonHiddenNode?.offset ?? 0;\r\n    }\r\n\r\n    get length(): number {\r\n        return this.end - this.offset;\r\n    }\r\n\r\n    get end(): number {\r\n        return this.lastNonHiddenNode?.end ?? 0;\r\n    }\r\n\r\n    get range(): Range {\r\n        const firstNode = this.firstNonHiddenNode;\r\n        const lastNode = this.lastNonHiddenNode;\r\n        if (firstNode && lastNode) {\r\n            if (this._rangeCache === undefined) {\r\n                const { range: firstRange } = firstNode;\r\n                const { range: lastRange } = lastNode;\r\n                this._rangeCache = { start: firstRange.start, end: lastRange.end.line < firstRange.start.line ? firstRange.start : lastRange.end };\r\n            }\r\n            return this._rangeCache;\r\n        } else {\r\n            return { start: Position.create(0, 0), end: Position.create(0, 0) };\r\n        }\r\n    }\r\n\r\n    private get firstNonHiddenNode(): CstNode | undefined {\r\n        for (const child of this.content) {\r\n            if (!child.hidden) {\r\n                return child;\r\n            }\r\n        }\r\n        return this.content[0];\r\n    }\r\n\r\n    private get lastNonHiddenNode(): CstNode | undefined {\r\n        for (let i = this.content.length - 1; i >= 0; i--) {\r\n            const child = this.content[i];\r\n            if (!child.hidden) {\r\n                return child;\r\n            }\r\n        }\r\n        return this.content[this.content.length - 1];\r\n    }\r\n}\r\n\r\nclass CstNodeContainer extends Array<CstNode> {\r\n    readonly parent: CompositeCstNode;\r\n\r\n    constructor(parent: CompositeCstNode) {\r\n        super();\r\n        this.parent = parent;\r\n        Object.setPrototypeOf(this, CstNodeContainer.prototype);\r\n    }\r\n\r\n    override push(...items: CstNode[]): number {\r\n        this.addParents(items);\r\n        return super.push(...items);\r\n    }\r\n\r\n    override unshift(...items: CstNode[]): number {\r\n        this.addParents(items);\r\n        return super.unshift(...items);\r\n    }\r\n\r\n    override splice(start: number, count: number, ...items: CstNode[]): CstNode[] {\r\n        this.addParents(items);\r\n        return super.splice(start, count, ...items);\r\n    }\r\n\r\n    private addParents(items: CstNode[]): void {\r\n        for (const item of items) {\r\n            (<AbstractCstNode>item).container = this.parent;\r\n        }\r\n    }\r\n}\r\n\r\nexport class RootCstNodeImpl extends CompositeCstNodeImpl implements RootCstNode {\r\n    private _text = '';\r\n\r\n    override get text(): string {\r\n        return this._text.substring(this.offset, this.end);\r\n    }\r\n\r\n    get fullText(): string {\r\n        return this._text;\r\n    }\r\n\r\n    constructor(input?: string) {\r\n        super();\r\n        this._text = input ?? '';\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\n/* eslint-disable @typescript-eslint/no-explicit-any */\r\nimport type { DSLMethodOpts, ILexingError, IOrAlt, IParserErrorMessageProvider, IRecognitionException, IToken, TokenType, TokenVocabulary } from 'chevrotain';\r\nimport type { AbstractElement, Action, Assignment, ParserRule } from '../languages/generated/ast.js';\r\nimport type { Linker } from '../references/linker.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, AstReflection, CompositeCstNode, CstNode } from '../syntax-tree.js';\r\nimport type { Lexer, LexerResult } from './lexer.js';\r\nimport type { IParserConfig } from './parser-config.js';\r\nimport type { ValueConverter } from './value-converter.js';\r\nimport { defaultParserErrorProvider, EmbeddedActionsParser, LLkLookaheadStrategy } from 'chevrotain';\r\nimport { LLStarLookaheadStrategy } from 'chevrotain-allstar';\r\nimport { isAssignment, isCrossReference, isKeyword } from '../languages/generated/ast.js';\r\nimport { getExplicitRuleType, isDataTypeRule } from '../utils/grammar-utils.js';\r\nimport { assignMandatoryProperties, getContainerOfType, linkContentToContainer } from '../utils/ast-utils.js';\r\nimport { CstNodeBuilder } from './cst-node-builder.js';\r\nimport type { LexingReport } from './token-builder.js';\r\n\r\nexport type ParseResult<T = AstNode> = {\r\n    value: T,\r\n    parserErrors: IRecognitionException[],\r\n    lexerErrors: ILexingError[],\r\n    lexerReport?: LexingReport\r\n}\r\n\r\nexport const DatatypeSymbol = Symbol('Datatype');\r\n\r\ninterface DataTypeNode {\r\n    $cstNode: CompositeCstNode\r\n    /** Instead of a string, this node is uniquely identified by the `Datatype` symbol */\r\n    $type: symbol\r\n    /** Used as a storage for all parsed terminals, keywords and sub-datatype rules */\r\n    value: string\r\n}\r\n\r\nfunction isDataTypeNode(node: { $type: string | symbol | undefined }): node is DataTypeNode {\r\n    return node.$type === DatatypeSymbol;\r\n}\r\n\r\ntype RuleResult = (args: Args) => any;\r\n\r\ntype Args = Record<string, boolean>;\r\n\r\ntype RuleImpl = (args: Args) => any;\r\n\r\ninterface AssignmentElement {\r\n    assignment?: Assignment\r\n    isCrossRef: boolean\r\n}\r\n\r\n/**\r\n * Base interface for all parsers. Mainly used by the `parser-builder-base.ts` to perform work on different kinds of parsers.\r\n * The main use cases are:\r\n * * AST parser: Based on a string, create an AST for the current grammar\r\n * * Completion parser: Based on a partial string, identify the current position of the input within the grammar\r\n */\r\nexport interface BaseParser {\r\n    /**\r\n     * Adds a new parser rule to the parser\r\n     */\r\n    rule(rule: ParserRule, impl: RuleImpl): RuleResult;\r\n    /**\r\n     * Returns the executable rule function for the specified rule name\r\n     */\r\n    getRule(name: string): RuleResult | undefined;\r\n    /**\r\n     * Performs alternatives parsing (the `|` operation in EBNF/Langium)\r\n     */\r\n    alternatives(idx: number, choices: Array<IOrAlt<any>>): void;\r\n    /**\r\n     * Parses the callback as optional (the `?` operation in EBNF/Langium)\r\n     */\r\n    optional(idx: number, callback: DSLMethodOpts<unknown>): void;\r\n    /**\r\n     * Parses the callback 0 or more times (the `*` operation in EBNF/Langium)\r\n     */\r\n    many(idx: number, callback: DSLMethodOpts<unknown>): void;\r\n    /**\r\n     * Parses the callback 1 or more times (the `+` operation in EBNF/Langium)\r\n     */\r\n    atLeastOne(idx: number, callback: DSLMethodOpts<unknown>): void;\r\n    /**\r\n     * Consumes a specific token type from the token input stream.\r\n     * Requires a unique index within the rule for a specific token type.\r\n     */\r\n    consume(idx: number, tokenType: TokenType, feature: AbstractElement): void;\r\n    /**\r\n     * Invokes the executable function for a given parser rule.\r\n     * Requires a unique index within the rule for a specific sub rule.\r\n     * Arguments can be supplied to the rule invocation for semantic predicates\r\n     */\r\n    subrule(idx: number, rule: RuleResult, fragment: boolean, feature: AbstractElement, args: Args): void;\r\n    /**\r\n     * Executes a grammar action that modifies the currently active AST node\r\n     */\r\n    action($type: string, action: Action): void;\r\n    /**\r\n     * Finishes construction of the current AST node. Only used by the AST parser.\r\n     */\r\n    construct(): unknown;\r\n    /**\r\n     * Whether the parser is currently actually in use or in \"recording mode\".\r\n     * Recording mode is activated once when the parser is analyzing itself.\r\n     * During this phase, no input exists and therefore no AST should be constructed\r\n     */\r\n    isRecording(): boolean;\r\n    /**\r\n     * Current state of the unordered groups\r\n     */\r\n    get unorderedGroups(): Map<string, boolean[]>;\r\n    /**\r\n     * The rule stack indicates the indices of rules that are currently invoked,\r\n     * in order of their invocation.\r\n     */\r\n    getRuleStack(): number[];\r\n}\r\n\r\nconst ruleSuffix = '\\u200B';\r\nconst withRuleSuffix = (name: string): string => name.endsWith(ruleSuffix) ? name : name + ruleSuffix;\r\n\r\nexport abstract class AbstractLangiumParser implements BaseParser {\r\n\r\n    protected readonly lexer: Lexer;\r\n    protected readonly wrapper: ChevrotainWrapper;\r\n    protected _unorderedGroups: Map<string, boolean[]> = new Map<string, boolean[]>();\r\n\r\n    protected allRules = new Map<string, RuleResult>();\r\n    protected mainRule!: RuleResult;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.lexer = services.parser.Lexer;\r\n        const tokens = this.lexer.definition;\r\n        const production = services.LanguageMetaData.mode === 'production';\r\n        this.wrapper = new ChevrotainWrapper(tokens, {\r\n            ...services.parser.ParserConfig,\r\n            skipValidations: production,\r\n            errorMessageProvider: services.parser.ParserErrorMessageProvider\r\n        });\r\n    }\r\n\r\n    alternatives(idx: number, choices: Array<IOrAlt<any>>): void {\r\n        this.wrapper.wrapOr(idx, choices);\r\n    }\r\n\r\n    optional(idx: number, callback: DSLMethodOpts<unknown>): void {\r\n        this.wrapper.wrapOption(idx, callback);\r\n    }\r\n\r\n    many(idx: number, callback: DSLMethodOpts<unknown>): void {\r\n        this.wrapper.wrapMany(idx, callback);\r\n    }\r\n\r\n    atLeastOne(idx: number, callback: DSLMethodOpts<unknown>): void {\r\n        this.wrapper.wrapAtLeastOne(idx, callback);\r\n    }\r\n\r\n    abstract rule(rule: ParserRule, impl: RuleImpl): RuleResult;\r\n    abstract consume(idx: number, tokenType: TokenType, feature: AbstractElement): void;\r\n    abstract subrule(idx: number, rule: RuleResult, fragment: boolean, feature: AbstractElement, args: Args): void;\r\n    abstract action($type: string, action: Action): void;\r\n    abstract construct(): unknown;\r\n\r\n    getRule(name: string): RuleResult | undefined {\r\n        return this.allRules.get(name);\r\n    }\r\n\r\n    isRecording(): boolean {\r\n        return this.wrapper.IS_RECORDING;\r\n    }\r\n\r\n    get unorderedGroups(): Map<string, boolean[]> {\r\n        return this._unorderedGroups;\r\n    }\r\n\r\n    getRuleStack(): number[] {\r\n        return (this.wrapper as any).RULE_STACK;\r\n    }\r\n\r\n    finalize(): void {\r\n        this.wrapper.wrapSelfAnalysis();\r\n    }\r\n}\r\n\r\nexport interface ParserOptions {\r\n    rule?: string\r\n}\r\n\r\nexport class LangiumParser extends AbstractLangiumParser {\r\n    private readonly linker: Linker;\r\n    private readonly converter: ValueConverter;\r\n    private readonly astReflection: AstReflection;\r\n    private readonly nodeBuilder = new CstNodeBuilder();\r\n    private lexerResult?: LexerResult;\r\n    private stack: any[] = [];\r\n    private assignmentMap = new Map<AbstractElement, AssignmentElement | undefined>();\r\n\r\n    private get current(): any {\r\n        return this.stack[this.stack.length - 1];\r\n    }\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        super(services);\r\n        this.linker = services.references.Linker;\r\n        this.converter = services.parser.ValueConverter;\r\n        this.astReflection = services.shared.AstReflection;\r\n    }\r\n\r\n    rule(rule: ParserRule, impl: RuleImpl): RuleResult {\r\n        const type = this.computeRuleType(rule);\r\n        const ruleMethod = this.wrapper.DEFINE_RULE(withRuleSuffix(rule.name), this.startImplementation(type, impl).bind(this));\r\n        this.allRules.set(rule.name, ruleMethod);\r\n        if (rule.entry) {\r\n            this.mainRule = ruleMethod;\r\n        }\r\n        return ruleMethod;\r\n    }\r\n\r\n    private computeRuleType(rule: ParserRule): string | symbol | undefined {\r\n        if (rule.fragment) {\r\n            return undefined;\r\n        } else if (isDataTypeRule(rule)) {\r\n            return DatatypeSymbol;\r\n        } else {\r\n            const explicit = getExplicitRuleType(rule);\r\n            return explicit ?? rule.name;\r\n        }\r\n    }\r\n\r\n    parse<T extends AstNode = AstNode>(input: string, options: ParserOptions = {}): ParseResult<T> {\r\n        this.nodeBuilder.buildRootNode(input);\r\n        const lexerResult = this.lexerResult = this.lexer.tokenize(input);\r\n        this.wrapper.input = lexerResult.tokens;\r\n        const ruleMethod = options.rule ? this.allRules.get(options.rule) : this.mainRule;\r\n        if (!ruleMethod) {\r\n            throw new Error(options.rule ? `No rule found with name '${options.rule}'` : 'No main rule available.');\r\n        }\r\n        const result = ruleMethod.call(this.wrapper, {});\r\n        this.nodeBuilder.addHiddenNodes(lexerResult.hidden);\r\n        this.unorderedGroups.clear();\r\n        this.lexerResult = undefined;\r\n        return {\r\n            value: result,\r\n            lexerErrors: lexerResult.errors,\r\n            lexerReport: lexerResult.report,\r\n            parserErrors: this.wrapper.errors\r\n        };\r\n    }\r\n\r\n    private startImplementation($type: string | symbol | undefined, implementation: RuleImpl): RuleImpl {\r\n        return (args) => {\r\n            // Only create a new AST node in case the calling rule is not a fragment rule\r\n            const createNode = !this.isRecording() && $type !== undefined;\r\n            if (createNode) {\r\n                const node: any = { $type };\r\n                this.stack.push(node);\r\n                if ($type === DatatypeSymbol) {\r\n                    node.value = '';\r\n                }\r\n            }\r\n            let result: unknown;\r\n            try {\r\n                result = implementation(args);\r\n            } catch (err) {\r\n                result = undefined;\r\n            }\r\n            if (result === undefined && createNode) {\r\n                result = this.construct();\r\n            }\r\n            return result;\r\n        };\r\n    }\r\n\r\n    private extractHiddenTokens(token: IToken): IToken[] {\r\n        const hiddenTokens = this.lexerResult!.hidden;\r\n        if (!hiddenTokens.length) {\r\n            return [];\r\n        }\r\n        const offset = token.startOffset;\r\n        for (let i = 0; i < hiddenTokens.length; i++) {\r\n            const token = hiddenTokens[i];\r\n            if (token.startOffset > offset) {\r\n                return hiddenTokens.splice(0, i);\r\n            }\r\n        }\r\n        return hiddenTokens.splice(0, hiddenTokens.length);\r\n    }\r\n\r\n    consume(idx: number, tokenType: TokenType, feature: AbstractElement): void {\r\n        const token = this.wrapper.wrapConsume(idx, tokenType);\r\n        if (!this.isRecording() && this.isValidToken(token)) {\r\n            const hiddenTokens = this.extractHiddenTokens(token);\r\n            this.nodeBuilder.addHiddenNodes(hiddenTokens);\r\n            const leafNode = this.nodeBuilder.buildLeafNode(token, feature);\r\n            const { assignment, isCrossRef } = this.getAssignment(feature);\r\n            const current = this.current;\r\n            if (assignment) {\r\n                const convertedValue = isKeyword(feature) ? token.image : this.converter.convert(token.image, leafNode);\r\n                this.assign(assignment.operator, assignment.feature, convertedValue, leafNode, isCrossRef);\r\n            } else if (isDataTypeNode(current)) {\r\n                let text = token.image;\r\n                if (!isKeyword(feature)) {\r\n                    text = this.converter.convert(text, leafNode).toString();\r\n                }\r\n                current.value += text;\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Most consumed parser tokens are valid. However there are two cases in which they are not valid:\r\n     *\r\n     * 1. They were inserted during error recovery by the parser. These tokens don't really exist and should not be further processed\r\n     * 2. They contain invalid token ranges. This might include the special EOF token, or other tokens produced by invalid token builders.\r\n     */\r\n    private isValidToken(token: IToken): boolean {\r\n        return !token.isInsertedInRecovery && !isNaN(token.startOffset) && typeof token.endOffset === 'number' && !isNaN(token.endOffset);\r\n    }\r\n\r\n    subrule(idx: number, rule: RuleResult, fragment: boolean, feature: AbstractElement, args: Args): void {\r\n        let cstNode: CompositeCstNode | undefined;\r\n        if (!this.isRecording() && !fragment) {\r\n            // We only want to create a new CST node if the subrule actually creates a new AST node.\r\n            // In other cases like calls of fragment rules the current CST/AST is populated further.\r\n            // Note that skipping this initialization and leaving cstNode unassigned also skips the subrule assignment later on.\r\n            // This is intended, as fragment rules only enrich the current AST node\r\n            cstNode = this.nodeBuilder.buildCompositeNode(feature);\r\n        }\r\n        const subruleResult = this.wrapper.wrapSubrule(idx, rule, args) as any;\r\n        if (!this.isRecording() && cstNode && cstNode.length > 0) {\r\n            this.performSubruleAssignment(subruleResult, feature, cstNode);\r\n        }\r\n    }\r\n\r\n    private performSubruleAssignment(result: any, feature: AbstractElement, cstNode: CompositeCstNode): void {\r\n        const { assignment, isCrossRef } = this.getAssignment(feature);\r\n        if (assignment) {\r\n            this.assign(assignment.operator, assignment.feature, result, cstNode, isCrossRef);\r\n        } else if (!assignment) {\r\n            // If we call a subrule without an assignment we either:\r\n            // 1. append the result of the subrule (data type rule)\r\n            // 2. override the current object with the newly parsed object\r\n            // If the current element is an AST node and the result of the subrule\r\n            // is a data type rule, we can safely discard the results.\r\n            const current = this.current;\r\n            if (isDataTypeNode(current)) {\r\n                current.value += result.toString();\r\n            } else if (typeof result === 'object' && result) {\r\n                const object = this.assignWithoutOverride(result, current);\r\n                const newItem = object;\r\n                this.stack.pop();\r\n                this.stack.push(newItem);\r\n            }\r\n        }\r\n    }\r\n\r\n    action($type: string, action: Action): void {\r\n        if (!this.isRecording()) {\r\n            let last = this.current;\r\n            if (action.feature && action.operator) {\r\n                last = this.construct();\r\n                this.nodeBuilder.removeNode(last.$cstNode);\r\n                const node = this.nodeBuilder.buildCompositeNode(action);\r\n                node.content.push(last.$cstNode);\r\n                const newItem = { $type };\r\n                this.stack.push(newItem);\r\n                this.assign(action.operator, action.feature, last, last.$cstNode, false);\r\n            } else {\r\n                last.$type = $type;\r\n            }\r\n        }\r\n    }\r\n\r\n    construct(): unknown {\r\n        if (this.isRecording()) {\r\n            return undefined;\r\n        }\r\n        const obj = this.current;\r\n        linkContentToContainer(obj);\r\n        this.nodeBuilder.construct(obj);\r\n        this.stack.pop();\r\n        if (isDataTypeNode(obj)) {\r\n            return this.converter.convert(obj.value, obj.$cstNode);\r\n        } else {\r\n            assignMandatoryProperties(this.astReflection, obj);\r\n        }\r\n        return obj;\r\n    }\r\n\r\n    private getAssignment(feature: AbstractElement): AssignmentElement {\r\n        if (!this.assignmentMap.has(feature)) {\r\n            const assignment = getContainerOfType(feature, isAssignment);\r\n            this.assignmentMap.set(feature, {\r\n                assignment: assignment,\r\n                isCrossRef: assignment ? isCrossReference(assignment.terminal) : false\r\n            });\r\n        }\r\n        return this.assignmentMap.get(feature)!;\r\n    }\r\n\r\n    private assign(operator: string, feature: string, value: unknown, cstNode: CstNode, isCrossRef: boolean): void {\r\n        const obj = this.current;\r\n        let item: unknown;\r\n        if (isCrossRef && typeof value === 'string') {\r\n            item = this.linker.buildReference(obj, feature, cstNode, value);\r\n        } else {\r\n            item = value;\r\n        }\r\n        switch (operator) {\r\n            case '=': {\r\n                obj[feature] = item;\r\n                break;\r\n            }\r\n            case '?=': {\r\n                obj[feature] = true;\r\n                break;\r\n            }\r\n            case '+=': {\r\n                if (!Array.isArray(obj[feature])) {\r\n                    obj[feature] = [];\r\n                }\r\n                obj[feature].push(item);\r\n            }\r\n        }\r\n    }\r\n\r\n    private assignWithoutOverride(target: any, source: any): any {\r\n        for (const [name, existingValue] of Object.entries(source)) {\r\n            const newValue = target[name];\r\n            if (newValue === undefined) {\r\n                target[name] = existingValue;\r\n            } else if (Array.isArray(newValue) && Array.isArray(existingValue)) {\r\n                existingValue.push(...newValue);\r\n                target[name] = existingValue;\r\n            }\r\n        }\r\n        // The target was parsed from a unassigned subrule\r\n        // After the subrule construction, it received a cst node\r\n        // This CST node will later be overriden by the cst node builder\r\n        // To prevent references to stale AST nodes in the CST,\r\n        // we need to remove the reference here\r\n        const targetCstNode = target.$cstNode;\r\n        if (targetCstNode) {\r\n            targetCstNode.astNode = undefined;\r\n            target.$cstNode = undefined;\r\n        }\r\n        return target;\r\n    }\r\n\r\n    get definitionErrors(): IParserDefinitionError[] {\r\n        return this.wrapper.definitionErrors;\r\n    }\r\n}\r\n\r\nexport interface IParserDefinitionError {\r\n    message: string\r\n    type: number\r\n    ruleName?: string\r\n}\r\n\r\nexport abstract class AbstractParserErrorMessageProvider implements IParserErrorMessageProvider {\r\n\r\n    buildMismatchTokenMessage(options: {\r\n        expected: TokenType\r\n        actual: IToken\r\n        previous: IToken\r\n        ruleName: string\r\n    }): string {\r\n        return defaultParserErrorProvider.buildMismatchTokenMessage(options);\r\n    }\r\n\r\n    buildNotAllInputParsedMessage(options: {\r\n        firstRedundant: IToken\r\n        ruleName: string\r\n    }): string {\r\n        return defaultParserErrorProvider.buildNotAllInputParsedMessage(options);\r\n    }\r\n\r\n    buildNoViableAltMessage(options: {\r\n        expectedPathsPerAlt: TokenType[][][]\r\n        actual: IToken[]\r\n        previous: IToken\r\n        customUserDescription: string\r\n        ruleName: string\r\n    }): string {\r\n        return defaultParserErrorProvider.buildNoViableAltMessage(options);\r\n    }\r\n\r\n    buildEarlyExitMessage(options: {\r\n        expectedIterationPaths: TokenType[][]\r\n        actual: IToken[]\r\n        previous: IToken\r\n        customUserDescription: string\r\n        ruleName: string\r\n    }): string {\r\n        return defaultParserErrorProvider.buildEarlyExitMessage(options);\r\n    }\r\n\r\n}\r\n\r\nexport class LangiumParserErrorMessageProvider extends AbstractParserErrorMessageProvider {\r\n\r\n    override buildMismatchTokenMessage({ expected, actual }: {\r\n        expected: TokenType\r\n        actual: IToken\r\n        previous: IToken\r\n        ruleName: string\r\n    }): string {\r\n        const expectedMsg = expected.LABEL\r\n            ? '`' + expected.LABEL + '`'\r\n            : expected.name.endsWith(':KW')\r\n                ? `keyword '${expected.name.substring(0, expected.name.length - 3)}'`\r\n                : `token of type '${expected.name}'`;\r\n        return `Expecting ${expectedMsg} but found \\`${actual.image}\\`.`;\r\n    }\r\n\r\n    override buildNotAllInputParsedMessage({ firstRedundant }: {\r\n        firstRedundant: IToken\r\n        ruleName: string\r\n    }): string {\r\n        return `Expecting end of file but found \\`${firstRedundant.image}\\`.`;\r\n    }\r\n}\r\n\r\nexport interface CompletionParserResult {\r\n    tokens: IToken[]\r\n    elementStack: AbstractElement[]\r\n    tokenIndex: number\r\n}\r\n\r\nexport class LangiumCompletionParser extends AbstractLangiumParser {\r\n    private tokens: IToken[] = [];\r\n\r\n    private elementStack: AbstractElement[] = [];\r\n    private lastElementStack: AbstractElement[] = [];\r\n    private nextTokenIndex = 0;\r\n    private stackSize = 0;\r\n\r\n    action(): void {\r\n        // NOOP\r\n    }\r\n\r\n    construct(): unknown {\r\n        // NOOP\r\n        return undefined;\r\n    }\r\n\r\n    parse(input: string): CompletionParserResult {\r\n        this.resetState();\r\n        const tokens = this.lexer.tokenize(input, { mode: 'partial' });\r\n        this.tokens = tokens.tokens;\r\n        this.wrapper.input = [...this.tokens];\r\n        this.mainRule.call(this.wrapper, {});\r\n        this.unorderedGroups.clear();\r\n        return {\r\n            tokens: this.tokens,\r\n            elementStack: [...this.lastElementStack],\r\n            tokenIndex: this.nextTokenIndex\r\n        };\r\n    }\r\n\r\n    rule(rule: ParserRule, impl: RuleImpl): RuleResult {\r\n        const ruleMethod = this.wrapper.DEFINE_RULE(withRuleSuffix(rule.name), this.startImplementation(impl).bind(this));\r\n        this.allRules.set(rule.name, ruleMethod);\r\n        if (rule.entry) {\r\n            this.mainRule = ruleMethod;\r\n        }\r\n        return ruleMethod;\r\n    }\r\n\r\n    private resetState(): void {\r\n        this.elementStack = [];\r\n        this.lastElementStack = [];\r\n        this.nextTokenIndex = 0;\r\n        this.stackSize = 0;\r\n    }\r\n\r\n    private startImplementation(implementation: RuleImpl): RuleImpl {\r\n        return (args) => {\r\n            const size = this.keepStackSize();\r\n            try {\r\n                implementation(args);\r\n            } finally {\r\n                this.resetStackSize(size);\r\n            }\r\n        };\r\n    }\r\n\r\n    private removeUnexpectedElements(): void {\r\n        this.elementStack.splice(this.stackSize);\r\n    }\r\n\r\n    keepStackSize(): number {\r\n        const size = this.elementStack.length;\r\n        this.stackSize = size;\r\n        return size;\r\n    }\r\n\r\n    resetStackSize(size: number): void {\r\n        this.removeUnexpectedElements();\r\n        this.stackSize = size;\r\n    }\r\n\r\n    consume(idx: number, tokenType: TokenType, feature: AbstractElement): void {\r\n        this.wrapper.wrapConsume(idx, tokenType);\r\n        if (!this.isRecording()) {\r\n            this.lastElementStack = [...this.elementStack, feature];\r\n            this.nextTokenIndex = this.currIdx + 1;\r\n        }\r\n    }\r\n\r\n    subrule(idx: number, rule: RuleResult, fragment: boolean, feature: AbstractElement, args: Args): void {\r\n        this.before(feature);\r\n        this.wrapper.wrapSubrule(idx, rule, args);\r\n        this.after(feature);\r\n    }\r\n\r\n    before(element: AbstractElement): void {\r\n        if (!this.isRecording()) {\r\n            this.elementStack.push(element);\r\n        }\r\n    }\r\n\r\n    after(element: AbstractElement): void {\r\n        if (!this.isRecording()) {\r\n            const index = this.elementStack.lastIndexOf(element);\r\n            if (index >= 0) {\r\n                this.elementStack.splice(index);\r\n            }\r\n        }\r\n    }\r\n\r\n    get currIdx(): number {\r\n        return (this.wrapper as any).currIdx;\r\n    }\r\n}\r\n\r\nconst defaultConfig: IParserConfig = {\r\n    recoveryEnabled: true,\r\n    nodeLocationTracking: 'full',\r\n    skipValidations: true,\r\n    errorMessageProvider: new LangiumParserErrorMessageProvider()\r\n};\r\n\r\n/**\r\n * This class wraps the embedded actions parser of chevrotain and exposes protected methods.\r\n * This way, we can build the `LangiumParser` as a composition.\r\n */\r\nclass ChevrotainWrapper extends EmbeddedActionsParser {\r\n\r\n    // This array is set in the base implementation of Chevrotain.\r\n    definitionErrors: IParserDefinitionError[];\r\n\r\n    constructor(tokens: TokenVocabulary, config: IParserConfig) {\r\n        const useDefaultLookahead = config && 'maxLookahead' in config;\r\n        super(tokens, {\r\n            ...defaultConfig,\r\n            lookaheadStrategy: useDefaultLookahead\r\n                ? new LLkLookaheadStrategy({ maxLookahead: config.maxLookahead })\r\n                : new LLStarLookaheadStrategy({\r\n                    // If validations are skipped, don't log the lookahead warnings\r\n                    logging: config.skipValidations ? () => { } : undefined\r\n                }),\r\n            ...config,\r\n        });\r\n    }\r\n\r\n    get IS_RECORDING(): boolean {\r\n        return this.RECORDING_PHASE;\r\n    }\r\n\r\n    DEFINE_RULE(name: string, impl: RuleImpl): RuleResult {\r\n        return this.RULE(name, impl);\r\n    }\r\n\r\n    wrapSelfAnalysis(): void {\r\n        this.performSelfAnalysis();\r\n    }\r\n\r\n    wrapConsume(idx: number, tokenType: TokenType): IToken {\r\n        return this.consume(idx, tokenType);\r\n    }\r\n\r\n    wrapSubrule(idx: number, rule: RuleResult, args: Args): unknown {\r\n        return this.subrule(idx, rule, {\r\n            ARGS: [args]\r\n        });\r\n    }\r\n\r\n    wrapOr(idx: number, choices: Array<IOrAlt<any>>): void {\r\n        this.or(idx, choices);\r\n    }\r\n\r\n    wrapOption(idx: number, callback: DSLMethodOpts<unknown>): void {\r\n        this.option(idx, callback);\r\n    }\r\n\r\n    wrapMany(idx: number, callback: DSLMethodOpts<unknown>): void {\r\n        this.many(idx, callback);\r\n    }\r\n\r\n    wrapAtLeastOne(idx: number, callback: DSLMethodOpts<unknown>): void {\r\n        this.atLeastOne(idx, callback);\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { IOrAlt, TokenType, TokenTypeDictionary } from 'chevrotain';\r\nimport type { AbstractElement, Action, Alternatives, Condition, CrossReference, Grammar, Group, Keyword, NamedArgument, ParserRule, RuleCall, UnorderedGroup } from '../languages/generated/ast.js';\r\nimport type { BaseParser } from './langium-parser.js';\r\nimport type { AstNode } from '../syntax-tree.js';\r\nimport type { Cardinality } from '../utils/grammar-utils.js';\r\nimport { EMPTY_ALT, EOF } from 'chevrotain';\r\nimport { isAction, isAlternatives, isEndOfFile, isAssignment, isConjunction, isCrossReference, isDisjunction, isGroup, isKeyword, isNegation, isParameterReference, isParserRule, isRuleCall, isTerminalRule, isUnorderedGroup, isBooleanLiteral } from '../languages/generated/ast.js';\r\nimport { assertUnreachable, ErrorWithLocation } from '../utils/errors.js';\r\nimport { stream } from '../utils/stream.js';\r\nimport { findNameAssignment, getAllReachableRules, getTypeName } from '../utils/grammar-utils.js';\r\n\r\ntype RuleContext = {\r\n    optional: number,\r\n    consume: number,\r\n    subrule: number,\r\n    many: number,\r\n    or: number\r\n} & ParserContext;\r\n\r\ntype ParserContext = {\r\n    parser: BaseParser\r\n    tokens: TokenTypeDictionary\r\n    ruleNames: Map<AstNode, string>\r\n}\r\n\r\ntype Rule = (args: Args) => unknown;\r\n\r\ntype Args = Record<string, boolean>;\r\n\r\ntype Predicate = (args: Args) => boolean;\r\n\r\ntype Method = (args: Args) => void;\r\n\r\nexport function createParser<T extends BaseParser>(grammar: Grammar, parser: T, tokens: TokenTypeDictionary): T {\r\n    const parserContext: ParserContext = {\r\n        parser,\r\n        tokens,\r\n        ruleNames: new Map()\r\n    };\r\n    buildRules(parserContext, grammar);\r\n    return parser;\r\n}\r\n\r\nfunction buildRules(parserContext: ParserContext, grammar: Grammar): void {\r\n    const reachable = getAllReachableRules(grammar, false);\r\n    const parserRules = stream(grammar.rules).filter(isParserRule).filter(rule => reachable.has(rule));\r\n    for (const rule of parserRules) {\r\n        const ctx: RuleContext = {\r\n            ...parserContext,\r\n            consume: 1,\r\n            optional: 1,\r\n            subrule: 1,\r\n            many: 1,\r\n            or: 1\r\n        };\r\n        parserContext.parser.rule(rule, buildElement(ctx, rule.definition));\r\n    }\r\n}\r\n\r\nfunction buildElement(ctx: RuleContext, element: AbstractElement, ignoreGuard = false): Method {\r\n    let method: Method;\r\n    if (isKeyword(element)) {\r\n        method = buildKeyword(ctx, element);\r\n    } else if (isAction(element)) {\r\n        method = buildAction(ctx, element);\r\n    } else if (isAssignment(element)) {\r\n        method = buildElement(ctx, element.terminal);\r\n    } else if (isCrossReference(element)) {\r\n        method = buildCrossReference(ctx, element);\r\n    } else if (isRuleCall(element)) {\r\n        method = buildRuleCall(ctx, element);\r\n    } else if (isAlternatives(element)) {\r\n        method = buildAlternatives(ctx, element);\r\n    } else if (isUnorderedGroup(element)) {\r\n        method = buildUnorderedGroup(ctx, element);\r\n    } else if (isGroup(element)) {\r\n        method = buildGroup(ctx, element);\r\n    } else if(isEndOfFile(element)) {\r\n        const idx = ctx.consume++;\r\n        method = () => ctx.parser.consume(idx, EOF, element);\r\n    } else {\r\n        throw new ErrorWithLocation(element.$cstNode, `Unexpected element type: ${element.$type}`);\r\n    }\r\n    return wrap(ctx, ignoreGuard ? undefined : getGuardCondition(element), method, element.cardinality);\r\n}\r\n\r\nfunction buildAction(ctx: RuleContext, action: Action): Method {\r\n    const actionType = getTypeName(action);\r\n    return () => ctx.parser.action(actionType, action);\r\n}\r\n\r\nfunction buildRuleCall(ctx: RuleContext, ruleCall: RuleCall): Method {\r\n    const rule = ruleCall.rule.ref;\r\n    if (isParserRule(rule)) {\r\n        const idx = ctx.subrule++;\r\n        const fragment = rule.fragment;\r\n        const predicate = ruleCall.arguments.length > 0 ? buildRuleCallPredicate(rule, ruleCall.arguments) : () => ({});\r\n        return (args) => ctx.parser.subrule(idx, getRule(ctx, rule), fragment, ruleCall, predicate(args));\r\n    } else if (isTerminalRule(rule)) {\r\n        const idx = ctx.consume++;\r\n        const method = getToken(ctx, rule.name);\r\n        return () => ctx.parser.consume(idx, method, ruleCall);\r\n    } else if (!rule) {\r\n        throw new ErrorWithLocation(ruleCall.$cstNode, `Undefined rule: ${ruleCall.rule.$refText}`);\r\n    } else {\r\n        assertUnreachable(rule);\r\n    }\r\n}\r\n\r\nfunction buildRuleCallPredicate(rule: ParserRule, namedArgs: NamedArgument[]): (args: Args) => Args {\r\n    const predicates = namedArgs.map(e => buildPredicate(e.value));\r\n    return (args) => {\r\n        const ruleArgs: Args = {};\r\n        for (let i = 0; i < predicates.length; i++) {\r\n            const ruleTarget = rule.parameters[i];\r\n            const predicate = predicates[i];\r\n            ruleArgs[ruleTarget.name] = predicate(args);\r\n        }\r\n        return ruleArgs;\r\n    };\r\n}\r\n\r\ninterface PredicatedMethod {\r\n    ALT: Method,\r\n    GATE?: Predicate\r\n}\r\n\r\nfunction buildPredicate(condition: Condition): Predicate {\r\n    if (isDisjunction(condition)) {\r\n        const left = buildPredicate(condition.left);\r\n        const right = buildPredicate(condition.right);\r\n        return (args) => (left(args) || right(args));\r\n    } else if (isConjunction(condition)) {\r\n        const left = buildPredicate(condition.left);\r\n        const right = buildPredicate(condition.right);\r\n        return (args) => (left(args) && right(args));\r\n    } else if (isNegation(condition)) {\r\n        const value = buildPredicate(condition.value);\r\n        return (args) => !value(args);\r\n    } else if (isParameterReference(condition)) {\r\n        const name = condition.parameter.ref!.name;\r\n        return (args) => args !== undefined && args[name] === true;\r\n    } else if (isBooleanLiteral(condition)) {\r\n        const value = Boolean(condition.true);\r\n        return () => value;\r\n    }\r\n    assertUnreachable(condition);\r\n}\r\n\r\nfunction buildAlternatives(ctx: RuleContext, alternatives: Alternatives): Method {\r\n    if (alternatives.elements.length === 1) {\r\n        return buildElement(ctx, alternatives.elements[0]);\r\n    } else {\r\n        const methods: PredicatedMethod[] = [];\r\n\r\n        for (const element of alternatives.elements) {\r\n            const predicatedMethod: PredicatedMethod = {\r\n                // Since we handle the guard condition in the alternative already\r\n                // We can ignore the group guard condition inside\r\n                ALT: buildElement(ctx, element, true)\r\n            };\r\n            const guard = getGuardCondition(element);\r\n            if (guard) {\r\n                predicatedMethod.GATE = buildPredicate(guard);\r\n            }\r\n            methods.push(predicatedMethod);\r\n        }\r\n\r\n        const idx = ctx.or++;\r\n        return (args) => ctx.parser.alternatives(idx, methods.map(method => {\r\n            const alt: IOrAlt<unknown> = {\r\n                ALT: () => method.ALT(args)\r\n            };\r\n            const gate = method.GATE;\r\n            if (gate) {\r\n                alt.GATE = () => gate(args);\r\n            }\r\n            return alt;\r\n        }));\r\n    }\r\n}\r\n\r\nfunction buildUnorderedGroup(ctx: RuleContext, group: UnorderedGroup): Method {\r\n    if (group.elements.length === 1) {\r\n        return buildElement(ctx, group.elements[0]);\r\n    }\r\n    const methods: PredicatedMethod[] = [];\r\n\r\n    for (const element of group.elements) {\r\n        const predicatedMethod: PredicatedMethod = {\r\n            // Since we handle the guard condition in the alternative already\r\n            // We can ignore the group guard condition inside\r\n            ALT: buildElement(ctx, element, true)\r\n        };\r\n        const guard = getGuardCondition(element);\r\n        if (guard) {\r\n            predicatedMethod.GATE = buildPredicate(guard);\r\n        }\r\n        methods.push(predicatedMethod);\r\n    }\r\n\r\n    const orIdx = ctx.or++;\r\n\r\n    const idFunc = (groupIdx: number, lParser: BaseParser) => {\r\n        const stackId = lParser.getRuleStack().join('-');\r\n        return `uGroup_${groupIdx}_${stackId}`;\r\n    };\r\n    const alternatives: Method = (args) => ctx.parser.alternatives(orIdx, methods.map((method, idx) => {\r\n        const alt: IOrAlt<unknown> = { ALT: () => true };\r\n        const parser = ctx.parser;\r\n        alt.ALT = () => {\r\n            method.ALT(args);\r\n            if (!parser.isRecording()) {\r\n                const key = idFunc(orIdx, parser);\r\n                if (!parser.unorderedGroups.get(key)) {\r\n                    // init after clear state\r\n                    parser.unorderedGroups.set(key, []);\r\n                }\r\n                const groupState = parser.unorderedGroups.get(key)!;\r\n                if (typeof groupState?.[idx] === 'undefined') {\r\n                    // Not accessed yet\r\n                    groupState[idx] = true;\r\n                }\r\n            }\r\n        };\r\n        const gate = method.GATE;\r\n        if (gate) {\r\n            alt.GATE = () => gate(args);\r\n        } else {\r\n            alt.GATE = () => {\r\n                const trackedAlternatives = parser.unorderedGroups.get(idFunc(orIdx, parser));\r\n                const allow = !trackedAlternatives?.[idx];\r\n                return allow;\r\n            };\r\n        }\r\n        return alt;\r\n    }));\r\n    const wrapped = wrap(ctx, getGuardCondition(group), alternatives, '*');\r\n    return (args) => {\r\n        wrapped(args);\r\n        if (!ctx.parser.isRecording()) {\r\n            ctx.parser.unorderedGroups.delete(idFunc(orIdx, ctx.parser));\r\n        }\r\n    };\r\n}\r\n\r\nfunction buildGroup(ctx: RuleContext, group: Group): Method {\r\n    const methods = group.elements.map(e => buildElement(ctx, e));\r\n    return (args) => methods.forEach(method => method(args));\r\n}\r\n\r\nfunction getGuardCondition(element: AbstractElement): Condition | undefined {\r\n    if (isGroup(element)) {\r\n        return element.guardCondition;\r\n    }\r\n    return undefined;\r\n}\r\n\r\nfunction buildCrossReference(ctx: RuleContext, crossRef: CrossReference, terminal = crossRef.terminal): Method {\r\n    if (!terminal) {\r\n        if (!crossRef.type.ref) {\r\n            throw new Error('Could not resolve reference to type: ' + crossRef.type.$refText);\r\n        }\r\n        const assignment = findNameAssignment(crossRef.type.ref);\r\n        const assignTerminal = assignment?.terminal;\r\n        if (!assignTerminal) {\r\n            throw new Error('Could not find name assignment for type: ' + getTypeName(crossRef.type.ref));\r\n        }\r\n        return buildCrossReference(ctx, crossRef, assignTerminal);\r\n    } else if (isRuleCall(terminal) && isParserRule(terminal.rule.ref)) {\r\n        // The terminal is a data type rule here. Everything else will result in a validation error.\r\n        const rule = terminal.rule.ref;\r\n        const idx = ctx.subrule++;\r\n        return (args) => ctx.parser.subrule(idx, getRule(ctx, rule), false, crossRef, args);\r\n    } else if (isRuleCall(terminal) && isTerminalRule(terminal.rule.ref)) {\r\n        const idx = ctx.consume++;\r\n        const terminalRule = getToken(ctx, terminal.rule.ref.name);\r\n        return () => ctx.parser.consume(idx, terminalRule, crossRef);\r\n    } else if (isKeyword(terminal)) {\r\n        const idx = ctx.consume++;\r\n        const keyword = getToken(ctx, terminal.value);\r\n        return () => ctx.parser.consume(idx, keyword, crossRef);\r\n    }\r\n    else {\r\n        throw new Error('Could not build cross reference parser');\r\n    }\r\n}\r\n\r\nfunction buildKeyword(ctx: RuleContext, keyword: Keyword): Method {\r\n    const idx = ctx.consume++;\r\n    const token = ctx.tokens[keyword.value];\r\n    if (!token) {\r\n        throw new Error('Could not find token for keyword: ' + keyword.value);\r\n    }\r\n    return () => ctx.parser.consume(idx, token, keyword);\r\n}\r\n\r\nfunction wrap(ctx: RuleContext, guard: Condition | undefined, method: Method, cardinality: Cardinality): Method {\r\n    const gate = guard && buildPredicate(guard);\r\n\r\n    if (!cardinality) {\r\n        if (gate) {\r\n            const idx = ctx.or++;\r\n            return (args) => ctx.parser.alternatives(idx, [\r\n                {\r\n                    ALT: () => method(args),\r\n                    GATE: () => gate(args)\r\n                },\r\n                {\r\n                    ALT: EMPTY_ALT(),\r\n                    GATE: () => !gate(args)\r\n                }\r\n            ]);\r\n        } else {\r\n            return method;\r\n        }\r\n    }\r\n\r\n    if (cardinality === '*') {\r\n        const idx = ctx.many++;\r\n        return (args) => ctx.parser.many(idx, {\r\n            DEF: () => method(args),\r\n            GATE: gate ? () => gate(args) : undefined\r\n        });\r\n    } else if (cardinality === '+') {\r\n        const idx = ctx.many++;\r\n        if (gate) {\r\n            const orIdx = ctx.or++;\r\n            // In the case of a guard condition for the `+` group\r\n            // We combine it with an empty alternative\r\n            // If the condition returns true, it needs to parse at least a single iteration\r\n            // If its false, it is not allowed to parse anything\r\n            return (args) => ctx.parser.alternatives(orIdx, [\r\n                {\r\n                    ALT: () => ctx.parser.atLeastOne(idx, {\r\n                        DEF: () => method(args)\r\n                    }),\r\n                    GATE: () => gate(args)\r\n                },\r\n                {\r\n                    ALT: EMPTY_ALT(),\r\n                    GATE: () => !gate(args)\r\n                }\r\n            ]);\r\n        } else {\r\n            return (args) => ctx.parser.atLeastOne(idx, {\r\n                DEF: () => method(args),\r\n            });\r\n        }\r\n    } else if (cardinality === '?') {\r\n        const idx = ctx.optional++;\r\n        return (args) => ctx.parser.optional(idx, {\r\n            DEF: () => method(args),\r\n            GATE: gate ? () => gate(args) : undefined\r\n        });\r\n    } else {\r\n        assertUnreachable(cardinality);\r\n    }\r\n}\r\n\r\nfunction getRule(ctx: ParserContext, element: ParserRule | AbstractElement): Rule {\r\n    const name = getRuleName(ctx, element);\r\n    const rule = ctx.parser.getRule(name);\r\n    if (!rule) throw new Error(`Rule \"${name}\" not found.\"`);\r\n    return rule;\r\n}\r\n\r\nfunction getRuleName(ctx: ParserContext, element: ParserRule | AbstractElement): string {\r\n    if (isParserRule(element)) {\r\n        return element.name;\r\n    } else if (ctx.ruleNames.has(element)) {\r\n        return ctx.ruleNames.get(element)!;\r\n    } else {\r\n        let item: AstNode = element;\r\n        let parent: AstNode = item.$container!;\r\n        let ruleName: string = element.$type;\r\n        while (!isParserRule(parent)) {\r\n            if (isGroup(parent) || isAlternatives(parent) || isUnorderedGroup(parent)) {\r\n                const index = parent.elements.indexOf(item as AbstractElement);\r\n                ruleName = index.toString() + ':' + ruleName;\r\n            }\r\n            item = parent;\r\n            parent = parent.$container!;\r\n        }\r\n        const rule = parent as ParserRule;\r\n        ruleName = rule.name + ':' + ruleName;\r\n        ctx.ruleNames.set(element, ruleName);\r\n        return ruleName;\r\n    }\r\n}\r\n\r\nfunction getToken(ctx: ParserContext, name: string): TokenType {\r\n    const token = ctx.tokens[name];\r\n    if (!token) throw new Error(`Token \"${name}\" not found.\"`);\r\n    return token;\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport { LangiumParser } from './langium-parser.js';\r\nimport { createParser } from './parser-builder-base.js';\r\n\r\n/**\r\n * Create and finalize a Langium parser. The parser rules are derived from the grammar, which is\r\n * available at `services.Grammar`.\r\n */\r\nexport function createLangiumParser(services: LangiumCoreServices): LangiumParser {\r\n    const parser = prepareLangiumParser(services);\r\n    parser.finalize();\r\n    return parser;\r\n}\r\n\r\n/**\r\n * Create a Langium parser without finalizing it. This is used to extract more detailed error\r\n * information when the parser is initially validated.\r\n */\r\nexport function prepareLangiumParser(services: LangiumCoreServices): LangiumParser {\r\n    const grammar = services.Grammar;\r\n    const lexer = services.parser.Lexer;\r\n    const parser = new LangiumParser(services);\r\n    return createParser(grammar, parser, lexer.definition);\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { CancellationToken, CancellationTokenSource, type AbstractCancellationTokenSource } from '../utils/cancellation.js';\r\n\r\nexport type MaybePromise<T> = T | Promise<T>\r\n\r\n/**\r\n * Delays the execution of the current code to the next tick of the event loop.\r\n * Don't call this method directly in a tight loop to prevent too many promises from being created.\r\n */\r\nexport function delayNextTick(): Promise<void> {\r\n    return new Promise(resolve => {\r\n        // In case we are running in a non-node environment, `setImmediate` isn't available.\r\n        // Using `setTimeout` of the browser API accomplishes the same result.\r\n        if (typeof setImmediate === 'undefined') {\r\n            setTimeout(resolve, 0);\r\n        } else {\r\n            setImmediate(resolve);\r\n        }\r\n    });\r\n}\r\n\r\nlet lastTick = 0;\r\nlet globalInterruptionPeriod = 10;\r\n\r\n/**\r\n * Reset the global interruption period and create a cancellation token source.\r\n */\r\nexport function startCancelableOperation(): AbstractCancellationTokenSource {\r\n    lastTick = performance.now();\r\n    return new CancellationTokenSource();\r\n}\r\n\r\n/**\r\n * Change the period duration for `interruptAndCheck` to the given number of milliseconds.\r\n * The default value is 10ms.\r\n */\r\nexport function setInterruptionPeriod(period: number): void {\r\n    globalInterruptionPeriod = period;\r\n}\r\n\r\n/**\r\n * This symbol may be thrown in an asynchronous context by any Langium service that receives\r\n * a `CancellationToken`. This means that the promise returned by such a service is rejected with\r\n * this symbol as rejection reason.\r\n */\r\nexport const OperationCancelled = Symbol('OperationCancelled');\r\n\r\n/**\r\n * Use this in a `catch` block to check whether the thrown object indicates that the operation\r\n * has been cancelled.\r\n */\r\nexport function isOperationCancelled(err: unknown): err is typeof OperationCancelled {\r\n    return err === OperationCancelled;\r\n}\r\n\r\n/**\r\n * This function does two things:\r\n *  1. Check the elapsed time since the last call to this function or to `startCancelableOperation`. If the predefined\r\n *     period (configured with `setInterruptionPeriod`) is exceeded, execution is delayed with `delayNextTick`.\r\n *  2. If the predefined period is not met yet or execution is resumed after an interruption, the given cancellation\r\n *     token is checked, and if cancellation is requested, `OperationCanceled` is thrown.\r\n *\r\n * All services in Langium that receive a `CancellationToken` may potentially call this function, so the\r\n * `CancellationToken` must be caught (with an `async` try-catch block or a `catch` callback attached to\r\n * the promise) to avoid that event being exposed as an error.\r\n */\r\nexport async function interruptAndCheck(token: CancellationToken): Promise<void> {\r\n    if (token === CancellationToken.None) {\r\n        // Early exit in case cancellation was disabled by the caller\r\n        return;\r\n    }\r\n    const current = performance.now();\r\n    if (current - lastTick >= globalInterruptionPeriod) {\r\n        lastTick = current;\r\n        await delayNextTick();\r\n        // prevent calling delayNextTick every iteration of loop\r\n        // where delayNextTick takes up the majority or all of the\r\n        // globalInterruptionPeriod itself\r\n        lastTick = performance.now();\r\n    }\r\n    if (token.isCancellationRequested) {\r\n        throw OperationCancelled;\r\n    }\r\n}\r\n\r\n/**\r\n * Simple implementation of the deferred pattern.\r\n * An object that exposes a promise and functions to resolve and reject it.\r\n */\r\nexport class Deferred<T = void> {\r\n    resolve: (value: T) => this;\r\n    reject: (err?: unknown) => this;\r\n\r\n    promise = new Promise<T>((resolve, reject) => {\r\n        this.resolve = (arg) => {\r\n            resolve(arg);\r\n            return this;\r\n        };\r\n        this.reject = (err) => {\r\n            reject(err);\r\n            return this;\r\n        };\r\n    });\r\n}\r\n","/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\n'use strict';\nclass FullTextDocument {\n    constructor(uri, languageId, version, content) {\n        this._uri = uri;\n        this._languageId = languageId;\n        this._version = version;\n        this._content = content;\n        this._lineOffsets = undefined;\n    }\n    get uri() {\n        return this._uri;\n    }\n    get languageId() {\n        return this._languageId;\n    }\n    get version() {\n        return this._version;\n    }\n    getText(range) {\n        if (range) {\n            const start = this.offsetAt(range.start);\n            const end = this.offsetAt(range.end);\n            return this._content.substring(start, end);\n        }\n        return this._content;\n    }\n    update(changes, version) {\n        for (const change of changes) {\n            if (FullTextDocument.isIncremental(change)) {\n                // makes sure start is before end\n                const range = getWellformedRange(change.range);\n                // update content\n                const startOffset = this.offsetAt(range.start);\n                const endOffset = this.offsetAt(range.end);\n                this._content = this._content.substring(0, startOffset) + change.text + this._content.substring(endOffset, this._content.length);\n                // update the offsets\n                const startLine = Math.max(range.start.line, 0);\n                const endLine = Math.max(range.end.line, 0);\n                let lineOffsets = this._lineOffsets;\n                const addedLineOffsets = computeLineOffsets(change.text, false, startOffset);\n                if (endLine - startLine === addedLineOffsets.length) {\n                    for (let i = 0, len = addedLineOffsets.length; i < len; i++) {\n                        lineOffsets[i + startLine + 1] = addedLineOffsets[i];\n                    }\n                }\n                else {\n                    if (addedLineOffsets.length < 10000) {\n                        lineOffsets.splice(startLine + 1, endLine - startLine, ...addedLineOffsets);\n                    }\n                    else { // avoid too many arguments for splice\n                        this._lineOffsets = lineOffsets = lineOffsets.slice(0, startLine + 1).concat(addedLineOffsets, lineOffsets.slice(endLine + 1));\n                    }\n                }\n                const diff = change.text.length - (endOffset - startOffset);\n                if (diff !== 0) {\n                    for (let i = startLine + 1 + addedLineOffsets.length, len = lineOffsets.length; i < len; i++) {\n                        lineOffsets[i] = lineOffsets[i] + diff;\n                    }\n                }\n            }\n            else if (FullTextDocument.isFull(change)) {\n                this._content = change.text;\n                this._lineOffsets = undefined;\n            }\n            else {\n                throw new Error('Unknown change event received');\n            }\n        }\n        this._version = version;\n    }\n    getLineOffsets() {\n        if (this._lineOffsets === undefined) {\n            this._lineOffsets = computeLineOffsets(this._content, true);\n        }\n        return this._lineOffsets;\n    }\n    positionAt(offset) {\n        offset = Math.max(Math.min(offset, this._content.length), 0);\n        const lineOffsets = this.getLineOffsets();\n        let low = 0, high = lineOffsets.length;\n        if (high === 0) {\n            return { line: 0, character: offset };\n        }\n        while (low < high) {\n            const mid = Math.floor((low + high) / 2);\n            if (lineOffsets[mid] > offset) {\n                high = mid;\n            }\n            else {\n                low = mid + 1;\n            }\n        }\n        // low is the least x for which the line offset is larger than the current offset\n        // or array.length if no line offset is larger than the current offset\n        const line = low - 1;\n        offset = this.ensureBeforeEOL(offset, lineOffsets[line]);\n        return { line, character: offset - lineOffsets[line] };\n    }\n    offsetAt(position) {\n        const lineOffsets = this.getLineOffsets();\n        if (position.line >= lineOffsets.length) {\n            return this._content.length;\n        }\n        else if (position.line < 0) {\n            return 0;\n        }\n        const lineOffset = lineOffsets[position.line];\n        if (position.character <= 0) {\n            return lineOffset;\n        }\n        const nextLineOffset = (position.line + 1 < lineOffsets.length) ? lineOffsets[position.line + 1] : this._content.length;\n        const offset = Math.min(lineOffset + position.character, nextLineOffset);\n        return this.ensureBeforeEOL(offset, lineOffset);\n    }\n    ensureBeforeEOL(offset, lineOffset) {\n        while (offset > lineOffset && isEOL(this._content.charCodeAt(offset - 1))) {\n            offset--;\n        }\n        return offset;\n    }\n    get lineCount() {\n        return this.getLineOffsets().length;\n    }\n    static isIncremental(event) {\n        const candidate = event;\n        return candidate !== undefined && candidate !== null &&\n            typeof candidate.text === 'string' && candidate.range !== undefined &&\n            (candidate.rangeLength === undefined || typeof candidate.rangeLength === 'number');\n    }\n    static isFull(event) {\n        const candidate = event;\n        return candidate !== undefined && candidate !== null &&\n            typeof candidate.text === 'string' && candidate.range === undefined && candidate.rangeLength === undefined;\n    }\n}\nexport var TextDocument;\n(function (TextDocument) {\n    /**\n     * Creates a new text document.\n     *\n     * @param uri The document's uri.\n     * @param languageId  The document's language Id.\n     * @param version The document's initial version number.\n     * @param content The document's content.\n     */\n    function create(uri, languageId, version, content) {\n        return new FullTextDocument(uri, languageId, version, content);\n    }\n    TextDocument.create = create;\n    /**\n     * Updates a TextDocument by modifying its content.\n     *\n     * @param document the document to update. Only documents created by TextDocument.create are valid inputs.\n     * @param changes the changes to apply to the document.\n     * @param version the changes version for the document.\n     * @returns The updated TextDocument. Note: That's the same document instance passed in as first parameter.\n     *\n     */\n    function update(document, changes, version) {\n        if (document instanceof FullTextDocument) {\n            document.update(changes, version);\n            return document;\n        }\n        else {\n            throw new Error('TextDocument.update: document must be created by TextDocument.create');\n        }\n    }\n    TextDocument.update = update;\n    function applyEdits(document, edits) {\n        const text = document.getText();\n        const sortedEdits = mergeSort(edits.map(getWellformedEdit), (a, b) => {\n            const diff = a.range.start.line - b.range.start.line;\n            if (diff === 0) {\n                return a.range.start.character - b.range.start.character;\n            }\n            return diff;\n        });\n        let lastModifiedOffset = 0;\n        const spans = [];\n        for (const e of sortedEdits) {\n            const startOffset = document.offsetAt(e.range.start);\n            if (startOffset < lastModifiedOffset) {\n                throw new Error('Overlapping edit');\n            }\n            else if (startOffset > lastModifiedOffset) {\n                spans.push(text.substring(lastModifiedOffset, startOffset));\n            }\n            if (e.newText.length) {\n                spans.push(e.newText);\n            }\n            lastModifiedOffset = document.offsetAt(e.range.end);\n        }\n        spans.push(text.substr(lastModifiedOffset));\n        return spans.join('');\n    }\n    TextDocument.applyEdits = applyEdits;\n})(TextDocument || (TextDocument = {}));\nfunction mergeSort(data, compare) {\n    if (data.length <= 1) {\n        // sorted\n        return data;\n    }\n    const p = (data.length / 2) | 0;\n    const left = data.slice(0, p);\n    const right = data.slice(p);\n    mergeSort(left, compare);\n    mergeSort(right, compare);\n    let leftIdx = 0;\n    let rightIdx = 0;\n    let i = 0;\n    while (leftIdx < left.length && rightIdx < right.length) {\n        const ret = compare(left[leftIdx], right[rightIdx]);\n        if (ret <= 0) {\n            // smaller_equal -> take left to preserve order\n            data[i++] = left[leftIdx++];\n        }\n        else {\n            // greater -> take right\n            data[i++] = right[rightIdx++];\n        }\n    }\n    while (leftIdx < left.length) {\n        data[i++] = left[leftIdx++];\n    }\n    while (rightIdx < right.length) {\n        data[i++] = right[rightIdx++];\n    }\n    return data;\n}\nfunction computeLineOffsets(text, isAtLineStart, textOffset = 0) {\n    const result = isAtLineStart ? [textOffset] : [];\n    for (let i = 0; i < text.length; i++) {\n        const ch = text.charCodeAt(i);\n        if (isEOL(ch)) {\n            if (ch === 13 /* CharCode.CarriageReturn */ && i + 1 < text.length && text.charCodeAt(i + 1) === 10 /* CharCode.LineFeed */) {\n                i++;\n            }\n            result.push(textOffset + i + 1);\n        }\n    }\n    return result;\n}\nfunction isEOL(char) {\n    return char === 13 /* CharCode.CarriageReturn */ || char === 10 /* CharCode.LineFeed */;\n}\nfunction getWellformedRange(range) {\n    const start = range.start;\n    const end = range.end;\n    if (start.line > end.line || (start.line === end.line && start.character > end.character)) {\n        return { start: end, end: start };\n    }\n    return range;\n}\nfunction getWellformedEdit(textEdit) {\n    const range = getWellformedRange(textEdit.range);\n    if (range !== textEdit.range) {\n        return { newText: textEdit.newText, range };\n    }\n    return textEdit;\n}\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\n/**\r\n * Re-export 'TextDocument' from 'vscode-languageserver-textdocument' for convenience,\r\n *  including both type _and_ symbol (namespace), as we here and there also refer to the symbol,\r\n *  the overhead is very small, just a few kilobytes.\r\n * Everything else of that package (at the time contributing) is also defined\r\n *  in 'vscode-languageserver-protocol' or 'vscode-languageserver-types'.\r\n */\r\nexport { TextDocument } from 'vscode-languageserver-textdocument';\r\n\r\nimport type { Diagnostic, Range } from 'vscode-languageserver-types';\r\nimport type { FileSystemProvider } from './file-system-provider.js';\r\nimport type { ParseResult, ParserOptions } from '../parser/langium-parser.js';\r\nimport type { ServiceRegistry } from '../service-registry.js';\r\nimport type { LangiumSharedCoreServices } from '../services.js';\r\nimport type { AstNode, AstNodeDescription, Mutable, Reference } from '../syntax-tree.js';\r\nimport type { MultiMap } from '../utils/collections.js';\r\nimport type { Stream } from '../utils/stream.js';\r\nimport { TextDocument } from './documents.js';\r\nimport { CancellationToken } from '../utils/cancellation.js';\r\nimport { stream } from '../utils/stream.js';\r\nimport { URI } from '../utils/uri-utils.js';\r\n\r\n/**\r\n * A Langium document holds the parse result (AST and CST) and any additional state that is derived\r\n * from the AST, e.g. the result of scope precomputation.\r\n */\r\nexport interface LangiumDocument<T extends AstNode = AstNode> {\r\n    /** The Uniform Resource Identifier (URI) of the document */\r\n    readonly uri: URI;\r\n    /** The text document used to convert between offsets and positions */\r\n    readonly textDocument: TextDocument;\r\n    /** The current state of the document */\r\n    state: DocumentState;\r\n    /** The parse result holds the Abstract Syntax Tree (AST) and potentially also parser / lexer errors */\r\n    parseResult: ParseResult<T>;\r\n    /** Result of the scope precomputation phase */\r\n    precomputedScopes?: PrecomputedScopes;\r\n    /** An array of all cross-references found in the AST while linking */\r\n    references: Reference[];\r\n    /** Result of the validation phase */\r\n    diagnostics?: Diagnostic[]\r\n}\r\n\r\n/**\r\n * A document is subject to several phases that are run in predefined order. Any state value implies that\r\n * smaller state values are finished as well.\r\n */\r\nexport enum DocumentState {\r\n    /**\r\n     * The text content has changed and needs to be parsed again. The AST held by this outdated\r\n     * document instance is no longer valid.\r\n     */\r\n    Changed = 0,\r\n    /**\r\n     * An AST has been created from the text content. The document structure can be traversed,\r\n     * but cross-references cannot be resolved yet. If necessary, the structure can be manipulated\r\n     * at this stage as a preprocessing step.\r\n     */\r\n    Parsed = 1,\r\n    /**\r\n     * The `IndexManager` service has processed AST nodes of this document. This means the\r\n     * exported symbols are available in the global scope and can be resolved from other documents.\r\n     */\r\n    IndexedContent = 2,\r\n    /**\r\n     * The `ScopeComputation` service has processed this document. This means the local symbols\r\n     * are stored in a MultiMap so they can be looked up by the `ScopeProvider` service.\r\n     * Once a document has reached this state, you may follow every reference - it will lazily\r\n     * resolve its `ref` property and yield either the target AST node or `undefined` in case\r\n     * the target is not in scope.\r\n     */\r\n    ComputedScopes = 3,\r\n    /**\r\n     * The `Linker` service has processed this document. All outgoing references have been\r\n     * resolved or marked as erroneous.\r\n     */\r\n    Linked = 4,\r\n    /**\r\n     * The `IndexManager` service has processed AST node references of this document. This is\r\n     * necessary to determine which documents are affected by a change in one of the workspace\r\n     * documents.\r\n     */\r\n    IndexedReferences = 5,\r\n    /**\r\n     * The `DocumentValidator` service has processed this document. The language server listens\r\n     * to the results of this phase and sends diagnostics to the client.\r\n     */\r\n    Validated = 6\r\n}\r\n\r\n/**\r\n * Result of the scope precomputation phase (`ScopeComputation` service).\r\n * It maps every AST node to the set of symbols that are visible in the subtree of that node.\r\n */\r\nexport type PrecomputedScopes = MultiMap<AstNode, AstNodeDescription>\r\n\r\nexport interface DocumentSegment {\r\n    readonly range: Range\r\n    readonly offset: number\r\n    readonly length: number\r\n    readonly end: number\r\n}\r\n\r\n/**\r\n * Surrogate definition of the `TextDocuments` interface from the `vscode-languageserver` package.\r\n * No implementation object is expected to be offered by `LangiumCoreServices`, but only by `LangiumLSPServices`.\r\n */\r\nexport type TextDocumentProvider = {\r\n    get(uri: string | URI): TextDocument | undefined\r\n}\r\n\r\n/**\r\n * Shared service for creating `LangiumDocument` instances.\r\n *\r\n * Register a custom implementation if special (additional) behavior is required for your language(s).\r\n * Note: If you specialize {@link fromString} or {@link fromTextDocument} you probably might want to\r\n * specialize {@link update}, too!\r\n */\r\nexport interface LangiumDocumentFactory {\r\n    /**\r\n     * Create a Langium document from a `TextDocument` (usually associated with a file).\r\n     */\r\n    fromTextDocument<T extends AstNode = AstNode>(textDocument: TextDocument, uri?: URI, options?: ParserOptions): LangiumDocument<T>;\r\n    /**\r\n     * Create a Langium document from a `TextDocument` asynchronously. This action can be cancelled if a cancellable parser implementation has been provided.\r\n     */\r\n    fromTextDocument<T extends AstNode = AstNode>(textDocument: TextDocument, uri: URI | undefined, cancellationToken: CancellationToken): Promise<LangiumDocument<T>>;\r\n\r\n    /**\r\n     * Create an Langium document from an in-memory string.\r\n     */\r\n    fromString<T extends AstNode = AstNode>(text: string, uri: URI, options?: ParserOptions): LangiumDocument<T>;\r\n    /**\r\n     * Create a Langium document from an in-memory string asynchronously. This action can be cancelled if a cancellable parser implementation has been provided.\r\n     */\r\n    fromString<T extends AstNode = AstNode>(text: string, uri: URI, cancellationToken: CancellationToken): Promise<LangiumDocument<T>>;\r\n\r\n    /**\r\n     * Create an Langium document from a model that has been constructed in memory.\r\n     */\r\n    fromModel<T extends AstNode = AstNode>(model: T, uri: URI): LangiumDocument<T>;\r\n\r\n    /**\r\n     * Create an Langium document from a specified `URI`. The factory will use the `FileSystemAccess` service to read the file.\r\n     */\r\n    fromUri<T extends AstNode = AstNode>(uri: URI, cancellationToken?: CancellationToken): Promise<LangiumDocument<T>>;\r\n\r\n    /**\r\n     * Update the given document after changes in the corresponding textual representation.\r\n     * Method is called by the document builder after it has been requested to build an existing\r\n     * document and the document's state is {@link DocumentState.Changed}.\r\n     * The text parsing is expected to be done the same way as in {@link fromTextDocument}\r\n     * and {@link fromString}.\r\n     */\r\n    update<T extends AstNode = AstNode>(document: LangiumDocument<T>, cancellationToken: CancellationToken): Promise<LangiumDocument<T>>\r\n}\r\n\r\nexport class DefaultLangiumDocumentFactory implements LangiumDocumentFactory {\r\n\r\n    protected readonly serviceRegistry: ServiceRegistry;\r\n    protected readonly textDocuments?: TextDocumentProvider;\r\n    protected readonly fileSystemProvider: FileSystemProvider;\r\n\r\n    constructor(services: LangiumSharedCoreServices) {\r\n        this.serviceRegistry = services.ServiceRegistry;\r\n        this.textDocuments = services.workspace.TextDocuments;\r\n        this.fileSystemProvider = services.workspace.FileSystemProvider;\r\n    }\r\n\r\n    async fromUri<T extends AstNode = AstNode>(uri: URI, cancellationToken = CancellationToken.None): Promise<LangiumDocument<T>> {\r\n        const content = await this.fileSystemProvider.readFile(uri);\r\n        return this.createAsync<T>(uri, content, cancellationToken);\r\n    }\r\n\r\n    fromTextDocument<T extends AstNode = AstNode>(textDocument: TextDocument, uri?: URI, options?: ParserOptions): LangiumDocument<T>;\r\n    fromTextDocument<T extends AstNode = AstNode>(textDocument: TextDocument, uri: URI | undefined, cancellationToken: CancellationToken): Promise<LangiumDocument<T>>;\r\n    fromTextDocument<T extends AstNode = AstNode>(textDocument: TextDocument, uri?: URI, token?: CancellationToken | ParserOptions): LangiumDocument<T> | Promise<LangiumDocument<T>> {\r\n        uri = uri ?? URI.parse(textDocument.uri);\r\n        if (CancellationToken.is(token)) {\r\n            return this.createAsync<T>(uri, textDocument, token);\r\n        } else {\r\n            return this.create<T>(uri, textDocument, token);\r\n        }\r\n    }\r\n\r\n    fromString<T extends AstNode = AstNode>(text: string, uri: URI, options?: ParserOptions): LangiumDocument<T>;\r\n    fromString<T extends AstNode = AstNode>(text: string, uri: URI, cancellationToken: CancellationToken): Promise<LangiumDocument<T>>;\r\n    fromString<T extends AstNode = AstNode>(text: string, uri: URI, token?: CancellationToken | ParserOptions): LangiumDocument<T> | Promise<LangiumDocument<T>> {\r\n        if (CancellationToken.is(token)) {\r\n            return this.createAsync<T>(uri, text, token);\r\n        } else {\r\n            return this.create<T>(uri, text, token);\r\n        }\r\n    }\r\n\r\n    fromModel<T extends AstNode = AstNode>(model: T, uri: URI): LangiumDocument<T> {\r\n        return this.create<T>(uri, { $model: model });\r\n    }\r\n\r\n    protected create<T extends AstNode = AstNode>(uri: URI, content: string | TextDocument | { $model: T }, options?: ParserOptions): LangiumDocument<T> {\r\n        if (typeof content === 'string') {\r\n            const parseResult = this.parse<T>(uri, content, options);\r\n            return this.createLangiumDocument<T>(parseResult, uri, undefined, content);\r\n\r\n        } else if ('$model' in content) {\r\n            const parseResult = { value: content.$model, parserErrors: [], lexerErrors: [] };\r\n            return this.createLangiumDocument<T>(parseResult, uri);\r\n\r\n        } else {\r\n            const parseResult = this.parse<T>(uri, content.getText(), options);\r\n            return this.createLangiumDocument(parseResult, uri, content);\r\n        }\r\n    }\r\n\r\n    protected async createAsync<T extends AstNode = AstNode>(uri: URI, content: string | TextDocument, cancelToken: CancellationToken): Promise<LangiumDocument<T>> {\r\n        if (typeof content === 'string') {\r\n            const parseResult = await this.parseAsync<T>(uri, content, cancelToken);\r\n            return this.createLangiumDocument<T>(parseResult, uri, undefined, content);\r\n        } else {\r\n            const parseResult = await this.parseAsync<T>(uri, content.getText(), cancelToken);\r\n            return this.createLangiumDocument(parseResult, uri, content);\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Create a LangiumDocument from a given parse result.\r\n     *\r\n     * A TextDocument is created on demand if it is not provided as argument here. Usually this\r\n     * should not be necessary because the main purpose of the TextDocument is to convert between\r\n     * text ranges and offsets, which is done solely in LSP request handling.\r\n     *\r\n     * With the introduction of {@link update} below this method is supposed to be mainly called\r\n     * during workspace initialization and on addition/recognition of new files, while changes in\r\n     * existing documents are processed via {@link update}.\r\n     */\r\n    protected createLangiumDocument<T extends AstNode = AstNode>(parseResult: ParseResult<T>, uri: URI, textDocument?: TextDocument, text?: string): LangiumDocument<T> {\r\n        let document: LangiumDocument<T>;\r\n        if (textDocument) {\r\n            document = {\r\n                parseResult,\r\n                uri,\r\n                state: DocumentState.Parsed,\r\n                references: [],\r\n                textDocument\r\n            };\r\n        } else {\r\n            const textDocumentGetter = this.createTextDocumentGetter(uri, text);\r\n            document = {\r\n                parseResult,\r\n                uri,\r\n                state: DocumentState.Parsed,\r\n                references: [],\r\n                get textDocument() {\r\n                    return textDocumentGetter();\r\n                }\r\n            };\r\n        }\r\n        (parseResult.value as Mutable<AstNode>).$document = document;\r\n        return document;\r\n    }\r\n\r\n    async update<T extends AstNode = AstNode>(document: Mutable<LangiumDocument<T>>, cancellationToken: CancellationToken): Promise<LangiumDocument<T>> {\r\n        // The CST full text property contains the original text that was used to create the AST.\r\n        const oldText = document.parseResult.value.$cstNode?.root.fullText;\r\n        const textDocument = this.textDocuments?.get(document.uri.toString());\r\n        const text = textDocument ? textDocument.getText() : await this.fileSystemProvider.readFile(document.uri);\r\n\r\n        if (textDocument) {\r\n            Object.defineProperty(\r\n                document,\r\n                'textDocument',\r\n                {\r\n                    value: textDocument\r\n                }\r\n            );\r\n        } else {\r\n            const textDocumentGetter = this.createTextDocumentGetter(document.uri, text);\r\n            Object.defineProperty(\r\n                document,\r\n                'textDocument',\r\n                {\r\n                    get: textDocumentGetter\r\n                }\r\n            );\r\n        }\r\n\r\n        // Some of these documents can be pretty large, so parsing them again can be quite expensive.\r\n        // Therefore, we only parse if the text has actually changed.\r\n        if (oldText !== text) {\r\n            document.parseResult = await this.parseAsync(document.uri, text, cancellationToken);\r\n            (document.parseResult.value as Mutable<AstNode>).$document = document;\r\n        }\r\n        document.state = DocumentState.Parsed;\r\n        return document;\r\n    }\r\n\r\n    protected parse<T extends AstNode>(uri: URI, text: string, options?: ParserOptions): ParseResult<T> {\r\n        const services = this.serviceRegistry.getServices(uri);\r\n        return services.parser.LangiumParser.parse<T>(text, options);\r\n    }\r\n\r\n    protected parseAsync<T extends AstNode>(uri: URI, text: string, cancellationToken: CancellationToken): Promise<ParseResult<T>> {\r\n        const services = this.serviceRegistry.getServices(uri);\r\n        return services.parser.AsyncParser.parse<T>(text, cancellationToken);\r\n    }\r\n\r\n    protected createTextDocumentGetter(uri: URI, text?: string): () => TextDocument {\r\n        const serviceRegistry = this.serviceRegistry;\r\n        let textDoc: TextDocument | undefined = undefined;\r\n        return () => {\r\n            return textDoc ??= TextDocument.create(\r\n                uri.toString(), serviceRegistry.getServices(uri).LanguageMetaData.languageId, 0, text ?? ''\r\n            );\r\n        };\r\n    }\r\n}\r\n\r\n/**\r\n * Shared service for managing Langium documents.\r\n */\r\nexport interface LangiumDocuments {\r\n\r\n    /**\r\n     * A stream of all documents managed under this service.\r\n     */\r\n    readonly all: Stream<LangiumDocument>\r\n\r\n    /**\r\n     * Manage a new document under this service.\r\n     * @throws an error if a document with the same URI is already present.\r\n     */\r\n    addDocument(document: LangiumDocument): void;\r\n\r\n    /**\r\n     * Retrieve the document with the given URI, if present. Otherwise returns `undefined`.\r\n     */\r\n    getDocument(uri: URI): LangiumDocument | undefined;\r\n\r\n    /**\r\n     * Retrieve the document with the given URI. If not present, a new one will be created using the file system access.\r\n     * The new document will be added to the list of documents managed under this service.\r\n     */\r\n    getOrCreateDocument(uri: URI, cancellationToken?: CancellationToken): Promise<LangiumDocument>;\r\n\r\n    /**\r\n     * Creates a new document with the given URI and text content.\r\n     * The new document is automatically added to this service and can be retrieved using {@link getDocument}.\r\n     *\r\n     * @throws an error if a document with the same URI is already present.\r\n     */\r\n    createDocument(uri: URI, text: string): LangiumDocument;\r\n\r\n    /**\r\n     * Creates a new document with the given URI and text content asynchronously.\r\n     * The process can be interrupted with a cancellation token.\r\n     * The new document is automatically added to this service and can be retrieved using {@link getDocument}.\r\n     *\r\n     * @throws an error if a document with the same URI is already present.\r\n     */\r\n    createDocument(uri: URI, text: string, cancellationToken: CancellationToken): Promise<LangiumDocument>;\r\n\r\n    /**\r\n     * Returns `true` if a document with the given URI is managed under this service.\r\n     */\r\n    hasDocument(uri: URI): boolean;\r\n\r\n    /**\r\n     * Flag the document with the given URI as `Changed`, if present, meaning that its content\r\n     * is no longer valid. The content (parseResult) stays untouched, while internal data may\r\n     * be dropped to reduce memory footprint.\r\n     *\r\n     * @returns the affected {@link LangiumDocument} if existing for convenience\r\n     */\r\n    invalidateDocument(uri: URI): LangiumDocument | undefined;\r\n\r\n    /**\r\n     * Remove the document with the given URI, if present, and mark it as `Changed`, meaning\r\n     * that its content is no longer valid. The next call to `getOrCreateDocument` with the same\r\n     * URI will create a new document instance.\r\n     *\r\n     * @returns the affected {@link LangiumDocument} if existing for convenience\r\n     */\r\n    deleteDocument(uri: URI): LangiumDocument | undefined;\r\n}\r\n\r\nexport class DefaultLangiumDocuments implements LangiumDocuments {\r\n\r\n    protected readonly langiumDocumentFactory: LangiumDocumentFactory;\r\n    protected readonly serviceRegistry: ServiceRegistry;\r\n\r\n    protected readonly documentMap: Map<string, LangiumDocument> = new Map();\r\n\r\n    constructor(services: LangiumSharedCoreServices) {\r\n        this.langiumDocumentFactory = services.workspace.LangiumDocumentFactory;\r\n        this.serviceRegistry = services.ServiceRegistry;\r\n    }\r\n\r\n    get all(): Stream<LangiumDocument> {\r\n        return stream(this.documentMap.values());\r\n    }\r\n\r\n    addDocument(document: LangiumDocument): void {\r\n        const uriString = document.uri.toString();\r\n        if (this.documentMap.has(uriString)) {\r\n            throw new Error(`A document with the URI '${uriString}' is already present.`);\r\n        }\r\n        this.documentMap.set(uriString, document);\r\n    }\r\n\r\n    getDocument(uri: URI): LangiumDocument | undefined {\r\n        const uriString = uri.toString();\r\n        return this.documentMap.get(uriString);\r\n    }\r\n\r\n    async getOrCreateDocument(uri: URI, cancellationToken?: CancellationToken): Promise<LangiumDocument> {\r\n        let document = this.getDocument(uri);\r\n        if (document) {\r\n            return document;\r\n        }\r\n        document = await this.langiumDocumentFactory.fromUri(uri, cancellationToken);\r\n        this.addDocument(document);\r\n        return document;\r\n    }\r\n\r\n    createDocument(uri: URI, text: string): LangiumDocument;\r\n    createDocument(uri: URI, text: string, cancellationToken: CancellationToken): Promise<LangiumDocument>;\r\n    createDocument(uri: URI, text: string, cancellationToken?: CancellationToken): LangiumDocument | Promise<LangiumDocument> {\r\n        if (cancellationToken) {\r\n            return this.langiumDocumentFactory.fromString(text, uri, cancellationToken).then(document => {\r\n                this.addDocument(document);\r\n                return document;\r\n            });\r\n        } else {\r\n            const document = this.langiumDocumentFactory.fromString(text, uri);\r\n            this.addDocument(document);\r\n            return document;\r\n        }\r\n    }\r\n\r\n    hasDocument(uri: URI): boolean {\r\n        return this.documentMap.has(uri.toString());\r\n    }\r\n\r\n    invalidateDocument(uri: URI): LangiumDocument | undefined {\r\n        const uriString = uri.toString();\r\n        const langiumDoc = this.documentMap.get(uriString);\r\n        if (langiumDoc) {\r\n            const linker = this.serviceRegistry.getServices(uri).references.Linker;\r\n            linker.unlink(langiumDoc);\r\n            langiumDoc.state = DocumentState.Changed;\r\n            langiumDoc.precomputedScopes = undefined;\r\n            langiumDoc.diagnostics = undefined;\r\n        }\r\n        return langiumDoc;\r\n    }\r\n\r\n    deleteDocument(uri: URI): LangiumDocument | undefined {\r\n        const uriString = uri.toString();\r\n        const langiumDoc = this.documentMap.get(uriString);\r\n        if (langiumDoc) {\r\n            langiumDoc.state = DocumentState.Changed;\r\n            this.documentMap.delete(uriString);\r\n        }\r\n        return langiumDoc;\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, AstNodeDescription, AstReflection, CstNode, LinkingError, Reference, ReferenceInfo } from '../syntax-tree.js';\r\nimport type { AstNodeLocator } from '../workspace/ast-node-locator.js';\r\nimport type { LangiumDocument, LangiumDocuments } from '../workspace/documents.js';\r\nimport type { ScopeProvider } from './scope-provider.js';\r\nimport { CancellationToken } from '../utils/cancellation.js';\r\nimport { isAstNode, isAstNodeDescription, isLinkingError } from '../syntax-tree.js';\r\nimport { findRootNode, streamAst, streamReferences } from '../utils/ast-utils.js';\r\nimport { interruptAndCheck } from '../utils/promise-utils.js';\r\nimport { DocumentState } from '../workspace/documents.js';\r\n\r\n/**\r\n * Language-specific service for resolving cross-references in the AST.\r\n */\r\nexport interface Linker {\r\n\r\n    /**\r\n     * Links all cross-references within the specified document. The default implementation loads only target\r\n     * elements from documents that are present in the `LangiumDocuments` service. The linked references are\r\n     * stored in the document's `references` property.\r\n     *\r\n     * @param document A LangiumDocument that shall be linked.\r\n     * @param cancelToken A token for cancelling the operation.\r\n     *\r\n     * @throws `OperationCancelled` if a cancellation event is detected\r\n     */\r\n    link(document: LangiumDocument, cancelToken?: CancellationToken): Promise<void>;\r\n\r\n    /**\r\n     * Unlinks all references within the specified document and removes them from the list of `references`.\r\n     *\r\n     * @param document A LangiumDocument that shall be unlinked.\r\n     */\r\n    unlink(document: LangiumDocument): void;\r\n\r\n    /**\r\n     * Determines a candidate AST node description for linking the given reference.\r\n     *\r\n     * @param refInfo Information about the reference.\r\n     */\r\n    getCandidate(refInfo: ReferenceInfo): AstNodeDescription | LinkingError;\r\n\r\n    /**\r\n     * Creates a cross reference node being aware of its containing AstNode, the corresponding CstNode,\r\n     * the cross reference text denoting the target AstNode being already extracted of the document text,\r\n     * as well as the unique cross reference identifier.\r\n     *\r\n     * Default behavior:\r\n     *  - The returned Reference's 'ref' property pointing to the target AstNode is populated lazily on its\r\n     *    first visit.\r\n     *  - If the target AstNode cannot be resolved on the first visit, an error indicator will be installed\r\n     *    and further resolution attempts will *not* be performed.\r\n     *\r\n     * @param node The containing AST node\r\n     * @param property The AST node property being referenced\r\n     * @param refNode The corresponding CST node\r\n     * @param refText The cross reference text denoting the target AstNode\r\n     * @returns the desired Reference node, whose behavior wrt. resolving the cross reference is implementation specific.\r\n     */\r\n    buildReference(node: AstNode, property: string, refNode: CstNode | undefined, refText: string): Reference;\r\n\r\n}\r\n\r\nconst ref_resolving = Symbol('ref_resolving');\r\n\r\ninterface DefaultReference extends Reference {\r\n    _ref?: AstNode | LinkingError | typeof ref_resolving;\r\n    _nodeDescription?: AstNodeDescription;\r\n}\r\n\r\nexport class DefaultLinker implements Linker {\r\n    protected readonly reflection: AstReflection;\r\n    protected readonly scopeProvider: ScopeProvider;\r\n    protected readonly astNodeLocator: AstNodeLocator;\r\n    protected readonly langiumDocuments: () => LangiumDocuments;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.reflection = services.shared.AstReflection;\r\n        this.langiumDocuments = () => services.shared.workspace.LangiumDocuments;\r\n        this.scopeProvider = services.references.ScopeProvider;\r\n        this.astNodeLocator = services.workspace.AstNodeLocator;\r\n    }\r\n\r\n    async link(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<void> {\r\n        for (const node of streamAst(document.parseResult.value)) {\r\n            await interruptAndCheck(cancelToken);\r\n            streamReferences(node).forEach(ref => this.doLink(ref, document));\r\n        }\r\n    }\r\n\r\n    protected doLink(refInfo: ReferenceInfo, document: LangiumDocument): void {\r\n        const ref = refInfo.reference as DefaultReference;\r\n        // The reference may already have been resolved lazily by accessing its `ref` property.\r\n        if (ref._ref === undefined) {\r\n            ref._ref = ref_resolving;\r\n            try {\r\n                const description = this.getCandidate(refInfo);\r\n                if (isLinkingError(description)) {\r\n                    ref._ref = description;\r\n                } else {\r\n                    ref._nodeDescription = description;\r\n                    if (this.langiumDocuments().hasDocument(description.documentUri)) {\r\n                        // The target document is already loaded\r\n                        const linkedNode = this.loadAstNode(description);\r\n                        ref._ref = linkedNode ?? this.createLinkingError(refInfo, description);\r\n                    } else {\r\n                        // Try to load the target AST node later using the already provided description\r\n                        ref._ref = undefined;\r\n                    }\r\n                }\r\n            } catch (err) {\r\n                console.error(`An error occurred while resolving reference to '${ref.$refText}':`, err);\r\n                const errorMessage = (err as Error).message ?? String(err);\r\n                ref._ref = {\r\n                    ...refInfo,\r\n                    message: `An error occurred while resolving reference to '${ref.$refText}': ${errorMessage}`\r\n                };\r\n            }\r\n            // Add the reference to the document's array of references\r\n            // Only add if the reference has been not been resolved earlier\r\n            // Otherwise we end up with duplicates\r\n            // See also implementation of `buildReference`\r\n            document.references.push(ref);\r\n        }\r\n    }\r\n\r\n    unlink(document: LangiumDocument): void {\r\n        for (const ref of document.references) {\r\n            delete (ref as DefaultReference)._ref;\r\n            delete (ref as DefaultReference)._nodeDescription;\r\n        }\r\n        document.references = [];\r\n    }\r\n\r\n    getCandidate(refInfo: ReferenceInfo): AstNodeDescription | LinkingError {\r\n        const scope = this.scopeProvider.getScope(refInfo);\r\n        const description = scope.getElement(refInfo.reference.$refText);\r\n        return description ?? this.createLinkingError(refInfo);\r\n    }\r\n\r\n    buildReference(node: AstNode, property: string, refNode: CstNode | undefined, refText: string): Reference {\r\n        // See behavior description in doc of Linker, update that on changes in here.\r\n        // eslint-disable-next-line @typescript-eslint/no-this-alias\r\n        const linker = this;\r\n        const reference: DefaultReference = {\r\n            $refNode: refNode,\r\n            $refText: refText,\r\n\r\n            get ref() {\r\n                if (isAstNode(this._ref)) {\r\n                    // Most frequent case: the target is already resolved.\r\n                    return this._ref;\r\n                } else if (isAstNodeDescription(this._nodeDescription)) {\r\n                    // A candidate has been found before, but it is not loaded yet.\r\n                    const linkedNode = linker.loadAstNode(this._nodeDescription);\r\n                    this._ref = linkedNode ??\r\n                        linker.createLinkingError({ reference, container: node, property }, this._nodeDescription);\r\n                } else if (this._ref === undefined) {\r\n                    // The reference has not been linked yet, so do that now.\r\n                    this._ref = ref_resolving;\r\n                    const document = findRootNode(node).$document;\r\n                    const refData = linker.getLinkedNode({ reference, container: node, property });\r\n                    if (refData.error && document && document.state < DocumentState.ComputedScopes) {\r\n                        // Document scope is not ready, don't set `this._ref` so linker can retry later.\r\n                        return this._ref = undefined;\r\n                    }\r\n                    this._ref = refData.node ?? refData.error;\r\n                    this._nodeDescription = refData.descr;\r\n                    document?.references.push(this);\r\n                } else if (this._ref === ref_resolving) {\r\n                    throw new Error(`Cyclic reference resolution detected: ${linker.astNodeLocator.getAstNodePath(node)}/${property} (symbol '${refText}')`);\r\n                }\r\n                return isAstNode(this._ref) ? this._ref : undefined;\r\n            },\r\n            get $nodeDescription() {\r\n                return this._nodeDescription;\r\n            },\r\n            get error() {\r\n                return isLinkingError(this._ref) ? this._ref : undefined;\r\n            }\r\n        };\r\n        return reference;\r\n    }\r\n\r\n    protected getLinkedNode(refInfo: ReferenceInfo): { node?: AstNode, descr?: AstNodeDescription, error?: LinkingError } {\r\n        try {\r\n            const description = this.getCandidate(refInfo);\r\n            if (isLinkingError(description)) {\r\n                return { error: description };\r\n            }\r\n            const linkedNode = this.loadAstNode(description);\r\n            if (linkedNode) {\r\n                return { node: linkedNode, descr: description };\r\n            }\r\n            else {\r\n                return {\r\n                    descr: description,\r\n                    error:\r\n                        this.createLinkingError(refInfo, description)\r\n                };\r\n            }\r\n        } catch (err) {\r\n            console.error(`An error occurred while resolving reference to '${refInfo.reference.$refText}':`, err);\r\n            const errorMessage = (err as Error).message ?? String(err);\r\n            return {\r\n                error: {\r\n                    ...refInfo,\r\n                    message: `An error occurred while resolving reference to '${refInfo.reference.$refText}': ${errorMessage}`\r\n                }\r\n            };\r\n        }\r\n    }\r\n\r\n    protected loadAstNode(nodeDescription: AstNodeDescription): AstNode | undefined {\r\n        if (nodeDescription.node) {\r\n            return nodeDescription.node;\r\n        }\r\n        const doc = this.langiumDocuments().getDocument(nodeDescription.documentUri);\r\n        if (!doc) {\r\n            return undefined;\r\n        }\r\n        return this.astNodeLocator.getAstNode(doc.parseResult.value, nodeDescription.path);\r\n    }\r\n\r\n    protected createLinkingError(refInfo: ReferenceInfo, targetDescription?: AstNodeDescription): LinkingError {\r\n        // Check whether the document is sufficiently processed by the DocumentBuilder. If not, this is a hint for a bug\r\n        // in the language implementation.\r\n        const document = findRootNode(refInfo.container).$document;\r\n        if (document && document.state < DocumentState.ComputedScopes) {\r\n            console.warn(`Attempted reference resolution before document reached ComputedScopes state (${document.uri}).`);\r\n        }\r\n        const referenceType = this.reflection.getReferenceType(refInfo);\r\n        return {\r\n            ...refInfo,\r\n            message: `Could not resolve reference to ${referenceType} named '${refInfo.reference.$refText}'.`,\r\n            targetDescription\r\n        };\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { AstNode, CstNode } from '../syntax-tree.js';\r\nimport { findNodeForProperty } from '../utils/grammar-utils.js';\r\n\r\nexport interface NamedAstNode extends AstNode {\r\n    name: string;\r\n}\r\n\r\nexport function isNamed(node: AstNode): node is NamedAstNode {\r\n    return typeof (node as NamedAstNode).name === 'string';\r\n}\r\n\r\n/**\r\n * Utility service for retrieving the `name` of an `AstNode` or the `CstNode` containing a `name`.\r\n */\r\nexport interface NameProvider {\r\n    /**\r\n     * Returns the `name` of a given AstNode.\r\n     * @param node Specified `AstNode` whose name node shall be retrieved.\r\n     */\r\n    getName(node: AstNode): string | undefined;\r\n    /**\r\n     * Returns the `CstNode` which contains the parsed value of the `name` assignment.\r\n     * @param node Specified `AstNode` whose name node shall be retrieved.\r\n     */\r\n    getNameNode(node: AstNode): CstNode | undefined;\r\n}\r\n\r\nexport class DefaultNameProvider implements NameProvider {\r\n    getName(node: AstNode): string | undefined {\r\n        if (isNamed(node)) {\r\n            return node.name;\r\n        }\r\n        return undefined;\r\n    }\r\n\r\n    getNameNode(node: AstNode): CstNode | undefined {\r\n        return findNodeForProperty(node.$cstNode, 'name');\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { URI, Utils } from 'vscode-uri';\r\n\r\nexport { URI };\r\n\r\nexport namespace UriUtils {\r\n\r\n    export const basename = Utils.basename;\r\n    export const dirname = Utils.dirname;\r\n    export const extname = Utils.extname;\r\n    export const joinPath = Utils.joinPath;\r\n    export const resolvePath = Utils.resolvePath;\r\n\r\n    export function equals(a?: URI | string, b?: URI | string): boolean {\r\n        return a?.toString() === b?.toString();\r\n    }\r\n\r\n    export function relative(from: URI | string, to: URI | string): string {\r\n        const fromPath = typeof from === 'string' ? from : from.path;\r\n        const toPath = typeof to === 'string' ? to : to.path;\r\n        const fromParts = fromPath.split('/').filter(e => e.length > 0);\r\n        const toParts = toPath.split('/').filter(e => e.length > 0);\r\n        let i = 0;\r\n        for (; i < fromParts.length; i++) {\r\n            if (fromParts[i] !== toParts[i]) {\r\n                break;\r\n            }\r\n        }\r\n        const backPart = '../'.repeat(fromParts.length - i);\r\n        const toPart = toParts.slice(i).join('/');\r\n        return backPart + toPart;\r\n    }\r\n\r\n    export function normalize(uri: URI | string): string {\r\n        return URI.parse(uri.toString()).toString();\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, CstNode, GenericAstNode } from '../syntax-tree.js';\r\nimport type { Stream } from '../utils/stream.js';\r\nimport type { ReferenceDescription } from '../workspace/ast-descriptions.js';\r\nimport type { AstNodeLocator } from '../workspace/ast-node-locator.js';\r\nimport type { IndexManager } from '../workspace/index-manager.js';\r\nimport type { NameProvider } from './name-provider.js';\r\nimport type { URI } from '../utils/uri-utils.js';\r\nimport { findAssignment } from '../utils/grammar-utils.js';\r\nimport { isReference } from '../syntax-tree.js';\r\nimport { getDocument } from '../utils/ast-utils.js';\r\nimport { isChildNode, toDocumentSegment } from '../utils/cst-utils.js';\r\nimport { stream } from '../utils/stream.js';\r\nimport { UriUtils } from '../utils/uri-utils.js';\r\n\r\n/**\r\n * Language-specific service for finding references and declaration of a given `CstNode`.\r\n */\r\nexport interface References {\r\n\r\n    /**\r\n     * If the CstNode is a reference node the target CstNode will be returned.\r\n     * If the CstNode is a significant node of the CstNode this CstNode will be returned.\r\n     *\r\n     * @param sourceCstNode CstNode that points to a AstNode\r\n     */\r\n    findDeclaration(sourceCstNode: CstNode): AstNode | undefined;\r\n\r\n    /**\r\n     * If the CstNode is a reference node the target CstNode will be returned.\r\n     * If the CstNode is a significant node of the CstNode this CstNode will be returned.\r\n     *\r\n     * @param sourceCstNode CstNode that points to a AstNode\r\n     */\r\n    findDeclarationNode(sourceCstNode: CstNode): CstNode | undefined;\r\n\r\n    /**\r\n     * Finds all references to the target node as references (local references) or reference descriptions.\r\n     *\r\n     * @param targetNode Specified target node whose references should be returned\r\n     */\r\n    findReferences(targetNode: AstNode, options: FindReferencesOptions): Stream<ReferenceDescription>;\r\n}\r\n\r\nexport interface FindReferencesOptions {\r\n    /**\r\n     * @deprecated Since v1.2.0. Please use `documentUri` instead.\r\n     */\r\n    onlyLocal?: boolean;\r\n    /**\r\n     * When set, the `findReferences` method will only return references/declarations from the specified document.\r\n     */\r\n    documentUri?: URI;\r\n    /**\r\n     * Whether the returned list of references should include the declaration.\r\n     */\r\n    includeDeclaration?: boolean;\r\n}\r\n\r\nexport class DefaultReferences implements References {\r\n    protected readonly nameProvider: NameProvider;\r\n    protected readonly index: IndexManager;\r\n    protected readonly nodeLocator: AstNodeLocator;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.nameProvider = services.references.NameProvider;\r\n        this.index = services.shared.workspace.IndexManager;\r\n        this.nodeLocator = services.workspace.AstNodeLocator;\r\n    }\r\n\r\n    findDeclaration(sourceCstNode: CstNode): AstNode | undefined {\r\n        if (sourceCstNode) {\r\n            const assignment = findAssignment(sourceCstNode);\r\n            const nodeElem = sourceCstNode.astNode;\r\n            if (assignment && nodeElem) {\r\n                const reference = (nodeElem as GenericAstNode)[assignment.feature];\r\n\r\n                if (isReference(reference)) {\r\n                    return reference.ref;\r\n                } else if (Array.isArray(reference)) {\r\n                    for (const ref of reference) {\r\n                        if (isReference(ref) && ref.$refNode\r\n                            && ref.$refNode.offset <= sourceCstNode.offset\r\n                            && ref.$refNode.end >= sourceCstNode.end) {\r\n                            return ref.ref;\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n            if (nodeElem) {\r\n                const nameNode = this.nameProvider.getNameNode(nodeElem);\r\n                // Only return the targeted node in case the targeted cst node is the name node or part of it\r\n                if (nameNode && (nameNode === sourceCstNode || isChildNode(sourceCstNode, nameNode))) {\r\n                    return nodeElem;\r\n                }\r\n            }\r\n        }\r\n        return undefined;\r\n    }\r\n\r\n    findDeclarationNode(sourceCstNode: CstNode): CstNode | undefined {\r\n        const astNode = this.findDeclaration(sourceCstNode);\r\n        if (astNode?.$cstNode) {\r\n            const targetNode = this.nameProvider.getNameNode(astNode);\r\n            return targetNode ?? astNode.$cstNode;\r\n        }\r\n        return undefined;\r\n    }\r\n\r\n    findReferences(targetNode: AstNode, options: FindReferencesOptions): Stream<ReferenceDescription> {\r\n        const refs: ReferenceDescription[] = [];\r\n        if (options.includeDeclaration) {\r\n            const ref = this.getReferenceToSelf(targetNode);\r\n            if (ref) {\r\n                refs.push(ref);\r\n            }\r\n        }\r\n        let indexReferences = this.index.findAllReferences(targetNode, this.nodeLocator.getAstNodePath(targetNode));\r\n        if (options.documentUri) {\r\n            indexReferences = indexReferences.filter(ref => UriUtils.equals(ref.sourceUri, options.documentUri));\r\n        }\r\n        refs.push(...indexReferences);\r\n        return stream(refs);\r\n    }\r\n\r\n    protected getReferenceToSelf(targetNode: AstNode): ReferenceDescription | undefined {\r\n        const nameNode = this.nameProvider.getNameNode(targetNode);\r\n        if (nameNode) {\r\n            const doc = getDocument(targetNode);\r\n            const path = this.nodeLocator.getAstNodePath(targetNode);\r\n            return {\r\n                sourceUri: doc.uri,\r\n                sourcePath: path,\r\n                targetUri: doc.uri,\r\n                targetPath: path,\r\n                segment: toDocumentSegment(nameNode),\r\n                local: true\r\n            };\r\n        }\r\n        return undefined;\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { Stream } from './stream.js';\r\nimport { Reduction, stream } from './stream.js';\r\n\r\n/**\r\n * A multimap is a variation of a Map that has potentially multiple values for every key.\r\n */\r\nexport class MultiMap<K, V> {\r\n\r\n    private map = new Map<K, V[]>();\r\n\r\n    constructor()\r\n    constructor(elements: Array<[K, V]>)\r\n    constructor(elements?: Array<[K, V]>) {\r\n        if (elements) {\r\n            for (const [key, value] of elements) {\r\n                this.add(key, value);\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * The total number of values in the multimap.\r\n     */\r\n    get size(): number {\r\n        return Reduction.sum(stream(this.map.values()).map(a => a.length));\r\n    }\r\n\r\n    /**\r\n     * Clear all entries in the multimap.\r\n     */\r\n    clear(): void {\r\n        this.map.clear();\r\n    }\r\n\r\n    /**\r\n     * Operates differently depending on whether a `value` is given:\r\n     *  * With a value, this method deletes the specific key / value pair from the multimap.\r\n     *  * Without a value, all values associated with the given key are deleted.\r\n     *\r\n     * @returns `true` if a value existed and has been removed, or `false` if the specified\r\n     *     key / value does not exist.\r\n     */\r\n    delete(key: K, value?: V): boolean {\r\n        if (value === undefined) {\r\n            return this.map.delete(key);\r\n        } else {\r\n            const values = this.map.get(key);\r\n            if (values) {\r\n                const index = values.indexOf(value);\r\n                if (index >= 0) {\r\n                    if (values.length === 1) {\r\n                        this.map.delete(key);\r\n                    } else {\r\n                        values.splice(index, 1);\r\n                    }\r\n                    return true;\r\n                }\r\n            }\r\n            return false;\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Returns an array of all values associated with the given key. If no value exists,\r\n     * an empty array is returned.\r\n     *\r\n     * _Note:_ The returned array is assumed not to be modified. Use the `set` method to add a\r\n     * value and `delete` to remove a value from the multimap.\r\n     */\r\n    get(key: K): readonly V[] {\r\n        return this.map.get(key) ?? [];\r\n    }\r\n\r\n    /**\r\n     * Operates differently depending on whether a `value` is given:\r\n     *  * With a value, this method returns `true` if the specific key / value pair is present in the multimap.\r\n     *  * Without a value, this method returns `true` if the given key is present in the multimap.\r\n     */\r\n    has(key: K, value?: V): boolean {\r\n        if (value === undefined) {\r\n            return this.map.has(key);\r\n        } else {\r\n            const values = this.map.get(key);\r\n            if (values) {\r\n                return values.indexOf(value) >= 0;\r\n            }\r\n            return false;\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Add the given key / value pair to the multimap.\r\n     */\r\n    add(key: K, value: V): this {\r\n        if (this.map.has(key)) {\r\n            this.map.get(key)!.push(value);\r\n        } else {\r\n            this.map.set(key, [value]);\r\n        }\r\n        return this;\r\n    }\r\n\r\n    /**\r\n     * Add the given set of key / value pairs to the multimap.\r\n     */\r\n    addAll(key: K, values: Iterable<V>): this {\r\n        if (this.map.has(key)) {\r\n            this.map.get(key)!.push(...values);\r\n        } else {\r\n            this.map.set(key, Array.from(values));\r\n        }\r\n        return this;\r\n    }\r\n\r\n    /**\r\n     * Invokes the given callback function for every key / value pair in the multimap.\r\n     */\r\n    forEach(callbackfn: (value: V, key: K, map: this) => void): void {\r\n        this.map.forEach((array, key) =>\r\n            array.forEach(value => callbackfn(value, key, this))\r\n        );\r\n    }\r\n\r\n    /**\r\n     * Returns an iterator of key, value pairs for every entry in the map.\r\n     */\r\n    [Symbol.iterator](): Iterator<[K, V]> {\r\n        return this.entries().iterator();\r\n    }\r\n\r\n    /**\r\n     * Returns a stream of key, value pairs for every entry in the map.\r\n     */\r\n    entries(): Stream<[K, V]> {\r\n        return stream(this.map.entries())\r\n            .flatMap(([key, array]) => array.map(value => [key, value] as [K, V]));\r\n    }\r\n\r\n    /**\r\n     * Returns a stream of keys in the map.\r\n     */\r\n    keys(): Stream<K> {\r\n        return stream(this.map.keys());\r\n    }\r\n\r\n    /**\r\n     * Returns a stream of values in the map.\r\n     */\r\n    values(): Stream<V> {\r\n        return stream(this.map.values()).flat();\r\n    }\r\n\r\n    /**\r\n     * Returns a stream of key, value set pairs for every key in the map.\r\n     */\r\n    entriesGroupedByKey(): Stream<[K, V[]]> {\r\n        return stream(this.map.entries());\r\n    }\r\n\r\n}\r\n\r\nexport class BiMap<K, V> {\r\n\r\n    private map = new Map<K, V>();\r\n    private inverse = new Map<V, K>();\r\n\r\n    get size(): number {\r\n        return this.map.size;\r\n    }\r\n\r\n    constructor()\r\n    constructor(elements: Array<[K, V]>)\r\n    constructor(elements?: Array<[K, V]>) {\r\n        if (elements) {\r\n            for (const [key, value] of elements) {\r\n                this.set(key, value);\r\n            }\r\n        }\r\n    }\r\n\r\n    clear(): void {\r\n        this.map.clear();\r\n        this.inverse.clear();\r\n    }\r\n\r\n    set(key: K, value: V): this {\r\n        this.map.set(key, value);\r\n        this.inverse.set(value, key);\r\n        return this;\r\n    }\r\n\r\n    get(key: K): V | undefined {\r\n        return this.map.get(key);\r\n    }\r\n\r\n    getKey(value: V): K | undefined {\r\n        return this.inverse.get(value);\r\n    }\r\n\r\n    delete(key: K): boolean {\r\n        const value = this.map.get(key);\r\n        if (value !== undefined) {\r\n            this.map.delete(key);\r\n            this.inverse.delete(value);\r\n            return true;\r\n        }\r\n        return false;\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021-2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, AstNodeDescription } from '../syntax-tree.js';\r\nimport type { AstNodeDescriptionProvider } from '../workspace/ast-descriptions.js';\r\nimport type { LangiumDocument, PrecomputedScopes } from '../workspace/documents.js';\r\nimport type { NameProvider } from './name-provider.js';\r\nimport { CancellationToken } from '../utils/cancellation.js';\r\nimport { streamAllContents, streamContents } from '../utils/ast-utils.js';\r\nimport { MultiMap } from '../utils/collections.js';\r\nimport { interruptAndCheck } from '../utils/promise-utils.js';\r\n\r\n/**\r\n * Language-specific service for precomputing global and local scopes. The service methods are executed\r\n * as the first and second phase in the `DocumentBuilder`.\r\n */\r\nexport interface ScopeComputation {\r\n\r\n    /**\r\n     * Creates descriptions of all AST nodes that shall be exported into the _global_ scope from the given\r\n     * document. These descriptions are gathered by the `IndexManager` and stored in the global index so\r\n     * they can be referenced from other documents.\r\n     *\r\n     * _Note:_ You should not resolve any cross-references in this service method. Cross-reference resolution\r\n     * depends on the scope computation phase to be completed (`computeScope` method), which runs after the\r\n     * initial indexing where this method is used.\r\n     *\r\n     * @param document The document from which to gather exported AST nodes.\r\n     * @param cancelToken Indicates when to cancel the current operation.\r\n     * @throws `OperationCanceled` if a user action occurs during execution\r\n     */\r\n    computeExports(document: LangiumDocument, cancelToken?: CancellationToken): Promise<AstNodeDescription[]>;\r\n\r\n    /**\r\n     * Precomputes the _local_ scopes for a document, which are necessary for the default way of\r\n     * resolving references to symbols in the same document. The result is a multimap assigning a\r\n     * set of AST node descriptions to every level of the AST. These data are used by the `ScopeProvider`\r\n     * service to determine which target nodes are visible in the context of a specific cross-reference.\r\n     *\r\n     * _Note:_ You should not resolve any cross-references in this service method. Cross-reference\r\n     * resolution depends on the scope computation phase to be completed.\r\n     *\r\n     * @param document The document in which to compute scopes.\r\n     * @param cancelToken Indicates when to cancel the current operation.\r\n     * @throws `OperationCanceled` if a user action occurs during execution\r\n     */\r\n    computeLocalScopes(document: LangiumDocument, cancelToken?: CancellationToken): Promise<PrecomputedScopes>;\r\n\r\n}\r\n\r\n/**\r\n * The default scope computation creates and collectes descriptions of the AST nodes to be exported into the\r\n * _global_ scope from the given document. By default those are the document's root AST node and its directly\r\n * contained child nodes.\r\n *\r\n * Besides, it gathers all AST nodes that have a name (according to the `NameProvider` service) and includes them\r\n * in the local scope of their particular container nodes. As a result, for every cross-reference in the AST,\r\n * target elements from the same level (siblings) and further up towards the root (parents and siblings of parents)\r\n * are visible. Elements being nested inside lower levels (children, children of siblings and parents' siblings)\r\n * are _invisible_ by default, but that can be changed by customizing this service.\r\n */\r\nexport class DefaultScopeComputation implements ScopeComputation {\r\n\r\n    protected readonly nameProvider: NameProvider;\r\n    protected readonly descriptions: AstNodeDescriptionProvider;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.nameProvider = services.references.NameProvider;\r\n        this.descriptions = services.workspace.AstNodeDescriptionProvider;\r\n    }\r\n\r\n    async computeExports(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<AstNodeDescription[]> {\r\n        return this.computeExportsForNode(document.parseResult.value, document, undefined, cancelToken);\r\n    }\r\n\r\n    /**\r\n     * Creates {@link AstNodeDescription AstNodeDescriptions} for the given {@link AstNode parentNode} and its children.\r\n     * The list of children to be considered is determined by the function parameter {@link children}.\r\n     * By default only the direct children of {@link parentNode} are visited, nested nodes are not exported.\r\n     *\r\n     * @param parentNode AST node to be exported, i.e., of which an {@link AstNodeDescription} shall be added to the returned list.\r\n     * @param document The document containing the AST node to be exported.\r\n     * @param children A function called with {@link parentNode} as single argument and returning an {@link Iterable} supplying the children to be visited, which must be directly or transitively contained in {@link parentNode}.\r\n     * @param cancelToken Indicates when to cancel the current operation.\r\n     * @throws `OperationCancelled` if a user action occurs during execution.\r\n     * @returns A list of {@link AstNodeDescription AstNodeDescriptions} to be published to index.\r\n     */\r\n    async computeExportsForNode(parentNode: AstNode, document: LangiumDocument<AstNode>, children: (root: AstNode) => Iterable<AstNode> = streamContents, cancelToken: CancellationToken = CancellationToken.None): Promise<AstNodeDescription[]> {\r\n        const exports: AstNodeDescription[] = [];\r\n\r\n        this.exportNode(parentNode, exports, document);\r\n        for (const node of children(parentNode)) {\r\n            await interruptAndCheck(cancelToken);\r\n            this.exportNode(node, exports, document);\r\n        }\r\n        return exports;\r\n    }\r\n\r\n    /**\r\n     * Add a single node to the list of exports if it has a name. Override this method to change how\r\n     * symbols are exported, e.g. by modifying their exported name.\r\n     */\r\n    protected exportNode(node: AstNode, exports: AstNodeDescription[], document: LangiumDocument): void {\r\n        const name = this.nameProvider.getName(node);\r\n        if (name) {\r\n            exports.push(this.descriptions.createDescription(node, name, document));\r\n        }\r\n    }\r\n\r\n    async computeLocalScopes(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<PrecomputedScopes> {\r\n        const rootNode = document.parseResult.value;\r\n        const scopes = new MultiMap<AstNode, AstNodeDescription>();\r\n        // Here we navigate the full AST - local scopes shall be available in the whole document\r\n        for (const node of streamAllContents(rootNode)) {\r\n            await interruptAndCheck(cancelToken);\r\n            this.processNode(node, document, scopes);\r\n        }\r\n        return scopes;\r\n    }\r\n\r\n    /**\r\n     * Process a single node during scopes computation. The default implementation makes the node visible\r\n     * in the subtree of its container (if the node has a name). Override this method to change this,\r\n     * e.g. by increasing the visibility to a higher level in the AST.\r\n     */\r\n    protected processNode(node: AstNode, document: LangiumDocument, scopes: PrecomputedScopes): void {\r\n        const container = node.$container;\r\n        if (container) {\r\n            const name = this.nameProvider.getName(node);\r\n            if (name) {\r\n                scopes.add(container, this.descriptions.createDescription(node, name, document));\r\n            }\r\n        }\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2023 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { AstNodeDescription } from '../syntax-tree.js';\r\nimport type { Stream } from '../utils/stream.js';\r\nimport { EMPTY_STREAM, stream } from '../utils/stream.js';\r\n\r\n/**\r\n * A scope describes what target elements are visible from a specific cross-reference context.\r\n */\r\nexport interface Scope {\r\n\r\n    /**\r\n     * Find a target element matching the given name. If no element is found, `undefined` is returned.\r\n     * If multiple matching elements are present, the selection of the returned element should be done\r\n     * according to the semantics of your language. Usually it is the element that is most closely defined.\r\n     *\r\n     * @param name Name of the cross-reference target as it appears in the source text.\r\n     */\r\n    getElement(name: string): AstNodeDescription | undefined;\r\n\r\n    /**\r\n     * Create a stream of all elements in the scope. This is used to compute completion proposals to be\r\n     * shown in the editor.\r\n     */\r\n    getAllElements(): Stream<AstNodeDescription>;\r\n\r\n}\r\n\r\nexport interface ScopeOptions {\r\n    caseInsensitive?: boolean;\r\n}\r\n\r\n/**\r\n * The default scope implementation is based on a `Stream`. It has an optional _outer scope_ describing\r\n * the next level of elements, which are queried when a target element is not found in the stream provided\r\n * to this scope.\r\n */\r\nexport class StreamScope implements Scope {\r\n    readonly elements: Stream<AstNodeDescription>;\r\n    readonly outerScope?: Scope;\r\n    readonly caseInsensitive: boolean;\r\n\r\n    constructor(elements: Stream<AstNodeDescription>, outerScope?: Scope, options?: ScopeOptions) {\r\n        this.elements = elements;\r\n        this.outerScope = outerScope;\r\n        this.caseInsensitive = options?.caseInsensitive ?? false;\r\n    }\r\n\r\n    getAllElements(): Stream<AstNodeDescription> {\r\n        if (this.outerScope) {\r\n            return this.elements.concat(this.outerScope.getAllElements());\r\n        } else {\r\n            return this.elements;\r\n        }\r\n    }\r\n\r\n    getElement(name: string): AstNodeDescription | undefined {\r\n        const local = this.caseInsensitive\r\n            ? this.elements.find(e => e.name.toLowerCase() === name.toLowerCase())\r\n            : this.elements.find(e => e.name === name);\r\n        if (local) {\r\n            return local;\r\n        }\r\n        if (this.outerScope) {\r\n            return this.outerScope.getElement(name);\r\n        }\r\n        return undefined;\r\n    }\r\n}\r\n\r\nexport class MapScope implements Scope {\r\n    readonly elements: Map<string, AstNodeDescription>;\r\n    readonly outerScope?: Scope;\r\n    readonly caseInsensitive: boolean;\r\n\r\n    constructor(elements: Iterable<AstNodeDescription>, outerScope?: Scope, options?: ScopeOptions) {\r\n        this.elements = new Map();\r\n        this.caseInsensitive = options?.caseInsensitive ?? false;\r\n        for (const element of elements) {\r\n            const name = this.caseInsensitive\r\n                ? element.name.toLowerCase()\r\n                : element.name;\r\n            this.elements.set(name, element);\r\n        }\r\n        this.outerScope = outerScope;\r\n    }\r\n\r\n    getElement(name: string): AstNodeDescription | undefined {\r\n        const localName = this.caseInsensitive ? name.toLowerCase() : name;\r\n        const local = this.elements.get(localName);\r\n        if (local) {\r\n            return local;\r\n        }\r\n        if (this.outerScope) {\r\n            return this.outerScope.getElement(name);\r\n        }\r\n        return undefined;\r\n    }\r\n\r\n    getAllElements(): Stream<AstNodeDescription> {\r\n        let elementStream = stream(this.elements.values());\r\n        if (this.outerScope) {\r\n            elementStream = elementStream.concat(this.outerScope.getAllElements());\r\n        }\r\n        return elementStream;\r\n    }\r\n\r\n}\r\n\r\nexport const EMPTY_SCOPE: Scope = {\r\n    getElement(): undefined {\r\n        return undefined;\r\n    },\r\n    getAllElements(): Stream<AstNodeDescription> {\r\n        return EMPTY_STREAM;\r\n    }\r\n};\r\n","/******************************************************************************\r\n * Copyright 2023 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { Disposable } from './disposable.js';\r\nimport type { URI } from './uri-utils.js';\r\nimport type { LangiumSharedCoreServices } from '../services.js';\r\nimport type { DocumentState } from '../workspace/documents.js';\r\n\r\nexport abstract class DisposableCache implements Disposable {\r\n\r\n    protected toDispose: Disposable[] = [];\r\n    protected isDisposed = false;\r\n\r\n    onDispose(disposable: Disposable): void {\r\n        this.toDispose.push(disposable);\r\n    }\r\n\r\n    dispose(): void {\r\n        this.throwIfDisposed();\r\n        this.clear();\r\n        this.isDisposed = true;\r\n        this.toDispose.forEach(disposable => disposable.dispose());\r\n    }\r\n\r\n    protected throwIfDisposed(): void {\r\n        if (this.isDisposed) {\r\n            throw new Error('This cache has already been disposed');\r\n        }\r\n    }\r\n\r\n    abstract clear(): void;\r\n}\r\n\r\nexport class SimpleCache<K, V> extends DisposableCache {\r\n    protected readonly cache = new Map<K, V>();\r\n\r\n    has(key: K): boolean {\r\n        this.throwIfDisposed();\r\n        return this.cache.has(key);\r\n    }\r\n\r\n    set(key: K, value: V): void {\r\n        this.throwIfDisposed();\r\n        this.cache.set(key, value);\r\n    }\r\n\r\n    get(key: K): V | undefined;\r\n    get(key: K, provider: () => V): V;\r\n    get(key: K, provider?: () => V): V | undefined {\r\n        this.throwIfDisposed();\r\n        if (this.cache.has(key)) {\r\n            return this.cache.get(key);\r\n        } else if (provider) {\r\n            const value = provider();\r\n            this.cache.set(key, value);\r\n            return value;\r\n        } else {\r\n            return undefined;\r\n        }\r\n    }\r\n\r\n    delete(key: K): boolean {\r\n        this.throwIfDisposed();\r\n        return this.cache.delete(key);\r\n    }\r\n\r\n    clear(): void {\r\n        this.throwIfDisposed();\r\n        this.cache.clear();\r\n    }\r\n}\r\n\r\nexport class ContextCache<Context, Key, Value, ContextKey = Context> extends DisposableCache {\r\n\r\n    private readonly cache = new Map<ContextKey | Context, Map<Key, Value>>();\r\n    private readonly converter: (input: Context) => ContextKey | Context;\r\n\r\n    constructor(converter?: (input: Context) => ContextKey) {\r\n        super();\r\n        this.converter = converter ?? (value => value);\r\n    }\r\n\r\n    has(contextKey: Context, key: Key): boolean {\r\n        this.throwIfDisposed();\r\n        return this.cacheForContext(contextKey).has(key);\r\n    }\r\n\r\n    set(contextKey: Context, key: Key, value: Value): void {\r\n        this.throwIfDisposed();\r\n        this.cacheForContext(contextKey).set(key, value);\r\n    }\r\n\r\n    get(contextKey: Context, key: Key): Value | undefined;\r\n    get(contextKey: Context, key: Key, provider: () => Value): Value;\r\n    get(contextKey: Context, key: Key, provider?: () => Value): Value | undefined {\r\n        this.throwIfDisposed();\r\n        const contextCache = this.cacheForContext(contextKey);\r\n        if (contextCache.has(key)) {\r\n            return contextCache.get(key);\r\n        } else if (provider) {\r\n            const value = provider();\r\n            contextCache.set(key, value);\r\n            return value;\r\n        } else {\r\n            return undefined;\r\n        }\r\n    }\r\n\r\n    delete(contextKey: Context, key: Key): boolean {\r\n        this.throwIfDisposed();\r\n        return this.cacheForContext(contextKey).delete(key);\r\n    }\r\n\r\n    clear(): void;\r\n    clear(contextKey: Context): void;\r\n    clear(contextKey?: Context): void {\r\n        this.throwIfDisposed();\r\n        if (contextKey) {\r\n            const mapKey = this.converter(contextKey);\r\n            this.cache.delete(mapKey);\r\n        } else {\r\n            this.cache.clear();\r\n        }\r\n    }\r\n\r\n    protected cacheForContext(contextKey: Context): Map<Key, Value> {\r\n        const mapKey = this.converter(contextKey);\r\n        let documentCache = this.cache.get(mapKey);\r\n        if (!documentCache) {\r\n            documentCache = new Map();\r\n            this.cache.set(mapKey, documentCache);\r\n        }\r\n        return documentCache;\r\n    }\r\n}\r\n\r\n/**\r\n * Every key/value pair in this cache is scoped to a document.\r\n * If this document is changed or deleted, all associated key/value pairs are deleted.\r\n */\r\nexport class DocumentCache<K, V> extends ContextCache<URI | string, K, V, string> {\r\n\r\n    /**\r\n     * Creates a new document cache.\r\n     *\r\n     * @param sharedServices Service container instance to hook into document lifecycle events.\r\n     * @param state Optional document state on which the cache should evict.\r\n     * If not provided, the cache will evict on `DocumentBuilder#onUpdate`.\r\n     * *Deleted* documents are considered in both cases.\r\n     *\r\n     * Providing a state here will use `DocumentBuilder#onDocumentPhase` instead,\r\n     * which triggers on all documents that have been affected by this change, assuming that the\r\n     * state is `DocumentState.Linked` or a later state.\r\n     */\r\n    constructor(sharedServices: LangiumSharedCoreServices, state?: DocumentState) {\r\n        super(uri => uri.toString());\r\n        if (state) {\r\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onDocumentPhase(state, document => {\r\n                this.clear(document.uri.toString());\r\n            }));\r\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate((_changed, deleted) => {\r\n                for (const uri of deleted) { // react only on deleted documents\r\n                    this.clear(uri);\r\n                }\r\n            }));\r\n        } else {\r\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate((changed, deleted) => {\r\n                const allUris = changed.concat(deleted); // react on both changed and deleted documents\r\n                for (const uri of allUris) {\r\n                    this.clear(uri);\r\n                }\r\n            }));\r\n        }\r\n    }\r\n}\r\n\r\n/**\r\n * Every key/value pair in this cache is scoped to the whole workspace.\r\n * If any document in the workspace is added, changed or deleted, the whole cache is evicted.\r\n */\r\nexport class WorkspaceCache<K, V> extends SimpleCache<K, V> {\r\n\r\n    /**\r\n     * Creates a new workspace cache.\r\n     *\r\n     * @param sharedServices Service container instance to hook into document lifecycle events.\r\n     * @param state Optional document state on which the cache should evict.\r\n     * If not provided, the cache will evict on `DocumentBuilder#onUpdate`.\r\n     * *Deleted* documents are considered in both cases.\r\n     */\r\n    constructor(sharedServices: LangiumSharedCoreServices, state?: DocumentState) {\r\n        super();\r\n        if (state) {\r\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onBuildPhase(state, () => {\r\n                this.clear();\r\n            }));\r\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate((_changed, deleted) => {\r\n                if (deleted.length > 0) { // react only on deleted documents\r\n                    this.clear();\r\n                }\r\n            }));\r\n        } else {\r\n            this.toDispose.push(sharedServices.workspace.DocumentBuilder.onUpdate(() => { // react on both changed and deleted documents\r\n                this.clear();\r\n            }));\r\n        }\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021-2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, AstNodeDescription, AstReflection, ReferenceInfo } from '../syntax-tree.js';\r\nimport type { Stream } from '../utils/stream.js';\r\nimport type { AstNodeDescriptionProvider } from '../workspace/ast-descriptions.js';\r\nimport type { IndexManager } from '../workspace/index-manager.js';\r\nimport type { NameProvider } from './name-provider.js';\r\nimport type { Scope, ScopeOptions} from './scope.js';\r\nimport { MapScope, StreamScope } from './scope.js';\r\nimport { getDocument } from '../utils/ast-utils.js';\r\nimport { stream } from '../utils/stream.js';\r\nimport { WorkspaceCache } from '../utils/caching.js';\r\n\r\n/**\r\n * Language-specific service for determining the scope of target elements visible in a specific cross-reference context.\r\n */\r\nexport interface ScopeProvider {\r\n\r\n    /**\r\n     * Return a scope describing what elements are visible for the given AST node and cross-reference\r\n     * identifier.\r\n     *\r\n     * @param context Information about the reference for which a scope is requested.\r\n     */\r\n    getScope(context: ReferenceInfo): Scope;\r\n\r\n}\r\n\r\nexport class DefaultScopeProvider implements ScopeProvider {\r\n\r\n    protected readonly reflection: AstReflection;\r\n    protected readonly nameProvider: NameProvider;\r\n    protected readonly descriptions: AstNodeDescriptionProvider;\r\n    protected readonly indexManager: IndexManager;\r\n\r\n    protected readonly globalScopeCache: WorkspaceCache<string, Scope>;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.reflection = services.shared.AstReflection;\r\n        this.nameProvider = services.references.NameProvider;\r\n        this.descriptions = services.workspace.AstNodeDescriptionProvider;\r\n        this.indexManager = services.shared.workspace.IndexManager;\r\n        this.globalScopeCache = new WorkspaceCache<string, Scope>(services.shared);\r\n    }\r\n\r\n    getScope(context: ReferenceInfo): Scope {\r\n        const scopes: Array<Stream<AstNodeDescription>> = [];\r\n        const referenceType = this.reflection.getReferenceType(context);\r\n\r\n        const precomputed = getDocument(context.container).precomputedScopes;\r\n        if (precomputed) {\r\n            let currentNode: AstNode | undefined = context.container;\r\n            do {\r\n                const allDescriptions = precomputed.get(currentNode);\r\n                if (allDescriptions.length > 0) {\r\n                    scopes.push(stream(allDescriptions).filter(\r\n                        desc => this.reflection.isSubtype(desc.type, referenceType)));\r\n                }\r\n                currentNode = currentNode.$container;\r\n            } while (currentNode);\r\n        }\r\n\r\n        let result: Scope = this.getGlobalScope(referenceType, context);\r\n        for (let i = scopes.length - 1; i >= 0; i--) {\r\n            result = this.createScope(scopes[i], result);\r\n        }\r\n        return result;\r\n    }\r\n\r\n    /**\r\n     * Create a scope for the given collection of AST node descriptions.\r\n     */\r\n    protected createScope(elements: Iterable<AstNodeDescription>, outerScope?: Scope, options?: ScopeOptions): Scope {\r\n        return new StreamScope(stream(elements), outerScope, options);\r\n    }\r\n\r\n    /**\r\n     * Create a scope for the given collection of AST nodes, which need to be transformed into respective\r\n     * descriptions first. This is done using the `NameProvider` and `AstNodeDescriptionProvider` services.\r\n     */\r\n    protected createScopeForNodes(elements: Iterable<AstNode>, outerScope?: Scope, options?: ScopeOptions): Scope {\r\n        const s = stream(elements).map(e => {\r\n            const name = this.nameProvider.getName(e);\r\n            if (name) {\r\n                return this.descriptions.createDescription(e, name);\r\n            }\r\n            return undefined;\r\n        }).nonNullable();\r\n        return new StreamScope(s, outerScope, options);\r\n    }\r\n\r\n    /**\r\n     * Create a global scope filtered for the given reference type.\r\n     */\r\n    protected getGlobalScope(referenceType: string, _context: ReferenceInfo): Scope {\r\n        return this.globalScopeCache.get(referenceType, () => new MapScope(this.indexManager.allElements(referenceType)));\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { URI } from 'vscode-uri';\r\nimport type { CommentProvider } from '../documentation/comment-provider.js';\r\nimport type { NameProvider } from '../references/name-provider.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, CstNode, GenericAstNode, Mutable, Reference } from '../syntax-tree.js';\r\nimport { isAstNode, isReference } from '../syntax-tree.js';\r\nimport { getDocument } from '../utils/ast-utils.js';\r\nimport { findNodesForProperty } from '../utils/grammar-utils.js';\r\nimport type { AstNodeLocator } from '../workspace/ast-node-locator.js';\r\nimport type { DocumentSegment, LangiumDocument, LangiumDocuments } from '../workspace/documents.js';\r\n\r\nexport interface JsonSerializeOptions {\r\n    /** The space parameter for `JSON.stringify`, controlling whether and how to pretty-print the output. */\r\n    space?: string | number;\r\n    /** Whether to include the `$refText` property for references (the name used to identify the target node). */\r\n    refText?: boolean;\r\n    /** Whether to include the `$sourceText` property, which holds the full source text from which an AST node was parsed. */\r\n    sourceText?: boolean;\r\n    /** Whether to include the `$textRegion` property, which holds information to trace AST node properties to their respective source text regions. */\r\n    textRegions?: boolean;\r\n    /** Whether to include the `$comment` property, which holds comments according to the CommentProvider service. */\r\n    comments?: boolean;\r\n    /** The replacer parameter for `JSON.stringify`; the default replacer given as parameter should be used to apply basic replacements. */\r\n    replacer?: (key: string, value: unknown, defaultReplacer: (key: string, value: unknown) => unknown) => unknown\r\n    /** Used to convert and serialize URIs when the target of a cross-reference is in a different document. */\r\n    uriConverter?: (uri: URI, reference: Reference) => string\r\n}\r\n\r\nexport interface JsonDeserializeOptions {\r\n    /** Used to parse and convert URIs when the target of a cross-reference is in a different document. */\r\n    uriConverter?: (uri: string) => URI\r\n}\r\n\r\n/**\r\n * {@link AstNode}s that may carry information on their definition area within the DSL text.\r\n */\r\nexport interface AstNodeWithTextRegion extends AstNode {\r\n    $sourceText?: string;\r\n    $textRegion?: AstNodeRegionWithAssignments;\r\n}\r\n\r\n/**\r\n * {@link AstNode}s that may carry a semantically relevant comment.\r\n */\r\nexport interface AstNodeWithComment extends AstNode {\r\n    $comment?: string;\r\n}\r\n\r\nexport function isAstNodeWithComment(node: AstNode): node is AstNodeWithComment {\r\n    return typeof (node as AstNodeWithComment).$comment === 'string';\r\n}\r\n\r\n/**\r\n * A {@link DocumentSegment} representing the definition area of an AstNode within the DSL text.\r\n * Usually contains text region information on all assigned property values of the AstNode,\r\n * and may contain the defining file's URI as string.\r\n */\r\nexport interface AstNodeRegionWithAssignments extends DocumentSegment {\r\n    /**\r\n     * A record containing an entry for each assigned property of the AstNode.\r\n     * The key is equal to the property name and the value is an array of the property values'\r\n     * text regions, regardless of whether the property is a single value or list property.\r\n     */\r\n    assignments?: Record<string, DocumentSegment[]>;\r\n    /**\r\n     * The AstNode defining file's URI as string\r\n     */\r\n    documentURI?: string;\r\n}\r\n\r\n/**\r\n * Utility service for transforming an `AstNode` into a JSON string and vice versa.\r\n */\r\nexport interface JsonSerializer {\r\n    /**\r\n     * Serialize an `AstNode` into a JSON `string`.\r\n     * @param node The `AstNode` to be serialized.\r\n     * @param options Serialization options\r\n     */\r\n    serialize(node: AstNode, options?: JsonSerializeOptions): string;\r\n    /**\r\n     * Deserialize (parse) a JSON `string` into an `AstNode`.\r\n     */\r\n    deserialize<T extends AstNode = AstNode>(content: string, options?: JsonDeserializeOptions): T;\r\n}\r\n\r\n/**\r\n * A cross-reference in the serialized JSON representation of an AstNode.\r\n */\r\ninterface IntermediateReference {\r\n    /** URI pointing to the target element. This is either `#${path}` if the target is in the same document, or `${documentURI}#${path}` otherwise. */\r\n    $ref?: string\r\n    /** The actual text used to look up the reference target in the surrounding scope. */\r\n    $refText?: string\r\n    /** If any problem occurred while resolving the reference, it is described by this property. */\r\n    $error?: string\r\n}\r\n\r\nfunction isIntermediateReference(obj: unknown): obj is IntermediateReference {\r\n    return typeof obj === 'object' && !!obj && ('$ref' in obj || '$error' in obj);\r\n}\r\n\r\nexport class DefaultJsonSerializer implements JsonSerializer {\r\n\r\n    /** The set of AstNode properties to be ignored by the serializer. */\r\n    ignoreProperties = new Set(['$container', '$containerProperty', '$containerIndex', '$document', '$cstNode']);\r\n\r\n    /** The document that is currently processed by the serializer; this is used by the replacer function.  */\r\n    protected currentDocument: LangiumDocument | undefined;\r\n\r\n    protected readonly langiumDocuments: LangiumDocuments;\r\n    protected readonly astNodeLocator: AstNodeLocator;\r\n    protected readonly nameProvider: NameProvider;\r\n    protected readonly commentProvider: CommentProvider;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.langiumDocuments = services.shared.workspace.LangiumDocuments;\r\n        this.astNodeLocator = services.workspace.AstNodeLocator;\r\n        this.nameProvider = services.references.NameProvider;\r\n        this.commentProvider = services.documentation.CommentProvider;\r\n    }\r\n\r\n    serialize(node: AstNode, options?: JsonSerializeOptions): string {\r\n        const serializeOptions = options ?? {};\r\n        const specificReplacer = options?.replacer;\r\n        const defaultReplacer = (key: string, value: unknown) => this.replacer(key, value, serializeOptions);\r\n        const replacer = specificReplacer ? (key: string, value: unknown) => specificReplacer(key, value, defaultReplacer) : defaultReplacer;\r\n\r\n        try {\r\n            this.currentDocument = getDocument(node);\r\n            return JSON.stringify(node, replacer, options?.space);\r\n        } finally {\r\n            this.currentDocument = undefined;\r\n        }\r\n    }\r\n\r\n    deserialize<T extends AstNode = AstNode>(content: string, options?: JsonDeserializeOptions): T {\r\n        const deserializeOptions = options ?? {};\r\n        const root = JSON.parse(content);\r\n        this.linkNode(root, root, deserializeOptions);\r\n        return root;\r\n    }\r\n\r\n    protected replacer(key: string, value: unknown, { refText, sourceText, textRegions, comments, uriConverter }: JsonSerializeOptions): unknown {\r\n        if (this.ignoreProperties.has(key)) {\r\n            return undefined;\r\n        } else if (isReference(value)) {\r\n            const refValue = value.ref;\r\n            const $refText = refText ? value.$refText : undefined;\r\n            if (refValue) {\r\n                const targetDocument = getDocument(refValue);\r\n                let targetUri = '';\r\n                if (this.currentDocument && this.currentDocument !== targetDocument) {\r\n                    if (uriConverter) {\r\n                        targetUri = uriConverter(targetDocument.uri, value);\r\n                    } else {\r\n                        targetUri = targetDocument.uri.toString();\r\n                    }\r\n                }\r\n                const targetPath = this.astNodeLocator.getAstNodePath(refValue);\r\n                return {\r\n                    $ref: `${targetUri}#${targetPath}`,\r\n                    $refText\r\n                } satisfies IntermediateReference;\r\n            } else {\r\n                return {\r\n                    $error: value.error?.message ?? 'Could not resolve reference',\r\n                    $refText\r\n                } satisfies IntermediateReference;\r\n            }\r\n        } else if (isAstNode(value)) {\r\n            let astNode: AstNodeWithTextRegion | undefined = undefined;\r\n            if (textRegions) {\r\n                astNode = this.addAstNodeRegionWithAssignmentsTo({ ...value });\r\n                if ((!key || value.$document) && astNode?.$textRegion) {\r\n                    // The document URI is added to the root node of the resulting JSON tree\r\n                    astNode.$textRegion.documentURI = this.currentDocument?.uri.toString();\r\n                }\r\n            }\r\n            if (sourceText && !key) {\r\n                astNode ??= { ...value };\r\n                astNode.$sourceText = value.$cstNode?.text;\r\n            }\r\n            if (comments) {\r\n                astNode ??= { ...value };\r\n                const comment = this.commentProvider.getComment(value);\r\n                if (comment) {\r\n                    (astNode as AstNodeWithComment).$comment = comment.replace(/\\r/g, '');\r\n                }\r\n            }\r\n            return astNode ?? value;\r\n        } else {\r\n            return value;\r\n        }\r\n    }\r\n\r\n    protected addAstNodeRegionWithAssignmentsTo(node: AstNodeWithTextRegion) {\r\n        const createDocumentSegment: (cstNode: CstNode) => AstNodeRegionWithAssignments = cstNode => <DocumentSegment>{\r\n            offset: cstNode.offset,\r\n            end: cstNode.end,\r\n            length: cstNode.length,\r\n            range: cstNode.range,\r\n        };\r\n\r\n        if (node.$cstNode) {\r\n            const textRegion = node.$textRegion = createDocumentSegment(node.$cstNode);\r\n            const assignments: Record<string, DocumentSegment[]> = textRegion.assignments = {};\r\n\r\n            Object.keys(node).filter(key => !key.startsWith('$')).forEach(key => {\r\n                const propertyAssignments = findNodesForProperty(node.$cstNode, key).map(createDocumentSegment);\r\n                if (propertyAssignments.length !== 0) {\r\n                    assignments[key] = propertyAssignments;\r\n                }\r\n            });\r\n\r\n            return node;\r\n        }\r\n        return undefined;\r\n    }\r\n\r\n    protected linkNode(node: GenericAstNode, root: AstNode, options: JsonDeserializeOptions, container?: AstNode, containerProperty?: string, containerIndex?: number) {\r\n        for (const [propertyName, item] of Object.entries(node)) {\r\n            if (Array.isArray(item)) {\r\n                for (let index = 0; index < item.length; index++) {\r\n                    const element = item[index];\r\n                    if (isIntermediateReference(element)) {\r\n                        item[index] = this.reviveReference(node, propertyName, root, element, options);\r\n                    } else if (isAstNode(element)) {\r\n                        this.linkNode(element as GenericAstNode, root, options, node, propertyName, index);\r\n                    }\r\n                }\r\n            } else if (isIntermediateReference(item)) {\r\n                node[propertyName] = this.reviveReference(node, propertyName, root, item, options);\r\n            } else if (isAstNode(item)) {\r\n                this.linkNode(item as GenericAstNode, root, options, node, propertyName);\r\n            }\r\n        }\r\n        const mutable = node as Mutable<AstNode>;\r\n        mutable.$container = container;\r\n        mutable.$containerProperty = containerProperty;\r\n        mutable.$containerIndex = containerIndex;\r\n    }\r\n\r\n    protected reviveReference(container: AstNode, property: string, root: AstNode, reference: IntermediateReference, options: JsonDeserializeOptions): Reference | undefined {\r\n        let refText = reference.$refText;\r\n        let error = reference.$error;\r\n        if (reference.$ref) {\r\n            const ref = this.getRefNode(root, reference.$ref, options.uriConverter);\r\n            if (isAstNode(ref)) {\r\n                if (!refText) {\r\n                    refText = this.nameProvider.getName(ref);\r\n                }\r\n                return {\r\n                    $refText: refText ?? '',\r\n                    ref\r\n                };\r\n            } else {\r\n                error = ref;\r\n            }\r\n        }\r\n        if (error) {\r\n            const ref: Mutable<Reference> = {\r\n                $refText: refText ?? ''\r\n            };\r\n            ref.error = {\r\n                container,\r\n                property,\r\n                message: error,\r\n                reference: ref\r\n            };\r\n            return ref;\r\n        } else {\r\n            return undefined;\r\n        }\r\n    }\r\n\r\n    protected getRefNode(root: AstNode, uri: string, uriConverter?: (uri: string) => URI): AstNode | string {\r\n        try {\r\n            const fragmentIndex = uri.indexOf('#');\r\n            if (fragmentIndex === 0) {\r\n                const node = this.astNodeLocator.getAstNode(root, uri.substring(1));\r\n                if (!node) {\r\n                    return 'Could not resolve path: ' + uri;\r\n                }\r\n                return node;\r\n            }\r\n            if (fragmentIndex < 0) {\r\n                const documentUri = uriConverter ? uriConverter(uri) : URI.parse(uri);\r\n                const document = this.langiumDocuments.getDocument(documentUri);\r\n                if (!document) {\r\n                    return 'Could not find document for URI: ' + uri;\r\n                }\r\n                return document.parseResult.value;\r\n            }\r\n            const documentUri = uriConverter ? uriConverter(uri.substring(0, fragmentIndex)) : URI.parse(uri.substring(0, fragmentIndex));\r\n            const document = this.langiumDocuments.getDocument(documentUri);\r\n            if (!document) {\r\n                return 'Could not find document for URI: ' + uri;\r\n            }\r\n            if (fragmentIndex === uri.length - 1) {\r\n                return document.parseResult.value;\r\n            }\r\n            const node = this.astNodeLocator.getAstNode(document.parseResult.value, uri.substring(fragmentIndex + 1));\r\n            if (!node) {\r\n                return 'Could not resolve URI: ' + uri;\r\n            }\r\n            return node;\r\n        } catch (err) {\r\n            return String(err);\r\n        }\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices, LangiumSharedCoreServices } from './services.js';\r\nimport type { TextDocumentProvider } from './workspace/documents.js';\r\nimport { UriUtils, type URI } from './utils/uri-utils.js';\r\n\r\n/**\r\n * The service registry provides access to the language-specific {@link LangiumCoreServices} optionally including LSP-related services.\r\n * These are resolved via the URI of a text document.\r\n */\r\nexport interface ServiceRegistry {\r\n\r\n    /**\r\n     * Register a language via its injected services.\r\n     */\r\n    register(language: LangiumCoreServices): void;\r\n\r\n    /**\r\n     * Retrieve the language-specific services for the given URI. In case only one language is\r\n     * registered, it may be used regardless of the URI format.\r\n     */\r\n    getServices(uri: URI): LangiumCoreServices;\r\n\r\n    /**\r\n     * Check whether services are available for the given URI.\r\n     */\r\n    hasServices(uri: URI): boolean;\r\n\r\n    /**\r\n     * The full set of registered language services.\r\n     */\r\n    readonly all: readonly LangiumCoreServices[];\r\n}\r\n\r\n/**\r\n * Generic registry for Langium services, but capable of being used with extending service sets as well (such as the lsp-complete LangiumCoreServices set)\r\n */\r\nexport class DefaultServiceRegistry implements ServiceRegistry {\r\n\r\n    protected singleton?: LangiumCoreServices;\r\n    protected readonly languageIdMap = new Map<string, LangiumCoreServices>();\r\n    protected readonly fileExtensionMap = new Map<string, LangiumCoreServices>();\r\n\r\n    /**\r\n     * @deprecated Use the new `fileExtensionMap` (or `languageIdMap`) property instead.\r\n     */\r\n    protected get map(): Map<string, LangiumCoreServices> | undefined {\r\n        return this.fileExtensionMap;\r\n    }\r\n\r\n    protected readonly textDocuments?: TextDocumentProvider;\r\n\r\n    constructor(services?: LangiumSharedCoreServices) {\r\n        this.textDocuments = services?.workspace.TextDocuments;\r\n    }\r\n\r\n    register(language: LangiumCoreServices): void {\r\n        const data = language.LanguageMetaData;\r\n        for (const ext of data.fileExtensions) {\r\n            if (this.fileExtensionMap.has(ext)) {\r\n                console.warn(`The file extension ${ext} is used by multiple languages. It is now assigned to '${data.languageId}'.`);\r\n            }\r\n            this.fileExtensionMap.set(ext, language);\r\n        }\r\n        this.languageIdMap.set(data.languageId, language);\r\n        if (this.languageIdMap.size === 1) {\r\n            this.singleton = language;\r\n        } else {\r\n            this.singleton = undefined;\r\n        }\r\n    }\r\n\r\n    getServices(uri: URI): LangiumCoreServices {\r\n        if (this.singleton !== undefined) {\r\n            return this.singleton;\r\n        }\r\n        if (this.languageIdMap.size === 0) {\r\n            throw new Error('The service registry is empty. Use `register` to register the services of a language.');\r\n        }\r\n        const languageId = this.textDocuments?.get(uri)?.languageId;\r\n        if (languageId !== undefined) {\r\n            const services = this.languageIdMap.get(languageId);\r\n            if (services) {\r\n                return services;\r\n            }\r\n        }\r\n        const ext = UriUtils.extname(uri);\r\n        const services = this.fileExtensionMap.get(ext);\r\n        if (!services) {\r\n            if (languageId) {\r\n                throw new Error(`The service registry contains no services for the extension '${ext}' for language '${languageId}'.`);\r\n            } else {\r\n                throw new Error(`The service registry contains no services for the extension '${ext}'.`);\r\n            }\r\n        }\r\n        return services;\r\n    }\r\n\r\n    hasServices(uri: URI): boolean {\r\n        try {\r\n            this.getServices(uri);\r\n            return true;\r\n        } catch {\r\n            return false;\r\n        }\r\n    }\r\n\r\n    get all(): readonly LangiumCoreServices[] {\r\n        return Array.from(this.languageIdMap.values());\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { CodeDescription, DiagnosticRelatedInformation, DiagnosticTag, integer, Range } from 'vscode-languageserver-types';\r\nimport { assertUnreachable } from '../index.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, AstReflection, Properties } from '../syntax-tree.js';\r\nimport type { CancellationToken } from '../utils/cancellation.js';\r\nimport { MultiMap } from '../utils/collections.js';\r\nimport type { MaybePromise } from '../utils/promise-utils.js';\r\nimport { isOperationCancelled } from '../utils/promise-utils.js';\r\nimport type { Stream } from '../utils/stream.js';\r\nimport { stream } from '../utils/stream.js';\r\nimport type { DocumentSegment } from '../workspace/documents.js';\r\n\r\nexport type DiagnosticInfo<N extends AstNode, P extends string = Properties<N>> = {\r\n    /** The AST node to which the diagnostic is attached. */\r\n    node: N;\r\n    /** If a property name is given, the diagnostic is restricted to the corresponding text region. */\r\n    property?: P;\r\n    /** If the value of a keyword is given, the diagnostic will appear at its corresponding text region */\r\n    keyword?: string;\r\n    /** In case of a multi-value property (array), an index can be given to select a specific element. */\r\n    index?: number;\r\n    /** If you want to create a diagnostic independent to any property, use the range property. */\r\n    range?: Range;\r\n    /** The diagnostic's code, which usually appear in the user interface. */\r\n    code?: integer | string;\r\n    /** An optional property to describe the error code. */\r\n    codeDescription?: CodeDescription;\r\n    /** Additional metadata about the diagnostic. */\r\n    tags?: DiagnosticTag[];\r\n    /** An array of related diagnostic information, e.g. when symbol-names within a scope collide all definitions can be marked via this property. */\r\n    relatedInformation?: DiagnosticRelatedInformation[];\r\n    /** A data entry field that is preserved between a `textDocument/publishDiagnostics` notification and `textDocument/codeAction` request. */\r\n    data?: unknown;\r\n}\r\n\r\n/**\r\n * Shape of information commonly used in the `data` field of diagnostics.\r\n */\r\nexport interface DiagnosticData {\r\n    /** Diagnostic code for identifying which code action to apply. This code is _not_ shown in the user interface. */\r\n    code: string\r\n    /** Specifies where to apply the code action in the form of a `DocumentSegment`. */\r\n    actionSegment?: DocumentSegment\r\n    /** Specifies where to apply the code action in the form of a `Range`. */\r\n    actionRange?: Range\r\n}\r\n\r\n/**\r\n * Create DiagnosticData for a given diagnostic code. The result can be put into the `data` field of a DiagnosticInfo.\r\n */\r\nexport function diagnosticData(code: string): DiagnosticData {\r\n    return { code };\r\n}\r\n\r\nexport type ValidationSeverity = 'error' | 'warning' | 'info' | 'hint';\r\n\r\nexport type ValidationAcceptor = <N extends AstNode>(severity: ValidationSeverity, message: string, info: DiagnosticInfo<N>) => void\r\n\r\nexport type ValidationCheck<T extends AstNode = AstNode> = (node: T, accept: ValidationAcceptor, cancelToken: CancellationToken) => MaybePromise<void>;\r\n\r\n/**\r\n * A utility type for describing functions which will be called once before or after all the AstNodes of an AST/Langium document are validated.\r\n *\r\n * The AST is represented by its root AstNode.\r\n *\r\n * The given validation acceptor helps to report some early or lately detected issues.\r\n *\r\n * The 'categories' indicate, which validation categories are executed for all the AstNodes.\r\n * This helps to tailor the preparations/tear-down logic to the actually executed checks on the nodes.\r\n *\r\n * It is recommended to support interrupts during long-running logic with 'interruptAndCheck(cancelToken)'.\r\n */\r\nexport type ValidationPreparation = (rootNode: AstNode, accept: ValidationAcceptor, categories: ValidationCategory[], cancelToken: CancellationToken) => MaybePromise<void>;\r\n\r\n/**\r\n * A utility type for associating non-primitive AST types to corresponding validation checks. For example:\r\n *\r\n * ```ts\r\n *   const checks: ValidationChecks<StatemachineAstType> = {\r\n *       State: validator.checkStateNameStartsWithCapital\r\n *    };\r\n * ```\r\n *\r\n * If an AST type does not extend AstNode, e.g. if it describes a union of string literals, that type's name must not occur as a key in objects of type `ValidationCheck<...>`.\r\n *\r\n * @param T a type definition mapping language specific type names (keys) to the corresponding types (values)\r\n */\r\nexport type ValidationChecks<T> = {\r\n    [K in keyof T]?: T[K] extends AstNode ? ValidationCheck<T[K]> | Array<ValidationCheck<T[K]>> : never\r\n} & {\r\n    AstNode?: ValidationCheck<AstNode> | Array<ValidationCheck<AstNode>>;\r\n}\r\n\r\n/**\r\n * `fast` checks can be executed after every document change (i.e. as the user is typing). If a check\r\n * is too slow it can delay the response to document changes, yielding bad user experience. By marking\r\n * it as `slow`, it will be skipped for normal as-you-type validation. Then it's up to you when to\r\n * schedule these long-running checks: after the fast checks are done, or after saving a document,\r\n * or with an explicit command, etc.\r\n *\r\n * `built-in` checks are errors produced by the lexer, the parser, or the linker. They cannot be used\r\n * for custom validation checks.\r\n */\r\nexport type ValidationCategory = 'fast' | 'slow' | 'built-in'\r\n\r\nexport namespace ValidationCategory {\r\n    export const all: readonly ValidationCategory[] = ['fast', 'slow', 'built-in'];\r\n}\r\n\r\ntype ValidationCheckEntry = {\r\n    check: ValidationCheck\r\n    category: ValidationCategory\r\n}\r\n\r\n/**\r\n * Manages a set of `ValidationCheck`s to be applied when documents are validated.\r\n */\r\nexport class ValidationRegistry {\r\n    private readonly entries = new MultiMap<string, ValidationCheckEntry>();\r\n    private readonly reflection: AstReflection;\r\n\r\n    private entriesBefore: ValidationPreparation[] = [];\r\n    private entriesAfter: ValidationPreparation[] = [];\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.reflection = services.shared.AstReflection;\r\n    }\r\n\r\n    /**\r\n     * Register a set of validation checks. Each value in the record can be either a single validation check (i.e. a function)\r\n     * or an array of validation checks.\r\n     *\r\n     * @param checksRecord Set of validation checks to register.\r\n     * @param category Optional category for the validation checks (defaults to `'fast'`).\r\n     * @param thisObj Optional object to be used as `this` when calling the validation check functions.\r\n     */\r\n    register<T>(checksRecord: ValidationChecks<T>, thisObj: ThisParameterType<unknown> = this, category: ValidationCategory = 'fast'): void {\r\n        if (category === 'built-in') {\r\n            throw new Error(\"The 'built-in' category is reserved for lexer, parser, and linker errors.\");\r\n        }\r\n        for (const [type, ch] of Object.entries(checksRecord)) {\r\n            const callbacks = ch as ValidationCheck | ValidationCheck[];\r\n            if (Array.isArray(callbacks)) {\r\n                for (const check of callbacks) {\r\n                    const entry: ValidationCheckEntry = {\r\n                        check: this.wrapValidationException(check, thisObj),\r\n                        category\r\n                    };\r\n                    this.addEntry(type, entry);\r\n                }\r\n            } else if (typeof callbacks === 'function') {\r\n                const entry: ValidationCheckEntry = {\r\n                    check: this.wrapValidationException(callbacks, thisObj),\r\n                    category\r\n                };\r\n                this.addEntry(type, entry);\r\n            } else {\r\n                assertUnreachable(callbacks);\r\n            }\r\n        }\r\n    }\r\n\r\n    protected wrapValidationException(check: ValidationCheck, thisObj: unknown): ValidationCheck {\r\n        return async (node, accept, cancelToken) => {\r\n            await this.handleException(() => check.call(thisObj, node, accept, cancelToken), 'An error occurred during validation', accept, node);\r\n        };\r\n    }\r\n\r\n    protected async handleException(functionality: () => MaybePromise<void>, messageContext: string, accept: ValidationAcceptor, node: AstNode): Promise<void> {\r\n        try {\r\n            await functionality();\r\n        } catch (err) {\r\n            if (isOperationCancelled(err)) {\r\n                throw err;\r\n            }\r\n            console.error(`${messageContext}:`, err);\r\n            if (err instanceof Error && err.stack) {\r\n                console.error(err.stack);\r\n            }\r\n            const messageDetails = err instanceof Error ? err.message : String(err);\r\n            accept('error', `${messageContext}: ${messageDetails}`, { node });\r\n        }\r\n    }\r\n\r\n    protected addEntry(type: string, entry: ValidationCheckEntry): void {\r\n        if (type === 'AstNode') {\r\n            this.entries.add('AstNode', entry);\r\n            return;\r\n        }\r\n        for (const subtype of this.reflection.getAllSubTypes(type)) {\r\n            this.entries.add(subtype, entry);\r\n        }\r\n    }\r\n\r\n    getChecks(type: string, categories?: ValidationCategory[]): Stream<ValidationCheck> {\r\n        let checks = stream(this.entries.get(type))\r\n            .concat(this.entries.get('AstNode'));\r\n        if (categories) {\r\n            checks = checks.filter(entry => categories.includes(entry.category));\r\n        }\r\n        return checks.map(entry => entry.check);\r\n    }\r\n\r\n    /**\r\n     * Register logic which will be executed once before validating all the nodes of an AST/Langium document.\r\n     * This helps to prepare or initialize some information which are required or reusable for the following checks on the AstNodes.\r\n     *\r\n     * As an example, for validating unique fully-qualified names of nodes in the AST,\r\n     * here the map for mapping names to nodes could be established.\r\n     * During the usual checks on the nodes, they are put into this map with their name.\r\n     *\r\n     * Note that this approach makes validations stateful, which is relevant e.g. when cancelling the validation.\r\n     * Therefore it is recommended to clear stored information\r\n     * _before_ validating an AST to validate each AST unaffected from other ASTs\r\n     * AND _after_ validating the AST to free memory by information which are no longer used.\r\n     *\r\n     * @param checkBefore a set-up function which will be called once before actually validating an AST\r\n     * @param thisObj Optional object to be used as `this` when calling the validation check functions.\r\n     */\r\n    registerBeforeDocument(checkBefore: ValidationPreparation, thisObj: ThisParameterType<unknown> = this): void {\r\n        this.entriesBefore.push(this.wrapPreparationException(checkBefore, 'An error occurred during set-up of the validation', thisObj));\r\n    }\r\n\r\n    /**\r\n     * Register logic which will be executed once after validating all the nodes of an AST/Langium document.\r\n     * This helps to finally evaluate information which are collected during the checks on the AstNodes.\r\n     *\r\n     * As an example, for validating unique fully-qualified names of nodes in the AST,\r\n     * here the map with all the collected nodes and their names is checked\r\n     * and validation hints are created for all nodes with the same name.\r\n     *\r\n     * Note that this approach makes validations stateful, which is relevant e.g. when cancelling the validation.\r\n     * Therefore it is recommended to clear stored information\r\n     * _before_ validating an AST to validate each AST unaffected from other ASTs\r\n     * AND _after_ validating the AST to free memory by information which are no longer used.\r\n     *\r\n     * @param checkBefore a set-up function which will be called once before actually validating an AST\r\n     * @param thisObj Optional object to be used as `this` when calling the validation check functions.\r\n     */\r\n    registerAfterDocument(checkAfter: ValidationPreparation, thisObj: ThisParameterType<unknown> = this): void {\r\n        this.entriesAfter.push(this.wrapPreparationException(checkAfter, 'An error occurred during tear-down of the validation', thisObj));\r\n    }\r\n\r\n    protected wrapPreparationException(check: ValidationPreparation, messageContext: string, thisObj: unknown): ValidationPreparation {\r\n        return async (rootNode, accept, categories, cancelToken) => {\r\n            await this.handleException(() => check.call(thisObj, rootNode, accept, categories, cancelToken), messageContext, accept, rootNode);\r\n        };\r\n    }\r\n\r\n    get checksBefore(): ValidationPreparation[] {\r\n        return this.entriesBefore;\r\n    }\r\n\r\n    get checksAfter(): ValidationPreparation[] {\r\n        return this.entriesAfter;\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { MismatchedTokenException } from 'chevrotain';\r\nimport type { DiagnosticSeverity, Position, Range, Diagnostic } from 'vscode-languageserver-types';\r\nimport type { LanguageMetaData } from '../languages/language-meta-data.js';\r\nimport type { ParseResult } from '../parser/langium-parser.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, CstNode } from '../syntax-tree.js';\r\nimport type { LangiumDocument } from '../workspace/documents.js';\r\nimport type { DiagnosticData, DiagnosticInfo, ValidationAcceptor, ValidationCategory, ValidationRegistry, ValidationSeverity } from './validation-registry.js';\r\nimport { CancellationToken } from '../utils/cancellation.js';\r\nimport { findNodeForKeyword, findNodeForProperty } from '../utils/grammar-utils.js';\r\nimport { streamAst } from '../utils/ast-utils.js';\r\nimport { tokenToRange } from '../utils/cst-utils.js';\r\nimport { interruptAndCheck, isOperationCancelled } from '../utils/promise-utils.js';\r\nimport { diagnosticData } from './validation-registry.js';\r\nimport type { LexingDiagnostic, LexingDiagnosticSeverity } from '../parser/token-builder.js';\r\n\r\nexport interface ValidationOptions {\r\n    /**\r\n     * If this is set, only the checks associated with these categories are executed; otherwise\r\n     * all checks are executed. The default category if not specified to the registry is `'fast'`.\r\n     */\r\n    categories?: ValidationCategory[];\r\n    /** If true, no further diagnostics are reported if there are lexing errors. */\r\n    stopAfterLexingErrors?: boolean\r\n    /** If true, no further diagnostics are reported if there are parsing errors. */\r\n    stopAfterParsingErrors?: boolean\r\n    /** If true, no further diagnostics are reported if there are linking errors. */\r\n    stopAfterLinkingErrors?: boolean\r\n}\r\n\r\n/**\r\n * Language-specific service for validating `LangiumDocument`s.\r\n */\r\nexport interface DocumentValidator {\r\n    /**\r\n     * Validates the whole specified document.\r\n     *\r\n     * @param document specified document to validate\r\n     * @param options options to control the validation process\r\n     * @param cancelToken allows to cancel the current operation\r\n     * @throws `OperationCanceled` if a user action occurs during execution\r\n     */\r\n    validateDocument(document: LangiumDocument, options?: ValidationOptions, cancelToken?: CancellationToken): Promise<Diagnostic[]>;\r\n}\r\n\r\nexport class DefaultDocumentValidator implements DocumentValidator {\r\n\r\n    protected readonly validationRegistry: ValidationRegistry;\r\n    protected readonly metadata: LanguageMetaData;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.validationRegistry = services.validation.ValidationRegistry;\r\n        this.metadata = services.LanguageMetaData;\r\n    }\r\n\r\n    async validateDocument(document: LangiumDocument, options: ValidationOptions = {}, cancelToken = CancellationToken.None): Promise<Diagnostic[]> {\r\n        const parseResult = document.parseResult;\r\n        const diagnostics: Diagnostic[] = [];\r\n\r\n        await interruptAndCheck(cancelToken);\r\n\r\n        if (!options.categories || options.categories.includes('built-in')) {\r\n            this.processLexingErrors(parseResult, diagnostics, options);\r\n            if (options.stopAfterLexingErrors && diagnostics.some(d => d.data?.code === DocumentValidator.LexingError)) {\r\n                return diagnostics;\r\n            }\r\n\r\n            this.processParsingErrors(parseResult, diagnostics, options);\r\n            if (options.stopAfterParsingErrors && diagnostics.some(d => d.data?.code === DocumentValidator.ParsingError)) {\r\n                return diagnostics;\r\n            }\r\n\r\n            this.processLinkingErrors(document, diagnostics, options);\r\n            if (options.stopAfterLinkingErrors && diagnostics.some(d => d.data?.code === DocumentValidator.LinkingError)) {\r\n                return diagnostics;\r\n            }\r\n        }\r\n\r\n        // Process custom validations\r\n        try {\r\n            diagnostics.push(...await this.validateAst(parseResult.value, options, cancelToken));\r\n        } catch (err) {\r\n            if (isOperationCancelled(err)) {\r\n                throw err;\r\n            }\r\n            console.error('An error occurred during validation:', err);\r\n        }\r\n\r\n        await interruptAndCheck(cancelToken);\r\n\r\n        return diagnostics;\r\n    }\r\n\r\n    protected processLexingErrors(parseResult: ParseResult, diagnostics: Diagnostic[], _options: ValidationOptions): void {\r\n        const lexerDiagnostics = [...parseResult.lexerErrors, ...parseResult.lexerReport?.diagnostics ?? []] as LexingDiagnostic[];\r\n        for (const lexerDiagnostic of lexerDiagnostics) {\r\n            const severity = lexerDiagnostic.severity ?? 'error';\r\n            const diagnostic: Diagnostic = {\r\n                severity: toDiagnosticSeverity(severity),\r\n                range: {\r\n                    start: {\r\n                        line: lexerDiagnostic.line! - 1,\r\n                        character: lexerDiagnostic.column! - 1\r\n                    },\r\n                    end: {\r\n                        line: lexerDiagnostic.line! - 1,\r\n                        character: lexerDiagnostic.column! + lexerDiagnostic.length - 1\r\n                    }\r\n                },\r\n                message: lexerDiagnostic.message,\r\n                data: toDiagnosticData(severity),\r\n                source: this.getSource()\r\n            };\r\n            diagnostics.push(diagnostic);\r\n        }\r\n    }\r\n\r\n    protected processParsingErrors(parseResult: ParseResult, diagnostics: Diagnostic[], _options: ValidationOptions): void {\r\n        for (const parserError of parseResult.parserErrors) {\r\n            let range: Range | undefined = undefined;\r\n            // We can run into the chevrotain error recovery here\r\n            // The token contained in the parser error might be automatically inserted\r\n            // In this case every position value will be `NaN`\r\n            if (isNaN(parserError.token.startOffset)) {\r\n                // Some special parser error types contain a `previousToken`\r\n                // We can simply append our diagnostic to that token\r\n                if ('previousToken' in parserError) {\r\n                    const token = (parserError as MismatchedTokenException).previousToken;\r\n                    if (!isNaN(token.startOffset)) {\r\n                        const position: Position = { line: token.endLine! - 1, character: token.endColumn! };\r\n                        range = { start: position, end: position};\r\n                    } else {\r\n                        // No valid prev token. Might be empty document or containing only hidden tokens.\r\n                        // Point to document start\r\n                        const position: Position = { line: 0, character: 0 };\r\n                        range = { start: position, end: position};\r\n                    }\r\n                }\r\n            } else {\r\n                range = tokenToRange(parserError.token);\r\n            }\r\n            if (range) {\r\n                const diagnostic: Diagnostic = {\r\n                    severity: toDiagnosticSeverity('error'),\r\n                    range,\r\n                    message: parserError.message,\r\n                    data: diagnosticData(DocumentValidator.ParsingError),\r\n                    source: this.getSource()\r\n                };\r\n                diagnostics.push(diagnostic);\r\n            }\r\n        }\r\n    }\r\n\r\n    protected processLinkingErrors(document: LangiumDocument, diagnostics: Diagnostic[], _options: ValidationOptions): void {\r\n        for (const reference of document.references) {\r\n            const linkingError = reference.error;\r\n            if (linkingError) {\r\n                const info: DiagnosticInfo<AstNode, string> = {\r\n                    node: linkingError.container,\r\n                    property: linkingError.property,\r\n                    index: linkingError.index,\r\n                    data: {\r\n                        code: DocumentValidator.LinkingError,\r\n                        containerType: linkingError.container.$type,\r\n                        property: linkingError.property,\r\n                        refText: linkingError.reference.$refText\r\n                    } satisfies LinkingErrorData\r\n                };\r\n                diagnostics.push(this.toDiagnostic('error', linkingError.message, info));\r\n            }\r\n        }\r\n    }\r\n\r\n    protected async validateAst(rootNode: AstNode, options: ValidationOptions, cancelToken = CancellationToken.None): Promise<Diagnostic[]> {\r\n        const validationItems: Diagnostic[] = [];\r\n        const acceptor: ValidationAcceptor = <N extends AstNode>(severity: ValidationSeverity, message: string, info: DiagnosticInfo<N>) => {\r\n            validationItems.push(this.toDiagnostic(severity, message, info));\r\n        };\r\n\r\n        await this.validateAstBefore(rootNode, options, acceptor, cancelToken);\r\n        await this.validateAstNodes(rootNode, options, acceptor, cancelToken);\r\n        await this.validateAstAfter(rootNode, options, acceptor, cancelToken);\r\n\r\n        return validationItems;\r\n    }\r\n\r\n    protected async validateAstBefore(rootNode: AstNode, options: ValidationOptions, acceptor: ValidationAcceptor, cancelToken = CancellationToken.None): Promise<void> {\r\n        const checksBefore = this.validationRegistry.checksBefore;\r\n        for (const checkBefore of checksBefore) {\r\n            await interruptAndCheck(cancelToken);\r\n            await checkBefore(rootNode, acceptor, options.categories ?? [], cancelToken);\r\n        }\r\n    }\r\n\r\n    protected async validateAstNodes(rootNode: AstNode, options: ValidationOptions, acceptor: ValidationAcceptor, cancelToken = CancellationToken.None): Promise<void> {\r\n        await Promise.all(streamAst(rootNode).map(async node => {\r\n            await interruptAndCheck(cancelToken);\r\n            const checks = this.validationRegistry.getChecks(node.$type, options.categories);\r\n            for (const check of checks) {\r\n                await check(node, acceptor, cancelToken);\r\n            }\r\n        }));\r\n    }\r\n\r\n    protected async validateAstAfter(rootNode: AstNode, options: ValidationOptions, acceptor: ValidationAcceptor, cancelToken = CancellationToken.None): Promise<void> {\r\n        const checksAfter = this.validationRegistry.checksAfter;\r\n        for (const checkAfter of checksAfter) {\r\n            await interruptAndCheck(cancelToken);\r\n            await checkAfter(rootNode, acceptor, options.categories ?? [], cancelToken);\r\n        }\r\n    }\r\n\r\n    protected toDiagnostic<N extends AstNode>(severity: ValidationSeverity, message: string, info: DiagnosticInfo<N, string>): Diagnostic {\r\n        return {\r\n            message,\r\n            range: getDiagnosticRange(info),\r\n            severity: toDiagnosticSeverity(severity),\r\n            code: info.code,\r\n            codeDescription: info.codeDescription,\r\n            tags: info.tags,\r\n            relatedInformation: info.relatedInformation,\r\n            data: info.data,\r\n            source: this.getSource()\r\n        };\r\n    }\r\n\r\n    protected getSource(): string | undefined {\r\n        return this.metadata.languageId;\r\n    }\r\n}\r\n\r\nexport function getDiagnosticRange<N extends AstNode>(info: DiagnosticInfo<N, string>): Range {\r\n    if (info.range) {\r\n        return info.range;\r\n    }\r\n    let cstNode: CstNode | undefined;\r\n    if (typeof info.property === 'string') {\r\n        cstNode = findNodeForProperty(info.node.$cstNode, info.property, info.index);\r\n    } else if (typeof info.keyword === 'string') {\r\n        cstNode = findNodeForKeyword(info.node.$cstNode, info.keyword, info.index);\r\n    }\r\n    cstNode ??= info.node.$cstNode;\r\n    if (!cstNode) {\r\n        return {\r\n            start: { line: 0, character: 0 },\r\n            end: { line: 0, character: 0 }\r\n        };\r\n    }\r\n    return cstNode.range;\r\n}\r\n\r\n/**\r\n * Transforms the diagnostic severity from the {@link LexingDiagnosticSeverity} format to LSP's `DiagnosticSeverity` format.\r\n *\r\n * @param severity The lexing diagnostic severity\r\n * @returns Diagnostic severity according to `vscode-languageserver-types/lib/esm/main.js#DiagnosticSeverity`\r\n */\r\nexport function toDiagnosticSeverity(severity: LexingDiagnosticSeverity): DiagnosticSeverity {\r\n    switch (severity) {\r\n        case 'error':\r\n            return 1 satisfies typeof DiagnosticSeverity.Error;\r\n        case 'warning':\r\n            return 2 satisfies typeof DiagnosticSeverity.Warning;\r\n        case 'info':\r\n            return 3 satisfies typeof DiagnosticSeverity.Information;\r\n        case 'hint':\r\n            return 4 satisfies typeof DiagnosticSeverity.Hint;\r\n        default:\r\n            throw new Error('Invalid diagnostic severity: ' + severity);\r\n    }\r\n}\r\n\r\nexport function toDiagnosticData(severity: LexingDiagnosticSeverity): DiagnosticData {\r\n    switch (severity) {\r\n        case 'error':\r\n            return diagnosticData(DocumentValidator.LexingError);\r\n        case 'warning':\r\n            return diagnosticData(DocumentValidator.LexingWarning);\r\n        case 'info':\r\n            return diagnosticData(DocumentValidator.LexingInfo);\r\n        case 'hint':\r\n            return diagnosticData(DocumentValidator.LexingHint);\r\n        default:\r\n            throw new Error('Invalid diagnostic severity: ' + severity);\r\n    }\r\n}\r\n\r\nexport namespace DocumentValidator {\r\n    export const LexingError = 'lexing-error';\r\n    export const LexingWarning = 'lexing-warning';\r\n    export const LexingInfo = 'lexing-info';\r\n    export const LexingHint = 'lexing-hint';\r\n    export const ParsingError = 'parsing-error';\r\n    export const LinkingError = 'linking-error';\r\n}\r\n\r\nexport interface LinkingErrorData extends DiagnosticData {\r\n    containerType: string\r\n    property: string\r\n    refText: string\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { URI } from '../utils/uri-utils.js';\r\nimport type { NameProvider } from '../references/name-provider.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, AstNodeDescription, ReferenceInfo } from '../syntax-tree.js';\r\nimport type { AstNodeLocator } from './ast-node-locator.js';\r\nimport type { DocumentSegment, LangiumDocument } from './documents.js';\r\nimport { CancellationToken } from '../utils/cancellation.js';\r\nimport { isLinkingError } from '../syntax-tree.js';\r\nimport { getDocument, streamAst, streamReferences } from '../utils/ast-utils.js';\r\nimport { toDocumentSegment } from '../utils/cst-utils.js';\r\nimport { interruptAndCheck } from '../utils/promise-utils.js';\r\nimport { UriUtils } from '../utils/uri-utils.js';\r\n\r\n/**\r\n * Language-specific service for creating descriptions of AST nodes to be used for cross-reference resolutions.\r\n */\r\nexport interface AstNodeDescriptionProvider {\r\n\r\n    /**\r\n     * Create a description for the given AST node. This service method is typically used while indexing\r\n     * the contents of a document and during scope computation.\r\n     *\r\n     * @param node An AST node.\r\n     * @param name The name to be used to refer to the AST node. By default, this is determined by the\r\n     *     `NameProvider` service, but alternative names may be provided according to the semantics\r\n     *     of your language.\r\n     * @param document The document containing the AST node. If omitted, it is taken from the root AST node.\r\n     */\r\n    createDescription(node: AstNode, name: string | undefined, document?: LangiumDocument): AstNodeDescription;\r\n\r\n}\r\n\r\nexport class DefaultAstNodeDescriptionProvider implements AstNodeDescriptionProvider {\r\n\r\n    protected readonly astNodeLocator: AstNodeLocator;\r\n    protected readonly nameProvider: NameProvider;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.astNodeLocator = services.workspace.AstNodeLocator;\r\n        this.nameProvider = services.references.NameProvider;\r\n    }\r\n\r\n    createDescription(node: AstNode, name: string | undefined, document?: LangiumDocument): AstNodeDescription {\r\n        const doc = document ?? getDocument(node);\r\n        name ??= this.nameProvider.getName(node);\r\n        const path = this.astNodeLocator.getAstNodePath(node);\r\n        if (!name) {\r\n            throw new Error(`Node at path ${path} has no name.`);\r\n        }\r\n        let nameNodeSegment: DocumentSegment | undefined;\r\n        const nameSegmentGetter = () => nameNodeSegment ??= toDocumentSegment(this.nameProvider.getNameNode(node) ?? node.$cstNode);\r\n        return {\r\n            node,\r\n            name,\r\n            get nameSegment() {\r\n                return nameSegmentGetter();\r\n            },\r\n            selectionSegment: toDocumentSegment(node.$cstNode),\r\n            type: node.$type,\r\n            documentUri: doc.uri,\r\n            path\r\n        };\r\n    }\r\n\r\n}\r\n\r\n/**\r\n * Describes a cross-reference within a document or between two documents.\r\n */\r\nexport interface ReferenceDescription {\r\n    /** URI of the document that holds a reference */\r\n    sourceUri: URI\r\n    /** Path to AstNode that holds a reference */\r\n    sourcePath: string\r\n    /** Target document uri */\r\n    targetUri: URI\r\n    /** Path to the target AstNode inside the document */\r\n    targetPath: string\r\n    /** Segment of the reference text. */\r\n    segment: DocumentSegment\r\n    /** Marks a local reference i.e. a cross reference inside a document.   */\r\n    local?: boolean\r\n}\r\n\r\n/**\r\n * Language-specific service to create descriptions of all cross-references in a document. These are used by the `IndexManager`\r\n * to determine which documents are affected and should be rebuilt when a document is changed.\r\n */\r\nexport interface ReferenceDescriptionProvider {\r\n    /**\r\n     * Create descriptions of all cross-references found in the given document. These descriptions are\r\n     * gathered by the `IndexManager` and stored in the global index so they can be considered when\r\n     * a document change is reported by the client.\r\n     *\r\n     * @param document The document in which to gather cross-references.\r\n     * @param cancelToken Indicates when to cancel the current operation.\r\n     * @throws `OperationCanceled` if a user action occurs during execution\r\n     */\r\n    createDescriptions(document: LangiumDocument, cancelToken?: CancellationToken): Promise<ReferenceDescription[]>;\r\n}\r\n\r\nexport class DefaultReferenceDescriptionProvider implements ReferenceDescriptionProvider {\r\n\r\n    protected readonly nodeLocator: AstNodeLocator;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.nodeLocator = services.workspace.AstNodeLocator;\r\n    }\r\n\r\n    async createDescriptions(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<ReferenceDescription[]> {\r\n        const descr: ReferenceDescription[] = [];\r\n        const rootNode = document.parseResult.value;\r\n        for (const astNode of streamAst(rootNode)) {\r\n            await interruptAndCheck(cancelToken);\r\n            streamReferences(astNode).filter(refInfo => !isLinkingError(refInfo)).forEach(refInfo => {\r\n                // TODO: Consider logging a warning or throw an exception when DocumentState is < than Linked\r\n                const description = this.createDescription(refInfo);\r\n                if (description) {\r\n                    descr.push(description);\r\n                }\r\n            });\r\n        }\r\n        return descr;\r\n    }\r\n\r\n    protected createDescription(refInfo: ReferenceInfo): ReferenceDescription | undefined {\r\n        const targetNodeDescr = refInfo.reference.$nodeDescription;\r\n        const refCstNode = refInfo.reference.$refNode;\r\n        if (!targetNodeDescr || !refCstNode) {\r\n            return undefined;\r\n        }\r\n        const docUri = getDocument(refInfo.container).uri;\r\n        return {\r\n            sourceUri: docUri,\r\n            sourcePath: this.nodeLocator.getAstNodePath(refInfo.container),\r\n            targetUri: targetNodeDescr.documentUri,\r\n            targetPath: targetNodeDescr.path,\r\n            segment: toDocumentSegment(refCstNode),\r\n            local: UriUtils.equals(targetNodeDescr.documentUri, docUri)\r\n        };\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { AstNode } from '../syntax-tree.js';\r\n\r\n/**\r\n * Language-specific service for locating an `AstNode` in a document.\r\n */\r\nexport interface AstNodeLocator {\r\n\r\n    /**\r\n     * Creates a path represented by a `string` that identifies an `AstNode` inside its document.\r\n     * It must be possible to retrieve exactly the same `AstNode` from the document using this path.\r\n     *\r\n     * @param node The `AstNode` for which to create the path.\r\n     * @returns a path represented by a `string` that identifies `node` inside its document.\r\n     * @see AstNodeLocator.getAstNode\r\n     */\r\n    getAstNodePath(node: AstNode): string;\r\n\r\n    /**\r\n     * Locates an `AstNode` inside another node by following the given path.\r\n     *\r\n     * @param node Parent element.\r\n     * @param path Describes how to locate the `AstNode` inside the given `node`.\r\n     * @returns The `AstNode` located under the given path, or `undefined` if the path cannot be resolved.\r\n     * @see AstNodeLocator.getAstNodePath\r\n     */\r\n    getAstNode<T extends AstNode = AstNode>(node: AstNode, path: string): T | undefined;\r\n\r\n}\r\n\r\nexport class DefaultAstNodeLocator implements AstNodeLocator {\r\n    protected segmentSeparator = '/';\r\n    protected indexSeparator = '@';\r\n\r\n    getAstNodePath(node: AstNode): string {\r\n        if (node.$container) {\r\n            const containerPath = this.getAstNodePath(node.$container);\r\n            const newSegment = this.getPathSegment(node);\r\n            const nodePath = containerPath + this.segmentSeparator + newSegment;\r\n            return nodePath;\r\n        }\r\n        return '';\r\n    }\r\n\r\n    protected getPathSegment({ $containerProperty, $containerIndex }: AstNode): string {\r\n        if (!$containerProperty) {\r\n            throw new Error(\"Missing '$containerProperty' in AST node.\");\r\n        }\r\n        if ($containerIndex !== undefined) {\r\n            return $containerProperty + this.indexSeparator + $containerIndex;\r\n        }\r\n        return $containerProperty;\r\n    }\r\n\r\n    getAstNode<T extends AstNode = AstNode>(node: AstNode, path: string): T | undefined {\r\n        const segments = path.split(this.segmentSeparator);\r\n        return segments.reduce((previousValue, currentValue) => {\r\n            if (!previousValue || currentValue.length === 0) {\r\n                return previousValue;\r\n            }\r\n            const propertyIndex = currentValue.indexOf(this.indexSeparator);\r\n            if (propertyIndex > 0) {\r\n                const property = currentValue.substring(0, propertyIndex);\r\n                const arrayIndex = parseInt(currentValue.substring(propertyIndex + 1));\r\n                const array = (previousValue as unknown as Record<string, AstNode[]>)[property];\r\n                return array?.[arrayIndex];\r\n            }\r\n            return (previousValue as unknown as Record<string, AstNode>)[currentValue];\r\n        }, node) as T;\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nexport interface Disposable {\r\n    /**\r\n     * Dispose this object.\r\n     */\r\n    dispose(): void;\r\n}\r\n\r\nexport interface AsyncDisposable {\r\n    /**\r\n     * Dispose this object.\r\n     */\r\n    dispose(): Promise<void>;\r\n}\r\n\r\nexport namespace Disposable {\r\n    export function create(callback: () => Promise<void>): AsyncDisposable;\r\n    export function create(callback: () => void): Disposable;\r\n    export function create(callback: () => void | Promise<void>): Disposable | AsyncDisposable {\r\n        return {\r\n            dispose: async () => await callback()\r\n        };\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { Emitter } from '../utils/event.js';\r\nimport type {\r\n    ConfigurationItem,\r\n    DidChangeConfigurationParams,\r\n    DidChangeConfigurationRegistrationOptions,\r\n    Disposable,\r\n    Event,\r\n    InitializeParams,\r\n    InitializedParams\r\n} from 'vscode-languageserver-protocol';\r\nimport type { ServiceRegistry } from '../service-registry.js';\r\nimport type { LangiumSharedCoreServices } from '../services.js';\r\nimport { Deferred } from '../utils/promise-utils.js';\r\n\r\n/* eslint-disable @typescript-eslint/no-explicit-any */\r\n\r\nexport interface ConfigurationProvider {\r\n\r\n    /**\r\n     * A promise that resolves when the configuration provider is ready to be used.\r\n     */\r\n    readonly ready: Promise<void>;\r\n\r\n    /**\r\n     * When used in a language server context, this method is called when the server receives\r\n     * the `initialize` request.\r\n     */\r\n    initialize(params: InitializeParams): void;\r\n\r\n    /**\r\n     * When used in a language server context, this method is called when the server receives\r\n     * the `initialized` notification.\r\n     */\r\n    initialized(params: ConfigurationInitializedParams): Promise<void>;\r\n\r\n    /**\r\n     * Returns a configuration value stored for the given language.\r\n     *\r\n     * @param language The language id\r\n     * @param configuration Configuration name\r\n     */\r\n    getConfiguration(language: string, configuration: string): Promise<any>;\r\n\r\n    /**\r\n     *  Updates the cached configurations using the `change` notification parameters.\r\n     *\r\n     * @param change The parameters of a change configuration notification.\r\n     * `settings` property of the change object could be expressed as `Record<string, Record<string, any>>`\r\n     */\r\n    updateConfiguration(change: DidChangeConfigurationParams): void;\r\n\r\n    /**\r\n     * Get notified after a configuration section has been updated.\r\n     */\r\n    onConfigurationSectionUpdate(callback: ConfigurationSectionUpdateListener): Disposable\r\n}\r\n\r\nexport interface ConfigurationInitializedParams extends InitializedParams {\r\n    register?: (params: DidChangeConfigurationRegistrationOptions) => void,\r\n    fetchConfiguration?: (configuration: ConfigurationItem[]) => Promise<any>\r\n}\r\n\r\nexport interface ConfigurationSectionUpdate {\r\n    /**\r\n     * The name of the configuration section that has been updated.\r\n     */\r\n    section: string;\r\n\r\n    /**\r\n     * The updated configuration section.\r\n     */\r\n    configuration: any;\r\n}\r\n\r\nexport type ConfigurationSectionUpdateListener = (update: ConfigurationSectionUpdate) => void;\r\n\r\n/**\r\n * Base configuration provider for building up other configuration providers\r\n */\r\nexport class DefaultConfigurationProvider implements ConfigurationProvider {\r\n\r\n    protected readonly serviceRegistry: ServiceRegistry;\r\n    protected readonly _ready = new Deferred<void>();\r\n    protected settings: Record<string, Record<string, any>> = {};\r\n    protected workspaceConfig = false;\r\n    protected onConfigurationSectionUpdateEmitter = new Emitter<ConfigurationSectionUpdate>();\r\n\r\n    constructor(services: LangiumSharedCoreServices) {\r\n        this.serviceRegistry = services.ServiceRegistry;\r\n    }\r\n\r\n    get ready(): Promise<void> {\r\n        return this._ready.promise;\r\n    }\r\n\r\n    initialize(params: InitializeParams): void {\r\n        this.workspaceConfig = params.capabilities.workspace?.configuration ?? false;\r\n    }\r\n\r\n    async initialized(params: ConfigurationInitializedParams): Promise<void> {\r\n        if (this.workspaceConfig) {\r\n            if (params.register) {\r\n                // params.register(...) is a function to be provided by the calling language server for the sake of\r\n                //  decoupling this implementation from the concrete LSP implementations, specifically the LSP Connection\r\n\r\n                const languages = this.serviceRegistry.all;\r\n                params.register({\r\n                    // Listen to configuration changes for all languages\r\n                    section: languages.map(lang => this.toSectionName(lang.LanguageMetaData.languageId))\r\n                });\r\n            }\r\n\r\n            if (params.fetchConfiguration) {\r\n                // params.fetchConfiguration(...) is a function to be provided by the calling language server for the sake of\r\n                //  decoupling this implementation from the concrete LSP implementations, specifically the LSP Connection\r\n                const configToUpdate = this.serviceRegistry.all.map(lang => <ConfigurationItem>{\r\n                    // Fetch the configuration changes for all languages\r\n                    section: this.toSectionName(lang.LanguageMetaData.languageId)\r\n                });\r\n\r\n                // get workspace configurations (default scope URI)\r\n                const configs = await params.fetchConfiguration(configToUpdate);\r\n                configToUpdate.forEach((conf, idx) => {\r\n                    this.updateSectionConfiguration(conf.section!, configs[idx]);\r\n                });\r\n            }\r\n        }\r\n        this._ready.resolve();\r\n    }\r\n\r\n    /**\r\n     *  Updates the cached configurations using the `change` notification parameters.\r\n     *\r\n     * @param change The parameters of a change configuration notification.\r\n     * `settings` property of the change object could be expressed as `Record<string, Record<string, any>>`\r\n     */\r\n    updateConfiguration(change: DidChangeConfigurationParams): void {\r\n        if (!change.settings) {\r\n            return;\r\n        }\r\n        Object.keys(change.settings).forEach(section => {\r\n            const configuration = change.settings[section];\r\n            this.updateSectionConfiguration(section, configuration);\r\n            this.onConfigurationSectionUpdateEmitter.fire({ section, configuration });\r\n        });\r\n    }\r\n\r\n    protected updateSectionConfiguration(section: string, configuration: any): void {\r\n        this.settings[section] = configuration;\r\n    }\r\n\r\n    /**\r\n    * Returns a configuration value stored for the given language.\r\n    *\r\n    * @param language The language id\r\n    * @param configuration Configuration name\r\n    */\r\n    async getConfiguration(language: string, configuration: string): Promise<any> {\r\n        await this.ready;\r\n\r\n        const sectionName = this.toSectionName(language);\r\n        if (this.settings[sectionName]) {\r\n            return this.settings[sectionName][configuration];\r\n        }\r\n    }\r\n\r\n    protected toSectionName(languageId: string): string {\r\n        return `${languageId}`;\r\n    }\r\n\r\n    get onConfigurationSectionUpdate(): Event<ConfigurationSectionUpdate> {\r\n        return this.onConfigurationSectionUpdateEmitter.event;\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { CancellationToken } from '../utils/cancellation.js';\r\nimport { Disposable } from '../utils/disposable.js';\r\nimport type { ServiceRegistry } from '../service-registry.js';\r\nimport type { LangiumSharedCoreServices } from '../services.js';\r\nimport type { AstNode } from '../syntax-tree.js';\r\nimport type { MaybePromise } from '../utils/promise-utils.js';\r\nimport type { Deferred } from '../utils/promise-utils.js';\r\nimport type { ValidationOptions } from '../validation/document-validator.js';\r\nimport type { IndexManager } from '../workspace/index-manager.js';\r\nimport type { LangiumDocument, LangiumDocuments, LangiumDocumentFactory, TextDocumentProvider } from './documents.js';\r\nimport { MultiMap } from '../utils/collections.js';\r\nimport { OperationCancelled, interruptAndCheck, isOperationCancelled } from '../utils/promise-utils.js';\r\nimport { stream } from '../utils/stream.js';\r\nimport type { URI } from '../utils/uri-utils.js';\r\nimport { ValidationCategory } from '../validation/validation-registry.js';\r\nimport { DocumentState } from './documents.js';\r\n\r\nexport interface BuildOptions {\r\n    /**\r\n     * Control the validation phase with this option:\r\n     *  - `true` enables all validation checks and forces revalidating the documents\r\n     *  - `false` or `undefined` disables all validation checks\r\n     *  - An object runs only the necessary validation checks; the `categories` property restricts this to a specific subset\r\n     */\r\n    validation?: boolean | ValidationOptions\r\n}\r\n\r\nexport interface DocumentBuildState {\r\n    /** Whether a document has completed its last build process. */\r\n    completed: boolean\r\n    /** The options used for the last build process. */\r\n    options: BuildOptions\r\n    /** Additional information about the last build result. */\r\n    result?: {\r\n        validationChecks?: ValidationCategory[]\r\n    }\r\n}\r\n\r\n/**\r\n * Shared-service for building and updating `LangiumDocument`s.\r\n */\r\nexport interface DocumentBuilder {\r\n\r\n    /** The options used for rebuilding documents after an update. */\r\n    updateBuildOptions: BuildOptions;\r\n\r\n    /**\r\n     * Execute all necessary build steps for the given documents.\r\n     *\r\n     * @param documents Set of documents to be built.\r\n     * @param options Options for the document builder.\r\n     * @param cancelToken Indicates when to cancel the current operation.\r\n     * @throws `OperationCanceled` if a user action occurs during execution\r\n     */\r\n    build<T extends AstNode>(documents: Array<LangiumDocument<T>>, options?: BuildOptions, cancelToken?: CancellationToken): Promise<void>;\r\n\r\n    /**\r\n     * This method is called when a document change is detected. It updates the state of all\r\n     * affected documents, including those with references to the changed ones, so they are rebuilt.\r\n     *\r\n     * @param changed URIs of changed or created documents\r\n     * @param deleted URIs of deleted documents\r\n     * @param cancelToken allows to cancel the current operation\r\n     * @throws `OperationCancelled` if cancellation is detected during execution\r\n     */\r\n    update(changed: URI[], deleted: URI[], cancelToken?: CancellationToken): Promise<void>;\r\n\r\n    /**\r\n     * Notify the given callback when a document update was triggered, but before any document\r\n     * is rebuilt. Listeners to this event should not perform any long-running task.\r\n     */\r\n    onUpdate(callback: DocumentUpdateListener): Disposable;\r\n\r\n    /**\r\n     * Notify the given callback when a set of documents has been built reaching the specified target state.\r\n     */\r\n    onBuildPhase(targetState: DocumentState, callback: DocumentBuildListener): Disposable;\r\n\r\n    /**\r\n     * Notify the specified callback when a document has been built reaching the specified target state.\r\n     * Unlike {@link onBuildPhase} the listener is called for every single document.\r\n     *\r\n     * There are two main advantages compared to {@link onBuildPhase}:\r\n     * 1. If the build is cancelled, {@link onDocumentPhase} will still fire for documents that have reached a specific state.\r\n     *    Meanwhile, {@link onBuildPhase} won't fire for that state.\r\n     * 2. The {@link DocumentBuilder} ensures that all {@link DocumentPhaseListener} instances are called for a built document.\r\n     *    Even if the build is cancelled before those listeners were called.\r\n     */\r\n    onDocumentPhase(targetState: DocumentState, callback: DocumentPhaseListener): Disposable;\r\n\r\n    /**\r\n     * Wait until the workspace has reached the specified state for all documents.\r\n     *\r\n     * @param state The desired state. The promise won't resolve until all documents have reached this state\r\n     * @param cancelToken Optionally allows to cancel the wait operation, disposing any listeners in the process\r\n     * @throws `OperationCancelled` if cancellation has been requested before the state has been reached\r\n     */\r\n    waitUntil(state: DocumentState, cancelToken?: CancellationToken): Promise<void>;\r\n\r\n    /**\r\n     * Wait until the document specified by the {@link uri} has reached the specified state.\r\n     *\r\n     * @param state The desired state. The promise won't resolve until the document has reached this state.\r\n     * @param uri The specified URI that points to the document. If the URI does not exist, the promise will resolve once the workspace has reached the specified state.\r\n     * @param cancelToken Optionally allows to cancel the wait operation, disposing any listeners in the process.\r\n     * @return The URI of the document that has reached the desired state, or `undefined` if the document does not exist.\r\n     * @throws `OperationCancelled` if cancellation has been requested before the state has been reached\r\n     */\r\n    waitUntil(state: DocumentState, uri?: URI, cancelToken?: CancellationToken): Promise<URI | undefined>;\r\n}\r\n\r\nexport type DocumentUpdateListener = (changed: URI[], deleted: URI[]) => void | Promise<void>\r\nexport type DocumentBuildListener = (built: LangiumDocument[], cancelToken: CancellationToken) => void | Promise<void>\r\nexport type DocumentPhaseListener = (built: LangiumDocument, cancelToken: CancellationToken) => void | Promise<void>\r\nexport class DefaultDocumentBuilder implements DocumentBuilder {\r\n\r\n    updateBuildOptions: BuildOptions = {\r\n        // Default: run only the built-in validation checks and those in the _fast_ category (includes those without category)\r\n        validation: {\r\n            categories: ['built-in', 'fast']\r\n        }\r\n    };\r\n\r\n    protected readonly langiumDocuments: LangiumDocuments;\r\n    protected readonly langiumDocumentFactory: LangiumDocumentFactory;\r\n    protected readonly textDocuments: TextDocumentProvider | undefined;\r\n    protected readonly indexManager: IndexManager;\r\n    protected readonly serviceRegistry: ServiceRegistry;\r\n    protected readonly updateListeners: DocumentUpdateListener[] = [];\r\n    protected readonly buildPhaseListeners = new MultiMap<DocumentState, DocumentBuildListener>();\r\n    protected readonly documentPhaseListeners = new MultiMap<DocumentState, DocumentPhaseListener>();\r\n    protected readonly buildState = new Map<string, DocumentBuildState>();\r\n    protected readonly documentBuildWaiters = new Map<string, Deferred<void>>();\r\n    protected currentState = DocumentState.Changed;\r\n\r\n    constructor(services: LangiumSharedCoreServices) {\r\n        this.langiumDocuments = services.workspace.LangiumDocuments;\r\n        this.langiumDocumentFactory = services.workspace.LangiumDocumentFactory;\r\n        this.textDocuments = services.workspace.TextDocuments;\r\n        this.indexManager = services.workspace.IndexManager;\r\n        this.serviceRegistry = services.ServiceRegistry;\r\n    }\r\n\r\n    async build<T extends AstNode>(documents: Array<LangiumDocument<T>>, options: BuildOptions = {}, cancelToken = CancellationToken.None): Promise<void> {\r\n        for (const document of documents) {\r\n            const key = document.uri.toString();\r\n            if (document.state === DocumentState.Validated) {\r\n                if (typeof options.validation === 'boolean' && options.validation) {\r\n                    // Force re-running all validation checks\r\n                    document.state = DocumentState.IndexedReferences;\r\n                    document.diagnostics = undefined;\r\n                    this.buildState.delete(key);\r\n                } else if (typeof options.validation === 'object') {\r\n                    const buildState = this.buildState.get(key);\r\n                    const previousCategories = buildState?.result?.validationChecks;\r\n                    if (previousCategories) {\r\n                        // Validation with explicit options was requested for a document that has already been partly validated.\r\n                        // In this case, we need to merge the previous validation categories with the new ones.\r\n                        const newCategories = options.validation.categories ?? ValidationCategory.all as ValidationCategory[];\r\n                        const categories = newCategories.filter(c => !previousCategories.includes(c));\r\n                        if (categories.length > 0) {\r\n                            this.buildState.set(key, {\r\n                                completed: false,\r\n                                options: {\r\n                                    validation: {\r\n                                        ...options.validation,\r\n                                        categories\r\n                                    }\r\n                                },\r\n                                result: buildState.result\r\n                            });\r\n                            document.state = DocumentState.IndexedReferences;\r\n                        }\r\n                    }\r\n                }\r\n            } else {\r\n                // Default: forget any previous build options\r\n                this.buildState.delete(key);\r\n            }\r\n        }\r\n        this.currentState = DocumentState.Changed;\r\n        await this.emitUpdate(documents.map(e => e.uri), []);\r\n        await this.buildDocuments(documents, options, cancelToken);\r\n    }\r\n\r\n    async update(changed: URI[], deleted: URI[], cancelToken = CancellationToken.None): Promise<void> {\r\n        this.currentState = DocumentState.Changed;\r\n        // Remove all metadata of documents that are reported as deleted\r\n        for (const deletedUri of deleted) {\r\n            this.langiumDocuments.deleteDocument(deletedUri);\r\n            this.buildState.delete(deletedUri.toString());\r\n            this.indexManager.remove(deletedUri);\r\n        }\r\n        // Set the state of all changed documents to `Changed` so they are completely rebuilt\r\n        for (const changedUri of changed) {\r\n            const invalidated = this.langiumDocuments.invalidateDocument(changedUri);\r\n            if (!invalidated) {\r\n                // We create an unparsed, invalid document.\r\n                // This will be parsed as soon as we reach the first document builder phase.\r\n                // This allows to cancel the parsing process later in case we need it.\r\n                const newDocument = this.langiumDocumentFactory.fromModel({ $type: 'INVALID' }, changedUri);\r\n                newDocument.state = DocumentState.Changed;\r\n                this.langiumDocuments.addDocument(newDocument);\r\n            }\r\n            this.buildState.delete(changedUri.toString());\r\n        }\r\n        // Set the state of all documents that should be relinked to `ComputedScopes` (if not already lower)\r\n        const allChangedUris = stream(changed).concat(deleted).map(uri => uri.toString()).toSet();\r\n        this.langiumDocuments.all\r\n            .filter(doc => !allChangedUris.has(doc.uri.toString()) && this.shouldRelink(doc, allChangedUris))\r\n            .forEach(doc => {\r\n                const linker = this.serviceRegistry.getServices(doc.uri).references.Linker;\r\n                linker.unlink(doc);\r\n                doc.state = Math.min(doc.state, DocumentState.ComputedScopes);\r\n                doc.diagnostics = undefined;\r\n            });\r\n        // Notify listeners of the update\r\n        await this.emitUpdate(changed, deleted);\r\n        // Only allow interrupting the execution after all state changes are done\r\n        await interruptAndCheck(cancelToken);\r\n\r\n        // Collect and sort all documents that we should rebuild\r\n        const rebuildDocuments = this.sortDocuments(\r\n            this.langiumDocuments.all\r\n                .filter(doc =>\r\n                    // This includes those that were reported as changed and those that we selected for relinking\r\n                    doc.state < DocumentState.Linked\r\n                    // This includes those for which a previous build has been cancelled\r\n                    || !this.buildState.get(doc.uri.toString())?.completed\r\n                )\r\n                .toArray()\r\n        );\r\n        await this.buildDocuments(rebuildDocuments, this.updateBuildOptions, cancelToken);\r\n    }\r\n\r\n    protected async emitUpdate(changed: URI[], deleted: URI[]): Promise<void> {\r\n        await Promise.all(this.updateListeners.map(listener => listener(changed, deleted)));\r\n    }\r\n\r\n    /**\r\n     * Sort the given documents by priority. By default, documents with an open text document are prioritized.\r\n     * This is useful to ensure that visible documents show their diagnostics before all other documents.\r\n     *\r\n     * This improves the responsiveness in large workspaces as users usually don't care about diagnostics\r\n     * in files that are currently not opened in the editor.\r\n     */\r\n    protected sortDocuments(documents: LangiumDocument[]): LangiumDocument[] {\r\n        let left = 0;\r\n        let right = documents.length - 1;\r\n\r\n        while (left < right) {\r\n            while (left < documents.length && this.hasTextDocument(documents[left])) {\r\n                left++;\r\n            }\r\n\r\n            while (right >= 0 && !this.hasTextDocument(documents[right])) {\r\n                right--;\r\n            }\r\n\r\n            if (left < right) {\r\n                [documents[left], documents[right]] = [documents[right], documents[left]];\r\n            }\r\n        }\r\n\r\n        return documents;\r\n    }\r\n\r\n    private hasTextDocument(doc: LangiumDocument): boolean {\r\n        return Boolean(this.textDocuments?.get(doc.uri));\r\n    }\r\n\r\n    /**\r\n     * Check whether the given document should be relinked after changes were found in the given URIs.\r\n     */\r\n    protected shouldRelink(document: LangiumDocument, changedUris: Set<string>): boolean {\r\n        // Relink documents with linking errors -- maybe those references can be resolved now\r\n        if (document.references.some(ref => ref.error !== undefined)) {\r\n            return true;\r\n        }\r\n        // Check whether the document is affected by any of the changed URIs\r\n        return this.indexManager.isAffected(document, changedUris);\r\n    }\r\n\r\n    onUpdate(callback: DocumentUpdateListener): Disposable {\r\n        this.updateListeners.push(callback);\r\n        return Disposable.create(() => {\r\n            const index = this.updateListeners.indexOf(callback);\r\n            if (index >= 0) {\r\n                this.updateListeners.splice(index, 1);\r\n            }\r\n        });\r\n    }\r\n\r\n    /**\r\n     * Build the given documents by stepping through all build phases. If a document's state indicates\r\n     * that a certain build phase is already done, the phase is skipped for that document.\r\n     *\r\n     * @param documents The documents to build.\r\n     * @param options the {@link BuildOptions} to use.\r\n     * @param cancelToken A cancellation token that can be used to cancel the build.\r\n     * @returns A promise that resolves when the build is done.\r\n     */\r\n    protected async buildDocuments(documents: LangiumDocument[], options: BuildOptions, cancelToken: CancellationToken): Promise<void> {\r\n        this.prepareBuild(documents, options);\r\n        // 0. Parse content\r\n        await this.runCancelable(documents, DocumentState.Parsed, cancelToken, doc =>\r\n            this.langiumDocumentFactory.update(doc, cancelToken)\r\n        );\r\n        // 1. Index content\r\n        await this.runCancelable(documents, DocumentState.IndexedContent, cancelToken, doc =>\r\n            this.indexManager.updateContent(doc, cancelToken)\r\n        );\r\n        // 2. Compute scopes\r\n        await this.runCancelable(documents, DocumentState.ComputedScopes, cancelToken, async doc => {\r\n            const scopeComputation = this.serviceRegistry.getServices(doc.uri).references.ScopeComputation;\r\n            doc.precomputedScopes = await scopeComputation.computeLocalScopes(doc, cancelToken);\r\n        });\r\n        // 3. Linking\r\n        await this.runCancelable(documents, DocumentState.Linked, cancelToken, doc => {\r\n            const linker = this.serviceRegistry.getServices(doc.uri).references.Linker;\r\n            return linker.link(doc, cancelToken);\r\n        });\r\n        // 4. Index references\r\n        await this.runCancelable(documents, DocumentState.IndexedReferences, cancelToken, doc =>\r\n            this.indexManager.updateReferences(doc, cancelToken)\r\n        );\r\n        // 5. Validation\r\n        const toBeValidated = documents.filter(doc => this.shouldValidate(doc));\r\n        await this.runCancelable(toBeValidated, DocumentState.Validated, cancelToken, doc =>\r\n            this.validate(doc, cancelToken)\r\n        );\r\n\r\n        // If we've made it to this point without being cancelled, we can mark the build state as completed.\r\n        for (const doc of documents) {\r\n            const state = this.buildState.get(doc.uri.toString());\r\n            if (state) {\r\n                state.completed = true;\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Runs prior to beginning the build process to update the {@link DocumentBuildState} for each document\r\n     *\r\n     * @param documents collection of documents to be built\r\n     * @param options the {@link BuildOptions} to use\r\n     */\r\n    protected prepareBuild(documents: LangiumDocument[], options: BuildOptions): void {\r\n        for (const doc of documents) {\r\n            const key = doc.uri.toString();\r\n            const state = this.buildState.get(key);\r\n            // If the document has no previous build state, we set it. If it has one, but it's already marked\r\n            // as completed, we overwrite it. If the previous build was not completed, we keep its state\r\n            // and continue where it was cancelled.\r\n            if (!state || state.completed) {\r\n                this.buildState.set(key, {\r\n                    completed: false,\r\n                    options,\r\n                    result: state?.result\r\n                });\r\n            }\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Runs a cancelable operation on a set of documents to bring them to a specified {@link DocumentState}.\r\n     *\r\n     * @param documents The array of documents to process.\r\n     * @param targetState The target {@link DocumentState} to bring the documents to.\r\n     * @param cancelToken A token that can be used to cancel the operation.\r\n     * @param callback A function to be called for each document.\r\n     * @returns A promise that resolves when all documents have been processed or the operation is canceled.\r\n     * @throws Will throw `OperationCancelled` if the operation is canceled via a `CancellationToken`.\r\n     */\r\n    protected async runCancelable(documents: LangiumDocument[], targetState: DocumentState, cancelToken: CancellationToken,\r\n        callback: (document: LangiumDocument) => MaybePromise<unknown>): Promise<void> {\r\n        const filtered = documents.filter(doc => doc.state < targetState);\r\n        for (const document of filtered) {\r\n            await interruptAndCheck(cancelToken);\r\n            await callback(document);\r\n            document.state = targetState;\r\n            await this.notifyDocumentPhase(document, targetState, cancelToken);\r\n        }\r\n\r\n        // Do not use `filtered` here, as that will miss documents that have previously reached the current target state\r\n        // For example, this happens in case the cancellation triggers between the processing of two documents\r\n        // Or files that were picked up during the workspace initialization\r\n        const targetStateDocs = documents.filter(doc => doc.state === targetState);\r\n        await this.notifyBuildPhase(targetStateDocs, targetState, cancelToken);\r\n        this.currentState = targetState;\r\n    }\r\n\r\n    onBuildPhase(targetState: DocumentState, callback: DocumentBuildListener): Disposable {\r\n        this.buildPhaseListeners.add(targetState, callback);\r\n        return Disposable.create(() => {\r\n            this.buildPhaseListeners.delete(targetState, callback);\r\n        });\r\n    }\r\n\r\n    onDocumentPhase(targetState: DocumentState, callback: DocumentPhaseListener): Disposable {\r\n        this.documentPhaseListeners.add(targetState, callback);\r\n        return Disposable.create(() => {\r\n            this.documentPhaseListeners.delete(targetState, callback);\r\n        });\r\n    }\r\n\r\n    waitUntil(state: DocumentState, cancelToken?: CancellationToken): Promise<void>;\r\n    waitUntil(state: DocumentState, uri?: URI, cancelToken?: CancellationToken): Promise<URI | undefined>;\r\n    waitUntil(state: DocumentState, uriOrToken?: URI | CancellationToken, cancelToken?: CancellationToken): Promise<URI | undefined | void> {\r\n        let uri: URI | undefined = undefined;\r\n        if (uriOrToken && 'path' in uriOrToken) {\r\n            uri = uriOrToken;\r\n        } else {\r\n            cancelToken = uriOrToken;\r\n        }\r\n        cancelToken ??= CancellationToken.None;\r\n        if (uri) {\r\n            const document = this.langiumDocuments.getDocument(uri);\r\n            if (document && document.state > state) {\r\n                return Promise.resolve(uri);\r\n            }\r\n        }\r\n        if (this.currentState >= state) {\r\n            return Promise.resolve(undefined);\r\n        } else if (cancelToken.isCancellationRequested) {\r\n            return Promise.reject(OperationCancelled);\r\n        }\r\n        return new Promise((resolve, reject) => {\r\n            const buildDisposable = this.onBuildPhase(state, () => {\r\n                buildDisposable.dispose();\r\n                cancelDisposable.dispose();\r\n                if (uri) {\r\n                    const document = this.langiumDocuments.getDocument(uri);\r\n                    resolve(document?.uri);\r\n                } else {\r\n                    resolve(undefined);\r\n                }\r\n            });\r\n            const cancelDisposable = cancelToken!.onCancellationRequested(() => {\r\n                buildDisposable.dispose();\r\n                cancelDisposable.dispose();\r\n                reject(OperationCancelled);\r\n            });\r\n        });\r\n    }\r\n\r\n    protected async notifyDocumentPhase(document: LangiumDocument, state: DocumentState, cancelToken: CancellationToken): Promise<void> {\r\n        const listeners = this.documentPhaseListeners.get(state);\r\n        const listenersCopy = listeners.slice();\r\n        for (const listener of listenersCopy) {\r\n            try {\r\n                await listener(document, cancelToken);\r\n            } catch (err) {\r\n                // Ignore cancellation errors\r\n                // We want to finish the listeners before throwing\r\n                if (!isOperationCancelled(err)) {\r\n                    throw err;\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    protected async notifyBuildPhase(documents: LangiumDocument[], state: DocumentState, cancelToken: CancellationToken): Promise<void> {\r\n        if (documents.length === 0) {\r\n            // Don't notify when no document has been processed\r\n            return;\r\n        }\r\n        const listeners = this.buildPhaseListeners.get(state);\r\n        const listenersCopy = listeners.slice();\r\n        for (const listener of listenersCopy) {\r\n            await interruptAndCheck(cancelToken);\r\n            await listener(documents, cancelToken);\r\n        }\r\n    }\r\n\r\n    /**\r\n     * Determine whether the given document should be validated during a build. The default\r\n     * implementation checks the `validation` property of the build options. If it's set to `true`\r\n     * or a `ValidationOptions` object, the document is included in the validation phase.\r\n     */\r\n    protected shouldValidate(document: LangiumDocument): boolean {\r\n        return Boolean(this.getBuildOptions(document).validation);\r\n    }\r\n\r\n    /**\r\n     * Run validation checks on the given document and store the resulting diagnostics in the document.\r\n     * If the document already contains diagnostics, the new ones are added to the list.\r\n     */\r\n    protected async validate(document: LangiumDocument, cancelToken: CancellationToken): Promise<void> {\r\n        const validator = this.serviceRegistry.getServices(document.uri).validation.DocumentValidator;\r\n        const validationSetting = this.getBuildOptions(document).validation;\r\n        const options = typeof validationSetting === 'object' ? validationSetting : undefined;\r\n        const diagnostics = await validator.validateDocument(document, options, cancelToken);\r\n        if (document.diagnostics) {\r\n            document.diagnostics.push(...diagnostics);\r\n        } else {\r\n            document.diagnostics = diagnostics;\r\n        }\r\n\r\n        // Store information about the executed validation in the build state\r\n        const state = this.buildState.get(document.uri.toString());\r\n        if (state) {\r\n            state.result ??= {};\r\n            const newCategories = options?.categories ?? ValidationCategory.all;\r\n            if (state.result.validationChecks) {\r\n                state.result.validationChecks.push(...newCategories);\r\n            } else {\r\n                state.result.validationChecks = [...newCategories];\r\n            }\r\n        }\r\n    }\r\n\r\n    protected getBuildOptions(document: LangiumDocument): BuildOptions {\r\n        return this.buildState.get(document.uri.toString())?.options ?? {};\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { ServiceRegistry } from '../service-registry.js';\r\nimport type { LangiumSharedCoreServices } from '../services.js';\r\nimport type { AstNode, AstNodeDescription, AstReflection } from '../syntax-tree.js';\r\nimport { getDocument } from '../utils/ast-utils.js';\r\nimport { ContextCache } from '../utils/caching.js';\r\nimport { CancellationToken } from '../utils/cancellation.js';\r\nimport type { Stream } from '../utils/stream.js';\r\nimport { stream } from '../utils/stream.js';\r\nimport type { URI } from '../utils/uri-utils.js';\r\nimport { UriUtils } from '../utils/uri-utils.js';\r\nimport type { ReferenceDescription } from './ast-descriptions.js';\r\nimport type { LangiumDocument, LangiumDocuments } from './documents.js';\r\n\r\n/**\r\n * The index manager is responsible for keeping metadata about symbols and cross-references\r\n * in the workspace. It is used to look up symbols in the global scope, mostly during linking\r\n * and completion. This service is shared between all languages of a language server.\r\n */\r\nexport interface IndexManager {\r\n\r\n    /**\r\n     * Removes the specified document URI from the index.\r\n     * Necessary when documents are deleted and not referenceable anymore.\r\n     *\r\n     * @param uri The URI of the document for which index data shall be removed\r\n     */\r\n    remove(uri: URI): void;\r\n\r\n    /**\r\n     * Updates the information about the exportable content of a document inside the index.\r\n     *\r\n     * @param document Document to be updated\r\n     * @param cancelToken Indicates when to cancel the current operation.\r\n     * @throws `OperationCanceled` if a user action occurs during execution\r\n     */\r\n    updateContent(document: LangiumDocument, cancelToken?: CancellationToken): Promise<void>;\r\n\r\n    /**\r\n     * Updates the information about the cross-references of a document inside the index.\r\n     *\r\n     * @param document Document to be updated\r\n     * @param cancelToken Indicates when to cancel the current operation.\r\n     * @throws `OperationCanceled` if a user action occurs during execution\r\n     */\r\n    updateReferences(document: LangiumDocument, cancelToken?: CancellationToken): Promise<void>;\r\n\r\n    /**\r\n     * Determine whether the given document could be affected by changes of the documents\r\n     * identified by the given URIs (second parameter). The document is typically regarded as\r\n     * affected if it contains a reference to any of the changed files.\r\n     *\r\n     * @param document Document to check whether it's affected\r\n     * @param changedUris URIs of the changed documents\r\n     */\r\n    isAffected(document: LangiumDocument, changedUris: Set<string>): boolean;\r\n\r\n    /**\r\n     * Compute a list of all exported elements, optionally filtered using a type identifier and document URIs.\r\n     *\r\n     * @param nodeType The type to filter with, or `undefined` to return descriptions of all types.\r\n     * @param uris If specified, only returns elements from the given URIs.\r\n     * @returns a `Stream` containing all globally visible nodes (of a given type).\r\n     */\r\n    allElements(nodeType?: string, uris?: Set<string>): Stream<AstNodeDescription>;\r\n\r\n    /**\r\n     * Returns all known references that are pointing to the given `targetNode`.\r\n     *\r\n     * @param targetNode the `AstNode` to look up references for\r\n     * @param astNodePath the path that points to the `targetNode` inside the document. See also `AstNodeLocator`\r\n     *\r\n     * @returns a `Stream` of references that are targeting the `targetNode`\r\n     */\r\n    findAllReferences(targetNode: AstNode, astNodePath: string): Stream<ReferenceDescription>;\r\n\r\n}\r\n\r\nexport class DefaultIndexManager implements IndexManager {\r\n\r\n    protected readonly serviceRegistry: ServiceRegistry;\r\n    protected readonly documents: LangiumDocuments;\r\n    protected readonly astReflection: AstReflection;\r\n\r\n    /**\r\n     * The symbol index stores all `AstNodeDescription` items exported by a document.\r\n     * The key used in this map is the string representation of the specific document URI.\r\n     */\r\n    protected readonly symbolIndex = new Map<string, AstNodeDescription[]>();\r\n    /**\r\n     * This is a cache for the `allElements()` method.\r\n     * It caches the descriptions from `symbolIndex` grouped by types.\r\n     */\r\n    protected readonly symbolByTypeIndex = new ContextCache<string, string, AstNodeDescription[]>();\r\n    /**\r\n     * This index keeps track of all `ReferenceDescription` items exported by a document.\r\n     * This is used to compute which elements are affected by a document change\r\n     * and for finding references to an AST node.\r\n     */\r\n    protected readonly referenceIndex = new Map<string, ReferenceDescription[]>();\r\n\r\n    constructor(services: LangiumSharedCoreServices) {\r\n        this.documents = services.workspace.LangiumDocuments;\r\n        this.serviceRegistry = services.ServiceRegistry;\r\n        this.astReflection = services.AstReflection;\r\n    }\r\n\r\n    findAllReferences(targetNode: AstNode, astNodePath: string): Stream<ReferenceDescription> {\r\n        const targetDocUri = getDocument(targetNode).uri;\r\n        const result: ReferenceDescription[] = [];\r\n        this.referenceIndex.forEach(docRefs => {\r\n            docRefs.forEach(refDescr => {\r\n                if (UriUtils.equals(refDescr.targetUri, targetDocUri) && refDescr.targetPath === astNodePath) {\r\n                    result.push(refDescr);\r\n                }\r\n            });\r\n        });\r\n        return stream(result);\r\n    }\r\n\r\n    allElements(nodeType?: string, uris?: Set<string>): Stream<AstNodeDescription> {\r\n        let documentUris = stream(this.symbolIndex.keys());\r\n        if (uris) {\r\n            documentUris = documentUris.filter(uri => !uris || uris.has(uri));\r\n        }\r\n        return documentUris\r\n            .map(uri => this.getFileDescriptions(uri, nodeType))\r\n            .flat();\r\n    }\r\n\r\n    protected getFileDescriptions(uri: string, nodeType?: string): AstNodeDescription[] {\r\n        if (!nodeType) {\r\n            return this.symbolIndex.get(uri) ?? [];\r\n        }\r\n        const descriptions = this.symbolByTypeIndex.get(uri, nodeType, () => {\r\n            const allFileDescriptions = this.symbolIndex.get(uri) ?? [];\r\n            return allFileDescriptions.filter(e => this.astReflection.isSubtype(e.type, nodeType));\r\n        });\r\n        return descriptions;\r\n    }\r\n\r\n    remove(uri: URI): void {\r\n        const uriString = uri.toString();\r\n        this.symbolIndex.delete(uriString);\r\n        this.symbolByTypeIndex.clear(uriString);\r\n        this.referenceIndex.delete(uriString);\r\n    }\r\n\r\n    async updateContent(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<void> {\r\n        const services = this.serviceRegistry.getServices(document.uri);\r\n        const exports = await services.references.ScopeComputation.computeExports(document, cancelToken);\r\n        const uri = document.uri.toString();\r\n        this.symbolIndex.set(uri, exports);\r\n        this.symbolByTypeIndex.clear(uri);\r\n    }\r\n\r\n    async updateReferences(document: LangiumDocument, cancelToken = CancellationToken.None): Promise<void> {\r\n        const services = this.serviceRegistry.getServices(document.uri);\r\n        const indexData = await services.workspace.ReferenceDescriptionProvider.createDescriptions(document, cancelToken);\r\n        this.referenceIndex.set(document.uri.toString(), indexData);\r\n    }\r\n\r\n    isAffected(document: LangiumDocument, changedUris: Set<string>): boolean {\r\n        const references = this.referenceIndex.get(document.uri.toString());\r\n        if (!references) {\r\n            return false;\r\n        }\r\n        return references.some(ref => !ref.local && changedUris.has(ref.targetUri.toString()));\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { InitializeParams, InitializedParams } from 'vscode-languageserver-protocol';\r\nimport type { WorkspaceFolder } from 'vscode-languageserver-types';\r\nimport type { ServiceRegistry } from '../service-registry.js';\r\nimport type { LangiumSharedCoreServices } from '../services.js';\r\nimport { CancellationToken } from '../utils/cancellation.js';\r\nimport { Deferred, interruptAndCheck } from '../utils/promise-utils.js';\r\nimport { URI, UriUtils } from '../utils/uri-utils.js';\r\nimport type { BuildOptions, DocumentBuilder } from './document-builder.js';\r\nimport type { LangiumDocument, LangiumDocuments } from './documents.js';\r\nimport type { FileSystemNode, FileSystemProvider } from './file-system-provider.js';\r\nimport type { WorkspaceLock } from './workspace-lock.js';\r\n\r\n// export type WorkspaceFolder from 'vscode-languageserver-types' for convenience,\r\n//  is supposed to avoid confusion as 'WorkspaceFolder' might accidentally be imported via 'vscode-languageclient'\r\nexport type { WorkspaceFolder };\r\n\r\n/**\r\n * The workspace manager is responsible for finding source files in the workspace.\r\n * This service is shared between all languages of a language server.\r\n */\r\nexport interface WorkspaceManager {\r\n\r\n    /** The options used for the initial workspace build. */\r\n    initialBuildOptions: BuildOptions | undefined;\r\n\r\n    /**\r\n     * A promise that resolves when the workspace manager is ready to be used.\r\n     * Use this to ensure that the workspace manager has finished its initialization.\r\n     */\r\n    readonly ready: Promise<void>;\r\n\r\n    /**\r\n     * The workspace folders of the current workspace.\r\n     * Available only after the `ready` promise resolves.\r\n     */\r\n    get workspaceFolders(): readonly WorkspaceFolder[] | undefined;\r\n\r\n    /**\r\n     * When used in a language server context, this method is called when the server receives\r\n     * the `initialize` request.\r\n     */\r\n    initialize(params: InitializeParams): void;\r\n\r\n    /**\r\n     * When used in a language server context, this method is called when the server receives\r\n     * the `initialized` notification.\r\n     */\r\n    initialized(params: InitializedParams): Promise<void>;\r\n\r\n    /**\r\n     * Does the initial indexing of workspace folders.\r\n     * Collects information about exported and referenced AstNodes in\r\n     * each language file and stores it locally.\r\n     *\r\n     * @param folders The set of workspace folders to be indexed.\r\n     * @param cancelToken A cancellation token that can be used to cancel the operation.\r\n     *\r\n     * @throws OperationCancelled if a cancellation event has been detected\r\n     */\r\n    initializeWorkspace(folders: WorkspaceFolder[], cancelToken?: CancellationToken): Promise<void>;\r\n\r\n}\r\n\r\nexport class DefaultWorkspaceManager implements WorkspaceManager {\r\n\r\n    initialBuildOptions: BuildOptions = {};\r\n\r\n    protected readonly serviceRegistry: ServiceRegistry;\r\n    protected readonly langiumDocuments: LangiumDocuments;\r\n    protected readonly documentBuilder: DocumentBuilder;\r\n    protected readonly fileSystemProvider: FileSystemProvider;\r\n    protected readonly mutex: WorkspaceLock;\r\n    protected readonly _ready = new Deferred<void>();\r\n    protected folders?: WorkspaceFolder[];\r\n\r\n    constructor(services: LangiumSharedCoreServices) {\r\n        this.serviceRegistry = services.ServiceRegistry;\r\n        this.langiumDocuments = services.workspace.LangiumDocuments;\r\n        this.documentBuilder = services.workspace.DocumentBuilder;\r\n        this.fileSystemProvider = services.workspace.FileSystemProvider;\r\n        this.mutex = services.workspace.WorkspaceLock;\r\n    }\r\n\r\n    get ready(): Promise<void> {\r\n        return this._ready.promise;\r\n    }\r\n\r\n    get workspaceFolders(): readonly WorkspaceFolder[] | undefined {\r\n        return this.folders;\r\n    }\r\n\r\n    initialize(params: InitializeParams): void {\r\n        this.folders = params.workspaceFolders ?? undefined;\r\n    }\r\n\r\n    initialized(_params: InitializedParams): Promise<void> {\r\n        // Initialize the workspace even if there are no workspace folders\r\n        // We still want to load additional documents (language library or similar) during initialization\r\n        return this.mutex.write(token => this.initializeWorkspace(this.folders ?? [], token));\r\n    }\r\n\r\n    async initializeWorkspace(folders: WorkspaceFolder[], cancelToken = CancellationToken.None): Promise<void> {\r\n        const documents = await this.performStartup(folders);\r\n        // Only after creating all documents do we check whether we need to cancel the initialization\r\n        // The document builder will later pick up on all unprocessed documents\r\n        await interruptAndCheck(cancelToken);\r\n        await this.documentBuilder.build(documents, this.initialBuildOptions, cancelToken);\r\n    }\r\n\r\n    /**\r\n     * Performs the uninterruptable startup sequence of the workspace manager.\r\n     * This methods loads all documents in the workspace and other documents and returns them.\r\n     */\r\n    protected async performStartup(folders: WorkspaceFolder[]): Promise<LangiumDocument[]> {\r\n        const fileExtensions = this.serviceRegistry.all.flatMap(e => e.LanguageMetaData.fileExtensions);\r\n        const documents: LangiumDocument[] = [];\r\n        const collector = (document: LangiumDocument) => {\r\n            documents.push(document);\r\n            if (!this.langiumDocuments.hasDocument(document.uri)) {\r\n                this.langiumDocuments.addDocument(document);\r\n            }\r\n        };\r\n        // Even though we don't await the initialization of the workspace manager,\r\n        // we can still assume that all library documents and file documents are loaded by the time we start building documents.\r\n        // The mutex prevents anything from performing a workspace build until we check the cancellation token\r\n        await this.loadAdditionalDocuments(folders, collector);\r\n        await Promise.all(\r\n            folders.map(wf => [wf, this.getRootFolder(wf)] as [WorkspaceFolder, URI])\r\n                .map(async entry => this.traverseFolder(...entry, fileExtensions, collector))\r\n        );\r\n        this._ready.resolve();\r\n        return documents;\r\n    }\r\n\r\n    /**\r\n     * Load all additional documents that shall be visible in the context of the given workspace\r\n     * folders and add them to the collector. This can be used to include built-in libraries of\r\n     * your language, which can be either loaded from provided files or constructed in memory.\r\n     */\r\n    protected loadAdditionalDocuments(_folders: WorkspaceFolder[], _collector: (document: LangiumDocument) => void): Promise<void> {\r\n        return Promise.resolve();\r\n    }\r\n\r\n    /**\r\n     * Determine the root folder of the source documents in the given workspace folder.\r\n     * The default implementation returns the URI of the workspace folder, but you can override\r\n     * this to return a subfolder like `src` instead.\r\n     */\r\n    protected getRootFolder(workspaceFolder: WorkspaceFolder): URI {\r\n        return URI.parse(workspaceFolder.uri);\r\n    }\r\n\r\n    /**\r\n     * Traverse the file system folder identified by the given URI and its subfolders. All\r\n     * contained files that match the file extensions are added to the collector.\r\n     */\r\n    protected async traverseFolder(workspaceFolder: WorkspaceFolder, folderPath: URI, fileExtensions: string[], collector: (document: LangiumDocument) => void): Promise<void> {\r\n        const content = await this.fileSystemProvider.readDirectory(folderPath);\r\n        await Promise.all(content.map(async entry => {\r\n            if (this.includeEntry(workspaceFolder, entry, fileExtensions)) {\r\n                if (entry.isDirectory) {\r\n                    await this.traverseFolder(workspaceFolder, entry.uri, fileExtensions, collector);\r\n                } else if (entry.isFile) {\r\n                    const document = await this.langiumDocuments.getOrCreateDocument(entry.uri);\r\n                    collector(document);\r\n                }\r\n            }\r\n        }));\r\n    }\r\n\r\n    /**\r\n     * Determine whether the given folder entry shall be included while indexing the workspace.\r\n     */\r\n    protected includeEntry(_workspaceFolder: WorkspaceFolder, entry: FileSystemNode, fileExtensions: string[]): boolean {\r\n        const name = UriUtils.basename(entry.uri);\r\n        if (name.startsWith('.')) {\r\n            return false;\r\n        }\r\n        if (entry.isDirectory) {\r\n            return name !== 'node_modules' && name !== 'out';\r\n        } else if (entry.isFile) {\r\n            const extname = UriUtils.extname(entry.uri);\r\n            return fileExtensions.includes(extname);\r\n        }\r\n        return false;\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { ILexerErrorMessageProvider, ILexingError, IMultiModeLexerDefinition, IToken, TokenType, TokenTypeDictionary, TokenVocabulary } from 'chevrotain';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport { Lexer as ChevrotainLexer, defaultLexerErrorProvider } from 'chevrotain';\r\nimport type { LexingReport, TokenBuilder } from './token-builder.js';\r\n\r\nexport class DefaultLexerErrorMessageProvider implements ILexerErrorMessageProvider {\r\n\r\n    buildUnexpectedCharactersMessage(fullText: string, startOffset: number, length: number, line?: number, column?: number): string {\r\n        return defaultLexerErrorProvider.buildUnexpectedCharactersMessage(fullText, startOffset, length, line, column);\r\n    }\r\n\r\n    buildUnableToPopLexerModeMessage(token: IToken): string {\r\n        return defaultLexerErrorProvider.buildUnableToPopLexerModeMessage(token);\r\n    }\r\n}\r\n\r\nexport interface LexerResult {\r\n    /**\r\n     * A list of all tokens that were lexed from the input.\r\n     *\r\n     * Note that Langium requires the optional properties\r\n     * `startLine`, `startColumn`, `endOffset`, `endLine` and `endColumn` to be set on each token.\r\n     */\r\n    tokens: IToken[];\r\n    /**\r\n     * Contains hidden tokens, usually comments.\r\n     */\r\n    hidden: IToken[];\r\n    errors: ILexingError[];\r\n    report?: LexingReport;\r\n}\r\n\r\nexport type TokenizeMode = 'full' | 'partial';\r\n\r\nexport interface TokenizeOptions {\r\n    mode?: TokenizeMode;\r\n}\r\n\r\nexport const DEFAULT_TOKENIZE_OPTIONS: TokenizeOptions = { mode: 'full' };\r\n\r\nexport interface Lexer {\r\n    readonly definition: TokenTypeDictionary;\r\n    tokenize(text: string, options?: TokenizeOptions): LexerResult;\r\n}\r\n\r\nexport class DefaultLexer implements Lexer {\r\n\r\n    protected readonly tokenBuilder: TokenBuilder;\r\n    protected readonly errorMessageProvider: ILexerErrorMessageProvider;\r\n    protected tokenTypes: TokenTypeDictionary;\r\n    protected chevrotainLexer: ChevrotainLexer;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.errorMessageProvider = services.parser.LexerErrorMessageProvider;\r\n        this.tokenBuilder = services.parser.TokenBuilder;\r\n        const tokens = this.tokenBuilder.buildTokens(services.Grammar, {\r\n            caseInsensitive: services.LanguageMetaData.caseInsensitive\r\n        });\r\n        this.tokenTypes = this.toTokenTypeDictionary(tokens);\r\n        const lexerTokens = isTokenTypeDictionary(tokens) ? Object.values(tokens) : tokens;\r\n        const production = services.LanguageMetaData.mode === 'production';\r\n        this.chevrotainLexer = new ChevrotainLexer(lexerTokens, {\r\n            positionTracking: 'full',\r\n            skipValidations: production,\r\n            errorMessageProvider: this.errorMessageProvider\r\n        });\r\n    }\r\n\r\n    get definition(): TokenTypeDictionary {\r\n        return this.tokenTypes;\r\n    }\r\n\r\n    tokenize(text: string, _options: TokenizeOptions = DEFAULT_TOKENIZE_OPTIONS): LexerResult {\r\n        const chevrotainResult = this.chevrotainLexer.tokenize(text);\r\n        return {\r\n            tokens: chevrotainResult.tokens,\r\n            errors: chevrotainResult.errors,\r\n            hidden: chevrotainResult.groups.hidden ?? [],\r\n            report: this.tokenBuilder.flushLexingReport?.(text)\r\n        };\r\n    }\r\n\r\n    protected toTokenTypeDictionary(buildTokens: TokenVocabulary): TokenTypeDictionary {\r\n        if (isTokenTypeDictionary(buildTokens)) return buildTokens;\r\n        const tokens = isIMultiModeLexerDefinition(buildTokens) ? Object.values(buildTokens.modes).flat() : buildTokens;\r\n        const res: TokenTypeDictionary = {};\r\n        tokens.forEach(token => res[token.name] = token);\r\n        return res;\r\n    }\r\n}\r\n\r\n/**\r\n * Returns a check whether the given TokenVocabulary is TokenType array\r\n */\r\nexport function isTokenTypeArray(tokenVocabulary: TokenVocabulary): tokenVocabulary is TokenType[] {\r\n    return Array.isArray(tokenVocabulary) && (tokenVocabulary.length === 0 || 'name' in tokenVocabulary[0]);\r\n}\r\n\r\n/**\r\n * Returns a check whether the given TokenVocabulary is IMultiModeLexerDefinition\r\n */\r\nexport function isIMultiModeLexerDefinition(tokenVocabulary: TokenVocabulary): tokenVocabulary is IMultiModeLexerDefinition {\r\n    return tokenVocabulary && 'modes' in tokenVocabulary && 'defaultMode' in tokenVocabulary;\r\n}\r\n\r\n/**\r\n * Returns a check whether the given TokenVocabulary is TokenTypeDictionary\r\n */\r\nexport function isTokenTypeDictionary(tokenVocabulary: TokenVocabulary): tokenVocabulary is TokenTypeDictionary {\r\n    return !isTokenTypeArray(tokenVocabulary) && !isIMultiModeLexerDefinition(tokenVocabulary);\r\n}\r\n","/******************************************************************************\r\n * Copyright 2023 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { Position, Range } from 'vscode-languageserver-types';\r\nimport type { CstNode } from '../syntax-tree.js';\r\nimport { NEWLINE_REGEXP, escapeRegExp } from '../utils/regexp-utils.js';\r\nimport { URI } from '../utils/uri-utils.js';\r\n\r\nexport interface JSDocComment extends JSDocValue {\r\n    readonly elements: JSDocElement[]\r\n    getTag(name: string): JSDocTag | undefined\r\n    getTags(name: string): JSDocTag[]\r\n}\r\n\r\nexport type JSDocElement = JSDocParagraph | JSDocTag;\r\n\r\nexport type JSDocInline = JSDocTag | JSDocLine;\r\n\r\nexport interface JSDocValue {\r\n    /**\r\n     * Represents the range that this JSDoc element occupies.\r\n     * If the JSDoc was parsed from a `CstNode`, the range will represent the location in the source document.\r\n     */\r\n    readonly range: Range\r\n    /**\r\n     * Renders this JSDoc element to a plain text representation.\r\n     */\r\n    toString(): string\r\n    /**\r\n     * Renders this JSDoc element to a markdown representation.\r\n     *\r\n     * @param options Rendering options to customize the markdown result.\r\n     */\r\n    toMarkdown(options?: JSDocRenderOptions): string\r\n}\r\n\r\nexport interface JSDocParagraph extends JSDocValue {\r\n    readonly inlines: JSDocInline[]\r\n}\r\n\r\nexport interface JSDocLine extends JSDocValue {\r\n    readonly text: string\r\n}\r\n\r\nexport interface JSDocTag extends JSDocValue {\r\n    readonly name: string\r\n    readonly content: JSDocParagraph\r\n    readonly inline: boolean\r\n}\r\n\r\nexport interface JSDocParseOptions {\r\n    /**\r\n     * The start symbol of your comment format. Defaults to `/**`.\r\n     */\r\n    readonly start?: RegExp | string\r\n    /**\r\n     * The symbol that start a line of your comment format. Defaults to `*`.\r\n     */\r\n    readonly line?: RegExp | string\r\n    /**\r\n     * The end symbol of your comment format. Defaults to `*\\/`.\r\n     */\r\n    readonly end?: RegExp | string\r\n}\r\n\r\nexport interface JSDocRenderOptions {\r\n    /**\r\n     * Determines the style for rendering tags. Defaults to `italic`.\r\n     */\r\n    tag?: 'plain' | 'italic' | 'bold' | 'bold-italic'\r\n    /**\r\n     * Determines the default for rendering `@link` tags. Defaults to `plain`.\r\n     */\r\n    link?: 'code' | 'plain'\r\n    /**\r\n     * Custom tag rendering function.\r\n     * Return a markdown formatted tag or `undefined` to fall back to the default rendering.\r\n     */\r\n    renderTag?(tag: JSDocTag): string | undefined\r\n    /**\r\n     * Custom link rendering function. Accepts a link target and a display value for the link.\r\n     * Return a markdown formatted link with the format `[$display]($link)` or `undefined` if the link is not a valid target.\r\n     */\r\n    renderLink?(link: string, display: string): string | undefined\r\n}\r\n\r\n/**\r\n * Parses a JSDoc from a `CstNode` containing a comment.\r\n *\r\n * @param node A `CstNode` from a parsed Langium document.\r\n * @param options Parsing options specialized to your language. See {@link JSDocParseOptions}.\r\n */\r\nexport function parseJSDoc(node: CstNode, options?: JSDocParseOptions): JSDocComment;\r\n/**\r\n * Parses a JSDoc from a string comment.\r\n *\r\n * @param content A string containing the source of the JSDoc comment.\r\n * @param start The start position the comment occupies in the source document.\r\n * @param options Parsing options specialized to your language. See {@link JSDocParseOptions}.\r\n */\r\nexport function parseJSDoc(content: string, start?: Position, options?: JSDocParseOptions): JSDocComment;\r\nexport function parseJSDoc(node: CstNode | string, start?: Position | JSDocParseOptions, options?: JSDocParseOptions): JSDocComment {\r\n    let opts: JSDocParseOptions | undefined;\r\n    let position: Position | undefined;\r\n    if (typeof node === 'string') {\r\n        position = start as Position | undefined;\r\n        opts = options as JSDocParseOptions | undefined;\r\n    } else {\r\n        position = node.range.start;\r\n        opts = start as JSDocParseOptions | undefined;\r\n    }\r\n    if (!position) {\r\n        position = Position.create(0, 0);\r\n    }\r\n\r\n    const lines = getLines(node);\r\n    const normalizedOptions = normalizeOptions(opts);\r\n\r\n    const tokens = tokenize({\r\n        lines,\r\n        position,\r\n        options: normalizedOptions\r\n    });\r\n\r\n    return parseJSDocComment({\r\n        index: 0,\r\n        tokens,\r\n        position\r\n    });\r\n}\r\n\r\nexport function isJSDoc(node: CstNode | string, options?: JSDocParseOptions): boolean {\r\n    const normalizedOptions = normalizeOptions(options);\r\n    const lines = getLines(node);\r\n    if (lines.length === 0) {\r\n        return false;\r\n    }\r\n\r\n    const first = lines[0];\r\n    const last = lines[lines.length - 1];\r\n    const firstRegex = normalizedOptions.start;\r\n    const lastRegex = normalizedOptions.end;\r\n\r\n    return Boolean(firstRegex?.exec(first)) && Boolean(lastRegex?.exec(last));\r\n}\r\n\r\nfunction getLines(node: CstNode | string): string[] {\r\n    let content = '';\r\n    if (typeof node === 'string') {\r\n        content = node;\r\n    } else {\r\n        content = node.text;\r\n    }\r\n    const lines = content.split(NEWLINE_REGEXP);\r\n    return lines;\r\n}\r\n\r\n// Tokenization\r\n\r\ninterface JSDocToken {\r\n    type: 'text' | 'tag' | 'inline-tag' | 'break'\r\n    content: string\r\n    range: Range\r\n}\r\n\r\nconst tagRegex = /\\s*(@([\\p{L}][\\p{L}\\p{N}]*)?)/uy;\r\nconst inlineTagRegex = /\\{(@[\\p{L}][\\p{L}\\p{N}]*)(\\s*)([^\\r\\n}]+)?\\}/gu;\r\n\r\nfunction tokenize(context: TokenizationContext): JSDocToken[] {\r\n    const tokens: JSDocToken[] = [];\r\n    let currentLine = context.position.line;\r\n    let currentCharacter = context.position.character;\r\n    for (let i = 0; i < context.lines.length; i++) {\r\n        const first = i === 0;\r\n        const last = i === context.lines.length - 1;\r\n        let line = context.lines[i];\r\n        let index = 0;\r\n\r\n        if (first && context.options.start) {\r\n            const match = context.options.start?.exec(line);\r\n            if (match) {\r\n                index = match.index + match[0].length;\r\n            }\r\n        } else {\r\n            const match = context.options.line?.exec(line);\r\n            if (match) {\r\n                index = match.index + match[0].length;\r\n            }\r\n        }\r\n        if (last) {\r\n            const match = context.options.end?.exec(line);\r\n            if (match) {\r\n                line = line.substring(0, match.index);\r\n            }\r\n        }\r\n\r\n        line = line.substring(0, lastCharacter(line));\r\n        const whitespaceEnd = skipWhitespace(line, index);\r\n\r\n        if (whitespaceEnd >= line.length) {\r\n            // Only create a break token when we already have previous tokens\r\n            if (tokens.length > 0) {\r\n                const position = Position.create(currentLine, currentCharacter);\r\n                tokens.push({\r\n                    type: 'break',\r\n                    content: '',\r\n                    range: Range.create(position, position)\r\n                });\r\n            }\r\n        } else {\r\n            tagRegex.lastIndex = index;\r\n            const tagMatch = tagRegex.exec(line);\r\n            if (tagMatch) {\r\n                const fullMatch = tagMatch[0];\r\n                const value = tagMatch[1];\r\n                const start = Position.create(currentLine, currentCharacter + index);\r\n                const end = Position.create(currentLine, currentCharacter + index + fullMatch.length);\r\n                tokens.push({\r\n                    type: 'tag',\r\n                    content: value,\r\n                    range: Range.create(start, end)\r\n                });\r\n                index += fullMatch.length;\r\n                index = skipWhitespace(line, index);\r\n            }\r\n\r\n            if (index < line.length) {\r\n                const rest = line.substring(index);\r\n                const inlineTagMatches = Array.from(rest.matchAll(inlineTagRegex));\r\n                tokens.push(...buildInlineTokens(inlineTagMatches, rest, currentLine, currentCharacter + index));\r\n            }\r\n        }\r\n\r\n        currentLine++;\r\n        currentCharacter = 0;\r\n    }\r\n\r\n    // Remove last break token if there is one\r\n    if (tokens.length > 0 && tokens[tokens.length - 1].type === 'break') {\r\n        return tokens.slice(0, -1);\r\n    }\r\n\r\n    return tokens;\r\n}\r\n\r\nfunction buildInlineTokens(tags: RegExpMatchArray[], line: string, lineIndex: number, characterIndex: number): JSDocToken[] {\r\n    const tokens: JSDocToken[] = [];\r\n\r\n    if (tags.length === 0) {\r\n        const start = Position.create(lineIndex, characterIndex);\r\n        const end = Position.create(lineIndex, characterIndex + line.length);\r\n        tokens.push({\r\n            type: 'text',\r\n            content: line,\r\n            range: Range.create(start, end)\r\n        });\r\n    } else {\r\n        let lastIndex = 0;\r\n        for (const match of tags) {\r\n            const matchIndex = match.index!;\r\n            const startContent = line.substring(lastIndex, matchIndex);\r\n            if (startContent.length > 0) {\r\n                tokens.push({\r\n                    type: 'text',\r\n                    content: line.substring(lastIndex, matchIndex),\r\n                    range: Range.create(\r\n                        Position.create(lineIndex, lastIndex + characterIndex),\r\n                        Position.create(lineIndex, matchIndex + characterIndex)\r\n                    )\r\n                });\r\n            }\r\n            let offset = startContent.length + 1;\r\n            const tagName = match[1];\r\n            tokens.push({\r\n                type: 'inline-tag',\r\n                content: tagName,\r\n                range: Range.create(\r\n                    Position.create(lineIndex, lastIndex + offset + characterIndex),\r\n                    Position.create(lineIndex, lastIndex + offset + tagName.length + characterIndex)\r\n                )\r\n            });\r\n            offset += tagName.length;\r\n            if (match.length === 4) {\r\n                offset += match[2].length;\r\n                const value = match[3];\r\n                tokens.push({\r\n                    type: 'text',\r\n                    content: value,\r\n                    range: Range.create(\r\n                        Position.create(lineIndex, lastIndex + offset + characterIndex),\r\n                        Position.create(lineIndex, lastIndex + offset + value.length + characterIndex)\r\n                    )\r\n                });\r\n            } else {\r\n                tokens.push({\r\n                    type: 'text',\r\n                    content: '',\r\n                    range: Range.create(\r\n                        Position.create(lineIndex, lastIndex + offset + characterIndex),\r\n                        Position.create(lineIndex, lastIndex + offset + characterIndex)\r\n                    )\r\n                });\r\n            }\r\n            lastIndex = matchIndex + match[0].length;\r\n        }\r\n        const endContent = line.substring(lastIndex);\r\n        if (endContent.length > 0) {\r\n            tokens.push({\r\n                type: 'text',\r\n                content: endContent,\r\n                range: Range.create(\r\n                    Position.create(lineIndex, lastIndex + characterIndex),\r\n                    Position.create(lineIndex, lastIndex + characterIndex + endContent.length)\r\n                )\r\n            });\r\n        }\r\n    }\r\n\r\n    return tokens;\r\n}\r\n\r\nconst nonWhitespaceRegex = /\\S/;\r\nconst whitespaceEndRegex = /\\s*$/;\r\n\r\nfunction skipWhitespace(line: string, index: number): number {\r\n    const match = line.substring(index).match(nonWhitespaceRegex);\r\n    if (match) {\r\n        return index + match.index!;\r\n    } else {\r\n        return line.length;\r\n    }\r\n}\r\n\r\nfunction lastCharacter(line: string): number | undefined {\r\n    const match = line.match(whitespaceEndRegex);\r\n    if (match && typeof match.index === 'number') {\r\n        return match.index;\r\n    }\r\n    return undefined;\r\n}\r\n\r\n// Parsing\r\n\r\nfunction parseJSDocComment(context: ParseContext): JSDocComment {\r\n    const startPosition: Position = Position.create(context.position.line, context.position.character);\r\n    if (context.tokens.length === 0) {\r\n        return new JSDocCommentImpl([], Range.create(startPosition, startPosition));\r\n    }\r\n    const elements: JSDocElement[] = [];\r\n    while (context.index < context.tokens.length) {\r\n        const element = parseJSDocElement(context, elements[elements.length - 1]);\r\n        if (element) {\r\n            elements.push(element);\r\n        }\r\n    }\r\n    const start = elements[0]?.range.start ?? startPosition;\r\n    const end = elements[elements.length - 1]?.range.end ?? startPosition;\r\n    return new JSDocCommentImpl(elements, Range.create(start, end));\r\n}\r\n\r\nfunction parseJSDocElement(context: ParseContext, last?: JSDocElement): JSDocElement | undefined {\r\n    const next = context.tokens[context.index];\r\n    if (next.type === 'tag') {\r\n        return parseJSDocTag(context, false);\r\n    } else if (next.type === 'text' || next.type === 'inline-tag') {\r\n        return parseJSDocText(context);\r\n    } else {\r\n        appendEmptyLine(next, last);\r\n        context.index++;\r\n        return undefined;\r\n    }\r\n}\r\n\r\nfunction appendEmptyLine(token: JSDocToken, element?: JSDocElement): void {\r\n    if (element) {\r\n        const line = new JSDocLineImpl('', token.range);\r\n        if ('inlines' in element) {\r\n            element.inlines.push(line);\r\n        } else {\r\n            element.content.inlines.push(line);\r\n        }\r\n    }\r\n}\r\n\r\nfunction parseJSDocText(context: ParseContext): JSDocParagraph {\r\n    let token = context.tokens[context.index];\r\n    const firstToken = token;\r\n    let lastToken = token;\r\n    const lines: JSDocInline[] = [];\r\n    while (token && token.type !== 'break' && token.type !== 'tag') {\r\n        lines.push(parseJSDocInline(context));\r\n        lastToken = token;\r\n        token = context.tokens[context.index];\r\n    }\r\n    return new JSDocTextImpl(lines, Range.create(firstToken.range.start, lastToken.range.end));\r\n}\r\n\r\nfunction parseJSDocInline(context: ParseContext): JSDocInline {\r\n    const token = context.tokens[context.index];\r\n    if (token.type === 'inline-tag') {\r\n        return parseJSDocTag(context, true);\r\n    } else {\r\n        return parseJSDocLine(context);\r\n    }\r\n}\r\n\r\nfunction parseJSDocTag(context: ParseContext, inline: boolean): JSDocTag {\r\n    const tagToken = context.tokens[context.index++];\r\n    const name = tagToken.content.substring(1);\r\n    const nextToken = context.tokens[context.index];\r\n    if (nextToken?.type === 'text') {\r\n        if (inline) {\r\n            const docLine = parseJSDocLine(context);\r\n            return new JSDocTagImpl(\r\n                name,\r\n                new JSDocTextImpl([docLine], docLine.range),\r\n                inline,\r\n                Range.create(tagToken.range.start, docLine.range.end)\r\n            );\r\n        } else {\r\n            const textDoc = parseJSDocText(context);\r\n            return new JSDocTagImpl(\r\n                name,\r\n                textDoc,\r\n                inline,\r\n                Range.create(tagToken.range.start, textDoc.range.end)\r\n            );\r\n        }\r\n    } else {\r\n        const range = tagToken.range;\r\n        return new JSDocTagImpl(name, new JSDocTextImpl([], range), inline, range);\r\n    }\r\n}\r\n\r\nfunction parseJSDocLine(context: ParseContext): JSDocLine {\r\n    const token = context.tokens[context.index++];\r\n    return new JSDocLineImpl(token.content, token.range);\r\n}\r\n\r\ninterface NormalizedOptions {\r\n    start?: RegExp\r\n    end?: RegExp\r\n    line?: RegExp\r\n}\r\n\r\ninterface TokenizationContext {\r\n    position: Position\r\n    lines: string[]\r\n    options: NormalizedOptions\r\n}\r\n\r\ninterface ParseContext {\r\n    position: Position\r\n    tokens: JSDocToken[]\r\n    index: number\r\n}\r\n\r\nfunction normalizeOptions(options?: JSDocParseOptions): NormalizedOptions {\r\n    if (!options) {\r\n        return normalizeOptions({\r\n            start: '/**',\r\n            end: '*/',\r\n            line: '*'\r\n        });\r\n    }\r\n    const { start, end, line } = options;\r\n    return {\r\n        start: normalizeOption(start, true),\r\n        end: normalizeOption(end, false),\r\n        line: normalizeOption(line, true)\r\n    };\r\n}\r\n\r\nfunction normalizeOption(option: RegExp | string | undefined, start: boolean): RegExp | undefined {\r\n    if (typeof option === 'string' || typeof option === 'object') {\r\n        const escaped = typeof option === 'string' ? escapeRegExp(option) : option.source;\r\n        if (start) {\r\n            return new RegExp(`^\\\\s*${escaped}`);\r\n        } else {\r\n            return new RegExp(`\\\\s*${escaped}\\\\s*$`);\r\n        }\r\n    } else {\r\n        return option;\r\n    }\r\n}\r\n\r\nclass JSDocCommentImpl implements JSDocComment {\r\n\r\n    readonly elements: JSDocElement[];\r\n    readonly range: Range;\r\n\r\n    constructor(elements: JSDocElement[], range: Range) {\r\n        this.elements = elements;\r\n        this.range = range;\r\n    }\r\n\r\n    getTag(name: string): JSDocTag | undefined {\r\n        return this.getAllTags().find(e => e.name === name);\r\n    }\r\n\r\n    getTags(name: string): JSDocTag[] {\r\n        return this.getAllTags().filter(e => e.name === name);\r\n    }\r\n\r\n    private getAllTags(): JSDocTag[] {\r\n        return this.elements.filter((e): e is JSDocTag => 'name' in e);\r\n    }\r\n\r\n    toString(): string {\r\n        let value = '';\r\n        for (const element of this.elements) {\r\n            if (value.length === 0) {\r\n                value = element.toString();\r\n            } else {\r\n                const text = element.toString();\r\n                value += fillNewlines(value) + text;\r\n            }\r\n        }\r\n        return value.trim();\r\n    }\r\n\r\n    toMarkdown(options?: JSDocRenderOptions): string {\r\n        let value = '';\r\n        for (const element of this.elements) {\r\n            if (value.length === 0) {\r\n                value = element.toMarkdown(options);\r\n            } else {\r\n                const text = element.toMarkdown(options);\r\n                value += fillNewlines(value) + text;\r\n            }\r\n        }\r\n        return value.trim();\r\n    }\r\n}\r\n\r\nclass JSDocTagImpl implements JSDocTag {\r\n    name: string;\r\n    content: JSDocParagraph;\r\n    range: Range;\r\n    inline: boolean;\r\n\r\n    constructor(name: string, content: JSDocParagraph, inline: boolean, range: Range) {\r\n        this.name = name;\r\n        this.content = content;\r\n        this.inline = inline;\r\n        this.range = range;\r\n    }\r\n\r\n    toString(): string {\r\n        let text = `@${this.name}`;\r\n        const content = this.content.toString();\r\n        if (this.content.inlines.length === 1) {\r\n            text = `${text} ${content}`;\r\n        } else if (this.content.inlines.length > 1) {\r\n            text = `${text}\\n${content}`;\r\n        }\r\n        if (this.inline) {\r\n            // Inline tags are surrounded by curly braces\r\n            return `{${text}}`;\r\n        } else {\r\n            return text;\r\n        }\r\n    }\r\n\r\n    toMarkdown(options?: JSDocRenderOptions): string {\r\n        return options?.renderTag?.(this) ?? this.toMarkdownDefault(options);\r\n    }\r\n\r\n    private toMarkdownDefault(options?: JSDocRenderOptions): string {\r\n        const content = this.content.toMarkdown(options);\r\n        if (this.inline) {\r\n            const rendered = renderInlineTag(this.name, content, options ?? {});\r\n            if (typeof rendered === 'string') {\r\n                return rendered;\r\n            }\r\n        }\r\n        let marker = '';\r\n        if (options?.tag === 'italic' || options?.tag === undefined) {\r\n            marker = '*';\r\n        } else if (options?.tag === 'bold') {\r\n            marker = '**';\r\n        } else if (options?.tag === 'bold-italic') {\r\n            marker = '***';\r\n        }\r\n        let text = `${marker}@${this.name}${marker}`;\r\n        if (this.content.inlines.length === 1) {\r\n            text = `${text} — ${content}`;\r\n        } else if (this.content.inlines.length > 1) {\r\n            text = `${text}\\n${content}`;\r\n        }\r\n        if (this.inline) {\r\n            // Inline tags are surrounded by curly braces\r\n            return `{${text}}`;\r\n        } else {\r\n            return text;\r\n        }\r\n    }\r\n}\r\n\r\nfunction renderInlineTag(tag: string, content: string, options: JSDocRenderOptions): string | undefined {\r\n    if (tag === 'linkplain' || tag === 'linkcode' || tag === 'link') {\r\n        const index = content.indexOf(' ');\r\n        let display = content;\r\n        if (index > 0) {\r\n            const displayStart = skipWhitespace(content, index);\r\n            display = content.substring(displayStart);\r\n            content = content.substring(0, index);\r\n        }\r\n        if (tag === 'linkcode' || (tag === 'link' && options.link === 'code')) {\r\n            // Surround the display value in a markdown inline code block\r\n            display = `\\`${display}\\``;\r\n        }\r\n        const renderedLink = options.renderLink?.(content, display) ?? renderLinkDefault(content, display);\r\n        return renderedLink;\r\n    }\r\n    return undefined;\r\n}\r\n\r\nfunction renderLinkDefault(content: string, display: string): string {\r\n    try {\r\n        URI.parse(content, true);\r\n        return `[${display}](${content})`;\r\n    } catch {\r\n        return content;\r\n    }\r\n}\r\n\r\nclass JSDocTextImpl implements JSDocParagraph {\r\n    inlines: JSDocInline[];\r\n    range: Range;\r\n\r\n    constructor(lines: JSDocInline[], range: Range) {\r\n        this.inlines = lines;\r\n        this.range = range;\r\n    }\r\n\r\n    toString(): string {\r\n        let text = '';\r\n        for (let i = 0; i < this.inlines.length; i++) {\r\n            const inline = this.inlines[i];\r\n            const next = this.inlines[i + 1];\r\n            text += inline.toString();\r\n            if (next && next.range.start.line > inline.range.start.line) {\r\n                text += '\\n';\r\n            }\r\n        }\r\n        return text;\r\n    }\r\n\r\n    toMarkdown(options?: JSDocRenderOptions): string {\r\n        let text = '';\r\n        for (let i = 0; i < this.inlines.length; i++) {\r\n            const inline = this.inlines[i];\r\n            const next = this.inlines[i + 1];\r\n            text += inline.toMarkdown(options);\r\n            if (next && next.range.start.line > inline.range.start.line) {\r\n                text += '\\n';\r\n            }\r\n        }\r\n        return text;\r\n    }\r\n}\r\n\r\nclass JSDocLineImpl implements JSDocLine {\r\n    text: string;\r\n    range: Range;\r\n\r\n    constructor(text: string, range: Range) {\r\n        this.text = text;\r\n        this.range = range;\r\n    }\r\n\r\n    toString(): string {\r\n        return this.text;\r\n    }\r\n    toMarkdown(): string {\r\n        return this.text;\r\n    }\r\n\r\n}\r\n\r\nfunction fillNewlines(text: string): string {\r\n    if (text.endsWith('\\n')) {\r\n        return '\\n';\r\n    } else {\r\n        return '\\n\\n';\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2023 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode, AstNodeDescription } from '../syntax-tree.js';\r\nimport type { IndexManager } from '../workspace/index-manager.js';\r\nimport type { CommentProvider } from './comment-provider.js';\r\nimport type { JSDocTag } from './jsdoc.js';\r\nimport { getDocument } from '../utils/ast-utils.js';\r\nimport { isJSDoc, parseJSDoc } from './jsdoc.js';\r\n\r\n/**\r\n * Provides documentation for AST nodes.\r\n */\r\nexport interface DocumentationProvider {\r\n    /**\r\n     * Returns a markdown documentation string for the specified AST node.\r\n     *\r\n     * The default implementation `JSDocDocumentationProvider` will inspect the comment associated with the specified node.\r\n     */\r\n    getDocumentation(node: AstNode): string | undefined;\r\n}\r\n\r\nexport class JSDocDocumentationProvider implements DocumentationProvider {\r\n\r\n    protected readonly indexManager: IndexManager;\r\n    protected readonly commentProvider: CommentProvider;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.indexManager = services.shared.workspace.IndexManager;\r\n        this.commentProvider = services.documentation.CommentProvider;\r\n    }\r\n\r\n    getDocumentation(node: AstNode): string | undefined {\r\n        const comment = this.commentProvider.getComment(node);\r\n        if (comment && isJSDoc(comment)) {\r\n            const parsedJSDoc = parseJSDoc(comment);\r\n            return parsedJSDoc.toMarkdown({\r\n                renderLink: (link, display) => {\r\n                    return this.documentationLinkRenderer(node, link, display);\r\n                },\r\n                renderTag: (tag) => {\r\n                    return this.documentationTagRenderer(node, tag);\r\n                }\r\n            });\r\n        }\r\n        return undefined;\r\n    }\r\n\r\n    protected documentationLinkRenderer(node: AstNode, name: string, display: string): string | undefined {\r\n        const description = this.findNameInPrecomputedScopes(node, name) ?? this.findNameInGlobalScope(node, name);\r\n        if (description && description.nameSegment) {\r\n            const line = description.nameSegment.range.start.line + 1;\r\n            const character = description.nameSegment.range.start.character + 1;\r\n            const uri = description.documentUri.with({ fragment: `L${line},${character}` });\r\n            return `[${display}](${uri.toString()})`;\r\n        } else {\r\n            return undefined;\r\n        }\r\n    }\r\n\r\n    protected documentationTagRenderer(_node: AstNode, _tag: JSDocTag): string | undefined {\r\n        // Fall back to the default tag rendering\r\n        return undefined;\r\n    }\r\n\r\n    protected findNameInPrecomputedScopes(node: AstNode, name: string): AstNodeDescription | undefined {\r\n        const document = getDocument(node);\r\n        const precomputed = document.precomputedScopes;\r\n        if (!precomputed) {\r\n            return undefined;\r\n        }\r\n        let currentNode: AstNode | undefined = node;\r\n        do {\r\n            const allDescriptions = precomputed.get(currentNode);\r\n            const description = allDescriptions.find(e => e.name === name);\r\n            if (description) {\r\n                return description;\r\n            }\r\n            currentNode = currentNode.$container;\r\n        } while (currentNode);\r\n\r\n        return undefined;\r\n    }\r\n\r\n    protected findNameInGlobalScope(node: AstNode, name: string): AstNodeDescription | undefined {\r\n        const description = this.indexManager.allElements().find(e => e.name === name);\r\n        return description;\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2023 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { GrammarConfig } from '../languages/grammar-config.js';\r\nimport { isAstNodeWithComment } from '../serializer/json-serializer.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode } from '../syntax-tree.js';\r\nimport { findCommentNode } from '../utils/cst-utils.js';\r\n\r\n/**\r\n * Provides comments for AST nodes.\r\n */\r\nexport interface CommentProvider {\r\n    /**\r\n     * Returns the comment associated with the specified AST node.\r\n     * @param node The AST node to get the comment for.\r\n     * @returns The comment associated with the specified AST node or `undefined` if there is no comment.\r\n     */\r\n    getComment(node: AstNode): string | undefined;\r\n}\r\n\r\nexport class DefaultCommentProvider implements CommentProvider {\r\n    protected readonly grammarConfig: () => GrammarConfig;\r\n    constructor(services: LangiumCoreServices) {\r\n        this.grammarConfig = () => services.parser.GrammarConfig;\r\n    }\r\n    getComment(node: AstNode): string | undefined {\r\n        if(isAstNodeWithComment(node)) {\r\n            return node.$comment;\r\n        }\r\n        return findCommentNode(node.$cstNode, this.grammarConfig().multilineCommentRules)?.text;\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2023 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { CancellationToken } from '../utils/cancellation.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { AstNode } from '../syntax-tree.js';\r\nimport type { LangiumParser, ParseResult } from './langium-parser.js';\r\nimport type { Hydrator } from '../serializer/hydrator.js';\r\nimport type { Event } from '../utils/event.js';\r\nimport { Deferred, OperationCancelled } from '../utils/promise-utils.js';\r\nimport { Emitter } from '../utils/event.js';\r\n\r\n/**\r\n * Async parser that allows cancellation of the current parsing process.\r\n *\r\n * @remarks\r\n * The sync parser implementation is blocking the event loop, which can become quite problematic for large files.\r\n * The default implementation is not actually async. It just wraps the sync parser in a promise. A real implementation would create worker threads or web workers to offload the parsing work.\r\n */\r\nexport interface AsyncParser {\r\n    /**\r\n     * Parses the given text and returns the parse result.\r\n     *\r\n     * @param text The text to parse.\r\n     * @param cancelToken A cancellation token that can be used to cancel the parsing process.\r\n     * @returns A promise that resolves to the parse result.\r\n     *\r\n     * @throws `OperationCancelled` if the parsing process is cancelled.\r\n     */\r\n    parse<T extends AstNode>(text: string, cancelToken: CancellationToken): Promise<ParseResult<T>>;\r\n}\r\n\r\n/**\r\n * Default implementation of the async parser which simply wraps the sync parser in a promise.\r\n *\r\n * @remarks\r\n * A real implementation would create worker threads or web workers to offload the parsing work.\r\n */\r\nexport class DefaultAsyncParser implements AsyncParser {\r\n\r\n    protected readonly syncParser: LangiumParser;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.syncParser = services.parser.LangiumParser;\r\n    }\r\n\r\n    parse<T extends AstNode>(text: string, _cancelToken: CancellationToken): Promise<ParseResult<T>> {\r\n        return Promise.resolve(this.syncParser.parse<T>(text));\r\n    }\r\n}\r\n\r\nexport abstract class AbstractThreadedAsyncParser implements AsyncParser {\r\n\r\n    /**\r\n     * The thread count determines how many threads are used to parse files in parallel.\r\n     * The default value is 8. Decreasing this value increases startup performance, but decreases parallel parsing performance.\r\n     */\r\n    protected threadCount = 8;\r\n    /**\r\n     * The termination delay determines how long the parser waits for a thread to finish after a cancellation request.\r\n     * The default value is 200(ms).\r\n     */\r\n    protected terminationDelay = 200;\r\n    protected workerPool: ParserWorker[] = [];\r\n    protected queue: Array<Deferred<ParserWorker>> = [];\r\n\r\n    protected readonly hydrator: Hydrator;\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.hydrator = services.serializer.Hydrator;\r\n    }\r\n\r\n    protected initializeWorkers(): void {\r\n        while (this.workerPool.length < this.threadCount) {\r\n            const worker = this.createWorker();\r\n            worker.onReady(() => {\r\n                if (this.queue.length > 0) {\r\n                    const deferred = this.queue.shift();\r\n                    if (deferred) {\r\n                        worker.lock();\r\n                        deferred.resolve(worker);\r\n                    }\r\n                }\r\n            });\r\n            this.workerPool.push(worker);\r\n        }\r\n    }\r\n\r\n    async parse<T extends AstNode>(text: string, cancelToken: CancellationToken): Promise<ParseResult<T>> {\r\n        const worker = await this.acquireParserWorker(cancelToken);\r\n        const deferred = new Deferred<ParseResult<T>>();\r\n        let timeout: NodeJS.Timeout | undefined;\r\n        // If the cancellation token is requested, we wait for a certain time before terminating the worker.\r\n        // Since the cancellation token lives longer than the parsing process, we need to dispose the event listener.\r\n        // Otherwise, we might accidentally terminate the worker after the parsing process has finished.\r\n        const cancellation = cancelToken.onCancellationRequested(() => {\r\n            timeout = setTimeout(() => {\r\n                this.terminateWorker(worker);\r\n            }, this.terminationDelay);\r\n        });\r\n        worker.parse(text).then(result => {\r\n            const hydrated = this.hydrator.hydrate<T>(result);\r\n            deferred.resolve(hydrated);\r\n        }).catch(err => {\r\n            deferred.reject(err);\r\n        }).finally(() => {\r\n            cancellation.dispose();\r\n            clearTimeout(timeout);\r\n        });\r\n        return deferred.promise;\r\n    }\r\n\r\n    protected terminateWorker(worker: ParserWorker): void {\r\n        worker.terminate();\r\n        const index = this.workerPool.indexOf(worker);\r\n        if (index >= 0) {\r\n            this.workerPool.splice(index, 1);\r\n        }\r\n    }\r\n\r\n    protected async acquireParserWorker(cancelToken: CancellationToken): Promise<ParserWorker> {\r\n        this.initializeWorkers();\r\n        for (const worker of this.workerPool) {\r\n            if (worker.ready) {\r\n                worker.lock();\r\n                return worker;\r\n            }\r\n        }\r\n        const deferred = new Deferred<ParserWorker>();\r\n        cancelToken.onCancellationRequested(() => {\r\n            const index = this.queue.indexOf(deferred);\r\n            if (index >= 0) {\r\n                this.queue.splice(index, 1);\r\n            }\r\n            deferred.reject(OperationCancelled);\r\n        });\r\n        this.queue.push(deferred);\r\n        return deferred.promise;\r\n    }\r\n\r\n    protected abstract createWorker(): ParserWorker;\r\n}\r\n\r\nexport type WorkerMessagePost = (message: unknown) => void;\r\nexport type WorkerMessageCallback = (cb: (message: unknown) => void) => void;\r\n\r\nexport class ParserWorker {\r\n\r\n    protected readonly sendMessage: WorkerMessagePost;\r\n    protected readonly _terminate: () => void;\r\n    protected readonly onReadyEmitter = new Emitter<void>();\r\n\r\n    protected deferred = new Deferred<ParseResult>();\r\n    protected _ready = true;\r\n    protected _parsing = false;\r\n\r\n    get ready(): boolean {\r\n        return this._ready;\r\n    }\r\n\r\n    get onReady(): Event<void> {\r\n        return this.onReadyEmitter.event;\r\n    }\r\n\r\n    constructor(sendMessage: WorkerMessagePost, onMessage: WorkerMessageCallback, onError: WorkerMessageCallback, terminate: () => void) {\r\n        this.sendMessage = sendMessage;\r\n        this._terminate = terminate;\r\n        onMessage(result => {\r\n            const parseResult = result as ParseResult;\r\n            this.deferred.resolve(parseResult);\r\n            this.unlock();\r\n        });\r\n        onError(error => {\r\n            this.deferred.reject(error);\r\n            this.unlock();\r\n        });\r\n    }\r\n\r\n    terminate(): void {\r\n        this.deferred.reject(OperationCancelled);\r\n        this._terminate();\r\n    }\r\n\r\n    lock(): void {\r\n        this._ready = false;\r\n    }\r\n\r\n    unlock(): void {\r\n        this._parsing = false;\r\n        this._ready = true;\r\n        this.onReadyEmitter.fire();\r\n    }\r\n\r\n    parse(text: string): Promise<ParseResult> {\r\n        if (this._parsing) {\r\n            throw new Error('Parser worker is busy');\r\n        }\r\n        this._parsing = true;\r\n        this.deferred = new Deferred();\r\n        this.sendMessage(text);\r\n        return this.deferred.promise;\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2023 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { type AbstractCancellationTokenSource, CancellationToken, CancellationTokenSource } from '../utils/cancellation.js';\r\nimport { Deferred, isOperationCancelled, startCancelableOperation, type MaybePromise } from '../utils/promise-utils.js';\r\n\r\n/**\r\n * Utility service to execute mutually exclusive actions.\r\n */\r\nexport interface WorkspaceLock {\r\n    /**\r\n     * Performs a single async action, like initializing the workspace or processing document changes.\r\n     * Only one action will be executed at a time.\r\n     *\r\n     * When another action is queued up, the token provided for the action will be cancelled.\r\n     * Assuming the action makes use of this token, the next action only has to wait for the current action to finish cancellation.\r\n     */\r\n    write(action: (token: CancellationToken) => MaybePromise<void>): Promise<void>;\r\n\r\n    /**\r\n     * Performs a single action, like computing completion results or providing workspace symbols.\r\n     * Read actions will only be executed after all write actions have finished. They will be executed in parallel if possible.\r\n     *\r\n     * If a write action is currently running, the read action will be queued up and executed afterwards.\r\n     * If a new write action is queued up while a read action is waiting, the write action will receive priority and will be handled before the read action.\r\n     *\r\n     * Note that read actions are not allowed to modify anything in the workspace. Please use {@link write} instead.\r\n     */\r\n    read<T>(action: () => MaybePromise<T>): Promise<T>;\r\n\r\n    /**\r\n     * Cancels the last queued write action. All previous write actions already have been cancelled.\r\n     */\r\n    cancelWrite(): void;\r\n}\r\n\r\ntype LockAction<T = void> = (token: CancellationToken) => MaybePromise<T>;\r\n\r\ninterface LockEntry {\r\n    action: LockAction<unknown>;\r\n    deferred: Deferred<unknown>;\r\n    cancellationToken: CancellationToken;\r\n}\r\n\r\nexport class DefaultWorkspaceLock implements WorkspaceLock {\r\n\r\n    private previousTokenSource: AbstractCancellationTokenSource = new CancellationTokenSource();\r\n    private writeQueue: LockEntry[] = [];\r\n    private readQueue: LockEntry[] = [];\r\n    private done = true;\r\n\r\n    write(action: (token: CancellationToken) => MaybePromise<void>): Promise<void> {\r\n        this.cancelWrite();\r\n        const tokenSource = startCancelableOperation();\r\n        this.previousTokenSource = tokenSource;\r\n        return this.enqueue(this.writeQueue, action, tokenSource.token);\r\n    }\r\n\r\n    read<T>(action: () => MaybePromise<T>): Promise<T> {\r\n        return this.enqueue(this.readQueue, action);\r\n    }\r\n\r\n    private enqueue<T = void>(queue: LockEntry[], action: LockAction<T>, cancellationToken = CancellationToken.None): Promise<T> {\r\n        const deferred = new Deferred<unknown>();\r\n        const entry: LockEntry = {\r\n            action,\r\n            deferred,\r\n            cancellationToken\r\n        };\r\n        queue.push(entry);\r\n        this.performNextOperation();\r\n        return deferred.promise as Promise<T>;\r\n    }\r\n\r\n    private async performNextOperation(): Promise<void> {\r\n        if (!this.done) {\r\n            return;\r\n        }\r\n        const entries: LockEntry[] = [];\r\n        if (this.writeQueue.length > 0) {\r\n            // Just perform the next write action\r\n            entries.push(this.writeQueue.shift()!);\r\n        } else if (this.readQueue.length > 0) {\r\n            // Empty the read queue and perform all actions in parallel\r\n            entries.push(...this.readQueue.splice(0, this.readQueue.length));\r\n        } else {\r\n            return;\r\n        }\r\n        this.done = false;\r\n        await Promise.all(entries.map(async ({ action, deferred, cancellationToken }) => {\r\n            try {\r\n                // Move the execution of the action to the next event loop tick via `Promise.resolve()`\r\n                const result = await Promise.resolve().then(() => action(cancellationToken));\r\n                deferred.resolve(result);\r\n            } catch (err) {\r\n                if (isOperationCancelled(err)) {\r\n                    // If the operation was cancelled, we don't want to reject the promise\r\n                    deferred.resolve(undefined);\r\n                } else {\r\n                    deferred.reject(err);\r\n                }\r\n            }\r\n        }));\r\n        this.done = true;\r\n        this.performNextOperation();\r\n    }\r\n\r\n    cancelWrite(): void {\r\n        this.previousTokenSource.cancel();\r\n    }\r\n}\r\n","/******************************************************************************\r\n * Copyright 2024 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\n/* eslint-disable @typescript-eslint/no-explicit-any */\r\n\r\nimport type { TokenType } from 'chevrotain';\r\nimport { CompositeCstNodeImpl, LeafCstNodeImpl, RootCstNodeImpl } from '../parser/cst-node-builder.js';\r\nimport { isAbstractElement, type AbstractElement, type Grammar } from '../languages/generated/ast.js';\r\nimport type { Linker } from '../references/linker.js';\r\nimport type { Lexer } from '../parser/lexer.js';\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport type { ParseResult } from '../parser/langium-parser.js';\r\nimport type { Reference, AstNode, CstNode, LeafCstNode, GenericAstNode, Mutable, RootCstNode } from '../syntax-tree.js';\r\nimport { isRootCstNode, isCompositeCstNode, isLeafCstNode, isAstNode, isReference } from '../syntax-tree.js';\r\nimport { streamAst } from '../utils/ast-utils.js';\r\nimport { BiMap } from '../utils/collections.js';\r\nimport { streamCst } from '../utils/cst-utils.js';\r\nimport type { LexingReport } from '../parser/token-builder.js';\r\n\r\n/**\r\n * The hydrator service is responsible for allowing AST parse results to be sent across worker threads.\r\n */\r\nexport interface Hydrator {\r\n    /**\r\n     * Converts a parse result to a plain object. The resulting object can be sent across worker threads.\r\n     */\r\n    dehydrate(result: ParseResult<AstNode>): ParseResult<object>;\r\n    /**\r\n     * Converts a plain object to a parse result. The included AST node can then be used in the main thread.\r\n     * Calling this method on objects that have not been dehydrated first will result in undefined behavior.\r\n     */\r\n    hydrate<T extends AstNode = AstNode>(result: ParseResult<object>): ParseResult<T>;\r\n}\r\n\r\nexport interface DehydrateContext {\r\n    astNodes: Map<AstNode, any>;\r\n    cstNodes: Map<CstNode, any>;\r\n}\r\n\r\nexport interface HydrateContext {\r\n    astNodes: Map<any, AstNode>;\r\n    cstNodes: Map<any, CstNode>;\r\n}\r\n\r\nexport class DefaultHydrator implements Hydrator {\r\n\r\n    protected readonly grammar: Grammar;\r\n    protected readonly lexer: Lexer;\r\n    protected readonly linker: Linker;\r\n\r\n    protected readonly grammarElementIdMap = new BiMap<AbstractElement, number>();\r\n    protected readonly tokenTypeIdMap = new BiMap<number, TokenType>();\r\n\r\n    constructor(services: LangiumCoreServices) {\r\n        this.grammar = services.Grammar;\r\n        this.lexer = services.parser.Lexer;\r\n        this.linker = services.references.Linker;\r\n    }\r\n\r\n    dehydrate(result: ParseResult<AstNode>): ParseResult<object> {\r\n        return {\r\n            lexerErrors: result.lexerErrors,\r\n            lexerReport: result.lexerReport ? this.dehydrateLexerReport(result.lexerReport) : undefined,\r\n            // We need to create shallow copies of the errors\r\n            // The original errors inherit from the `Error` class, which is not transferable across worker threads\r\n            parserErrors: result.parserErrors.map(e => ({ ...e, message: e.message })),\r\n            value: this.dehydrateAstNode(result.value, this.createDehyrationContext(result.value))\r\n        };\r\n    }\r\n\r\n    protected dehydrateLexerReport(lexerReport: LexingReport): LexingReport {\r\n        // By default, lexer reports are serializable\r\n        return lexerReport;\r\n    }\r\n\r\n    protected createDehyrationContext(node: AstNode): DehydrateContext {\r\n        const astNodes = new Map<AstNode, any>();\r\n        const cstNodes = new Map<CstNode, any>();\r\n        for (const astNode of streamAst(node)) {\r\n            astNodes.set(astNode, {});\r\n        }\r\n        if (node.$cstNode) {\r\n            for (const cstNode of streamCst(node.$cstNode)) {\r\n                cstNodes.set(cstNode, {});\r\n            }\r\n        }\r\n        return {\r\n            astNodes,\r\n            cstNodes\r\n        };\r\n    }\r\n\r\n    protected dehydrateAstNode(node: AstNode, context: DehydrateContext): object {\r\n        const obj = context.astNodes.get(node) as Record<string, any>;\r\n        obj.$type = node.$type;\r\n        obj.$containerIndex = node.$containerIndex;\r\n        obj.$containerProperty = node.$containerProperty;\r\n        if (node.$cstNode !== undefined) {\r\n            obj.$cstNode = this.dehydrateCstNode(node.$cstNode, context);\r\n        }\r\n        for (const [name, value] of Object.entries(node)) {\r\n            if (name.startsWith('$')) {\r\n                continue;\r\n            }\r\n            if (Array.isArray(value)) {\r\n                const arr: any[] = [];\r\n                obj[name] = arr;\r\n                for (const item of value) {\r\n                    if (isAstNode(item)) {\r\n                        arr.push(this.dehydrateAstNode(item, context));\r\n                    } else if (isReference(item)) {\r\n                        arr.push(this.dehydrateReference(item, context));\r\n                    } else {\r\n                        arr.push(item);\r\n                    }\r\n                }\r\n            } else if (isAstNode(value)) {\r\n                obj[name] = this.dehydrateAstNode(value, context);\r\n            } else if (isReference(value)) {\r\n                obj[name] = this.dehydrateReference(value, context);\r\n            } else if (value !== undefined) {\r\n                obj[name] = value;\r\n            }\r\n        }\r\n        return obj;\r\n    }\r\n\r\n    protected dehydrateReference(reference: Reference, context: DehydrateContext): any {\r\n        const obj: Record<string, unknown> = {};\r\n        obj.$refText = reference.$refText;\r\n        if (reference.$refNode) {\r\n            obj.$refNode = context.cstNodes.get(reference.$refNode);\r\n        }\r\n        return obj;\r\n    }\r\n\r\n    protected dehydrateCstNode(node: CstNode, context: DehydrateContext): any {\r\n        const cstNode = context.cstNodes.get(node) as Record<string, any>;\r\n        if (isRootCstNode(node)) {\r\n            cstNode.fullText = node.fullText;\r\n        } else {\r\n            // Note: This returns undefined for hidden nodes (i.e. comments)\r\n            cstNode.grammarSource = this.getGrammarElementId(node.grammarSource);\r\n        }\r\n        cstNode.hidden = node.hidden;\r\n        cstNode.astNode = context.astNodes.get(node.astNode);\r\n        if (isCompositeCstNode(node)) {\r\n            cstNode.content = node.content.map(child => this.dehydrateCstNode(child, context));\r\n        } else if (isLeafCstNode(node)) {\r\n            cstNode.tokenType = node.tokenType.name;\r\n            cstNode.offset = node.offset;\r\n            cstNode.length = node.length;\r\n            cstNode.startLine = node.range.start.line;\r\n            cstNode.startColumn = node.range.start.character;\r\n            cstNode.endLine = node.range.end.line;\r\n            cstNode.endColumn = node.range.end.character;\r\n        }\r\n        return cstNode;\r\n    }\r\n\r\n    hydrate<T extends AstNode = AstNode>(result: ParseResult<object>): ParseResult<T> {\r\n        const node = result.value;\r\n        const context = this.createHydrationContext(node);\r\n        if ('$cstNode' in node) {\r\n            this.hydrateCstNode(node.$cstNode, context);\r\n        }\r\n        return {\r\n            lexerErrors: result.lexerErrors,\r\n            lexerReport: result.lexerReport,\r\n            parserErrors: result.parserErrors,\r\n            value: this.hydrateAstNode(node, context) as T\r\n        };\r\n    }\r\n\r\n    protected createHydrationContext(node: any): HydrateContext {\r\n        const astNodes = new Map<any, AstNode>();\r\n        const cstNodes = new Map<any, CstNode>();\r\n        for (const astNode of streamAst(node)) {\r\n            astNodes.set(astNode, {} as AstNode);\r\n        }\r\n        let root: RootCstNode;\r\n        if (node.$cstNode) {\r\n            for (const cstNode of streamCst(node.$cstNode)) {\r\n                let cst: Mutable<CstNode> | undefined;\r\n                if ('fullText' in cstNode) {\r\n                    cst = new RootCstNodeImpl(cstNode.fullText as string);\r\n                    root = cst as RootCstNode;\r\n                } else if ('content' in cstNode) {\r\n                    cst = new CompositeCstNodeImpl();\r\n                } else if ('tokenType' in cstNode) {\r\n                    cst = this.hydrateCstLeafNode(cstNode);\r\n                }\r\n                if (cst) {\r\n                    cstNodes.set(cstNode, cst);\r\n                    cst.root = root!;\r\n                }\r\n            }\r\n        }\r\n        return {\r\n            astNodes,\r\n            cstNodes\r\n        };\r\n    }\r\n\r\n    protected hydrateAstNode(node: any, context: HydrateContext): AstNode {\r\n        const astNode = context.astNodes.get(node) as Mutable<GenericAstNode>;\r\n        astNode.$type = node.$type;\r\n        astNode.$containerIndex = node.$containerIndex;\r\n        astNode.$containerProperty = node.$containerProperty;\r\n        if (node.$cstNode) {\r\n            astNode.$cstNode = context.cstNodes.get(node.$cstNode);\r\n        }\r\n        for (const [name, value] of Object.entries(node)) {\r\n            if (name.startsWith('$')) {\r\n                continue;\r\n            }\r\n            if (Array.isArray(value)) {\r\n                const arr: unknown[] = [];\r\n                astNode[name] = arr;\r\n                for (const item of value) {\r\n                    if (isAstNode(item)) {\r\n                        arr.push(this.setParent(this.hydrateAstNode(item, context), astNode));\r\n                    } else if (isReference(item)) {\r\n                        arr.push(this.hydrateReference(item, astNode, name, context));\r\n                    } else {\r\n                        arr.push(item);\r\n                    }\r\n                }\r\n            } else if (isAstNode(value)) {\r\n                astNode[name] = this.setParent(this.hydrateAstNode(value, context), astNode);\r\n            } else if (isReference(value)) {\r\n                astNode[name] = this.hydrateReference(value, astNode, name, context);\r\n            } else if (value !== undefined) {\r\n                astNode[name] = value;\r\n            }\r\n        }\r\n        return astNode;\r\n    }\r\n\r\n    protected setParent(node: any, parent: any): any {\r\n        node.$container = parent as AstNode;\r\n        return node;\r\n    }\r\n\r\n    protected hydrateReference(reference: any, node: AstNode, name: string, context: HydrateContext): Reference {\r\n        return this.linker.buildReference(node, name, context.cstNodes.get(reference.$refNode)!, reference.$refText);\r\n    }\r\n\r\n    protected hydrateCstNode(cstNode: any, context: HydrateContext, num = 0): CstNode {\r\n        const cstNodeObj = context.cstNodes.get(cstNode) as Mutable<CstNode>;\r\n        if (typeof cstNode.grammarSource === 'number') {\r\n            cstNodeObj.grammarSource = this.getGrammarElement(cstNode.grammarSource);\r\n        }\r\n        cstNodeObj.astNode = context.astNodes.get(cstNode.astNode)!;\r\n        if (isCompositeCstNode(cstNodeObj)) {\r\n            for (const child of cstNode.content) {\r\n                const hydrated = this.hydrateCstNode(child, context, num++);\r\n                cstNodeObj.content.push(hydrated);\r\n            }\r\n        }\r\n        return cstNodeObj;\r\n    }\r\n\r\n    protected hydrateCstLeafNode(cstNode: any): LeafCstNode {\r\n        const tokenType = this.getTokenType(cstNode.tokenType);\r\n        const offset = cstNode.offset;\r\n        const length = cstNode.length;\r\n        const startLine = cstNode.startLine;\r\n        const startColumn = cstNode.startColumn;\r\n        const endLine = cstNode.endLine;\r\n        const endColumn = cstNode.endColumn;\r\n        const hidden = cstNode.hidden;\r\n        const node = new LeafCstNodeImpl(\r\n            offset,\r\n            length,\r\n            {\r\n                start: {\r\n                    line: startLine,\r\n                    character: startColumn\r\n                },\r\n                end: {\r\n                    line: endLine,\r\n                    character: endColumn\r\n                }\r\n            },\r\n            tokenType,\r\n            hidden\r\n        );\r\n        return node;\r\n    }\r\n\r\n    protected getTokenType(name: string): TokenType {\r\n        return this.lexer.definition[name];\r\n    }\r\n\r\n    protected getGrammarElementId(node: AbstractElement | undefined): number | undefined {\r\n        if (!node) {\r\n            return undefined;\r\n        }\r\n        if (this.grammarElementIdMap.size === 0) {\r\n            this.createGrammarElementIdMap();\r\n        }\r\n        return this.grammarElementIdMap.get(node);\r\n    }\r\n\r\n    protected getGrammarElement(id: number): AbstractElement | undefined {\r\n        if (this.grammarElementIdMap.size === 0) {\r\n            this.createGrammarElementIdMap();\r\n        }\r\n        const element = this.grammarElementIdMap.getKey(id);\r\n        return element;\r\n    }\r\n\r\n    protected createGrammarElementIdMap(): void {\r\n        let id = 0;\r\n        for (const element of streamAst(this.grammar)) {\r\n            if (isAbstractElement(element)) {\r\n                this.grammarElementIdMap.set(element, id++);\r\n            }\r\n        }\r\n    }\r\n\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n******************************************************************************/\r\n\r\nimport type { Module } from './dependency-injection.js';\r\nimport type { LangiumDefaultCoreServices, LangiumDefaultSharedCoreServices, LangiumCoreServices, LangiumSharedCoreServices } from './services.js';\r\nimport type { FileSystemProvider } from './workspace/file-system-provider.js';\r\nimport { createGrammarConfig } from './languages/grammar-config.js';\r\nimport { createCompletionParser } from './parser/completion-parser-builder.js';\r\nimport { createLangiumParser } from './parser/langium-parser-builder.js';\r\nimport { DefaultTokenBuilder } from './parser/token-builder.js';\r\nimport { DefaultValueConverter } from './parser/value-converter.js';\r\nimport { DefaultLinker } from './references/linker.js';\r\nimport { DefaultNameProvider } from './references/name-provider.js';\r\nimport { DefaultReferences } from './references/references.js';\r\nimport { DefaultScopeComputation } from './references/scope-computation.js';\r\nimport { DefaultScopeProvider } from './references/scope-provider.js';\r\nimport { DefaultJsonSerializer } from './serializer/json-serializer.js';\r\nimport { DefaultServiceRegistry } from './service-registry.js';\r\nimport { DefaultDocumentValidator } from './validation/document-validator.js';\r\nimport { ValidationRegistry } from './validation/validation-registry.js';\r\nimport { DefaultAstNodeDescriptionProvider, DefaultReferenceDescriptionProvider } from './workspace/ast-descriptions.js';\r\nimport { DefaultAstNodeLocator } from './workspace/ast-node-locator.js';\r\nimport { DefaultConfigurationProvider } from './workspace/configuration.js';\r\nimport { DefaultDocumentBuilder } from './workspace/document-builder.js';\r\nimport { DefaultLangiumDocumentFactory, DefaultLangiumDocuments } from './workspace/documents.js';\r\nimport { DefaultIndexManager } from './workspace/index-manager.js';\r\nimport { DefaultWorkspaceManager } from './workspace/workspace-manager.js';\r\nimport { DefaultLexer, DefaultLexerErrorMessageProvider } from './parser/lexer.js';\r\nimport { JSDocDocumentationProvider } from './documentation/documentation-provider.js';\r\nimport { DefaultCommentProvider } from './documentation/comment-provider.js';\r\nimport { LangiumParserErrorMessageProvider } from './parser/langium-parser.js';\r\nimport { DefaultAsyncParser } from './parser/async-parser.js';\r\nimport { DefaultWorkspaceLock } from './workspace/workspace-lock.js';\r\nimport { DefaultHydrator } from './serializer/hydrator.js';\r\n\r\n/**\r\n * Context required for creating the default language-specific dependency injection module.\r\n */\r\nexport interface DefaultCoreModuleContext {\r\n    shared: LangiumSharedCoreServices;\r\n}\r\n\r\n/**\r\n * Creates a dependency injection module configuring the default core services.\r\n * This is a set of services that are dedicated to a specific language.\r\n */\r\nexport function createDefaultCoreModule(context: DefaultCoreModuleContext): Module<LangiumCoreServices, LangiumDefaultCoreServices> {\r\n    return {\r\n        documentation: {\r\n            CommentProvider: (services) => new DefaultCommentProvider(services),\r\n            DocumentationProvider: (services) => new JSDocDocumentationProvider(services)\r\n        },\r\n        parser: {\r\n            AsyncParser: (services) => new DefaultAsyncParser(services),\r\n            GrammarConfig: (services) => createGrammarConfig(services),\r\n            LangiumParser: (services) => createLangiumParser(services),\r\n            CompletionParser: (services) => createCompletionParser(services),\r\n            ValueConverter: () => new DefaultValueConverter(),\r\n            TokenBuilder: () => new DefaultTokenBuilder(),\r\n            Lexer: (services) => new DefaultLexer(services),\r\n            ParserErrorMessageProvider: () => new LangiumParserErrorMessageProvider(),\r\n            LexerErrorMessageProvider: () => new DefaultLexerErrorMessageProvider()\r\n        },\r\n        workspace: {\r\n            AstNodeLocator: () => new DefaultAstNodeLocator(),\r\n            AstNodeDescriptionProvider: (services) => new DefaultAstNodeDescriptionProvider(services),\r\n            ReferenceDescriptionProvider: (services) => new DefaultReferenceDescriptionProvider(services)\r\n        },\r\n        references: {\r\n            Linker: (services) => new DefaultLinker(services),\r\n            NameProvider: () => new DefaultNameProvider(),\r\n            ScopeProvider: (services) => new DefaultScopeProvider(services),\r\n            ScopeComputation: (services) => new DefaultScopeComputation(services),\r\n            References: (services) => new DefaultReferences(services)\r\n        },\r\n        serializer: {\r\n            Hydrator: (services) => new DefaultHydrator(services),\r\n            JsonSerializer: (services) => new DefaultJsonSerializer(services)\r\n        },\r\n        validation: {\r\n            DocumentValidator: (services) => new DefaultDocumentValidator(services),\r\n            ValidationRegistry: (services) => new ValidationRegistry(services)\r\n        },\r\n        shared: () => context.shared\r\n    };\r\n}\r\n\r\n/**\r\n * Context required for creating the default shared dependency injection module.\r\n */\r\nexport interface DefaultSharedCoreModuleContext {\r\n    /**\r\n     * Factory function to create a {@link FileSystemProvider}.\r\n     *\r\n     * Langium exposes an `EmptyFileSystem` and `NodeFileSystem`, exported through `langium/node`.\r\n     * When running Langium as part of a vscode language server or a Node.js app, using the `NodeFileSystem` is recommended,\r\n     * the `EmptyFileSystem` in every other use case.\r\n     */\r\n    fileSystemProvider: (services: LangiumSharedCoreServices) => FileSystemProvider;\r\n}\r\n\r\n/**\r\n * Creates a dependency injection module configuring the default shared core services.\r\n * This is the set of services that are shared between multiple languages.\r\n */\r\nexport function createDefaultSharedCoreModule(context: DefaultSharedCoreModuleContext): Module<LangiumSharedCoreServices, LangiumDefaultSharedCoreServices> {\r\n    return {\r\n        ServiceRegistry: (services) => new DefaultServiceRegistry(services),\r\n        workspace: {\r\n            LangiumDocuments: (services) => new DefaultLangiumDocuments(services),\r\n            LangiumDocumentFactory: (services) => new DefaultLangiumDocumentFactory(services),\r\n            DocumentBuilder: (services) => new DefaultDocumentBuilder(services),\r\n            IndexManager: (services) => new DefaultIndexManager(services),\r\n            WorkspaceManager: (services) => new DefaultWorkspaceManager(services),\r\n            FileSystemProvider: (services) => context.fileSystemProvider(services),\r\n            WorkspaceLock: () => new DefaultWorkspaceLock(),\r\n            ConfigurationProvider: (services) => new DefaultConfigurationProvider(services)\r\n        }\r\n    };\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport { DefaultNameRegexp } from '../utils/cst-utils.js';\r\nimport { isCommentTerminal, terminalRegex } from '../utils/grammar-utils.js';\r\nimport { isMultilineComment } from '../utils/regexp-utils.js';\r\nimport { isTerminalRule } from './generated/ast.js';\r\n\r\nexport interface GrammarConfig {\r\n    /**\r\n     * Lists all rule names which are classified as multiline comment rules\r\n     */\r\n    multilineCommentRules: string[]\r\n    /**\r\n     * A regular expression which matches characters of names\r\n     */\r\n    nameRegexp: RegExp\r\n}\r\n\r\n/**\r\n * Create the default grammar configuration (used by `createDefaultModule`). This can be overridden in a\r\n * language-specific module.\r\n */\r\nexport function createGrammarConfig(services: LangiumCoreServices): GrammarConfig {\r\n    const rules: string[] = [];\r\n    const grammar = services.Grammar;\r\n    for (const rule of grammar.rules) {\r\n        if (isTerminalRule(rule) && isCommentTerminal(rule) && isMultilineComment(terminalRegex(rule))) {\r\n            rules.push(rule.name);\r\n        }\r\n    }\r\n    return {\r\n        multilineCommentRules: rules,\r\n        nameRegexp: DefaultNameRegexp\r\n    };\r\n}\r\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { LangiumCoreServices } from '../services.js';\r\nimport { LangiumCompletionParser } from './langium-parser.js';\r\nimport { createParser } from './parser-builder-base.js';\r\n\r\nexport function createCompletionParser(services: LangiumCoreServices): LangiumCompletionParser {\r\n    const grammar = services.Grammar;\r\n    const lexer = services.parser.Lexer;\r\n    const parser = new LangiumCompletionParser(services);\r\n    createParser(grammar, parser, lexer.definition);\r\n    parser.finalize();\r\n    return parser;\r\n}\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { Set, Group, Character, IRegExpAST } from '@chevrotain/regexp-to-ast';\r\nimport { RegExpParser, BaseRegExpVisitor } from '@chevrotain/regexp-to-ast';\r\n\r\nexport const NEWLINE_REGEXP = /\\r?\\n/gm;\r\n\r\nconst regexpParser = new RegExpParser();\r\n\r\n/**\r\n * This class is in charge of heuristically identifying start/end tokens of terminals.\r\n *\r\n * The way this works is by doing the following:\r\n * 1. Traverse the regular expression in the \"start state\"\r\n * 2. Add any encountered sets/single characters to the \"start regexp\"\r\n * 3. Once we encounter any variable-length content (i.e. with quantifiers such as +/?/*), we enter the \"end state\"\r\n * 4. In the end state, any sets/single characters are added to an \"end stack\".\r\n * 5. If we re-encounter any variable-length content we reset the end stack\r\n * 6. We continue visiting the regex until the end, reseting the end stack and rebuilding it as necessary\r\n *\r\n * After traversing a regular expression the `startRegexp/endRegexp` properties allow access to the stored start/end of the terminal\r\n */\r\nclass TerminalRegExpVisitor extends BaseRegExpVisitor {\r\n\r\n    private isStarting = true;\r\n    startRegexp: string;\r\n    private endRegexpStack: string[] = [];\r\n    multiline = false;\r\n    regex: string;\r\n\r\n    get endRegex(): string {\r\n        return this.endRegexpStack.join('');\r\n    }\r\n\r\n    reset(regex: string): void {\r\n        this.multiline = false;\r\n        this.regex = regex;\r\n        this.startRegexp = '';\r\n        this.isStarting = true;\r\n        this.endRegexpStack = [];\r\n    }\r\n\r\n    override visitGroup(node: Group) {\r\n        if (node.quantifier) {\r\n            this.isStarting = false;\r\n            this.endRegexpStack = [];\r\n        }\r\n    }\r\n\r\n    override visitCharacter(node: Character): void {\r\n        const char = String.fromCharCode(node.value);\r\n        if (!this.multiline && char === '\\n') {\r\n            this.multiline = true;\r\n        }\r\n        if (node.quantifier) {\r\n            this.isStarting = false;\r\n            this.endRegexpStack = [];\r\n        } else {\r\n            const escapedChar = escapeRegExp(char);\r\n            this.endRegexpStack.push(escapedChar);\r\n            if (this.isStarting) {\r\n                this.startRegexp += escapedChar;\r\n            }\r\n        }\r\n    }\r\n\r\n    override visitSet(node: Set): void {\r\n        if (!this.multiline) {\r\n            const set = this.regex.substring(node.loc.begin, node.loc.end);\r\n            const regex = new RegExp(set);\r\n            this.multiline = Boolean('\\n'.match(regex));\r\n        }\r\n        if (node.quantifier) {\r\n            this.isStarting = false;\r\n            this.endRegexpStack = [];\r\n        } else {\r\n            const set = this.regex.substring(node.loc.begin, node.loc.end);\r\n            this.endRegexpStack.push(set);\r\n            if (this.isStarting) {\r\n                this.startRegexp += set;\r\n            }\r\n        }\r\n    }\r\n\r\n    override visitChildren(node: IRegExpAST): void {\r\n        if (node.type === 'Group') {\r\n            // Ignore children of groups with quantifier (+/*/?)\r\n            // These groups are unrelated to start/end tokens of terminals\r\n            const group = node as Group;\r\n            if (group.quantifier) {\r\n                return;\r\n            }\r\n        }\r\n        super.visitChildren(node);\r\n    }\r\n}\r\n\r\nconst visitor = new TerminalRegExpVisitor();\r\n\r\nexport function getTerminalParts(regexp: RegExp | string): Array<{ start: string, end: string }> {\r\n    try {\r\n        if (typeof regexp !== 'string') {\r\n            regexp = regexp.source;\r\n        }\r\n        regexp = `/${regexp}/`;\r\n        const pattern = regexpParser.pattern(regexp);\r\n        const parts: Array<{ start: string, end: string }> = [];\r\n        for (const alternative of pattern.value.value) {\r\n            visitor.reset(regexp);\r\n            visitor.visit(alternative);\r\n            parts.push({\r\n                start: visitor.startRegexp,\r\n                end: visitor.endRegex\r\n            });\r\n        }\r\n        return parts;\r\n    } catch {\r\n        return [];\r\n    }\r\n}\r\n\r\nexport function isMultilineComment(regexp: RegExp | string): boolean {\r\n    try {\r\n        if (typeof regexp === 'string') {\r\n            regexp = new RegExp(regexp);\r\n        }\r\n        regexp = regexp.toString();\r\n        visitor.reset(regexp);\r\n        // Parsing the pattern might fail (since it's user code)\r\n        visitor.visit(regexpParser.pattern(regexp));\r\n        return visitor.multiline;\r\n    } catch {\r\n        return false;\r\n    }\r\n}\r\n\r\n/**\r\n * A set of all characters that are considered whitespace by the '\\s' RegExp character class.\r\n * Taken from [MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_expressions/Character_classes).\r\n */\r\nexport const whitespaceCharacters = (\r\n    '\\f\\n\\r\\t\\v\\u0020\\u00a0\\u1680\\u2000\\u2001\\u2002\\u2003\\u2004\\u2005\\u2006\\u2007' +\r\n    '\\u2008\\u2009\\u200a\\u2028\\u2029\\u202f\\u205f\\u3000\\ufeff').split('');\r\n\r\nexport function isWhitespace(value: RegExp | string): boolean {\r\n    const regexp = typeof value === 'string' ? new RegExp(value) : value;\r\n    return whitespaceCharacters.some((ws) => regexp.test(ws));\r\n}\r\n\r\nexport function escapeRegExp(value: string): string {\r\n    return value.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&');\r\n}\r\n\r\nexport function getCaseInsensitivePattern(keyword: string): string {\r\n    return Array.prototype.map.call(keyword, letter =>\r\n        /\\w/.test(letter) ? `[${letter.toLowerCase()}${letter.toUpperCase()}]` : escapeRegExp(letter)\r\n    ).join('');\r\n}\r\n\r\n/**\r\n * Determines whether the given input has a partial match with the specified regex.\r\n * @param regex The regex to partially match against\r\n * @param input The input string\r\n * @returns Whether any match exists.\r\n */\r\nexport function partialMatches(regex: RegExp | string, input: string): boolean {\r\n    const partial = partialRegExp(regex);\r\n    const match = input.match(partial);\r\n    return !!match && match[0].length > 0;\r\n}\r\n\r\n/**\r\n * Builds a partial regex from the input regex. A partial regex is able to match incomplete input strings. E.g.\r\n * a partial regex constructed from `/ab/` is able to match the string `a` without needing a following `b` character. However it won't match `b` alone.\r\n * @param regex The input regex to be converted.\r\n * @returns A partial regex constructed from the input regex.\r\n */\r\nexport function partialRegExp(regex: RegExp | string): RegExp {\r\n    if (typeof regex === 'string') {\r\n        regex = new RegExp(regex);\r\n    }\r\n    const re = regex, source = regex.source;\r\n    let i = 0;\r\n\r\n    function process() {\r\n        let result = '',\r\n            tmp;\r\n\r\n        function appendRaw(nbChars: number) {\r\n            result += source.substr(i, nbChars);\r\n            i += nbChars;\r\n        }\r\n\r\n        function appendOptional(nbChars: number) {\r\n            result += '(?:' + source.substr(i, nbChars) + '|$)';\r\n            i += nbChars;\r\n        }\r\n\r\n        while (i < source.length) {\r\n            switch (source[i]) {\r\n                case '\\\\':\r\n                    switch (source[i + 1]) {\r\n                        case 'c':\r\n                            appendOptional(3);\r\n                            break;\r\n                        case 'x':\r\n                            appendOptional(4);\r\n                            break;\r\n                        case 'u':\r\n                            if (re.unicode) {\r\n                                if (source[i + 2] === '{') {\r\n                                    appendOptional(source.indexOf('}', i) - i + 1);\r\n                                } else {\r\n                                    appendOptional(6);\r\n                                }\r\n                            } else {\r\n                                appendOptional(2);\r\n                            }\r\n                            break;\r\n                        case 'p':\r\n                        case 'P':\r\n                            if (re.unicode) {\r\n                                appendOptional(source.indexOf('}', i) - i + 1);\r\n                            } else {\r\n                                appendOptional(2);\r\n                            }\r\n                            break;\r\n                        case 'k':\r\n                            appendOptional(source.indexOf('>', i) - i + 1);\r\n                            break;\r\n                        default:\r\n                            appendOptional(2);\r\n                            break;\r\n                    }\r\n                    break;\r\n\r\n                case '[':\r\n                    tmp = /\\[(?:\\\\.|.)*?\\]/g;\r\n                    tmp.lastIndex = i;\r\n                    tmp = tmp.exec(source) || [];\r\n                    appendOptional(tmp[0].length);\r\n                    break;\r\n\r\n                case '|':\r\n                case '^':\r\n                case '$':\r\n                case '*':\r\n                case '+':\r\n                case '?':\r\n                    appendRaw(1);\r\n                    break;\r\n                case '{':\r\n                    tmp = /\\{\\d+,?\\d*\\}/g;\r\n                    tmp.lastIndex = i;\r\n                    tmp = tmp.exec(source);\r\n                    if (tmp) {\r\n                        appendRaw(tmp[0].length);\r\n                    } else {\r\n                        appendOptional(1);\r\n                    }\r\n                    break;\r\n                case '(':\r\n                    if (source[i + 1] === '?') {\r\n                        switch (source[i + 2]) {\r\n                            case ':':\r\n                                result += '(?:';\r\n                                i += 3;\r\n                                result += process() + '|$)';\r\n                                break;\r\n                            case '=':\r\n                                result += '(?=';\r\n                                i += 3;\r\n                                result += process() + ')';\r\n                                break;\r\n                            case '!':\r\n                                tmp = i;\r\n                                i += 3;\r\n                                process();\r\n                                result += source.substr(tmp, i - tmp);\r\n                                break;\r\n                            case '<':\r\n                                switch (source[i + 3]) {\r\n                                    case '=':\r\n                                    case '!':\r\n                                        tmp = i;\r\n                                        i += 4;\r\n                                        process();\r\n                                        result += source.substr(tmp, i - tmp);\r\n                                        break;\r\n                                    default:\r\n                                        appendRaw(source.indexOf('>', i) - i + 1);\r\n                                        result += process() + '|$)';\r\n                                        break;\r\n                                }\r\n                                break;\r\n                        }\r\n                    } else {\r\n                        appendRaw(1);\r\n                        result += process() + '|$)';\r\n                    }\r\n                    break;\r\n                case ')':\r\n                    ++i;\r\n                    return result;\r\n                default:\r\n                    appendOptional(1);\r\n                    break;\r\n            }\r\n        }\r\n\r\n        return result;\r\n    }\r\n\r\n    return new RegExp(process(), regex.flags);\r\n}\r\n","import baseClone from './_baseClone.js';\n\n/** Used to compose bitmasks for cloning. */\nvar CLONE_SYMBOLS_FLAG = 4;\n\n/**\n * Creates a shallow clone of `value`.\n *\n * **Note:** This method is loosely based on the\n * [structured clone algorithm](https://mdn.io/Structured_clone_algorithm)\n * and supports cloning arrays, array buffers, booleans, date objects, maps,\n * numbers, `Object` objects, regexes, sets, strings, symbols, and typed\n * arrays. The own enumerable properties of `arguments` objects are cloned\n * as plain objects. An empty object is returned for uncloneable values such\n * as error objects, functions, DOM nodes, and WeakMaps.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to clone.\n * @returns {*} Returns the cloned value.\n * @see _.cloneDeep\n * @example\n *\n * var objects = [{ 'a': 1 }, { 'b': 2 }];\n *\n * var shallow = _.clone(objects);\n * console.log(shallow[0] === objects[0]);\n * // => true\n */\nfunction clone(value) {\n  return baseClone(value, CLONE_SYMBOLS_FLAG);\n}\n\nexport default clone;\n","/** Used to match a single whitespace character. */\nvar reWhitespace = /\\s/;\n\n/**\n * Used by `_.trim` and `_.trimEnd` to get the index of the last non-whitespace\n * character of `string`.\n *\n * @private\n * @param {string} string The string to inspect.\n * @returns {number} Returns the index of the last non-whitespace character.\n */\nfunction trimmedEndIndex(string) {\n  var index = string.length;\n\n  while (index-- && reWhitespace.test(string.charAt(index))) {}\n  return index;\n}\n\nexport default trimmedEndIndex;\n","import trimmedEndIndex from './_trimmedEndIndex.js';\n\n/** Used to match leading whitespace. */\nvar reTrimStart = /^\\s+/;\n\n/**\n * The base implementation of `_.trim`.\n *\n * @private\n * @param {string} string The string to trim.\n * @returns {string} Returns the trimmed string.\n */\nfunction baseTrim(string) {\n  return string\n    ? string.slice(0, trimmedEndIndex(string) + 1).replace(reTrimStart, '')\n    : string;\n}\n\nexport default baseTrim;\n","import baseTrim from './_baseTrim.js';\nimport isObject from './isObject.js';\nimport isSymbol from './isSymbol.js';\n\n/** Used as references for various `Number` constants. */\nvar NAN = 0 / 0;\n\n/** Used to detect bad signed hexadecimal string values. */\nvar reIsBadHex = /^[-+]0x[0-9a-f]+$/i;\n\n/** Used to detect binary string values. */\nvar reIsBinary = /^0b[01]+$/i;\n\n/** Used to detect octal string values. */\nvar reIsOctal = /^0o[0-7]+$/i;\n\n/** Built-in method references without a dependency on `root`. */\nvar freeParseInt = parseInt;\n\n/**\n * Converts `value` to a number.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to process.\n * @returns {number} Returns the number.\n * @example\n *\n * _.toNumber(3.2);\n * // => 3.2\n *\n * _.toNumber(Number.MIN_VALUE);\n * // => 5e-324\n *\n * _.toNumber(Infinity);\n * // => Infinity\n *\n * _.toNumber('3.2');\n * // => 3.2\n */\nfunction toNumber(value) {\n  if (typeof value == 'number') {\n    return value;\n  }\n  if (isSymbol(value)) {\n    return NAN;\n  }\n  if (isObject(value)) {\n    var other = typeof value.valueOf == 'function' ? value.valueOf() : value;\n    value = isObject(other) ? (other + '') : other;\n  }\n  if (typeof value != 'string') {\n    return value === 0 ? value : +value;\n  }\n  value = baseTrim(value);\n  var isBinary = reIsBinary.test(value);\n  return (isBinary || reIsOctal.test(value))\n    ? freeParseInt(value.slice(2), isBinary ? 2 : 8)\n    : (reIsBadHex.test(value) ? NAN : +value);\n}\n\nexport default toNumber;\n","import toNumber from './toNumber.js';\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0,\n    MAX_INTEGER = 1.7976931348623157e+308;\n\n/**\n * Converts `value` to a finite number.\n *\n * @static\n * @memberOf _\n * @since 4.12.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {number} Returns the converted number.\n * @example\n *\n * _.toFinite(3.2);\n * // => 3.2\n *\n * _.toFinite(Number.MIN_VALUE);\n * // => 5e-324\n *\n * _.toFinite(Infinity);\n * // => 1.7976931348623157e+308\n *\n * _.toFinite('3.2');\n * // => 3.2\n */\nfunction toFinite(value) {\n  if (!value) {\n    return value === 0 ? value : 0;\n  }\n  value = toNumber(value);\n  if (value === INFINITY || value === -INFINITY) {\n    var sign = (value < 0 ? -1 : 1);\n    return sign * MAX_INTEGER;\n  }\n  return value === value ? value : 0;\n}\n\nexport default toFinite;\n","/******************************************************************************\r\n * This file was generated by langium-cli 3.3.0.\r\n * DO NOT EDIT MANUALLY!\r\n ******************************************************************************/\r\n\r\n/* eslint-disable */\r\nimport type { AstNode, Reference, ReferenceInfo, TypeMetaData } from '../../syntax-tree.js';\r\nimport { AbstractAstReflection } from '../../syntax-tree.js';\r\n\r\nexport const LangiumGrammarTerminals = {\r\n    ID: /\\^?[_a-zA-Z][\\w_]*/,\r\n    STRING: /\"(\\\\.|[^\"\\\\])*\"|'(\\\\.|[^'\\\\])*'/,\r\n    NUMBER: /NaN|-?((\\d*\\.\\d+|\\d+)([Ee][+-]?\\d+)?|Infinity)/,\r\n    RegexLiteral: /\\/(?![*+?])(?:[^\\r\\n\\[/\\\\]|\\\\.|\\[(?:[^\\r\\n\\]\\\\]|\\\\.)*\\])+\\/[a-z]*/,\r\n    WS: /\\s+/,\r\n    ML_COMMENT: /\\/\\*[\\s\\S]*?\\*\\//,\r\n    SL_COMMENT: /\\/\\/[^\\n\\r]*/,\r\n};\r\n\r\nexport type LangiumGrammarTerminalNames = keyof typeof LangiumGrammarTerminals;\r\n\r\nexport type LangiumGrammarKeywordNames = \r\n    | \"!\"\r\n    | \"&\"\r\n    | \"(\"\r\n    | \")\"\r\n    | \"*\"\r\n    | \"+\"\r\n    | \"+=\"\r\n    | \",\"\r\n    | \"->\"\r\n    | \".\"\r\n    | \"..\"\r\n    | \":\"\r\n    | \";\"\r\n    | \"<\"\r\n    | \"=\"\r\n    | \"=>\"\r\n    | \">\"\r\n    | \"?\"\r\n    | \"?!\"\r\n    | \"?<!\"\r\n    | \"?<=\"\r\n    | \"?=\"\r\n    | \"@\"\r\n    | \"Date\"\r\n    | \"EOF\"\r\n    | \"[\"\r\n    | \"]\"\r\n    | \"bigint\"\r\n    | \"boolean\"\r\n    | \"current\"\r\n    | \"entry\"\r\n    | \"extends\"\r\n    | \"false\"\r\n    | \"fragment\"\r\n    | \"grammar\"\r\n    | \"hidden\"\r\n    | \"import\"\r\n    | \"infer\"\r\n    | \"infers\"\r\n    | \"interface\"\r\n    | \"number\"\r\n    | \"returns\"\r\n    | \"string\"\r\n    | \"terminal\"\r\n    | \"true\"\r\n    | \"type\"\r\n    | \"with\"\r\n    | \"{\"\r\n    | \"|\"\r\n    | \"}\";\r\n\r\nexport type LangiumGrammarTokenNames = LangiumGrammarTerminalNames | LangiumGrammarKeywordNames;\r\n\r\nexport type AbstractRule = ParserRule | TerminalRule;\r\n\r\nexport const AbstractRule = 'AbstractRule';\r\n\r\nexport function isAbstractRule(item: unknown): item is AbstractRule {\r\n    return reflection.isInstance(item, AbstractRule);\r\n}\r\n\r\nexport type AbstractType = InferredType | Interface | ParserRule | Type;\r\n\r\nexport const AbstractType = 'AbstractType';\r\n\r\nexport function isAbstractType(item: unknown): item is AbstractType {\r\n    return reflection.isInstance(item, AbstractType);\r\n}\r\n\r\nexport type Condition = BooleanLiteral | Conjunction | Disjunction | Negation | ParameterReference;\r\n\r\nexport const Condition = 'Condition';\r\n\r\nexport function isCondition(item: unknown): item is Condition {\r\n    return reflection.isInstance(item, Condition);\r\n}\r\n\r\nexport type FeatureName = 'current' | 'entry' | 'extends' | 'false' | 'fragment' | 'grammar' | 'hidden' | 'import' | 'infer' | 'infers' | 'interface' | 'returns' | 'terminal' | 'true' | 'type' | 'with' | PrimitiveType | string;\r\n\r\nexport function isFeatureName(item: unknown): item is FeatureName {\r\n    return isPrimitiveType(item) || item === 'current' || item === 'entry' || item === 'extends' || item === 'false' || item === 'fragment' || item === 'grammar' || item === 'hidden' || item === 'import' || item === 'interface' || item === 'returns' || item === 'terminal' || item === 'true' || item === 'type' || item === 'infer' || item === 'infers' || item === 'with' || (typeof item === 'string' && (/\\^?[_a-zA-Z][\\w_]*/.test(item)));\r\n}\r\n\r\nexport type PrimitiveType = 'Date' | 'bigint' | 'boolean' | 'number' | 'string';\r\n\r\nexport function isPrimitiveType(item: unknown): item is PrimitiveType {\r\n    return item === 'string' || item === 'number' || item === 'boolean' || item === 'Date' || item === 'bigint';\r\n}\r\n\r\nexport type TypeDefinition = ArrayType | ReferenceType | SimpleType | UnionType;\r\n\r\nexport const TypeDefinition = 'TypeDefinition';\r\n\r\nexport function isTypeDefinition(item: unknown): item is TypeDefinition {\r\n    return reflection.isInstance(item, TypeDefinition);\r\n}\r\n\r\nexport type ValueLiteral = ArrayLiteral | BooleanLiteral | NumberLiteral | StringLiteral;\r\n\r\nexport const ValueLiteral = 'ValueLiteral';\r\n\r\nexport function isValueLiteral(item: unknown): item is ValueLiteral {\r\n    return reflection.isInstance(item, ValueLiteral);\r\n}\r\n\r\nexport interface AbstractElement extends AstNode {\r\n    readonly $type: 'AbstractElement' | 'Action' | 'Alternatives' | 'Assignment' | 'CharacterRange' | 'CrossReference' | 'EndOfFile' | 'Group' | 'Keyword' | 'NegatedToken' | 'RegexToken' | 'RuleCall' | 'TerminalAlternatives' | 'TerminalGroup' | 'TerminalRuleCall' | 'UnorderedGroup' | 'UntilToken' | 'Wildcard';\r\n    cardinality?: '*' | '+' | '?';\r\n    lookahead?: '?!' | '?<!' | '?<=' | '?=';\r\n}\r\n\r\nexport const AbstractElement = 'AbstractElement';\r\n\r\nexport function isAbstractElement(item: unknown): item is AbstractElement {\r\n    return reflection.isInstance(item, AbstractElement);\r\n}\r\n\r\nexport interface ArrayLiteral extends AstNode {\r\n    readonly $container: ArrayLiteral | TypeAttribute;\r\n    readonly $type: 'ArrayLiteral';\r\n    elements: Array<ValueLiteral>;\r\n}\r\n\r\nexport const ArrayLiteral = 'ArrayLiteral';\r\n\r\nexport function isArrayLiteral(item: unknown): item is ArrayLiteral {\r\n    return reflection.isInstance(item, ArrayLiteral);\r\n}\r\n\r\nexport interface ArrayType extends AstNode {\r\n    readonly $container: ArrayType | ReferenceType | Type | TypeAttribute | UnionType;\r\n    readonly $type: 'ArrayType';\r\n    elementType: TypeDefinition;\r\n}\r\n\r\nexport const ArrayType = 'ArrayType';\r\n\r\nexport function isArrayType(item: unknown): item is ArrayType {\r\n    return reflection.isInstance(item, ArrayType);\r\n}\r\n\r\nexport interface BooleanLiteral extends AstNode {\r\n    readonly $container: ArrayLiteral | Conjunction | Disjunction | Group | NamedArgument | Negation | TypeAttribute;\r\n    readonly $type: 'BooleanLiteral';\r\n    true: boolean;\r\n}\r\n\r\nexport const BooleanLiteral = 'BooleanLiteral';\r\n\r\nexport function isBooleanLiteral(item: unknown): item is BooleanLiteral {\r\n    return reflection.isInstance(item, BooleanLiteral);\r\n}\r\n\r\nexport interface Conjunction extends AstNode {\r\n    readonly $container: Conjunction | Disjunction | Group | NamedArgument | Negation;\r\n    readonly $type: 'Conjunction';\r\n    left: Condition;\r\n    right: Condition;\r\n}\r\n\r\nexport const Conjunction = 'Conjunction';\r\n\r\nexport function isConjunction(item: unknown): item is Conjunction {\r\n    return reflection.isInstance(item, Conjunction);\r\n}\r\n\r\nexport interface Disjunction extends AstNode {\r\n    readonly $container: Conjunction | Disjunction | Group | NamedArgument | Negation;\r\n    readonly $type: 'Disjunction';\r\n    left: Condition;\r\n    right: Condition;\r\n}\r\n\r\nexport const Disjunction = 'Disjunction';\r\n\r\nexport function isDisjunction(item: unknown): item is Disjunction {\r\n    return reflection.isInstance(item, Disjunction);\r\n}\r\n\r\nexport interface Grammar extends AstNode {\r\n    readonly $type: 'Grammar';\r\n    definesHiddenTokens: boolean;\r\n    hiddenTokens: Array<Reference<AbstractRule>>;\r\n    imports: Array<GrammarImport>;\r\n    interfaces: Array<Interface>;\r\n    isDeclared: boolean;\r\n    name?: string;\r\n    rules: Array<AbstractRule>;\r\n    types: Array<Type>;\r\n    usedGrammars: Array<Reference<Grammar>>;\r\n}\r\n\r\nexport const Grammar = 'Grammar';\r\n\r\nexport function isGrammar(item: unknown): item is Grammar {\r\n    return reflection.isInstance(item, Grammar);\r\n}\r\n\r\nexport interface GrammarImport extends AstNode {\r\n    readonly $container: Grammar;\r\n    readonly $type: 'GrammarImport';\r\n    path: string;\r\n}\r\n\r\nexport const GrammarImport = 'GrammarImport';\r\n\r\nexport function isGrammarImport(item: unknown): item is GrammarImport {\r\n    return reflection.isInstance(item, GrammarImport);\r\n}\r\n\r\nexport interface InferredType extends AstNode {\r\n    readonly $container: Action | ParserRule;\r\n    readonly $type: 'InferredType';\r\n    name: string;\r\n}\r\n\r\nexport const InferredType = 'InferredType';\r\n\r\nexport function isInferredType(item: unknown): item is InferredType {\r\n    return reflection.isInstance(item, InferredType);\r\n}\r\n\r\nexport interface Interface extends AstNode {\r\n    readonly $container: Grammar;\r\n    readonly $type: 'Interface';\r\n    attributes: Array<TypeAttribute>;\r\n    name: string;\r\n    superTypes: Array<Reference<AbstractType>>;\r\n}\r\n\r\nexport const Interface = 'Interface';\r\n\r\nexport function isInterface(item: unknown): item is Interface {\r\n    return reflection.isInstance(item, Interface);\r\n}\r\n\r\nexport interface NamedArgument extends AstNode {\r\n    readonly $container: RuleCall;\r\n    readonly $type: 'NamedArgument';\r\n    calledByName: boolean;\r\n    parameter?: Reference<Parameter>;\r\n    value: Condition;\r\n}\r\n\r\nexport const NamedArgument = 'NamedArgument';\r\n\r\nexport function isNamedArgument(item: unknown): item is NamedArgument {\r\n    return reflection.isInstance(item, NamedArgument);\r\n}\r\n\r\nexport interface Negation extends AstNode {\r\n    readonly $container: Conjunction | Disjunction | Group | NamedArgument | Negation;\r\n    readonly $type: 'Negation';\r\n    value: Condition;\r\n}\r\n\r\nexport const Negation = 'Negation';\r\n\r\nexport function isNegation(item: unknown): item is Negation {\r\n    return reflection.isInstance(item, Negation);\r\n}\r\n\r\nexport interface NumberLiteral extends AstNode {\r\n    readonly $container: ArrayLiteral | TypeAttribute;\r\n    readonly $type: 'NumberLiteral';\r\n    value: number;\r\n}\r\n\r\nexport const NumberLiteral = 'NumberLiteral';\r\n\r\nexport function isNumberLiteral(item: unknown): item is NumberLiteral {\r\n    return reflection.isInstance(item, NumberLiteral);\r\n}\r\n\r\nexport interface Parameter extends AstNode {\r\n    readonly $container: ParserRule;\r\n    readonly $type: 'Parameter';\r\n    name: string;\r\n}\r\n\r\nexport const Parameter = 'Parameter';\r\n\r\nexport function isParameter(item: unknown): item is Parameter {\r\n    return reflection.isInstance(item, Parameter);\r\n}\r\n\r\nexport interface ParameterReference extends AstNode {\r\n    readonly $container: Conjunction | Disjunction | Group | NamedArgument | Negation;\r\n    readonly $type: 'ParameterReference';\r\n    parameter: Reference<Parameter>;\r\n}\r\n\r\nexport const ParameterReference = 'ParameterReference';\r\n\r\nexport function isParameterReference(item: unknown): item is ParameterReference {\r\n    return reflection.isInstance(item, ParameterReference);\r\n}\r\n\r\nexport interface ParserRule extends AstNode {\r\n    readonly $container: Grammar;\r\n    readonly $type: 'ParserRule';\r\n    dataType?: PrimitiveType;\r\n    definesHiddenTokens: boolean;\r\n    definition: AbstractElement;\r\n    entry: boolean;\r\n    fragment: boolean;\r\n    hiddenTokens: Array<Reference<AbstractRule>>;\r\n    inferredType?: InferredType;\r\n    name: string;\r\n    parameters: Array<Parameter>;\r\n    returnType?: Reference<AbstractType>;\r\n    wildcard: boolean;\r\n}\r\n\r\nexport const ParserRule = 'ParserRule';\r\n\r\nexport function isParserRule(item: unknown): item is ParserRule {\r\n    return reflection.isInstance(item, ParserRule);\r\n}\r\n\r\nexport interface ReferenceType extends AstNode {\r\n    readonly $container: ArrayType | ReferenceType | Type | TypeAttribute | UnionType;\r\n    readonly $type: 'ReferenceType';\r\n    referenceType: TypeDefinition;\r\n}\r\n\r\nexport const ReferenceType = 'ReferenceType';\r\n\r\nexport function isReferenceType(item: unknown): item is ReferenceType {\r\n    return reflection.isInstance(item, ReferenceType);\r\n}\r\n\r\nexport interface ReturnType extends AstNode {\r\n    readonly $container: TerminalRule;\r\n    readonly $type: 'ReturnType';\r\n    name: PrimitiveType | string;\r\n}\r\n\r\nexport const ReturnType = 'ReturnType';\r\n\r\nexport function isReturnType(item: unknown): item is ReturnType {\r\n    return reflection.isInstance(item, ReturnType);\r\n}\r\n\r\nexport interface SimpleType extends AstNode {\r\n    readonly $container: ArrayType | ReferenceType | Type | TypeAttribute | UnionType;\r\n    readonly $type: 'SimpleType';\r\n    primitiveType?: PrimitiveType;\r\n    stringType?: string;\r\n    typeRef?: Reference<AbstractType>;\r\n}\r\n\r\nexport const SimpleType = 'SimpleType';\r\n\r\nexport function isSimpleType(item: unknown): item is SimpleType {\r\n    return reflection.isInstance(item, SimpleType);\r\n}\r\n\r\nexport interface StringLiteral extends AstNode {\r\n    readonly $container: ArrayLiteral | TypeAttribute;\r\n    readonly $type: 'StringLiteral';\r\n    value: string;\r\n}\r\n\r\nexport const StringLiteral = 'StringLiteral';\r\n\r\nexport function isStringLiteral(item: unknown): item is StringLiteral {\r\n    return reflection.isInstance(item, StringLiteral);\r\n}\r\n\r\nexport interface TerminalRule extends AstNode {\r\n    readonly $container: Grammar;\r\n    readonly $type: 'TerminalRule';\r\n    definition: AbstractElement;\r\n    fragment: boolean;\r\n    hidden: boolean;\r\n    name: string;\r\n    type?: ReturnType;\r\n}\r\n\r\nexport const TerminalRule = 'TerminalRule';\r\n\r\nexport function isTerminalRule(item: unknown): item is TerminalRule {\r\n    return reflection.isInstance(item, TerminalRule);\r\n}\r\n\r\nexport interface Type extends AstNode {\r\n    readonly $container: Grammar;\r\n    readonly $type: 'Type';\r\n    name: string;\r\n    type: TypeDefinition;\r\n}\r\n\r\nexport const Type = 'Type';\r\n\r\nexport function isType(item: unknown): item is Type {\r\n    return reflection.isInstance(item, Type);\r\n}\r\n\r\nexport interface TypeAttribute extends AstNode {\r\n    readonly $container: Interface;\r\n    readonly $type: 'TypeAttribute';\r\n    defaultValue?: ValueLiteral;\r\n    isOptional: boolean;\r\n    name: FeatureName;\r\n    type: TypeDefinition;\r\n}\r\n\r\nexport const TypeAttribute = 'TypeAttribute';\r\n\r\nexport function isTypeAttribute(item: unknown): item is TypeAttribute {\r\n    return reflection.isInstance(item, TypeAttribute);\r\n}\r\n\r\nexport interface UnionType extends AstNode {\r\n    readonly $container: ArrayType | ReferenceType | Type | TypeAttribute | UnionType;\r\n    readonly $type: 'UnionType';\r\n    types: Array<TypeDefinition>;\r\n}\r\n\r\nexport const UnionType = 'UnionType';\r\n\r\nexport function isUnionType(item: unknown): item is UnionType {\r\n    return reflection.isInstance(item, UnionType);\r\n}\r\n\r\nexport interface Action extends AbstractElement {\r\n    readonly $type: 'Action';\r\n    feature?: FeatureName;\r\n    inferredType?: InferredType;\r\n    operator?: '+=' | '=';\r\n    type?: Reference<AbstractType>;\r\n}\r\n\r\nexport const Action = 'Action';\r\n\r\nexport function isAction(item: unknown): item is Action {\r\n    return reflection.isInstance(item, Action);\r\n}\r\n\r\nexport interface Alternatives extends AbstractElement {\r\n    readonly $type: 'Alternatives';\r\n    elements: Array<AbstractElement>;\r\n}\r\n\r\nexport const Alternatives = 'Alternatives';\r\n\r\nexport function isAlternatives(item: unknown): item is Alternatives {\r\n    return reflection.isInstance(item, Alternatives);\r\n}\r\n\r\nexport interface Assignment extends AbstractElement {\r\n    readonly $type: 'Assignment';\r\n    feature: FeatureName;\r\n    operator: '+=' | '=' | '?=';\r\n    terminal: AbstractElement;\r\n}\r\n\r\nexport const Assignment = 'Assignment';\r\n\r\nexport function isAssignment(item: unknown): item is Assignment {\r\n    return reflection.isInstance(item, Assignment);\r\n}\r\n\r\nexport interface CharacterRange extends AbstractElement {\r\n    readonly $type: 'CharacterRange';\r\n    left: Keyword;\r\n    right?: Keyword;\r\n}\r\n\r\nexport const CharacterRange = 'CharacterRange';\r\n\r\nexport function isCharacterRange(item: unknown): item is CharacterRange {\r\n    return reflection.isInstance(item, CharacterRange);\r\n}\r\n\r\nexport interface CrossReference extends AbstractElement {\r\n    readonly $type: 'CrossReference';\r\n    deprecatedSyntax: boolean;\r\n    terminal?: AbstractElement;\r\n    type: Reference<AbstractType>;\r\n}\r\n\r\nexport const CrossReference = 'CrossReference';\r\n\r\nexport function isCrossReference(item: unknown): item is CrossReference {\r\n    return reflection.isInstance(item, CrossReference);\r\n}\r\n\r\nexport interface EndOfFile extends AbstractElement {\r\n    readonly $type: 'EndOfFile';\r\n}\r\n\r\nexport const EndOfFile = 'EndOfFile';\r\n\r\nexport function isEndOfFile(item: unknown): item is EndOfFile {\r\n    return reflection.isInstance(item, EndOfFile);\r\n}\r\n\r\nexport interface Group extends AbstractElement {\r\n    readonly $type: 'Group';\r\n    elements: Array<AbstractElement>;\r\n    guardCondition?: Condition;\r\n}\r\n\r\nexport const Group = 'Group';\r\n\r\nexport function isGroup(item: unknown): item is Group {\r\n    return reflection.isInstance(item, Group);\r\n}\r\n\r\nexport interface Keyword extends AbstractElement {\r\n    readonly $container: CharacterRange;\r\n    readonly $type: 'Keyword';\r\n    value: string;\r\n}\r\n\r\nexport const Keyword = 'Keyword';\r\n\r\nexport function isKeyword(item: unknown): item is Keyword {\r\n    return reflection.isInstance(item, Keyword);\r\n}\r\n\r\nexport interface NegatedToken extends AbstractElement {\r\n    readonly $type: 'NegatedToken';\r\n    terminal: AbstractElement;\r\n}\r\n\r\nexport const NegatedToken = 'NegatedToken';\r\n\r\nexport function isNegatedToken(item: unknown): item is NegatedToken {\r\n    return reflection.isInstance(item, NegatedToken);\r\n}\r\n\r\nexport interface RegexToken extends AbstractElement {\r\n    readonly $type: 'RegexToken';\r\n    regex: string;\r\n}\r\n\r\nexport const RegexToken = 'RegexToken';\r\n\r\nexport function isRegexToken(item: unknown): item is RegexToken {\r\n    return reflection.isInstance(item, RegexToken);\r\n}\r\n\r\nexport interface RuleCall extends AbstractElement {\r\n    readonly $type: 'RuleCall';\r\n    arguments: Array<NamedArgument>;\r\n    rule: Reference<AbstractRule>;\r\n}\r\n\r\nexport const RuleCall = 'RuleCall';\r\n\r\nexport function isRuleCall(item: unknown): item is RuleCall {\r\n    return reflection.isInstance(item, RuleCall);\r\n}\r\n\r\nexport interface TerminalAlternatives extends AbstractElement {\r\n    readonly $type: 'TerminalAlternatives';\r\n    elements: Array<AbstractElement>;\r\n}\r\n\r\nexport const TerminalAlternatives = 'TerminalAlternatives';\r\n\r\nexport function isTerminalAlternatives(item: unknown): item is TerminalAlternatives {\r\n    return reflection.isInstance(item, TerminalAlternatives);\r\n}\r\n\r\nexport interface TerminalGroup extends AbstractElement {\r\n    readonly $type: 'TerminalGroup';\r\n    elements: Array<AbstractElement>;\r\n}\r\n\r\nexport const TerminalGroup = 'TerminalGroup';\r\n\r\nexport function isTerminalGroup(item: unknown): item is TerminalGroup {\r\n    return reflection.isInstance(item, TerminalGroup);\r\n}\r\n\r\nexport interface TerminalRuleCall extends AbstractElement {\r\n    readonly $type: 'TerminalRuleCall';\r\n    rule: Reference<TerminalRule>;\r\n}\r\n\r\nexport const TerminalRuleCall = 'TerminalRuleCall';\r\n\r\nexport function isTerminalRuleCall(item: unknown): item is TerminalRuleCall {\r\n    return reflection.isInstance(item, TerminalRuleCall);\r\n}\r\n\r\nexport interface UnorderedGroup extends AbstractElement {\r\n    readonly $type: 'UnorderedGroup';\r\n    elements: Array<AbstractElement>;\r\n}\r\n\r\nexport const UnorderedGroup = 'UnorderedGroup';\r\n\r\nexport function isUnorderedGroup(item: unknown): item is UnorderedGroup {\r\n    return reflection.isInstance(item, UnorderedGroup);\r\n}\r\n\r\nexport interface UntilToken extends AbstractElement {\r\n    readonly $type: 'UntilToken';\r\n    terminal: AbstractElement;\r\n}\r\n\r\nexport const UntilToken = 'UntilToken';\r\n\r\nexport function isUntilToken(item: unknown): item is UntilToken {\r\n    return reflection.isInstance(item, UntilToken);\r\n}\r\n\r\nexport interface Wildcard extends AbstractElement {\r\n    readonly $type: 'Wildcard';\r\n}\r\n\r\nexport const Wildcard = 'Wildcard';\r\n\r\nexport function isWildcard(item: unknown): item is Wildcard {\r\n    return reflection.isInstance(item, Wildcard);\r\n}\r\n\r\nexport type LangiumGrammarAstType = {\r\n    AbstractElement: AbstractElement\r\n    AbstractRule: AbstractRule\r\n    AbstractType: AbstractType\r\n    Action: Action\r\n    Alternatives: Alternatives\r\n    ArrayLiteral: ArrayLiteral\r\n    ArrayType: ArrayType\r\n    Assignment: Assignment\r\n    BooleanLiteral: BooleanLiteral\r\n    CharacterRange: CharacterRange\r\n    Condition: Condition\r\n    Conjunction: Conjunction\r\n    CrossReference: CrossReference\r\n    Disjunction: Disjunction\r\n    EndOfFile: EndOfFile\r\n    Grammar: Grammar\r\n    GrammarImport: GrammarImport\r\n    Group: Group\r\n    InferredType: InferredType\r\n    Interface: Interface\r\n    Keyword: Keyword\r\n    NamedArgument: NamedArgument\r\n    NegatedToken: NegatedToken\r\n    Negation: Negation\r\n    NumberLiteral: NumberLiteral\r\n    Parameter: Parameter\r\n    ParameterReference: ParameterReference\r\n    ParserRule: ParserRule\r\n    ReferenceType: ReferenceType\r\n    RegexToken: RegexToken\r\n    ReturnType: ReturnType\r\n    RuleCall: RuleCall\r\n    SimpleType: SimpleType\r\n    StringLiteral: StringLiteral\r\n    TerminalAlternatives: TerminalAlternatives\r\n    TerminalGroup: TerminalGroup\r\n    TerminalRule: TerminalRule\r\n    TerminalRuleCall: TerminalRuleCall\r\n    Type: Type\r\n    TypeAttribute: TypeAttribute\r\n    TypeDefinition: TypeDefinition\r\n    UnionType: UnionType\r\n    UnorderedGroup: UnorderedGroup\r\n    UntilToken: UntilToken\r\n    ValueLiteral: ValueLiteral\r\n    Wildcard: Wildcard\r\n}\r\n\r\nexport class LangiumGrammarAstReflection extends AbstractAstReflection {\r\n\r\n    getAllTypes(): string[] {\r\n        return [AbstractElement, AbstractRule, AbstractType, Action, Alternatives, ArrayLiteral, ArrayType, Assignment, BooleanLiteral, CharacterRange, Condition, Conjunction, CrossReference, Disjunction, EndOfFile, Grammar, GrammarImport, Group, InferredType, Interface, Keyword, NamedArgument, NegatedToken, Negation, NumberLiteral, Parameter, ParameterReference, ParserRule, ReferenceType, RegexToken, ReturnType, RuleCall, SimpleType, StringLiteral, TerminalAlternatives, TerminalGroup, TerminalRule, TerminalRuleCall, Type, TypeAttribute, TypeDefinition, UnionType, UnorderedGroup, UntilToken, ValueLiteral, Wildcard];\r\n    }\r\n\r\n    protected override computeIsSubtype(subtype: string, supertype: string): boolean {\r\n        switch (subtype) {\r\n            case Action:\r\n            case Alternatives:\r\n            case Assignment:\r\n            case CharacterRange:\r\n            case CrossReference:\r\n            case EndOfFile:\r\n            case Group:\r\n            case Keyword:\r\n            case NegatedToken:\r\n            case RegexToken:\r\n            case RuleCall:\r\n            case TerminalAlternatives:\r\n            case TerminalGroup:\r\n            case TerminalRuleCall:\r\n            case UnorderedGroup:\r\n            case UntilToken:\r\n            case Wildcard: {\r\n                return this.isSubtype(AbstractElement, supertype);\r\n            }\r\n            case ArrayLiteral:\r\n            case NumberLiteral:\r\n            case StringLiteral: {\r\n                return this.isSubtype(ValueLiteral, supertype);\r\n            }\r\n            case ArrayType:\r\n            case ReferenceType:\r\n            case SimpleType:\r\n            case UnionType: {\r\n                return this.isSubtype(TypeDefinition, supertype);\r\n            }\r\n            case BooleanLiteral: {\r\n                return this.isSubtype(Condition, supertype) || this.isSubtype(ValueLiteral, supertype);\r\n            }\r\n            case Conjunction:\r\n            case Disjunction:\r\n            case Negation:\r\n            case ParameterReference: {\r\n                return this.isSubtype(Condition, supertype);\r\n            }\r\n            case InferredType:\r\n            case Interface:\r\n            case Type: {\r\n                return this.isSubtype(AbstractType, supertype);\r\n            }\r\n            case ParserRule: {\r\n                return this.isSubtype(AbstractRule, supertype) || this.isSubtype(AbstractType, supertype);\r\n            }\r\n            case TerminalRule: {\r\n                return this.isSubtype(AbstractRule, supertype);\r\n            }\r\n            default: {\r\n                return false;\r\n            }\r\n        }\r\n    }\r\n\r\n    getReferenceType(refInfo: ReferenceInfo): string {\r\n        const referenceId = `${refInfo.container.$type}:${refInfo.property}`;\r\n        switch (referenceId) {\r\n            case 'Action:type':\r\n            case 'CrossReference:type':\r\n            case 'Interface:superTypes':\r\n            case 'ParserRule:returnType':\r\n            case 'SimpleType:typeRef': {\r\n                return AbstractType;\r\n            }\r\n            case 'Grammar:hiddenTokens':\r\n            case 'ParserRule:hiddenTokens':\r\n            case 'RuleCall:rule': {\r\n                return AbstractRule;\r\n            }\r\n            case 'Grammar:usedGrammars': {\r\n                return Grammar;\r\n            }\r\n            case 'NamedArgument:parameter':\r\n            case 'ParameterReference:parameter': {\r\n                return Parameter;\r\n            }\r\n            case 'TerminalRuleCall:rule': {\r\n                return TerminalRule;\r\n            }\r\n            default: {\r\n                throw new Error(`${referenceId} is not a valid reference id.`);\r\n            }\r\n        }\r\n    }\r\n\r\n    getTypeMetaData(type: string): TypeMetaData {\r\n        switch (type) {\r\n            case AbstractElement: {\r\n                return {\r\n                    name: AbstractElement,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' }\r\n                    ]\r\n                };\r\n            }\r\n            case ArrayLiteral: {\r\n                return {\r\n                    name: ArrayLiteral,\r\n                    properties: [\r\n                        { name: 'elements', defaultValue: [] }\r\n                    ]\r\n                };\r\n            }\r\n            case ArrayType: {\r\n                return {\r\n                    name: ArrayType,\r\n                    properties: [\r\n                        { name: 'elementType' }\r\n                    ]\r\n                };\r\n            }\r\n            case BooleanLiteral: {\r\n                return {\r\n                    name: BooleanLiteral,\r\n                    properties: [\r\n                        { name: 'true', defaultValue: false }\r\n                    ]\r\n                };\r\n            }\r\n            case Conjunction: {\r\n                return {\r\n                    name: Conjunction,\r\n                    properties: [\r\n                        { name: 'left' },\r\n                        { name: 'right' }\r\n                    ]\r\n                };\r\n            }\r\n            case Disjunction: {\r\n                return {\r\n                    name: Disjunction,\r\n                    properties: [\r\n                        { name: 'left' },\r\n                        { name: 'right' }\r\n                    ]\r\n                };\r\n            }\r\n            case Grammar: {\r\n                return {\r\n                    name: Grammar,\r\n                    properties: [\r\n                        { name: 'definesHiddenTokens', defaultValue: false },\r\n                        { name: 'hiddenTokens', defaultValue: [] },\r\n                        { name: 'imports', defaultValue: [] },\r\n                        { name: 'interfaces', defaultValue: [] },\r\n                        { name: 'isDeclared', defaultValue: false },\r\n                        { name: 'name' },\r\n                        { name: 'rules', defaultValue: [] },\r\n                        { name: 'types', defaultValue: [] },\r\n                        { name: 'usedGrammars', defaultValue: [] }\r\n                    ]\r\n                };\r\n            }\r\n            case GrammarImport: {\r\n                return {\r\n                    name: GrammarImport,\r\n                    properties: [\r\n                        { name: 'path' }\r\n                    ]\r\n                };\r\n            }\r\n            case InferredType: {\r\n                return {\r\n                    name: InferredType,\r\n                    properties: [\r\n                        { name: 'name' }\r\n                    ]\r\n                };\r\n            }\r\n            case Interface: {\r\n                return {\r\n                    name: Interface,\r\n                    properties: [\r\n                        { name: 'attributes', defaultValue: [] },\r\n                        { name: 'name' },\r\n                        { name: 'superTypes', defaultValue: [] }\r\n                    ]\r\n                };\r\n            }\r\n            case NamedArgument: {\r\n                return {\r\n                    name: NamedArgument,\r\n                    properties: [\r\n                        { name: 'calledByName', defaultValue: false },\r\n                        { name: 'parameter' },\r\n                        { name: 'value' }\r\n                    ]\r\n                };\r\n            }\r\n            case Negation: {\r\n                return {\r\n                    name: Negation,\r\n                    properties: [\r\n                        { name: 'value' }\r\n                    ]\r\n                };\r\n            }\r\n            case NumberLiteral: {\r\n                return {\r\n                    name: NumberLiteral,\r\n                    properties: [\r\n                        { name: 'value' }\r\n                    ]\r\n                };\r\n            }\r\n            case Parameter: {\r\n                return {\r\n                    name: Parameter,\r\n                    properties: [\r\n                        { name: 'name' }\r\n                    ]\r\n                };\r\n            }\r\n            case ParameterReference: {\r\n                return {\r\n                    name: ParameterReference,\r\n                    properties: [\r\n                        { name: 'parameter' }\r\n                    ]\r\n                };\r\n            }\r\n            case ParserRule: {\r\n                return {\r\n                    name: ParserRule,\r\n                    properties: [\r\n                        { name: 'dataType' },\r\n                        { name: 'definesHiddenTokens', defaultValue: false },\r\n                        { name: 'definition' },\r\n                        { name: 'entry', defaultValue: false },\r\n                        { name: 'fragment', defaultValue: false },\r\n                        { name: 'hiddenTokens', defaultValue: [] },\r\n                        { name: 'inferredType' },\r\n                        { name: 'name' },\r\n                        { name: 'parameters', defaultValue: [] },\r\n                        { name: 'returnType' },\r\n                        { name: 'wildcard', defaultValue: false }\r\n                    ]\r\n                };\r\n            }\r\n            case ReferenceType: {\r\n                return {\r\n                    name: ReferenceType,\r\n                    properties: [\r\n                        { name: 'referenceType' }\r\n                    ]\r\n                };\r\n            }\r\n            case ReturnType: {\r\n                return {\r\n                    name: ReturnType,\r\n                    properties: [\r\n                        { name: 'name' }\r\n                    ]\r\n                };\r\n            }\r\n            case SimpleType: {\r\n                return {\r\n                    name: SimpleType,\r\n                    properties: [\r\n                        { name: 'primitiveType' },\r\n                        { name: 'stringType' },\r\n                        { name: 'typeRef' }\r\n                    ]\r\n                };\r\n            }\r\n            case StringLiteral: {\r\n                return {\r\n                    name: StringLiteral,\r\n                    properties: [\r\n                        { name: 'value' }\r\n                    ]\r\n                };\r\n            }\r\n            case TerminalRule: {\r\n                return {\r\n                    name: TerminalRule,\r\n                    properties: [\r\n                        { name: 'definition' },\r\n                        { name: 'fragment', defaultValue: false },\r\n                        { name: 'hidden', defaultValue: false },\r\n                        { name: 'name' },\r\n                        { name: 'type' }\r\n                    ]\r\n                };\r\n            }\r\n            case Type: {\r\n                return {\r\n                    name: Type,\r\n                    properties: [\r\n                        { name: 'name' },\r\n                        { name: 'type' }\r\n                    ]\r\n                };\r\n            }\r\n            case TypeAttribute: {\r\n                return {\r\n                    name: TypeAttribute,\r\n                    properties: [\r\n                        { name: 'defaultValue' },\r\n                        { name: 'isOptional', defaultValue: false },\r\n                        { name: 'name' },\r\n                        { name: 'type' }\r\n                    ]\r\n                };\r\n            }\r\n            case UnionType: {\r\n                return {\r\n                    name: UnionType,\r\n                    properties: [\r\n                        { name: 'types', defaultValue: [] }\r\n                    ]\r\n                };\r\n            }\r\n            case Action: {\r\n                return {\r\n                    name: Action,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'feature' },\r\n                        { name: 'inferredType' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'operator' },\r\n                        { name: 'type' }\r\n                    ]\r\n                };\r\n            }\r\n            case Alternatives: {\r\n                return {\r\n                    name: Alternatives,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'elements', defaultValue: [] },\r\n                        { name: 'lookahead' }\r\n                    ]\r\n                };\r\n            }\r\n            case Assignment: {\r\n                return {\r\n                    name: Assignment,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'feature' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'operator' },\r\n                        { name: 'terminal' }\r\n                    ]\r\n                };\r\n            }\r\n            case CharacterRange: {\r\n                return {\r\n                    name: CharacterRange,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'left' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'right' }\r\n                    ]\r\n                };\r\n            }\r\n            case CrossReference: {\r\n                return {\r\n                    name: CrossReference,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'deprecatedSyntax', defaultValue: false },\r\n                        { name: 'lookahead' },\r\n                        { name: 'terminal' },\r\n                        { name: 'type' }\r\n                    ]\r\n                };\r\n            }\r\n            case EndOfFile: {\r\n                return {\r\n                    name: EndOfFile,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' }\r\n                    ]\r\n                };\r\n            }\r\n            case Group: {\r\n                return {\r\n                    name: Group,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'elements', defaultValue: [] },\r\n                        { name: 'guardCondition' },\r\n                        { name: 'lookahead' }\r\n                    ]\r\n                };\r\n            }\r\n            case Keyword: {\r\n                return {\r\n                    name: Keyword,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'value' }\r\n                    ]\r\n                };\r\n            }\r\n            case NegatedToken: {\r\n                return {\r\n                    name: NegatedToken,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'terminal' }\r\n                    ]\r\n                };\r\n            }\r\n            case RegexToken: {\r\n                return {\r\n                    name: RegexToken,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'regex' }\r\n                    ]\r\n                };\r\n            }\r\n            case RuleCall: {\r\n                return {\r\n                    name: RuleCall,\r\n                    properties: [\r\n                        { name: 'arguments', defaultValue: [] },\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'rule' }\r\n                    ]\r\n                };\r\n            }\r\n            case TerminalAlternatives: {\r\n                return {\r\n                    name: TerminalAlternatives,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'elements', defaultValue: [] },\r\n                        { name: 'lookahead' }\r\n                    ]\r\n                };\r\n            }\r\n            case TerminalGroup: {\r\n                return {\r\n                    name: TerminalGroup,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'elements', defaultValue: [] },\r\n                        { name: 'lookahead' }\r\n                    ]\r\n                };\r\n            }\r\n            case TerminalRuleCall: {\r\n                return {\r\n                    name: TerminalRuleCall,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'rule' }\r\n                    ]\r\n                };\r\n            }\r\n            case UnorderedGroup: {\r\n                return {\r\n                    name: UnorderedGroup,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'elements', defaultValue: [] },\r\n                        { name: 'lookahead' }\r\n                    ]\r\n                };\r\n            }\r\n            case UntilToken: {\r\n                return {\r\n                    name: UntilToken,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' },\r\n                        { name: 'terminal' }\r\n                    ]\r\n                };\r\n            }\r\n            case Wildcard: {\r\n                return {\r\n                    name: Wildcard,\r\n                    properties: [\r\n                        { name: 'cardinality' },\r\n                        { name: 'lookahead' }\r\n                    ]\r\n                };\r\n            }\r\n            default: {\r\n                return {\r\n                    name: type,\r\n                    properties: []\r\n                };\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\nexport const reflection = new LangiumGrammarAstReflection();\r\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\n/* eslint-disable @typescript-eslint/no-explicit-any */\r\n\r\n/**\r\n * A `Module<I>` is a description of possibly grouped service factories.\r\n *\r\n * Given a type I = { group: { service: A } },\r\n * Module<I> := { group: { service: (injector: I) => A } }\r\n *\r\n * Making `I` available during the creation of `I` allows us to create cyclic\r\n * dependencies.\r\n */\r\nexport type Module<I, T = I> = {\r\n    [K in keyof T]: Module<I, T[K]> | ((injector: I) => T[K])\r\n}\r\n\r\nexport namespace Module {\r\n    export const merge = <M1, M2, R extends M1 & M2>(m1: Module<R, M1>, m2: Module<R, M2>) => (_merge(_merge({}, m1), m2) as Module<R, M1 & M2>);\r\n}\r\n\r\n/**\r\n * Given a set of modules, the inject function returns a lazily evaluated injector\r\n * that injects dependencies into the requested service when it is requested the\r\n * first time. Subsequent requests will return the same service.\r\n *\r\n * In the case of cyclic dependencies, an Error will be thrown. This can be fixed\r\n * by injecting a provider `() => T` instead of a `T`.\r\n *\r\n * Please note that the arguments may be objects or arrays. However, the result will\r\n * be an object. Using it with for..of will have no effect.\r\n *\r\n * @param module1 first Module\r\n * @param module2 (optional) second Module\r\n * @param module3 (optional) third Module\r\n * @param module4 (optional) fourth Module\r\n * @param module5 (optional) fifth Module\r\n * @param module6 (optional) sixth Module\r\n * @param module7 (optional) seventh Module\r\n * @param module8 (optional) eighth Module\r\n * @param module9 (optional) ninth Module\r\n * @returns a new object of type I\r\n */\r\nexport function inject<I1, I2, I3, I4, I5, I6, I7, I8, I9, I extends I1 & I2 & I3 & I4 & I5 & I6 & I7 & I8 & I9>(\r\n    module1: Module<I, I1>, module2?: Module<I, I2>, module3?: Module<I, I3>, module4?: Module<I, I4>, module5?: Module<I, I5>, module6?: Module<I, I6>, module7?: Module<I, I7>, module8?: Module<I, I8>, module9?: Module<I, I9>\r\n): I {\r\n    const module = [module1, module2, module3, module4, module5, module6, module7, module8, module9].reduce(_merge, {}) as Module<I>;\r\n    return _inject(module);\r\n}\r\n\r\nconst isProxy = Symbol('isProxy');\r\n\r\n/**\r\n * Eagerly load all services in the given dependency injection container. This is sometimes\r\n * necessary because services can register event listeners in their constructors.\r\n */\r\nexport function eagerLoad<T>(item: T): T {\r\n    if (item && (item as any)[isProxy]) {\r\n        for (const value of Object.values(item)) {\r\n            eagerLoad(value);\r\n        }\r\n    }\r\n    return item;\r\n}\r\n\r\n/**\r\n * Helper function that returns an injector by creating a proxy.\r\n * Invariant: injector is of type I. If injector is undefined, then T = I.\r\n */\r\nfunction _inject<I, T>(module: Module<I, T>, injector?: any): T {\r\n    const proxy: any = new Proxy({} as any, {\r\n        deleteProperty: () => false,\r\n        set: () => {\r\n            throw new Error('Cannot set property on injected service container');\r\n        },\r\n        get: (obj, prop) => {\r\n            if (prop === isProxy) {\r\n                return true;\r\n            } else {\r\n                return _resolve(obj, prop, module, injector || proxy);\r\n            }\r\n        },\r\n        getOwnPropertyDescriptor: (obj, prop) => (_resolve(obj, prop, module, injector || proxy), Object.getOwnPropertyDescriptor(obj, prop)), // used by for..in\r\n        has: (_, prop) => prop in module, // used by ..in..\r\n        ownKeys: () => [...Object.getOwnPropertyNames(module)] // used by for..in\r\n    });\r\n    return proxy;\r\n}\r\n\r\n/**\r\n * Internally used to tag a requested dependency, directly before calling the factory.\r\n * This allows us to find cycles during instance creation.\r\n */\r\nconst __requested__ = Symbol();\r\n\r\n/**\r\n * Returns the value `obj[prop]`. If the value does not exist, yet, it is resolved from\r\n * the module description. The result of service factories is cached. Groups are\r\n * recursively proxied.\r\n *\r\n * @param obj an object holding all group proxies and services\r\n * @param prop the key of a value within obj\r\n * @param module an object containing groups and service factories\r\n * @param injector the first level proxy that provides access to all values\r\n * @returns the requested value `obj[prop]`\r\n * @throws Error if a dependency cycle is detected\r\n */\r\nfunction _resolve<I, T>(obj: any, prop: string | symbol | number, module: Module<I, T>, injector: I): T[keyof T] | undefined {\r\n    if (prop in obj) {\r\n        if (obj[prop] instanceof Error) {\r\n            throw new Error('Construction failure. Please make sure that your dependencies are constructable.', {cause: obj[prop]});\r\n        }\r\n        if (obj[prop] === __requested__) {\r\n            throw new Error('Cycle detected. Please make \"' + String(prop) + '\" lazy. Visit https://langium.org/docs/reference/configuration-services/#resolving-cyclic-dependencies');\r\n        }\r\n        return obj[prop];\r\n    } else if (prop in module) {\r\n        const value: Module<I, T[keyof T]> | ((injector: I) => T[keyof T]) = module[prop as keyof T];\r\n        obj[prop] = __requested__;\r\n        try {\r\n            obj[prop] = (typeof value === 'function') ? value(injector) : _inject(value, injector);\r\n        } catch (error) {\r\n            obj[prop] = error instanceof Error ? error : undefined;\r\n            throw error;\r\n        }\r\n        return obj[prop];\r\n    } else {\r\n        return undefined;\r\n    }\r\n}\r\n\r\n/**\r\n * Performs a deep-merge of two modules by writing source entries into the target module.\r\n *\r\n * @param target the module which is written\r\n * @param source the module which is read\r\n * @returns the target module\r\n */\r\nfunction _merge(target: Module<any>, source?: Module<any>): Module<unknown> {\r\n    if (source) {\r\n        for (const [key, value2] of Object.entries(source)) {\r\n            if (value2 !== undefined) {\r\n                const value1 = target[key];\r\n                if (value1 !== null && value2 !== null && typeof value1 === 'object' && typeof value2 === 'object') {\r\n                    target[key] = _merge(value1, value2);\r\n                } else {\r\n                    target[key] = value2;\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return target;\r\n}\r\n","/**\n * Gets the last element of `array`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to query.\n * @returns {*} Returns the last element of `array`.\n * @example\n *\n * _.last([1, 2, 3]);\n * // => 3\n */\nfunction last(array) {\n  var length = array == null ? 0 : array.length;\n  return length ? array[length - 1] : undefined;\n}\n\nexport default last;\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { TokenType } from 'chevrotain';\r\nimport type { URI } from './utils/uri-utils.js';\r\nimport type { AbstractElement } from './languages/generated/ast.js';\r\nimport type { DocumentSegment, LangiumDocument } from './workspace/documents.js';\r\n\r\n/**\r\n * A node in the Abstract Syntax Tree (AST).\r\n */\r\nexport interface AstNode {\r\n    /** Every AST node has a type corresponding to what was specified in the grammar declaration. */\r\n    readonly $type: string;\r\n    /** The container node in the AST; every node except the root node has a container. */\r\n    readonly $container?: AstNode;\r\n    /** The property of the `$container` node that contains this node. This is either a direct reference or an array. */\r\n    readonly $containerProperty?: string;\r\n    /** In case `$containerProperty` is an array, the array index is stored here. */\r\n    readonly $containerIndex?: number;\r\n    /** The Concrete Syntax Tree (CST) node of the text range from which this node was parsed. */\r\n    readonly $cstNode?: CstNode;\r\n    /** The document containing the AST; only the root node has a direct reference to the document. */\r\n    readonly $document?: LangiumDocument;\r\n}\r\n\r\nexport function isAstNode(obj: unknown): obj is AstNode {\r\n    return typeof obj === 'object' && obj !== null && typeof (obj as AstNode).$type === 'string';\r\n}\r\n\r\nexport interface GenericAstNode extends AstNode {\r\n    [key: string]: unknown\r\n}\r\n\r\ntype SpecificNodeProperties<N extends AstNode> = keyof Omit<N, keyof AstNode | number | symbol>;\r\n\r\n/**\r\n * The property names of a given AST node type.\r\n */\r\nexport type Properties<N extends AstNode> = SpecificNodeProperties<N> extends never ? string : SpecificNodeProperties<N>\r\n\r\n/**\r\n * A cross-reference in the AST. Cross-references may or may not be successfully resolved.\r\n */\r\nexport interface Reference<T extends AstNode = AstNode> {\r\n    /**\r\n     * The target AST node of this reference. Accessing this property may trigger cross-reference\r\n     * resolution by the `Linker` in case it has not been done yet. If the reference cannot be resolved,\r\n     * the value is `undefined`.\r\n     */\r\n    readonly ref?: T;\r\n\r\n    /** If any problem occurred while resolving the reference, it is described by this property. */\r\n    readonly error?: LinkingError;\r\n    /** The CST node from which the reference was parsed */\r\n    readonly $refNode?: CstNode;\r\n    /** The actual text used to look up in the surrounding scope */\r\n    readonly $refText: string;\r\n    /** The node description for the AstNode returned by `ref`  */\r\n    readonly $nodeDescription?: AstNodeDescription;\r\n}\r\n\r\nexport function isReference(obj: unknown): obj is Reference {\r\n    return typeof obj === 'object' && obj !== null && typeof (obj as Reference).$refText === 'string';\r\n}\r\n\r\nexport type ResolvedReference<T extends AstNode = AstNode> = Reference<T> & {\r\n    readonly ref: T;\r\n}\r\n\r\n/**\r\n * A description of an AST node is used when constructing scopes and looking up cross-reference targets.\r\n */\r\nexport interface AstNodeDescription {\r\n    /** The target node; should be present only for local references (linking to the same document). */\r\n    node?: AstNode;\r\n    /**\r\n     * The document segment that represents the range of the name of the AST node.\r\n     */\r\n    nameSegment?: DocumentSegment;\r\n    /**\r\n     * The document segment that represents the full range of the AST node.\r\n     */\r\n    selectionSegment?: DocumentSegment;\r\n    /** `$type` property value of the AST node */\r\n    type: string;\r\n    /** Name of the AST node; this is usually determined by the `NameProvider` service. */\r\n    name: string;\r\n    /** URI to the document containing the AST node */\r\n    documentUri: URI;\r\n    /** Navigation path inside the document */\r\n    path: string;\r\n}\r\n\r\nexport function isAstNodeDescription(obj: unknown): obj is AstNodeDescription {\r\n    return typeof obj === 'object' && obj !== null\r\n        && typeof (obj as AstNodeDescription).name === 'string'\r\n        && typeof (obj as AstNodeDescription).type === 'string'\r\n        && typeof (obj as AstNodeDescription).path === 'string';\r\n}\r\n\r\n/**\r\n * Information about a cross-reference. This is used when traversing references in an AST or to describe\r\n * unresolved references.\r\n */\r\nexport interface ReferenceInfo {\r\n    reference: Reference\r\n    container: AstNode\r\n    property: string\r\n    index?: number\r\n}\r\n\r\n/**\r\n * Used to collect information when the `Linker` service fails to resolve a cross-reference.\r\n */\r\nexport interface LinkingError extends ReferenceInfo {\r\n    message: string;\r\n    targetDescription?: AstNodeDescription;\r\n}\r\n\r\nexport function isLinkingError(obj: unknown): obj is LinkingError {\r\n    return typeof obj === 'object' && obj !== null\r\n        && isAstNode((obj as LinkingError).container)\r\n        && isReference((obj as LinkingError).reference)\r\n        && typeof (obj as LinkingError).message === 'string';\r\n}\r\n\r\n/**\r\n * Service used for generic access to the structure of the AST. This service is shared between\r\n * all involved languages, so it operates on the superset of types of these languages.\r\n */\r\nexport interface AstReflection {\r\n    getAllTypes(): string[]\r\n    getAllSubTypes(type: string): string[]\r\n    getReferenceType(refInfo: ReferenceInfo): string\r\n    getTypeMetaData(type: string): TypeMetaData\r\n    isInstance(node: unknown, type: string): boolean\r\n    isSubtype(subtype: string, supertype: string): boolean\r\n}\r\n\r\n/**\r\n * An abstract implementation of the {@link AstReflection} interface.\r\n * Serves to cache subtype computation results to improve performance throughout different parts of Langium.\r\n */\r\nexport abstract class AbstractAstReflection implements AstReflection {\r\n\r\n    protected subtypes: Record<string, Record<string, boolean | undefined>> = {};\r\n    protected allSubtypes: Record<string, string[] | undefined> = {};\r\n\r\n    abstract getAllTypes(): string[];\r\n    abstract getReferenceType(refInfo: ReferenceInfo): string;\r\n    abstract getTypeMetaData(type: string): TypeMetaData;\r\n    protected abstract computeIsSubtype(subtype: string, supertype: string): boolean;\r\n\r\n    isInstance(node: unknown, type: string): boolean {\r\n        return isAstNode(node) && this.isSubtype(node.$type, type);\r\n    }\r\n\r\n    isSubtype(subtype: string, supertype: string): boolean {\r\n        if (subtype === supertype) {\r\n            return true;\r\n        }\r\n        let nested = this.subtypes[subtype];\r\n        if (!nested) {\r\n            nested = this.subtypes[subtype] = {};\r\n        }\r\n        const existing = nested[supertype];\r\n        if (existing !== undefined) {\r\n            return existing;\r\n        } else {\r\n            const result = this.computeIsSubtype(subtype, supertype);\r\n            nested[supertype] = result;\r\n            return result;\r\n        }\r\n    }\r\n\r\n    getAllSubTypes(type: string): string[] {\r\n        const existing = this.allSubtypes[type];\r\n        if (existing) {\r\n            return existing;\r\n        } else {\r\n            const allTypes = this.getAllTypes();\r\n            const types: string[] = [];\r\n            for (const possibleSubType of allTypes) {\r\n                if (this.isSubtype(possibleSubType, type)) {\r\n                    types.push(possibleSubType);\r\n                }\r\n            }\r\n            this.allSubtypes[type] = types;\r\n            return types;\r\n        }\r\n    }\r\n}\r\n\r\n/**\r\n * Represents runtime meta data about a meta model type.\r\n */\r\nexport interface TypeMetaData {\r\n    /** The name of this meta model type. Corresponds to the `AstNode.$type` value. */\r\n    name: string\r\n    /** A list of properties. They can contain default values for their respective property in the AST. */\r\n    properties: TypeProperty[]\r\n}\r\n\r\n/**\r\n * Describes the meta data of a property of an AST node.\r\n *\r\n * The optional `defaultValue` indicates that the property is mandatory in the AST node.\r\n * For example, if an AST node contains an array, but no elements of this array have been parsed, we still expect an empty array instead of `undefined`.\r\n */\r\nexport interface TypeProperty {\r\n    name: string\r\n    defaultValue?: PropertyType\r\n}\r\n\r\n/**\r\n * Represents a default value for an AST property.\r\n */\r\nexport type PropertyType = number | string | boolean | PropertyType[];\r\n\r\n/**\r\n * A node in the Concrete Syntax Tree (CST).\r\n */\r\nexport interface CstNode extends DocumentSegment {\r\n    /** The container node in the CST */\r\n    readonly container?: CompositeCstNode;\r\n    /** @deprecated use `container` instead. */\r\n    readonly parent?: CompositeCstNode;\r\n    /** The actual text */\r\n    readonly text: string;\r\n    /** The root CST node */\r\n    readonly root: RootCstNode;\r\n    /** The grammar element from which this node was parsed */\r\n    readonly grammarSource?: AbstractElement;\r\n    /** @deprecated use `grammarSource` instead. */\r\n    readonly feature?: AbstractElement;\r\n    /** The AST node created from this CST node */\r\n    readonly astNode: AstNode;\r\n    /** @deprecated use `astNode` instead. */\r\n    readonly element: AstNode;\r\n    /** Whether the token is hidden, i.e. not explicitly part of the containing grammar rule */\r\n    readonly hidden: boolean;\r\n}\r\n\r\n/**\r\n * A composite CST node contains other nodes, but no directly associated token.\r\n */\r\nexport interface CompositeCstNode extends CstNode {\r\n    readonly content: CstNode[];\r\n    /** @deprecated use `content` instead. */\r\n    readonly children: CstNode[];\r\n}\r\n\r\nexport function isCompositeCstNode(node: unknown): node is CompositeCstNode {\r\n    return typeof node === 'object' && node !== null && Array.isArray((node as CompositeCstNode).content);\r\n}\r\n\r\n/**\r\n * A leaf CST node corresponds to a token in the input token stream.\r\n */\r\nexport interface LeafCstNode extends CstNode {\r\n    readonly tokenType: TokenType;\r\n}\r\n\r\nexport function isLeafCstNode(node: unknown): node is LeafCstNode {\r\n    return typeof node === 'object' && node !== null && typeof (node as LeafCstNode).tokenType === 'object';\r\n}\r\n\r\nexport interface RootCstNode extends CompositeCstNode {\r\n    readonly fullText: string\r\n}\r\n\r\nexport function isRootCstNode(node: unknown): node is RootCstNode {\r\n    return isCompositeCstNode(node) && typeof (node as RootCstNode).fullText === 'string';\r\n}\r\n\r\n/**\r\n * Returns a type to have only properties names (!) of a type T whose property value is of a certain type K.\r\n */\r\ntype ExtractKeysOfValueType<T, K> = { [I in keyof T]: T[I] extends K ? I : never }[keyof T];\r\n\r\n/**\r\n * Returns the property names (!) of an AstNode that are cross-references.\r\n * Meant to be used during cross-reference resolution in combination with `assertUnreachable(context.property)`.\r\n */\r\nexport type CrossReferencesOfAstNodeType<N extends AstNode> = (\r\n    ExtractKeysOfValueType<N, Reference|undefined>\r\n    | ExtractKeysOfValueType<N, Array<Reference|undefined>|undefined>\r\n// eslint-disable-next-line @typescript-eslint/ban-types\r\n) & {};\r\n\r\n/**\r\n * Represents the enumeration-like type, that lists all AstNode types of your grammar.\r\n */\r\nexport type AstTypeList<T> = Record<keyof T, AstNode>;\r\n\r\n/**\r\n * Returns all types that contain cross-references, A is meant to be the interface `XXXAstType` fromm your generated `ast.ts` file.\r\n * Meant to be used during cross-reference resolution in combination with `assertUnreachable(context.container)`.\r\n */\r\nexport type AstNodeTypesWithCrossReferences<A extends AstTypeList<A>> = {\r\n    [T in keyof A]: CrossReferencesOfAstNodeType<A[T]> extends never ? never : A[T]\r\n}[keyof A];\r\n\r\nexport type Mutable<T> = {\r\n    -readonly [P in keyof T]: T[P]\r\n};\r\n","import {\n  AbstractMermaidTokenBuilder,\n  CommonValueConverter,\n  InfoGeneratedModule,\n  MermaidGeneratedSharedModule,\n  __name\n} from \"./chunk-4KMFLZZN.mjs\";\n\n// src/language/info/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/info/tokenBuilder.ts\nvar InfoTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"InfoTokenBuilder\");\n  }\n  constructor() {\n    super([\"info\", \"showInfo\"]);\n  }\n};\n\n// src/language/info/module.ts\nvar InfoModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new InfoTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new CommonValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createInfoServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Info = inject(\n    createDefaultCoreModule({ shared }),\n    InfoGeneratedModule,\n    InfoModule\n  );\n  shared.ServiceRegistry.register(Info);\n  return { shared, Info };\n}\n__name(createInfoServices, \"createInfoServices\");\n\nexport {\n  InfoModule,\n  createInfoServices\n};\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { Range } from 'vscode-languageserver-types';\r\nimport type { AstNode, AstReflection, CstNode, GenericAstNode, Mutable, PropertyType, Reference, ReferenceInfo } from '../syntax-tree.js';\r\nimport type { Stream, TreeStream } from './stream.js';\r\nimport type { LangiumDocument } from '../workspace/documents.js';\r\nimport { isAstNode, isReference } from '../syntax-tree.js';\r\nimport { DONE_RESULT, stream, StreamImpl, TreeStreamImpl } from './stream.js';\r\nimport { inRange } from './cst-utils.js';\r\n\r\n/**\r\n * Link the `$container` and other related properties of every AST node that is directly contained\r\n * in the given `node`.\r\n */\r\nexport function linkContentToContainer(node: AstNode): void {\r\n    for (const [name, value] of Object.entries(node)) {\r\n        if (!name.startsWith('$')) {\r\n            if (Array.isArray(value)) {\r\n                value.forEach((item, index) => {\r\n                    if (isAstNode(item)) {\r\n                        (item as Mutable<AstNode>).$container = node;\r\n                        (item as Mutable<AstNode>).$containerProperty = name;\r\n                        (item as Mutable<AstNode>).$containerIndex = index;\r\n                    }\r\n                });\r\n            } else if (isAstNode(value)) {\r\n                (value as Mutable<AstNode>).$container = node;\r\n                (value as Mutable<AstNode>).$containerProperty = name;\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\n/**\r\n * Walk along the hierarchy of containers from the given AST node to the root and return the first\r\n * node that matches the type predicate. If the start node itself matches, it is returned.\r\n * If no container matches, `undefined` is returned.\r\n */\r\nexport function getContainerOfType<T extends AstNode>(node: AstNode | undefined, typePredicate: (n: AstNode) => n is T): T | undefined {\r\n    let item = node;\r\n    while (item) {\r\n        if (typePredicate(item)) {\r\n            return item;\r\n        }\r\n        item = item.$container;\r\n    }\r\n    return undefined;\r\n}\r\n\r\n/**\r\n * Walk along the hierarchy of containers from the given AST node to the root and check for existence\r\n * of a container that matches the given predicate. The start node is included in the checks.\r\n */\r\nexport function hasContainerOfType(node: AstNode | undefined, predicate: (n: AstNode) => boolean): boolean {\r\n    let item = node;\r\n    while (item) {\r\n        if (predicate(item)) {\r\n            return true;\r\n        }\r\n        item = item.$container;\r\n    }\r\n    return false;\r\n}\r\n\r\n/**\r\n * Retrieve the document in which the given AST node is contained. A reference to the document is\r\n * usually held by the root node of the AST.\r\n *\r\n * @throws an error if the node is not contained in a document.\r\n */\r\nexport function getDocument<T extends AstNode = AstNode>(node: AstNode): LangiumDocument<T> {\r\n    const rootNode = findRootNode(node);\r\n    const result = rootNode.$document;\r\n    if (!result) {\r\n        throw new Error('AST node has no document.');\r\n    }\r\n    return result as LangiumDocument<T>;\r\n}\r\n\r\n/**\r\n * Returns the root node of the given AST node by following the `$container` references.\r\n */\r\nexport function findRootNode(node: AstNode): AstNode {\r\n    while (node.$container) {\r\n        node = node.$container;\r\n    }\r\n    return node;\r\n}\r\n\r\nexport interface AstStreamOptions {\r\n    /**\r\n     * Optional target range that the nodes in the stream need to intersect\r\n     */\r\n    range?: Range\r\n}\r\n\r\n/**\r\n * Create a stream of all AST nodes that are directly contained in the given node. This includes\r\n * single-valued as well as multi-valued (array) properties.\r\n */\r\nexport function streamContents(node: AstNode, options?: AstStreamOptions): Stream<AstNode> {\r\n    if (!node) {\r\n        throw new Error('Node must be an AstNode.');\r\n    }\r\n    const range = options?.range;\r\n    type State = { keys: string[], keyIndex: number, arrayIndex: number };\r\n    return new StreamImpl<State, AstNode>(() => ({\r\n        keys: Object.keys(node),\r\n        keyIndex: 0,\r\n        arrayIndex: 0\r\n    }), state => {\r\n        while (state.keyIndex < state.keys.length) {\r\n            const property = state.keys[state.keyIndex];\r\n            if (!property.startsWith('$')) {\r\n                const value = (node as GenericAstNode)[property];\r\n                if (isAstNode(value)) {\r\n                    state.keyIndex++;\r\n                    if (isAstNodeInRange(value, range)) {\r\n                        return { done: false, value };\r\n                    }\r\n                } else if (Array.isArray(value)) {\r\n                    while (state.arrayIndex < value.length) {\r\n                        const index = state.arrayIndex++;\r\n                        const element = value[index];\r\n                        if (isAstNode(element) && isAstNodeInRange(element, range)) {\r\n                            return { done: false, value: element };\r\n                        }\r\n                    }\r\n                    state.arrayIndex = 0;\r\n                }\r\n            }\r\n            state.keyIndex++;\r\n        }\r\n        return DONE_RESULT;\r\n    });\r\n}\r\n\r\n/**\r\n * Create a stream of all AST nodes that are directly and indirectly contained in the given root node.\r\n * This does not include the root node itself.\r\n */\r\nexport function streamAllContents(root: AstNode, options?: AstStreamOptions): TreeStream<AstNode> {\r\n    if (!root) {\r\n        throw new Error('Root node must be an AstNode.');\r\n    }\r\n    return new TreeStreamImpl(root, node => streamContents(node, options));\r\n}\r\n\r\n/**\r\n * Create a stream of all AST nodes that are directly and indirectly contained in the given root node,\r\n * including the root node itself.\r\n */\r\nexport function streamAst(root: AstNode, options?: AstStreamOptions): TreeStream<AstNode> {\r\n    if (!root) {\r\n        throw new Error('Root node must be an AstNode.');\r\n    } else if (options?.range && !isAstNodeInRange(root, options.range)) {\r\n        // Return an empty stream if the root node isn't in range\r\n        return new TreeStreamImpl(root, () => []);\r\n    }\r\n    return new TreeStreamImpl(root, node => streamContents(node, options), { includeRoot: true });\r\n}\r\n\r\nfunction isAstNodeInRange(astNode: AstNode, range?: Range): boolean {\r\n    if (!range) {\r\n        return true;\r\n    }\r\n    const nodeRange = astNode.$cstNode?.range;\r\n    if (!nodeRange) {\r\n        return false;\r\n    }\r\n    return inRange(nodeRange, range);\r\n}\r\n\r\n/**\r\n * Create a stream of all cross-references that are held by the given AST node. This includes\r\n * single-valued as well as multi-valued (array) properties.\r\n */\r\nexport function streamReferences(node: AstNode): Stream<ReferenceInfo> {\r\n    type State = { keys: string[], keyIndex: number, arrayIndex: number };\r\n    return new StreamImpl<State, ReferenceInfo>(() => ({\r\n        keys: Object.keys(node),\r\n        keyIndex: 0,\r\n        arrayIndex: 0\r\n    }), state => {\r\n        while (state.keyIndex < state.keys.length) {\r\n            const property = state.keys[state.keyIndex];\r\n            if (!property.startsWith('$')) {\r\n                const value = (node as GenericAstNode)[property];\r\n                if (isReference(value)) {\r\n                    state.keyIndex++;\r\n                    return { done: false, value: { reference: value, container: node, property } };\r\n                } else if (Array.isArray(value)) {\r\n                    while (state.arrayIndex < value.length) {\r\n                        const index = state.arrayIndex++;\r\n                        const element = value[index];\r\n                        if (isReference(element)) {\r\n                            return { done: false, value: { reference: element, container: node, property, index } };\r\n                        }\r\n                    }\r\n                    state.arrayIndex = 0;\r\n                }\r\n            }\r\n            state.keyIndex++;\r\n        }\r\n        return DONE_RESULT;\r\n    });\r\n}\r\n\r\n/**\r\n * Returns a Stream of references to the target node from the AstNode tree\r\n *\r\n * @param targetNode AstNode we are looking for\r\n * @param lookup AstNode where we search for references. If not provided, the root node of the document is used as the default value\r\n */\r\nexport function findLocalReferences(targetNode: AstNode, lookup = getDocument(targetNode).parseResult.value): Stream<Reference> {\r\n    const refs: Reference[] = [];\r\n    streamAst(lookup).forEach(node => {\r\n        streamReferences(node).forEach(refInfo => {\r\n            if (refInfo.reference.ref === targetNode) {\r\n                refs.push(refInfo.reference);\r\n            }\r\n        });\r\n    });\r\n    return stream(refs);\r\n}\r\n\r\n/**\r\n * Assigns all mandatory AST properties to the specified node.\r\n *\r\n * @param reflection Reflection object used to gather mandatory properties for the node.\r\n * @param node Specified node is modified in place and properties are directly assigned.\r\n */\r\nexport function assignMandatoryProperties(reflection: AstReflection, node: AstNode): void {\r\n    const typeMetaData = reflection.getTypeMetaData(node.$type);\r\n    const genericNode = node as GenericAstNode;\r\n    for (const property of typeMetaData.properties) {\r\n        // Only set the value if the property is not already set and if it has a default value\r\n        if (property.defaultValue !== undefined && genericNode[property.name] === undefined) {\r\n            genericNode[property.name] = copyDefaultValue(property.defaultValue);\r\n        }\r\n    }\r\n}\r\n\r\nfunction copyDefaultValue(propertyType: PropertyType): PropertyType {\r\n    if (Array.isArray(propertyType)) {\r\n        return [...propertyType.map(copyDefaultValue)];\r\n    } else {\r\n        return propertyType;\r\n    }\r\n}\r\n\r\n/**\r\n * Creates a deep copy of the specified AST node.\r\n * The resulting copy will only contain semantically relevant information, such as the `$type` property and AST properties.\r\n *\r\n * References are copied without resolved cross reference. The specified function is used to rebuild them.\r\n */\r\nexport function copyAstNode<T extends AstNode = AstNode>(node: T, buildReference: (node: AstNode, property: string, refNode: CstNode | undefined, refText: string) => Reference<AstNode>): T {\r\n    const copy: GenericAstNode = { $type: node.$type };\r\n\r\n    for (const [name, value] of Object.entries(node)) {\r\n        if (!name.startsWith('$')) {\r\n            if (isAstNode(value)) {\r\n                copy[name] = copyAstNode(value, buildReference);\r\n            } else if (isReference(value)) {\r\n                copy[name] = buildReference(\r\n                    copy,\r\n                    name,\r\n                    value.$refNode,\r\n                    value.$refText\r\n                );\r\n            } else if (Array.isArray(value)) {\r\n                const copiedArray: unknown[] = [];\r\n                for (const element of value) {\r\n                    if (isAstNode(element)) {\r\n                        copiedArray.push(copyAstNode(element, buildReference));\r\n                    } else if (isReference(element)) {\r\n                        copiedArray.push(\r\n                            buildReference(\r\n                                copy,\r\n                                name,\r\n                                element.$refNode,\r\n                                element.$refText\r\n                            )\r\n                        );\r\n                    } else {\r\n                        copiedArray.push(element);\r\n                    }\r\n                }\r\n                copy[name] = copiedArray;\r\n            } else {\r\n                copy[name] = value;\r\n            }\r\n        }\r\n    }\r\n\r\n    linkContentToContainer(copy);\r\n    return copy as unknown as T;\r\n}\r\n","// based on: https://github.com/petkaantonov/bluebird/blob/b97c0d2d487e8c5076e8bd897e0dcd4622d31846/src/util.js#L201-L216\nexport function toFastProperties(toBecomeFast: any) {\n  function FakeConstructor() {}\n\n  // If our object is used as a constructor, it would receive\n  FakeConstructor.prototype = toBecomeFast;\n  const fakeInstance = new (FakeConstructor as any)();\n\n  function fakeAccess() {\n    return typeof fakeInstance.bar;\n  }\n\n  // help V8 understand this is a \"real\" prototype by actually using\n  // the fake instance.\n  fakeAccess();\n  fakeAccess();\n\n  // Always true condition to suppress the Firefox warning of unreachable\n  // code after a return statement.\n  if (1) return toBecomeFast;\n\n  // Eval prevents optimization of this method (even though this is dead code)\n  // - https://esbuild.github.io/content-types/#direct-eval\n  /* istanbul ignore next */\n  // tslint:disable-next-line\n  (0, eval)(toBecomeFast);\n}\n","/**\n * The base implementation of `_.slice` without an iteratee call guard.\n *\n * @private\n * @param {Array} array The array to slice.\n * @param {number} [start=0] The start position.\n * @param {number} [end=array.length] The end position.\n * @returns {Array} Returns the slice of `array`.\n */\nfunction baseSlice(array, start, end) {\n  var index = -1,\n      length = array.length;\n\n  if (start < 0) {\n    start = -start > length ? 0 : (length + start);\n  }\n  end = end > length ? length : end;\n  if (end < 0) {\n    end += length;\n  }\n  length = start > end ? 0 : ((end - start) >>> 0);\n  start >>>= 0;\n\n  var result = Array(length);\n  while (++index < length) {\n    result[index] = array[index + start];\n  }\n  return result;\n}\n\nexport default baseSlice;\n","import baseSlice from './_baseSlice.js';\nimport toInteger from './toInteger.js';\n\n/**\n * Creates a slice of `array` with `n` elements dropped from the beginning.\n *\n * @static\n * @memberOf _\n * @since 0.5.0\n * @category Array\n * @param {Array} array The array to query.\n * @param {number} [n=1] The number of elements to drop.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {Array} Returns the slice of `array`.\n * @example\n *\n * _.drop([1, 2, 3]);\n * // => [2, 3]\n *\n * _.drop([1, 2, 3], 2);\n * // => [3]\n *\n * _.drop([1, 2, 3], 5);\n * // => []\n *\n * _.drop([1, 2, 3], 0);\n * // => [1, 2, 3]\n */\nfunction drop(array, n, guard) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return [];\n  }\n  n = (guard || n === undefined) ? 1 : toInteger(n);\n  return baseSlice(array, n < 0 ? 0 : n, length);\n}\n\nexport default drop;\n","import assignValue from './_assignValue.js';\nimport copyObject from './_copyObject.js';\nimport createAssigner from './_createAssigner.js';\nimport isArrayLike from './isArrayLike.js';\nimport isPrototype from './_isPrototype.js';\nimport keys from './keys.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Assigns own enumerable string keyed properties of source objects to the\n * destination object. Source objects are applied from left to right.\n * Subsequent sources overwrite property assignments of previous sources.\n *\n * **Note:** This method mutates `object` and is loosely based on\n * [`Object.assign`](https://mdn.io/Object/assign).\n *\n * @static\n * @memberOf _\n * @since 0.10.0\n * @category Object\n * @param {Object} object The destination object.\n * @param {...Object} [sources] The source objects.\n * @returns {Object} Returns `object`.\n * @see _.assignIn\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n * }\n *\n * function Bar() {\n *   this.c = 3;\n * }\n *\n * Foo.prototype.b = 2;\n * Bar.prototype.d = 4;\n *\n * _.assign({ 'a': 0 }, new Foo, new Bar);\n * // => { 'a': 1, 'c': 3 }\n */\nvar assign = createAssigner(function(object, source) {\n  if (isPrototype(source) || isArrayLike(source)) {\n    copyObject(source, keys(source), object);\n    return;\n  }\n  for (var key in source) {\n    if (hasOwnProperty.call(source, key)) {\n      assignValue(object, key, source[key]);\n    }\n  }\n});\n\nexport default assign;\n","import arrayMap from './_arrayMap.js';\nimport baseIteratee from './_baseIteratee.js';\nimport basePickBy from './_basePickBy.js';\nimport getAllKeysIn from './_getAllKeysIn.js';\n\n/**\n * Creates an object composed of the `object` properties `predicate` returns\n * truthy for. The predicate is invoked with two arguments: (value, key).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Object\n * @param {Object} object The source object.\n * @param {Function} [predicate=_.identity] The function invoked per property.\n * @returns {Object} Returns the new object.\n * @example\n *\n * var object = { 'a': 1, 'b': '2', 'c': 3 };\n *\n * _.pickBy(object, _.isNumber);\n * // => { 'a': 1, 'c': 3 }\n */\nfunction pickBy(object, predicate) {\n  if (object == null) {\n    return {};\n  }\n  var props = arrayMap(getAllKeysIn(object), function(prop) {\n    return [prop];\n  });\n  predicate = baseIteratee(predicate);\n  return basePickBy(object, props, function(value, path) {\n    return predicate(value, path[0]);\n  });\n}\n\nexport default pickBy;\n","import baseGetTag from './_baseGetTag.js';\nimport isObjectLike from './isObjectLike.js';\n\n/** `Object#toString` result references. */\nvar regexpTag = '[object RegExp]';\n\n/**\n * The base implementation of `_.isRegExp` without Node.js optimizations.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a regexp, else `false`.\n */\nfunction baseIsRegExp(value) {\n  return isObjectLike(value) && baseGetTag(value) == regexpTag;\n}\n\nexport default baseIsRegExp;\n","import baseIsRegExp from './_baseIsRegExp.js';\nimport baseUnary from './_baseUnary.js';\nimport nodeUtil from './_nodeUtil.js';\n\n/* Node.js helper references. */\nvar nodeIsRegExp = nodeUtil && nodeUtil.isRegExp;\n\n/**\n * Checks if `value` is classified as a `RegExp` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a regexp, else `false`.\n * @example\n *\n * _.isRegExp(/abc/);\n * // => true\n *\n * _.isRegExp('/abc/');\n * // => false\n */\nvar isRegExp = nodeIsRegExp ? baseUnary(nodeIsRegExp) : baseIsRegExp;\n\nexport default isRegExp;\n","import { assign, forEach, isRegExp, isString, map, pickBy } from \"lodash-es\";\nimport type {\n  IGASTVisitor,\n  IProduction,\n  IProductionWithOccurrence,\n  ISerializedGast,\n  TokenType,\n} from \"@chevrotain/types\";\n\n// TODO: duplicated code to avoid extracting another sub-package -- how to avoid?\nfunction tokenLabel(tokType: TokenType): string {\n  if (hasTokenLabel(tokType)) {\n    return tokType.LABEL;\n  } else {\n    return tokType.name;\n  }\n}\n\n// TODO: duplicated code to avoid extracting another sub-package -- how to avoid?\nfunction hasTokenLabel(\n  obj: TokenType,\n): obj is TokenType & Pick<Required<TokenType>, \"LABEL\"> {\n  return isString(obj.LABEL) && obj.LABEL !== \"\";\n}\n\nexport abstract class AbstractProduction<T extends IProduction = IProduction>\n  implements IProduction\n{\n  public get definition(): T[] {\n    return this._definition;\n  }\n  public set definition(value: T[]) {\n    this._definition = value;\n  }\n\n  constructor(protected _definition: T[]) {}\n\n  accept(visitor: IGASTVisitor): void {\n    visitor.visit(this);\n    forEach(this.definition, (prod) => {\n      prod.accept(visitor);\n    });\n  }\n}\n\nexport class NonTerminal\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public nonTerminalName!: string;\n  public label?: string;\n  public referencedRule!: Rule;\n  public idx: number = 1;\n\n  constructor(options: {\n    nonTerminalName: string;\n    label?: string;\n    referencedRule?: Rule;\n    idx?: number;\n  }) {\n    super([]);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n\n  set definition(definition: IProduction[]) {\n    // immutable\n  }\n\n  get definition(): IProduction[] {\n    if (this.referencedRule !== undefined) {\n      return this.referencedRule.definition;\n    }\n    return [];\n  }\n\n  accept(visitor: IGASTVisitor): void {\n    visitor.visit(this);\n    // don't visit children of a reference, we will get cyclic infinite loops if we do so\n  }\n}\n\nexport class Rule extends AbstractProduction {\n  public name!: string;\n  public orgText: string = \"\";\n\n  constructor(options: {\n    name: string;\n    definition: IProduction[];\n    orgText?: string;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class Alternative extends AbstractProduction {\n  public ignoreAmbiguities: boolean = false;\n\n  constructor(options: {\n    definition: IProduction[];\n    ignoreAmbiguities?: boolean;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class Option\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public idx: number = 1;\n  public maxLookahead?: number;\n\n  constructor(options: {\n    definition: IProduction[];\n    idx?: number;\n    maxLookahead?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class RepetitionMandatory\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public idx: number = 1;\n  public maxLookahead?: number;\n\n  constructor(options: {\n    definition: IProduction[];\n    idx?: number;\n    maxLookahead?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class RepetitionMandatoryWithSeparator\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public separator!: TokenType;\n  public idx: number = 1;\n  public maxLookahead?: number;\n\n  constructor(options: {\n    definition: IProduction[];\n    separator: TokenType;\n    idx?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class Repetition\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public separator!: TokenType;\n  public idx: number = 1;\n  public maxLookahead?: number;\n\n  constructor(options: {\n    definition: IProduction[];\n    idx?: number;\n    maxLookahead?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class RepetitionWithSeparator\n  extends AbstractProduction\n  implements IProductionWithOccurrence\n{\n  public separator!: TokenType;\n  public idx: number = 1;\n  public maxLookahead?: number;\n\n  constructor(options: {\n    definition: IProduction[];\n    separator: TokenType;\n    idx?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class Alternation\n  extends AbstractProduction<Alternative>\n  implements IProductionWithOccurrence\n{\n  public idx: number = 1;\n  public ignoreAmbiguities: boolean = false;\n  public hasPredicates: boolean = false;\n  public maxLookahead?: number;\n\n  public get definition(): Alternative[] {\n    return this._definition;\n  }\n  public set definition(value: Alternative[]) {\n    this._definition = value;\n  }\n\n  constructor(options: {\n    definition: Alternative[];\n    idx?: number;\n    ignoreAmbiguities?: boolean;\n    hasPredicates?: boolean;\n    maxLookahead?: number;\n  }) {\n    super(options.definition);\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n}\n\nexport class Terminal implements IProductionWithOccurrence {\n  public terminalType!: TokenType;\n  public label?: string;\n  public idx: number = 1;\n\n  constructor(options: {\n    terminalType: TokenType;\n    label?: string;\n    idx?: number;\n  }) {\n    assign(\n      this,\n      pickBy(options, (v) => v !== undefined),\n    );\n  }\n\n  accept(visitor: IGASTVisitor): void {\n    visitor.visit(this);\n  }\n}\n\nexport interface ISerializedBasic extends ISerializedGast {\n  type:\n    | \"Alternative\"\n    | \"Option\"\n    | \"RepetitionMandatory\"\n    | \"Repetition\"\n    | \"Alternation\";\n  idx?: number;\n}\n\nexport interface ISerializedGastRule extends ISerializedGast {\n  type: \"Rule\";\n  name: string;\n  orgText: string;\n}\n\nexport interface ISerializedNonTerminal extends ISerializedGast {\n  type: \"NonTerminal\";\n  name: string;\n  label?: string;\n  idx: number;\n}\n\nexport interface ISerializedTerminal extends ISerializedGast {\n  type: \"Terminal\";\n  name: string;\n  terminalLabel?: string;\n  label?: string;\n  pattern?: string;\n  idx: number;\n}\n\nexport interface ISerializedTerminalWithSeparator extends ISerializedGast {\n  type: \"RepetitionMandatoryWithSeparator\" | \"RepetitionWithSeparator\";\n  idx: number;\n  separator: ISerializedTerminal;\n}\n\nexport type ISerializedGastAny =\n  | ISerializedBasic\n  | ISerializedGastRule\n  | ISerializedNonTerminal\n  | ISerializedTerminal\n  | ISerializedTerminalWithSeparator;\n\nexport function serializeGrammar(topRules: Rule[]): ISerializedGast[] {\n  return map(topRules, serializeProduction);\n}\n\nexport function serializeProduction(node: IProduction): ISerializedGast {\n  function convertDefinition(definition: IProduction[]): ISerializedGast[] {\n    return map(definition, serializeProduction);\n  }\n  /* istanbul ignore else */\n  if (node instanceof NonTerminal) {\n    const serializedNonTerminal: ISerializedNonTerminal = {\n      type: \"NonTerminal\",\n      name: node.nonTerminalName,\n      idx: node.idx,\n    };\n\n    if (isString(node.label)) {\n      serializedNonTerminal.label = node.label;\n    }\n\n    return serializedNonTerminal;\n  } else if (node instanceof Alternative) {\n    return <ISerializedBasic>{\n      type: \"Alternative\",\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof Option) {\n    return <ISerializedBasic>{\n      type: \"Option\",\n      idx: node.idx,\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof RepetitionMandatory) {\n    return <ISerializedBasic>{\n      type: \"RepetitionMandatory\",\n      idx: node.idx,\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof RepetitionMandatoryWithSeparator) {\n    return <ISerializedTerminalWithSeparator>{\n      type: \"RepetitionMandatoryWithSeparator\",\n      idx: node.idx,\n      separator: <ISerializedTerminal>(\n        serializeProduction(new Terminal({ terminalType: node.separator }))\n      ),\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof RepetitionWithSeparator) {\n    return <ISerializedTerminalWithSeparator>{\n      type: \"RepetitionWithSeparator\",\n      idx: node.idx,\n      separator: <ISerializedTerminal>(\n        serializeProduction(new Terminal({ terminalType: node.separator }))\n      ),\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof Repetition) {\n    return <ISerializedBasic>{\n      type: \"Repetition\",\n      idx: node.idx,\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof Alternation) {\n    return <ISerializedBasic>{\n      type: \"Alternation\",\n      idx: node.idx,\n      definition: convertDefinition(node.definition),\n    };\n  } else if (node instanceof Terminal) {\n    const serializedTerminal = <ISerializedTerminal>{\n      type: \"Terminal\",\n      name: node.terminalType.name,\n      label: tokenLabel(node.terminalType),\n      idx: node.idx,\n    };\n\n    if (isString(node.label)) {\n      serializedTerminal.terminalLabel = node.label;\n    }\n\n    const pattern = node.terminalType.PATTERN;\n    if (node.terminalType.PATTERN) {\n      serializedTerminal.pattern = isRegExp(pattern)\n        ? (<any>pattern).source\n        : pattern;\n    }\n\n    return serializedTerminal;\n  } else if (node instanceof Rule) {\n    return <ISerializedGastRule>{\n      type: \"Rule\",\n      name: node.name,\n      orgText: node.orgText,\n      definition: convertDefinition(node.definition),\n    };\n    /* c8 ignore next 3 */\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n","import {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n} from \"./model.js\";\nimport type { IProduction } from \"@chevrotain/types\";\n\nexport abstract class GAstVisitor {\n  public visit(node: IProduction): any {\n    const nodeAny: any = node;\n    switch (nodeAny.constructor) {\n      case NonTerminal:\n        return this.visitNonTerminal(nodeAny);\n      case Alternative:\n        return this.visitAlternative(nodeAny);\n      case Option:\n        return this.visitOption(nodeAny);\n      case RepetitionMandatory:\n        return this.visitRepetitionMandatory(nodeAny);\n      case RepetitionMandatoryWithSeparator:\n        return this.visitRepetitionMandatoryWithSeparator(nodeAny);\n      case RepetitionWithSeparator:\n        return this.visitRepetitionWithSeparator(nodeAny);\n      case Repetition:\n        return this.visitRepetition(nodeAny);\n      case Alternation:\n        return this.visitAlternation(nodeAny);\n      case Terminal:\n        return this.visitTerminal(nodeAny);\n      case Rule:\n        return this.visitRule(nodeAny);\n      /* c8 ignore next 2 */\n      default:\n        throw Error(\"non exhaustive match\");\n    }\n  }\n\n  /* c8 ignore next */\n  public visitNonTerminal(node: NonTerminal): any {}\n\n  /* c8 ignore next */\n  public visitAlternative(node: Alternative): any {}\n\n  /* c8 ignore next */\n  public visitOption(node: Option): any {}\n\n  /* c8 ignore next */\n  public visitRepetition(node: Repetition): any {}\n\n  /* c8 ignore next */\n  public visitRepetitionMandatory(node: RepetitionMandatory): any {}\n\n  /* c8 ignore next 3 */\n  public visitRepetitionMandatoryWithSeparator(\n    node: RepetitionMandatoryWithSeparator,\n  ): any {}\n\n  /* c8 ignore next */\n  public visitRepetitionWithSeparator(node: RepetitionWithSeparator): any {}\n\n  /* c8 ignore next */\n  public visitAlternation(node: Alternation): any {}\n\n  /* c8 ignore next */\n  public visitTerminal(node: Terminal): any {}\n\n  /* c8 ignore next */\n  public visitRule(node: Rule): any {}\n}\n","import baseEach from './_baseEach.js';\n\n/**\n * The base implementation of `_.some` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if any element passes the predicate check,\n *  else `false`.\n */\nfunction baseSome(collection, predicate) {\n  var result;\n\n  baseEach(collection, function(value, index, collection) {\n    result = predicate(value, index, collection);\n    return !result;\n  });\n  return !!result;\n}\n\nexport default baseSome;\n","import arraySome from './_arraySome.js';\nimport baseIteratee from './_baseIteratee.js';\nimport baseSome from './_baseSome.js';\nimport isArray from './isArray.js';\nimport isIterateeCall from './_isIterateeCall.js';\n\n/**\n * Checks if `predicate` returns truthy for **any** element of `collection`.\n * Iteration is stopped once `predicate` returns truthy. The predicate is\n * invoked with three arguments: (value, index|key, collection).\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {boolean} Returns `true` if any element passes the predicate check,\n *  else `false`.\n * @example\n *\n * _.some([null, 0, 'yes', false], Boolean);\n * // => true\n *\n * var users = [\n *   { 'user': 'barney', 'active': true },\n *   { 'user': 'fred',   'active': false }\n * ];\n *\n * // The `_.matches` iteratee shorthand.\n * _.some(users, { 'user': 'barney', 'active': false });\n * // => false\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.some(users, ['active', false]);\n * // => true\n *\n * // The `_.property` iteratee shorthand.\n * _.some(users, 'active');\n * // => true\n */\nfunction some(collection, predicate, guard) {\n  var func = isArray(collection) ? arraySome : baseSome;\n  if (guard && isIterateeCall(collection, predicate, guard)) {\n    predicate = undefined;\n  }\n  return func(collection, baseIteratee(predicate, 3));\n}\n\nexport default some;\n","import baseIndexOf from './_baseIndexOf.js';\nimport isArrayLike from './isArrayLike.js';\nimport isString from './isString.js';\nimport toInteger from './toInteger.js';\nimport values from './values.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * Checks if `value` is in `collection`. If `collection` is a string, it's\n * checked for a substring of `value`, otherwise\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * is used for equality comparisons. If `fromIndex` is negative, it's used as\n * the offset from the end of `collection`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object|string} collection The collection to inspect.\n * @param {*} value The value to search for.\n * @param {number} [fromIndex=0] The index to search from.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.reduce`.\n * @returns {boolean} Returns `true` if `value` is found, else `false`.\n * @example\n *\n * _.includes([1, 2, 3], 1);\n * // => true\n *\n * _.includes([1, 2, 3], 1, 2);\n * // => false\n *\n * _.includes({ 'a': 1, 'b': 2 }, 1);\n * // => true\n *\n * _.includes('abcd', 'bc');\n * // => true\n */\nfunction includes(collection, value, fromIndex, guard) {\n  collection = isArrayLike(collection) ? collection : values(collection);\n  fromIndex = (fromIndex && !guard) ? toInteger(fromIndex) : 0;\n\n  var length = collection.length;\n  if (fromIndex < 0) {\n    fromIndex = nativeMax(length + fromIndex, 0);\n  }\n  return isString(collection)\n    ? (fromIndex <= length && collection.indexOf(value, fromIndex) > -1)\n    : (!!length && baseIndexOf(collection, value, fromIndex) > -1);\n}\n\nexport default includes;\n","/**\n * A specialized version of `_.every` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if all elements pass the predicate check,\n *  else `false`.\n */\nfunction arrayEvery(array, predicate) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    if (!predicate(array[index], index, array)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport default arrayEvery;\n","import baseEach from './_baseEach.js';\n\n/**\n * The base implementation of `_.every` without support for iteratee shorthands.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} predicate The function invoked per iteration.\n * @returns {boolean} Returns `true` if all elements pass the predicate check,\n *  else `false`\n */\nfunction baseEvery(collection, predicate) {\n  var result = true;\n  baseEach(collection, function(value, index, collection) {\n    result = !!predicate(value, index, collection);\n    return result;\n  });\n  return result;\n}\n\nexport default baseEvery;\n","import arrayEvery from './_arrayEvery.js';\nimport baseEvery from './_baseEvery.js';\nimport baseIteratee from './_baseIteratee.js';\nimport isArray from './isArray.js';\nimport isIterateeCall from './_isIterateeCall.js';\n\n/**\n * Checks if `predicate` returns truthy for **all** elements of `collection`.\n * Iteration is stopped once `predicate` returns falsey. The predicate is\n * invoked with three arguments: (value, index|key, collection).\n *\n * **Note:** This method returns `true` for\n * [empty collections](https://en.wikipedia.org/wiki/Empty_set) because\n * [everything is true](https://en.wikipedia.org/wiki/Vacuous_truth) of\n * elements of empty collections.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {boolean} Returns `true` if all elements pass the predicate check,\n *  else `false`.\n * @example\n *\n * _.every([true, 1, null, 'yes'], Boolean);\n * // => false\n *\n * var users = [\n *   { 'user': 'barney', 'age': 36, 'active': false },\n *   { 'user': 'fred',   'age': 40, 'active': false }\n * ];\n *\n * // The `_.matches` iteratee shorthand.\n * _.every(users, { 'user': 'barney', 'active': false });\n * // => false\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.every(users, ['active', false]);\n * // => true\n *\n * // The `_.property` iteratee shorthand.\n * _.every(users, 'active');\n * // => false\n */\nfunction every(collection, predicate, guard) {\n  var func = isArray(collection) ? arrayEvery : baseEvery;\n  if (guard && isIterateeCall(collection, predicate, guard)) {\n    predicate = undefined;\n  }\n  return func(collection, baseIteratee(predicate, 3));\n}\n\nexport default every;\n","import { every, includes, some } from \"lodash-es\";\nimport {\n  AbstractProduction,\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n} from \"./model.js\";\nimport type { IProduction, IProductionWithOccurrence } from \"@chevrotain/types\";\n\nexport function isSequenceProd(\n  prod: IProduction,\n): prod is { definition: IProduction[] } & IProduction {\n  return (\n    prod instanceof Alternative ||\n    prod instanceof Option ||\n    prod instanceof Repetition ||\n    prod instanceof RepetitionMandatory ||\n    prod instanceof RepetitionMandatoryWithSeparator ||\n    prod instanceof RepetitionWithSeparator ||\n    prod instanceof Terminal ||\n    prod instanceof Rule\n  );\n}\n\nexport function isOptionalProd(\n  prod: IProduction,\n  alreadyVisited: NonTerminal[] = [],\n): boolean {\n  const isDirectlyOptional =\n    prod instanceof Option ||\n    prod instanceof Repetition ||\n    prod instanceof RepetitionWithSeparator;\n  if (isDirectlyOptional) {\n    return true;\n  }\n\n  // note that this can cause infinite loop if one optional empty TOP production has a cyclic dependency with another\n  // empty optional top rule\n  // may be indirectly optional ((A?B?C?) | (D?E?F?))\n  if (prod instanceof Alternation) {\n    // for OR its enough for just one of the alternatives to be optional\n    return some((<Alternation>prod).definition, (subProd: IProduction) => {\n      return isOptionalProd(subProd, alreadyVisited);\n    });\n  } else if (prod instanceof NonTerminal && includes(alreadyVisited, prod)) {\n    // avoiding stack overflow due to infinite recursion\n    return false;\n  } else if (prod instanceof AbstractProduction) {\n    if (prod instanceof NonTerminal) {\n      alreadyVisited.push(prod);\n    }\n    return every(\n      (<AbstractProduction>prod).definition,\n      (subProd: IProduction) => {\n        return isOptionalProd(subProd, alreadyVisited);\n      },\n    );\n  } else {\n    return false;\n  }\n}\n\nexport function isBranchingProd(\n  prod: IProduction,\n): prod is { definition: IProduction[] } & IProduction {\n  return prod instanceof Alternation;\n}\n\nexport function getProductionDslName(prod: IProductionWithOccurrence): string {\n  /* istanbul ignore else */\n  if (prod instanceof NonTerminal) {\n    return \"SUBRULE\";\n  } else if (prod instanceof Option) {\n    return \"OPTION\";\n  } else if (prod instanceof Alternation) {\n    return \"OR\";\n  } else if (prod instanceof RepetitionMandatory) {\n    return \"AT_LEAST_ONE\";\n  } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n    return \"AT_LEAST_ONE_SEP\";\n  } else if (prod instanceof RepetitionWithSeparator) {\n    return \"MANY_SEP\";\n  } else if (prod instanceof Repetition) {\n    return \"MANY\";\n  } else if (prod instanceof Terminal) {\n    return \"CONSUME\";\n    /* c8 ignore next 3 */\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n","import { drop, forEach } from \"lodash-es\";\nimport {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport { IProduction } from \"@chevrotain/types\";\n\n/**\n *  A Grammar Walker that computes the \"remaining\" grammar \"after\" a productions in the grammar.\n */\nexport abstract class RestWalker {\n  walk(prod: { definition: IProduction[] }, prevRest: any[] = []): void {\n    forEach(prod.definition, (subProd: IProduction, index) => {\n      const currRest = drop(prod.definition, index + 1);\n      /* istanbul ignore else */\n      if (subProd instanceof NonTerminal) {\n        this.walkProdRef(subProd, currRest, prevRest);\n      } else if (subProd instanceof Terminal) {\n        this.walkTerminal(subProd, currRest, prevRest);\n      } else if (subProd instanceof Alternative) {\n        this.walkFlat(subProd, currRest, prevRest);\n      } else if (subProd instanceof Option) {\n        this.walkOption(subProd, currRest, prevRest);\n      } else if (subProd instanceof RepetitionMandatory) {\n        this.walkAtLeastOne(subProd, currRest, prevRest);\n      } else if (subProd instanceof RepetitionMandatoryWithSeparator) {\n        this.walkAtLeastOneSep(subProd, currRest, prevRest);\n      } else if (subProd instanceof RepetitionWithSeparator) {\n        this.walkManySep(subProd, currRest, prevRest);\n      } else if (subProd instanceof Repetition) {\n        this.walkMany(subProd, currRest, prevRest);\n      } else if (subProd instanceof Alternation) {\n        this.walkOr(subProd, currRest, prevRest);\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n  }\n\n  walkTerminal(\n    terminal: Terminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {}\n\n  walkProdRef(\n    refProd: NonTerminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {}\n\n  walkFlat(\n    flatProd: Alternative,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABCDEF => after the D the rest is EF\n    const fullOrRest = currRest.concat(prevRest);\n    this.walk(flatProd, <any>fullOrRest);\n  }\n\n  walkOption(\n    optionProd: Option,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC(DE)?F => after the (DE)? the rest is F\n    const fullOrRest = currRest.concat(prevRest);\n    this.walk(optionProd, <any>fullOrRest);\n  }\n\n  walkAtLeastOne(\n    atLeastOneProd: RepetitionMandatory,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC(DE)+F => after the (DE)+ the rest is (DE)?F\n    const fullAtLeastOneRest: IProduction[] = [\n      new Option({ definition: atLeastOneProd.definition }),\n    ].concat(<any>currRest, <any>prevRest);\n    this.walk(atLeastOneProd, fullAtLeastOneRest);\n  }\n\n  walkAtLeastOneSep(\n    atLeastOneSepProd: RepetitionMandatoryWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC DE(,DE)* F => after the (,DE)+ the rest is (,DE)?F\n    const fullAtLeastOneSepRest = restForRepetitionWithSeparator(\n      atLeastOneSepProd,\n      currRest,\n      prevRest,\n    );\n    this.walk(atLeastOneSepProd, fullAtLeastOneSepRest);\n  }\n\n  walkMany(\n    manyProd: Repetition,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC(DE)*F => after the (DE)* the rest is (DE)?F\n    const fullManyRest: IProduction[] = [\n      new Option({ definition: manyProd.definition }),\n    ].concat(<any>currRest, <any>prevRest);\n    this.walk(manyProd, fullManyRest);\n  }\n\n  walkManySep(\n    manySepProd: RepetitionWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC (DE(,DE)*)? F => after the (,DE)* the rest is (,DE)?F\n    const fullManySepRest = restForRepetitionWithSeparator(\n      manySepProd,\n      currRest,\n      prevRest,\n    );\n    this.walk(manySepProd, fullManySepRest);\n  }\n\n  walkOr(\n    orProd: Alternation,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // ABC(D|E|F)G => when finding the (D|E|F) the rest is G\n    const fullOrRest = currRest.concat(prevRest);\n    // walk all different alternatives\n    forEach(orProd.definition, (alt) => {\n      // wrapping each alternative in a single definition wrapper\n      // to avoid errors in computing the rest of that alternative in the invocation to computeInProdFollows\n      // (otherwise for OR([alt1,alt2]) alt2 will be considered in 'rest' of alt1\n      const prodWrapper = new Alternative({ definition: [alt] });\n      this.walk(prodWrapper, <any>fullOrRest);\n    });\n  }\n}\n\nfunction restForRepetitionWithSeparator(\n  repSepProd: RepetitionWithSeparator,\n  currRest: IProduction[],\n  prevRest: IProduction[],\n) {\n  const repSepRest = [\n    new Option({\n      definition: [\n        new Terminal({ terminalType: repSepProd.separator }) as IProduction,\n      ].concat(repSepProd.definition),\n    }) as IProduction,\n  ];\n  const fullRepSepRest: IProduction[] = repSepRest.concat(currRest, prevRest);\n  return fullRepSepRest;\n}\n","import baseUniq from './_baseUniq.js';\n\n/**\n * Creates a duplicate-free version of an array, using\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons, in which only the first occurrence of each element\n * is kept. The order of result values is determined by the order they occur\n * in the array.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @returns {Array} Returns the new duplicate free array.\n * @example\n *\n * _.uniq([2, 1, 2]);\n * // => [2, 1]\n */\nfunction uniq(array) {\n  return (array && array.length) ? baseUniq(array) : [];\n}\n\nexport default uniq;\n","import { flatten, map, uniq } from \"lodash-es\";\nimport {\n  isBranchingProd,\n  isOptionalProd,\n  isSequenceProd,\n  NonTerminal,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport { IProduction, TokenType } from \"@chevrotain/types\";\n\nexport function first(prod: IProduction): TokenType[] {\n  /* istanbul ignore else */\n  if (prod instanceof NonTerminal) {\n    // this could in theory cause infinite loops if\n    // (1) prod A refs prod B.\n    // (2) prod B refs prod A\n    // (3) AB can match the empty set\n    // in other words a cycle where everything is optional so the first will keep\n    // looking ahead for the next optional part and will never exit\n    // currently there is no safeguard for this unique edge case because\n    // (1) not sure a grammar in which this can happen is useful for anything (productive)\n    return first((<NonTerminal>prod).referencedRule);\n  } else if (prod instanceof Terminal) {\n    return firstForTerminal(<Terminal>prod);\n  } else if (isSequenceProd(prod)) {\n    return firstForSequence(prod);\n  } else if (isBranchingProd(prod)) {\n    return firstForBranching(prod);\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nexport function firstForSequence(prod: {\n  definition: IProduction[];\n}): TokenType[] {\n  let firstSet: TokenType[] = [];\n  const seq = prod.definition;\n  let nextSubProdIdx = 0;\n  let hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n  let currSubProd;\n  // so we enter the loop at least once (if the definition is not empty\n  let isLastInnerProdOptional = true;\n  // scan a sequence until it's end or until we have found a NONE optional production in it\n  while (hasInnerProdsRemaining && isLastInnerProdOptional) {\n    currSubProd = seq[nextSubProdIdx];\n    isLastInnerProdOptional = isOptionalProd(currSubProd);\n    firstSet = firstSet.concat(first(currSubProd));\n    nextSubProdIdx = nextSubProdIdx + 1;\n    hasInnerProdsRemaining = seq.length > nextSubProdIdx;\n  }\n\n  return uniq(firstSet);\n}\n\nexport function firstForBranching(prod: {\n  definition: IProduction[];\n}): TokenType[] {\n  const allAlternativesFirsts: TokenType[][] = map(\n    prod.definition,\n    (innerProd) => {\n      return first(innerProd);\n    },\n  );\n  return uniq(flatten<TokenType>(allAlternativesFirsts));\n}\n\nexport function firstForTerminal(terminal: Terminal): TokenType[] {\n  return [terminal.terminalType];\n}\n","// TODO: can this be removed? where is it used?\nexport const IN = \"_~IN~_\";\n","import { RestWalker } from \"./rest.js\";\nimport { first } from \"./first.js\";\nimport { assign, forEach } from \"lodash-es\";\nimport { IN } from \"../constants.js\";\nimport { Alternative, NonTerminal, Rule, Terminal } from \"@chevrotain/gast\";\nimport { IProduction, TokenType } from \"@chevrotain/types\";\n\n// This ResyncFollowsWalker computes all of the follows required for RESYNC\n// (skipping reference production).\nexport class ResyncFollowsWalker extends RestWalker {\n  public follows: Record<string, TokenType[]> = {};\n\n  constructor(private topProd: Rule) {\n    super();\n  }\n\n  startWalking(): Record<string, TokenType[]> {\n    this.walk(this.topProd);\n    return this.follows;\n  }\n\n  walkTerminal(\n    terminal: Terminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // do nothing! just like in the public sector after 13:00\n  }\n\n  walkProdRef(\n    refProd: NonTerminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    const followName =\n      buildBetweenProdsFollowPrefix(refProd.referencedRule, refProd.idx) +\n      this.topProd.name;\n    const fullRest: IProduction[] = currRest.concat(prevRest);\n    const restProd = new Alternative({ definition: fullRest });\n    const t_in_topProd_follows = first(restProd);\n    this.follows[followName] = t_in_topProd_follows;\n  }\n}\n\nexport function computeAllProdsFollows(\n  topProductions: Rule[],\n): Record<string, TokenType[]> {\n  const reSyncFollows = {};\n\n  forEach(topProductions, (topProd) => {\n    const currRefsFollow = new ResyncFollowsWalker(topProd).startWalking();\n    assign(reSyncFollows, currRefsFollow);\n  });\n  return reSyncFollows;\n}\n\nexport function buildBetweenProdsFollowPrefix(\n  inner: Rule,\n  occurenceInParent: number,\n): string {\n  return inner.name + occurenceInParent + IN;\n}\n\nexport function buildInProdFollowPrefix(terminal: Terminal): string {\n  const terminalName = terminal.terminalType.name;\n  return terminalName + terminal.idx + IN;\n}\n","/** Error message constants. */\nvar FUNC_ERROR_TEXT = 'Expected a function';\n\n/**\n * Creates a function that negates the result of the predicate `func`. The\n * `func` predicate is invoked with the `this` binding and arguments of the\n * created function.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Function\n * @param {Function} predicate The predicate to negate.\n * @returns {Function} Returns the new negated function.\n * @example\n *\n * function isEven(n) {\n *   return n % 2 == 0;\n * }\n *\n * _.filter([1, 2, 3, 4, 5, 6], _.negate(isEven));\n * // => [1, 3, 5]\n */\nfunction negate(predicate) {\n  if (typeof predicate != 'function') {\n    throw new TypeError(FUNC_ERROR_TEXT);\n  }\n  return function() {\n    var args = arguments;\n    switch (args.length) {\n      case 0: return !predicate.call(this);\n      case 1: return !predicate.call(this, args[0]);\n      case 2: return !predicate.call(this, args[0], args[1]);\n      case 3: return !predicate.call(this, args[0], args[1], args[2]);\n    }\n    return !predicate.apply(this, args);\n  };\n}\n\nexport default negate;\n","import arrayFilter from './_arrayFilter.js';\nimport baseFilter from './_baseFilter.js';\nimport baseIteratee from './_baseIteratee.js';\nimport isArray from './isArray.js';\nimport negate from './negate.js';\n\n/**\n * The opposite of `_.filter`; this method returns the elements of `collection`\n * that `predicate` does **not** return truthy for.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new filtered array.\n * @see _.filter\n * @example\n *\n * var users = [\n *   { 'user': 'barney', 'age': 36, 'active': false },\n *   { 'user': 'fred',   'age': 40, 'active': true }\n * ];\n *\n * _.reject(users, function(o) { return !o.active; });\n * // => objects for ['fred']\n *\n * // The `_.matches` iteratee shorthand.\n * _.reject(users, { 'age': 40, 'active': true });\n * // => objects for ['barney']\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.reject(users, ['active', false]);\n * // => objects for ['fred']\n *\n * // The `_.property` iteratee shorthand.\n * _.reject(users, 'active');\n * // => objects for ['barney']\n */\nfunction reject(collection, predicate) {\n  var func = isArray(collection) ? arrayFilter : baseFilter;\n  return func(collection, negate(baseIteratee(predicate, 3)));\n}\n\nexport default reject;\n","import baseIndexOf from './_baseIndexOf.js';\nimport toInteger from './toInteger.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * Gets the index at which the first occurrence of `value` is found in `array`\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons. If `fromIndex` is negative, it's used as the\n * offset from the end of `array`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {*} value The value to search for.\n * @param {number} [fromIndex=0] The index to search from.\n * @returns {number} Returns the index of the matched value, else `-1`.\n * @example\n *\n * _.indexOf([1, 2, 1, 2], 2);\n * // => 1\n *\n * // Search from the `fromIndex`.\n * _.indexOf([1, 2, 1, 2], 2, 2);\n * // => 3\n */\nfunction indexOf(array, value, fromIndex) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return -1;\n  }\n  var index = fromIndex == null ? 0 : toInteger(fromIndex);\n  if (index < 0) {\n    index = nativeMax(length + index, 0);\n  }\n  return baseIndexOf(array, value, index);\n}\n\nexport default indexOf;\n","import SetCache from './_SetCache.js';\nimport arrayIncludes from './_arrayIncludes.js';\nimport arrayIncludesWith from './_arrayIncludesWith.js';\nimport arrayMap from './_arrayMap.js';\nimport baseUnary from './_baseUnary.js';\nimport cacheHas from './_cacheHas.js';\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/**\n * The base implementation of methods like `_.difference` without support\n * for excluding multiple arrays or iteratee shorthands.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {Array} values The values to exclude.\n * @param {Function} [iteratee] The iteratee invoked per element.\n * @param {Function} [comparator] The comparator invoked per element.\n * @returns {Array} Returns the new array of filtered values.\n */\nfunction baseDifference(array, values, iteratee, comparator) {\n  var index = -1,\n      includes = arrayIncludes,\n      isCommon = true,\n      length = array.length,\n      result = [],\n      valuesLength = values.length;\n\n  if (!length) {\n    return result;\n  }\n  if (iteratee) {\n    values = arrayMap(values, baseUnary(iteratee));\n  }\n  if (comparator) {\n    includes = arrayIncludesWith;\n    isCommon = false;\n  }\n  else if (values.length >= LARGE_ARRAY_SIZE) {\n    includes = cacheHas;\n    isCommon = false;\n    values = new SetCache(values);\n  }\n  outer:\n  while (++index < length) {\n    var value = array[index],\n        computed = iteratee == null ? value : iteratee(value);\n\n    value = (comparator || value !== 0) ? value : 0;\n    if (isCommon && computed === computed) {\n      var valuesIndex = valuesLength;\n      while (valuesIndex--) {\n        if (values[valuesIndex] === computed) {\n          continue outer;\n        }\n      }\n      result.push(value);\n    }\n    else if (!includes(values, computed, comparator)) {\n      result.push(value);\n    }\n  }\n  return result;\n}\n\nexport default baseDifference;\n","import baseDifference from './_baseDifference.js';\nimport baseFlatten from './_baseFlatten.js';\nimport baseRest from './_baseRest.js';\nimport isArrayLikeObject from './isArrayLikeObject.js';\n\n/**\n * Creates an array of `array` values not included in the other given arrays\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons. The order and references of result values are\n * determined by the first array.\n *\n * **Note:** Unlike `_.pullAll`, this method returns a new array.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {...Array} [values] The values to exclude.\n * @returns {Array} Returns the new array of filtered values.\n * @see _.without, _.xor\n * @example\n *\n * _.difference([2, 1], [2, 3]);\n * // => [1]\n */\nvar difference = baseRest(function(array, values) {\n  return isArrayLikeObject(array)\n    ? baseDifference(array, baseFlatten(values, 1, isArrayLikeObject, true))\n    : [];\n});\n\nexport default difference;\n","/**\n * Creates an array with all falsey values removed. The values `false`, `null`,\n * `0`, `\"\"`, `undefined`, and `NaN` are falsey.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to compact.\n * @returns {Array} Returns the new array of filtered values.\n * @example\n *\n * _.compact([0, 1, false, 2, '', 3]);\n * // => [1, 2, 3]\n */\nfunction compact(array) {\n  var index = -1,\n      length = array == null ? 0 : array.length,\n      resIndex = 0,\n      result = [];\n\n  while (++index < length) {\n    var value = array[index];\n    if (value) {\n      result[resIndex++] = value;\n    }\n  }\n  return result;\n}\n\nexport default compact;\n","/**\n * Gets the first element of `array`.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @alias first\n * @category Array\n * @param {Array} array The array to query.\n * @returns {*} Returns the first element of `array`.\n * @example\n *\n * _.head([1, 2, 3]);\n * // => 1\n *\n * _.head([]);\n * // => undefined\n */\nfunction head(array) {\n  return (array && array.length) ? array[0] : undefined;\n}\n\nexport default head;\n","export function PRINT_ERROR(msg: string) {\n  /* istanbul ignore else - can't override global.console in node.js */\n  if (console && console.error) {\n    console.error(`Error: ${msg}`);\n  }\n}\n\nexport function PRINT_WARNING(msg: string) {\n  /* istanbul ignore else - can't override global.console in node.js*/\n  if (console && console.warn) {\n    // TODO: modify docs accordingly\n    console.warn(`Warning: ${msg}`);\n  }\n}\n","import {\n  Alternative,\n  Assertion,\n  Atom,\n  Disjunction,\n  RegExpParser,\n  RegExpPattern,\n} from \"@chevrotain/regexp-to-ast\";\n\nlet regExpAstCache: { [regex: string]: RegExpPattern } = {};\nconst regExpParser = new RegExpParser();\n\n// this should be moved to regexp-to-ast\nexport type ASTNode =\n  | RegExpPattern\n  | Disjunction\n  | Alternative\n  | Assertion\n  | Atom;\n\nexport function getRegExpAst(regExp: RegExp): RegExpPattern {\n  const regExpStr = regExp.toString();\n  if (regExpAstCache.hasOwnProperty(regExpStr)) {\n    return regExpAstCache[regExpStr];\n  } else {\n    const regExpAst = regExpParser.pattern(regExpStr);\n    regExpAstCache[regExpStr] = regExpAst;\n    return regExpAst;\n  }\n}\n\nexport function clearRegExpParserCache() {\n  regExpAstCache = {};\n}\n","import {\n  Alternative,\n  Atom,\n  BaseRegExpVisitor,\n  Character,\n  Disjunction,\n  Group,\n  Set,\n} from \"@chevrotain/regexp-to-ast\";\nimport { every, find, forEach, includes, isArray, values } from \"lodash-es\";\nimport { PRINT_ERROR, PRINT_WARNING } from \"@chevrotain/utils\";\nimport { ASTNode, getRegExpAst } from \"./reg_exp_parser.js\";\nimport { charCodeToOptimizedIndex, minOptimizationVal } from \"./lexer.js\";\n\nconst complementErrorMessage =\n  \"Complement Sets are not supported for first char optimization\";\nexport const failedOptimizationPrefixMsg =\n  'Unable to use \"first char\" lexer optimizations:\\n';\n\nexport function getOptimizedStartCodesIndices(\n  regExp: RegExp,\n  ensureOptimizations = false,\n): number[] {\n  try {\n    const ast = getRegExpAst(regExp);\n    const firstChars = firstCharOptimizedIndices(\n      ast.value,\n      {},\n      ast.flags.ignoreCase,\n    );\n    return firstChars;\n  } catch (e) {\n    /* istanbul ignore next */\n    // Testing this relies on the regexp-to-ast library having a bug... */\n    // TODO: only the else branch needs to be ignored, try to fix with newer prettier / tsc\n    if (e.message === complementErrorMessage) {\n      if (ensureOptimizations) {\n        PRINT_WARNING(\n          `${failedOptimizationPrefixMsg}` +\n            `\\tUnable to optimize: < ${regExp.toString()} >\\n` +\n            \"\\tComplement Sets cannot be automatically optimized.\\n\" +\n            \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n            \"\\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#COMPLEMENT for details.\",\n        );\n      }\n    } else {\n      let msgSuffix = \"\";\n      if (ensureOptimizations) {\n        msgSuffix =\n          \"\\n\\tThis will disable the lexer's first char optimizations.\\n\" +\n          \"\\tSee: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#REGEXP_PARSING for details.\";\n      }\n      PRINT_ERROR(\n        `${failedOptimizationPrefixMsg}\\n` +\n          `\\tFailed parsing: < ${regExp.toString()} >\\n` +\n          `\\tUsing the @chevrotain/regexp-to-ast library\\n` +\n          \"\\tPlease open an issue at: https://github.com/chevrotain/chevrotain/issues\" +\n          msgSuffix,\n      );\n    }\n  }\n\n  return [];\n}\n\nexport function firstCharOptimizedIndices(\n  ast: ASTNode,\n  result: { [charCode: number]: number },\n  ignoreCase: boolean,\n): number[] {\n  switch (ast.type) {\n    case \"Disjunction\":\n      for (let i = 0; i < ast.value.length; i++) {\n        firstCharOptimizedIndices(ast.value[i], result, ignoreCase);\n      }\n      break;\n    case \"Alternative\":\n      const terms = ast.value;\n      for (let i = 0; i < terms.length; i++) {\n        const term = terms[i];\n\n        // skip terms that cannot effect the first char results\n        switch (term.type) {\n          case \"EndAnchor\":\n          // A group back reference cannot affect potential starting char.\n          // because if a back reference is the first production than automatically\n          // the group being referenced has had to come BEFORE so its codes have already been added\n          case \"GroupBackReference\":\n          // assertions do not affect potential starting codes\n          case \"Lookahead\":\n          case \"NegativeLookahead\":\n          case \"StartAnchor\":\n          case \"WordBoundary\":\n          case \"NonWordBoundary\":\n            continue;\n        }\n\n        const atom = term;\n        switch (atom.type) {\n          case \"Character\":\n            addOptimizedIdxToResult(atom.value, result, ignoreCase);\n            break;\n          case \"Set\":\n            if (atom.complement === true) {\n              throw Error(complementErrorMessage);\n            }\n            forEach(atom.value, (code) => {\n              if (typeof code === \"number\") {\n                addOptimizedIdxToResult(code, result, ignoreCase);\n              } else {\n                // range\n                const range = code as any;\n                // cannot optimize when ignoreCase is\n                if (ignoreCase === true) {\n                  for (\n                    let rangeCode = range.from;\n                    rangeCode <= range.to;\n                    rangeCode++\n                  ) {\n                    addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                  }\n                }\n                // Optimization (2 orders of magnitude less work for very large ranges)\n                else {\n                  // handle unoptimized values\n                  for (\n                    let rangeCode = range.from;\n                    rangeCode <= range.to && rangeCode < minOptimizationVal;\n                    rangeCode++\n                  ) {\n                    addOptimizedIdxToResult(rangeCode, result, ignoreCase);\n                  }\n\n                  // Less common charCode where we optimize for faster init time, by using larger \"buckets\"\n                  if (range.to >= minOptimizationVal) {\n                    const minUnOptVal =\n                      range.from >= minOptimizationVal\n                        ? range.from\n                        : minOptimizationVal;\n                    const maxUnOptVal = range.to;\n                    const minOptIdx = charCodeToOptimizedIndex(minUnOptVal);\n                    const maxOptIdx = charCodeToOptimizedIndex(maxUnOptVal);\n\n                    for (\n                      let currOptIdx = minOptIdx;\n                      currOptIdx <= maxOptIdx;\n                      currOptIdx++\n                    ) {\n                      result[currOptIdx] = currOptIdx;\n                    }\n                  }\n                }\n              }\n            });\n            break;\n          case \"Group\":\n            firstCharOptimizedIndices(atom.value, result, ignoreCase);\n            break;\n          /* istanbul ignore next */\n          default:\n            throw Error(\"Non Exhaustive Match\");\n        }\n\n        // reached a mandatory production, no more **start** codes can be found on this alternative\n        const isOptionalQuantifier =\n          atom.quantifier !== undefined && atom.quantifier.atLeast === 0;\n        if (\n          // A group may be optional due to empty contents /(?:)/\n          // or if everything inside it is optional /((a)?)/\n          (atom.type === \"Group\" && isWholeOptional(atom) === false) ||\n          // If this term is not a group it may only be optional if it has an optional quantifier\n          (atom.type !== \"Group\" && isOptionalQuantifier === false)\n        ) {\n          break;\n        }\n      }\n      break;\n    /* istanbul ignore next */\n    default:\n      throw Error(\"non exhaustive match!\");\n  }\n\n  // console.log(Object.keys(result).length)\n  return values(result);\n}\n\nfunction addOptimizedIdxToResult(\n  code: number,\n  result: { [charCode: number]: number },\n  ignoreCase: boolean,\n) {\n  const optimizedCharIdx = charCodeToOptimizedIndex(code);\n  result[optimizedCharIdx] = optimizedCharIdx;\n\n  if (ignoreCase === true) {\n    handleIgnoreCase(code, result);\n  }\n}\n\nfunction handleIgnoreCase(\n  code: number,\n  result: { [charCode: number]: number },\n) {\n  const char = String.fromCharCode(code);\n  const upperChar = char.toUpperCase();\n  /* istanbul ignore else */\n  if (upperChar !== char) {\n    const optimizedCharIdx = charCodeToOptimizedIndex(upperChar.charCodeAt(0));\n    result[optimizedCharIdx] = optimizedCharIdx;\n  } else {\n    const lowerChar = char.toLowerCase();\n    if (lowerChar !== char) {\n      const optimizedCharIdx = charCodeToOptimizedIndex(\n        lowerChar.charCodeAt(0),\n      );\n      result[optimizedCharIdx] = optimizedCharIdx;\n    }\n  }\n}\n\nfunction findCode(setNode: Set, targetCharCodes: number[]) {\n  return find(setNode.value, (codeOrRange) => {\n    if (typeof codeOrRange === \"number\") {\n      return includes(targetCharCodes, codeOrRange);\n    } else {\n      // range\n      const range = <any>codeOrRange;\n      return (\n        find(\n          targetCharCodes,\n          (targetCode) => range.from <= targetCode && targetCode <= range.to,\n        ) !== undefined\n      );\n    }\n  });\n}\n\nfunction isWholeOptional(ast: any): boolean {\n  const quantifier = (ast as Atom).quantifier;\n  if (quantifier && quantifier.atLeast === 0) {\n    return true;\n  }\n\n  if (!ast.value) {\n    return false;\n  }\n\n  return isArray(ast.value)\n    ? every(ast.value, isWholeOptional)\n    : isWholeOptional(ast.value);\n}\n\nclass CharCodeFinder extends BaseRegExpVisitor {\n  found: boolean = false;\n\n  constructor(private targetCharCodes: number[]) {\n    super();\n  }\n\n  visitChildren(node: ASTNode) {\n    // No need to keep looking...\n    if (this.found === true) {\n      return;\n    }\n\n    // switch lookaheads as they do not actually consume any characters thus\n    // finding a charCode at lookahead context does not mean that regexp can actually contain it in a match.\n    switch (node.type) {\n      case \"Lookahead\":\n        this.visitLookahead(node);\n        return;\n      case \"NegativeLookahead\":\n        this.visitNegativeLookahead(node);\n        return;\n    }\n\n    super.visitChildren(node);\n  }\n\n  visitCharacter(node: Character) {\n    if (includes(this.targetCharCodes, node.value)) {\n      this.found = true;\n    }\n  }\n\n  visitSet(node: Set) {\n    if (node.complement) {\n      if (findCode(node, this.targetCharCodes) === undefined) {\n        this.found = true;\n      }\n    } else {\n      if (findCode(node, this.targetCharCodes) !== undefined) {\n        this.found = true;\n      }\n    }\n  }\n}\n\nexport function canMatchCharCode(\n  charCodes: number[],\n  pattern: RegExp | string,\n) {\n  if (pattern instanceof RegExp) {\n    const ast = getRegExpAst(pattern);\n    const charCodeFinder = new CharCodeFinder(charCodes);\n    charCodeFinder.visit(ast);\n    return charCodeFinder.found;\n  } else {\n    return (\n      find(<any>pattern, (char) => {\n        return includes(charCodes, (<string>char).charCodeAt(0));\n      }) !== undefined\n    );\n  }\n}\n","import { BaseRegExpVisitor } from \"@chevrotain/regexp-to-ast\";\nimport {\n  IRegExpExec,\n  Lexer,\n  LexerDefinitionErrorType,\n} from \"./lexer_public.js\";\nimport {\n  compact,\n  defaults,\n  difference,\n  filter,\n  find,\n  first,\n  flatten,\n  forEach,\n  has,\n  includes,\n  indexOf,\n  isArray,\n  isEmpty,\n  isFunction,\n  isRegExp,\n  isString,\n  isUndefined,\n  keys,\n  map,\n  reduce,\n  reject,\n  values,\n} from \"lodash-es\";\nimport { PRINT_ERROR } from \"@chevrotain/utils\";\nimport {\n  canMatchCharCode,\n  failedOptimizationPrefixMsg,\n  getOptimizedStartCodesIndices,\n} from \"./reg_exp.js\";\nimport {\n  ILexerDefinitionError,\n  ILineTerminatorsTester,\n  IMultiModeLexerDefinition,\n  IToken,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { getRegExpAst } from \"./reg_exp_parser.js\";\n\nconst PATTERN = \"PATTERN\";\nexport const DEFAULT_MODE = \"defaultMode\";\nexport const MODES = \"modes\";\n\nexport interface IPatternConfig {\n  pattern: IRegExpExec | string;\n  longerAlt: number[] | undefined;\n  canLineTerminator: boolean;\n  isCustom: boolean;\n  short: number | false;\n  group: string | undefined | false;\n  push: string | undefined;\n  pop: boolean;\n  tokenType: TokenType;\n  tokenTypeIdx: number;\n}\n\nexport interface IAnalyzeResult {\n  patternIdxToConfig: IPatternConfig[];\n  charCodeToPatternIdxToConfig: { [charCode: number]: IPatternConfig[] };\n  emptyGroups: { [groupName: string]: IToken[] };\n  hasCustom: boolean;\n  canBeOptimized: boolean;\n}\n\nexport let SUPPORT_STICKY =\n  typeof (<any>new RegExp(\"(?:)\")).sticky === \"boolean\";\n\nexport function disableSticky() {\n  SUPPORT_STICKY = false;\n}\n\nexport function enableSticky() {\n  SUPPORT_STICKY = true;\n}\n\nexport function analyzeTokenTypes(\n  tokenTypes: TokenType[],\n  options: {\n    positionTracking?: \"full\" | \"onlyStart\" | \"onlyOffset\";\n    ensureOptimizations?: boolean;\n    lineTerminatorCharacters?: (number | string)[];\n    // TODO: should `useSticky` be an argument here?\n    useSticky?: boolean;\n    safeMode?: boolean;\n    tracer?: (msg: string, action: () => void) => void;\n  },\n): IAnalyzeResult {\n  options = defaults(options, {\n    useSticky: SUPPORT_STICKY,\n    debug: false as boolean,\n    safeMode: false as boolean,\n    positionTracking: \"full\",\n    lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n    tracer: (msg: string, action: Function) => action(),\n  });\n\n  const tracer = options.tracer!;\n\n  tracer(\"initCharCodeToOptimizedIndexMap\", () => {\n    initCharCodeToOptimizedIndexMap();\n  });\n\n  let onlyRelevantTypes: TokenType[];\n  tracer(\"Reject Lexer.NA\", () => {\n    onlyRelevantTypes = reject(tokenTypes, (currType) => {\n      return currType[PATTERN] === Lexer.NA;\n    });\n  });\n\n  let hasCustom = false;\n  let allTransformedPatterns: (IRegExpExec | string)[];\n  tracer(\"Transform Patterns\", () => {\n    hasCustom = false;\n    allTransformedPatterns = map(\n      onlyRelevantTypes,\n      (currType): IRegExpExec | string => {\n        const currPattern = currType[PATTERN];\n\n        /* istanbul ignore else */\n        if (isRegExp(currPattern)) {\n          const regExpSource = currPattern.source;\n          if (\n            regExpSource.length === 1 &&\n            // only these regExp meta characters which can appear in a length one regExp\n            regExpSource !== \"^\" &&\n            regExpSource !== \"$\" &&\n            regExpSource !== \".\" &&\n            !currPattern.ignoreCase\n          ) {\n            return regExpSource;\n          } else if (\n            regExpSource.length === 2 &&\n            regExpSource[0] === \"\\\\\" &&\n            // not a meta character\n            !includes(\n              [\n                \"d\",\n                \"D\",\n                \"s\",\n                \"S\",\n                \"t\",\n                \"r\",\n                \"n\",\n                \"t\",\n                \"0\",\n                \"c\",\n                \"b\",\n                \"B\",\n                \"f\",\n                \"v\",\n                \"w\",\n                \"W\",\n              ],\n              regExpSource[1],\n            )\n          ) {\n            // escaped meta Characters: /\\+/ /\\[/\n            // or redundant escaping: /\\a/\n            // without the escaping \"\\\"\n            return regExpSource[1];\n          } else {\n            return options.useSticky\n              ? addStickyFlag(currPattern)\n              : addStartOfInput(currPattern);\n          }\n        } else if (isFunction(currPattern)) {\n          hasCustom = true;\n          // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n          return { exec: currPattern };\n        } else if (typeof currPattern === \"object\") {\n          hasCustom = true;\n          // ICustomPattern\n          return currPattern;\n        } else if (typeof currPattern === \"string\") {\n          if (currPattern.length === 1) {\n            return currPattern;\n          } else {\n            const escapedRegExpString = currPattern.replace(\n              /[\\\\^$.*+?()[\\]{}|]/g,\n              \"\\\\$&\",\n            );\n            const wrappedRegExp = new RegExp(escapedRegExpString);\n            return options.useSticky\n              ? addStickyFlag(wrappedRegExp)\n              : addStartOfInput(wrappedRegExp);\n          }\n        } else {\n          throw Error(\"non exhaustive match\");\n        }\n      },\n    );\n  });\n\n  let patternIdxToType: number[];\n  let patternIdxToGroup: (string | undefined | false)[];\n  let patternIdxToLongerAltIdxArr: (number[] | undefined)[];\n  let patternIdxToPushMode: (string | undefined)[];\n  let patternIdxToPopMode: boolean[];\n  tracer(\"misc mapping\", () => {\n    patternIdxToType = map(\n      onlyRelevantTypes,\n      (currType) => currType.tokenTypeIdx!,\n    );\n\n    patternIdxToGroup = map(onlyRelevantTypes, (clazz: any) => {\n      const groupName = clazz.GROUP;\n      /* istanbul ignore next */\n      if (groupName === Lexer.SKIPPED) {\n        return undefined;\n      } else if (isString(groupName)) {\n        return groupName;\n      } else if (isUndefined(groupName)) {\n        return false;\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n\n    patternIdxToLongerAltIdxArr = map(onlyRelevantTypes, (clazz: any) => {\n      const longerAltType = clazz.LONGER_ALT;\n\n      if (longerAltType) {\n        const longerAltIdxArr = isArray(longerAltType)\n          ? map(longerAltType, (type: any) => indexOf(onlyRelevantTypes, type))\n          : [indexOf(onlyRelevantTypes, longerAltType)];\n        return longerAltIdxArr;\n      }\n    });\n\n    patternIdxToPushMode = map(\n      onlyRelevantTypes,\n      (clazz: any) => clazz.PUSH_MODE,\n    );\n\n    patternIdxToPopMode = map(onlyRelevantTypes, (clazz: any) =>\n      has(clazz, \"POP_MODE\"),\n    );\n  });\n\n  let patternIdxToCanLineTerminator: boolean[];\n  tracer(\"Line Terminator Handling\", () => {\n    const lineTerminatorCharCodes = getCharCodes(\n      options.lineTerminatorCharacters!,\n    );\n    patternIdxToCanLineTerminator = map(onlyRelevantTypes, (tokType) => false);\n    if (options.positionTracking !== \"onlyOffset\") {\n      patternIdxToCanLineTerminator = map(onlyRelevantTypes, (tokType) => {\n        if (has(tokType, \"LINE_BREAKS\")) {\n          return !!tokType.LINE_BREAKS;\n        } else {\n          return (\n            checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false &&\n            canMatchCharCode(\n              lineTerminatorCharCodes,\n              tokType.PATTERN as RegExp | string,\n            )\n          );\n        }\n      });\n    }\n  });\n\n  let patternIdxToIsCustom: boolean[];\n  let patternIdxToShort: (number | false)[];\n  let emptyGroups!: { [groupName: string]: IToken[] };\n  let patternIdxToConfig!: IPatternConfig[];\n  tracer(\"Misc Mapping #2\", () => {\n    patternIdxToIsCustom = map(onlyRelevantTypes, isCustomPattern);\n    patternIdxToShort = map(allTransformedPatterns, isShortPattern);\n\n    emptyGroups = reduce(\n      onlyRelevantTypes,\n      (acc, clazz: any) => {\n        const groupName = clazz.GROUP;\n        if (isString(groupName) && !(groupName === Lexer.SKIPPED)) {\n          acc[groupName] = [];\n        }\n        return acc;\n      },\n      {} as { [groupName: string]: IToken[] },\n    );\n\n    patternIdxToConfig = map(\n      allTransformedPatterns,\n      (x, idx): IPatternConfig => {\n        return {\n          pattern: allTransformedPatterns[idx],\n          longerAlt: patternIdxToLongerAltIdxArr[idx],\n          canLineTerminator: patternIdxToCanLineTerminator[idx],\n          isCustom: patternIdxToIsCustom[idx],\n          short: patternIdxToShort[idx],\n          group: patternIdxToGroup[idx],\n          push: patternIdxToPushMode[idx],\n          pop: patternIdxToPopMode[idx],\n          tokenTypeIdx: patternIdxToType[idx],\n          tokenType: onlyRelevantTypes[idx],\n        };\n      },\n    );\n  });\n\n  let canBeOptimized = true;\n  let charCodeToPatternIdxToConfig: { [charCode: number]: IPatternConfig[] } =\n    [];\n\n  if (!options.safeMode) {\n    tracer(\"First Char Optimization\", () => {\n      charCodeToPatternIdxToConfig = reduce(\n        onlyRelevantTypes,\n        (result, currTokType, idx) => {\n          if (typeof currTokType.PATTERN === \"string\") {\n            const charCode = currTokType.PATTERN.charCodeAt(0);\n            const optimizedIdx = charCodeToOptimizedIndex(charCode);\n            addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n          } else if (isArray(currTokType.START_CHARS_HINT)) {\n            let lastOptimizedIdx: number;\n            forEach(currTokType.START_CHARS_HINT, (charOrInt) => {\n              const charCode =\n                typeof charOrInt === \"string\"\n                  ? charOrInt.charCodeAt(0)\n                  : charOrInt;\n              const currOptimizedIdx = charCodeToOptimizedIndex(charCode);\n              // Avoid adding the config multiple times\n              /* istanbul ignore else */\n              // - Difficult to check this scenario effects as it is only a performance\n              //   optimization that does not change correctness\n              if (lastOptimizedIdx !== currOptimizedIdx) {\n                lastOptimizedIdx = currOptimizedIdx;\n                addToMapOfArrays(\n                  result,\n                  currOptimizedIdx,\n                  patternIdxToConfig[idx],\n                );\n              }\n            });\n          } else if (isRegExp(currTokType.PATTERN)) {\n            if (currTokType.PATTERN.unicode) {\n              canBeOptimized = false;\n              if (options.ensureOptimizations) {\n                PRINT_ERROR(\n                  `${failedOptimizationPrefixMsg}` +\n                    `\\tUnable to analyze < ${currTokType.PATTERN.toString()} > pattern.\\n` +\n                    \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" +\n                    \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                    \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\",\n                );\n              }\n            } else {\n              const optimizedCodes = getOptimizedStartCodesIndices(\n                currTokType.PATTERN,\n                options.ensureOptimizations,\n              );\n              /* istanbul ignore if */\n              // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n              // the first should be a different validation and the second cannot be tested.\n              if (isEmpty(optimizedCodes)) {\n                // we cannot understand what codes may start possible matches\n                // The optimization correctness requires knowing start codes for ALL patterns.\n                // Not actually sure this is an error, no debug message\n                canBeOptimized = false;\n              }\n              forEach(optimizedCodes, (code) => {\n                addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n              });\n            }\n          } else {\n            if (options.ensureOptimizations) {\n              PRINT_ERROR(\n                `${failedOptimizationPrefixMsg}` +\n                  `\\tTokenType: <${currTokType.name}> is using a custom token pattern without providing <start_chars_hint> parameter.\\n` +\n                  \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                  \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\",\n              );\n            }\n            canBeOptimized = false;\n          }\n\n          return result;\n        },\n        [] as { [charCode: number]: IPatternConfig[] },\n      );\n    });\n  }\n\n  return {\n    emptyGroups: emptyGroups,\n    patternIdxToConfig: patternIdxToConfig,\n    charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n    hasCustom: hasCustom,\n    canBeOptimized: canBeOptimized,\n  };\n}\n\nexport function validatePatterns(\n  tokenTypes: TokenType[],\n  validModesNames: string[],\n): ILexerDefinitionError[] {\n  let errors: ILexerDefinitionError[] = [];\n\n  const missingResult = findMissingPatterns(tokenTypes);\n  errors = errors.concat(missingResult.errors);\n\n  const invalidResult = findInvalidPatterns(missingResult.valid);\n  const validTokenTypes = invalidResult.valid;\n  errors = errors.concat(invalidResult.errors);\n\n  errors = errors.concat(validateRegExpPattern(validTokenTypes));\n\n  errors = errors.concat(findInvalidGroupType(validTokenTypes));\n\n  errors = errors.concat(\n    findModesThatDoNotExist(validTokenTypes, validModesNames),\n  );\n\n  errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n\n  return errors;\n}\n\nfunction validateRegExpPattern(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  let errors: ILexerDefinitionError[] = [];\n  const withRegExpPatterns = filter(tokenTypes, (currTokType) =>\n    isRegExp(currTokType[PATTERN]),\n  );\n\n  errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n\n  errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n\n  errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n\n  errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n\n  errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n\n  return errors;\n}\n\nexport interface ILexerFilterResult {\n  errors: ILexerDefinitionError[];\n  valid: TokenType[];\n}\n\nexport function findMissingPatterns(\n  tokenTypes: TokenType[],\n): ILexerFilterResult {\n  const tokenTypesWithMissingPattern = filter(tokenTypes, (currType) => {\n    return !has(currType, PATTERN);\n  });\n\n  const errors = map(tokenTypesWithMissingPattern, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- missing static 'PATTERN' property\",\n      type: LexerDefinitionErrorType.MISSING_PATTERN,\n      tokenTypes: [currType],\n    };\n  });\n\n  const valid = difference(tokenTypes, tokenTypesWithMissingPattern);\n  return { errors, valid };\n}\n\nexport function findInvalidPatterns(\n  tokenTypes: TokenType[],\n): ILexerFilterResult {\n  const tokenTypesWithInvalidPattern = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN];\n    return (\n      !isRegExp(pattern) &&\n      !isFunction(pattern) &&\n      !has(pattern, \"exec\") &&\n      !isString(pattern)\n    );\n  });\n\n  const errors = map(tokenTypesWithInvalidPattern, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' can only be a RegExp, a\" +\n        \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n      type: LexerDefinitionErrorType.INVALID_PATTERN,\n      tokenTypes: [currType],\n    };\n  });\n\n  const valid = difference(tokenTypes, tokenTypesWithInvalidPattern);\n  return { errors, valid };\n}\n\nconst end_of_input = /[^\\\\][$]/;\n\nexport function findEndOfInputAnchor(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  class EndAnchorFinder extends BaseRegExpVisitor {\n    found = false;\n\n    visitEndAnchor(node: unknown) {\n      this.found = true;\n    }\n  }\n\n  const invalidRegex = filter(tokenTypes, (currType) => {\n    const pattern = currType.PATTERN;\n\n    try {\n      const regexpAst = getRegExpAst(pattern as RegExp);\n      const endAnchorVisitor = new EndAnchorFinder();\n      endAnchorVisitor.visit(regexpAst);\n\n      return endAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return end_of_input.test((pattern as RegExp).source);\n    }\n  });\n\n  const errors = map(invalidRegex, (currType) => {\n    return {\n      message:\n        \"Unexpected RegExp Anchor Error:\\n\" +\n        \"\\tToken Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" +\n        \"\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\nexport function findEmptyMatchRegExps(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const matchesEmptyString = filter(tokenTypes, (currType) => {\n    const pattern = currType.PATTERN as RegExp;\n    return pattern.test(\"\");\n  });\n\n  const errors = map(matchesEmptyString, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' must not match an empty string\",\n      type: LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\nconst start_of_input = /[^\\\\[][\\^]|^\\^/;\n\nexport function findStartOfInputAnchor(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  class StartAnchorFinder extends BaseRegExpVisitor {\n    found = false;\n\n    visitStartAnchor(node: unknown) {\n      this.found = true;\n    }\n  }\n\n  const invalidRegex = filter(tokenTypes, (currType) => {\n    const pattern = currType.PATTERN as RegExp;\n    try {\n      const regexpAst = getRegExpAst(pattern);\n      const startAnchorVisitor = new StartAnchorFinder();\n      startAnchorVisitor.visit(regexpAst);\n\n      return startAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return start_of_input.test(pattern.source);\n    }\n  });\n\n  const errors = map(invalidRegex, (currType) => {\n    return {\n      message:\n        \"Unexpected RegExp Anchor Error:\\n\" +\n        \"\\tToken Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" +\n        \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\nexport function findUnsupportedFlags(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const invalidFlags = filter(tokenTypes, (currType) => {\n    const pattern = currType[PATTERN];\n    return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n  });\n\n  const errors = map(invalidFlags, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n      type: LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\nexport function findDuplicatePatterns(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const found: TokenType[] = [];\n  let identicalPatterns = map(tokenTypes, (outerType: any) => {\n    return reduce(\n      tokenTypes,\n      (result, innerType) => {\n        if (\n          outerType.PATTERN.source === (innerType.PATTERN as RegExp).source &&\n          !includes(found, innerType) &&\n          innerType.PATTERN !== Lexer.NA\n        ) {\n          // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n          // in essence we are creating Equivalence classes on equality relation.\n          found.push(innerType);\n          result.push(innerType);\n          return result;\n        }\n        return result;\n      },\n      [] as TokenType[],\n    );\n  });\n\n  identicalPatterns = compact(identicalPatterns);\n\n  const duplicatePatterns = filter(identicalPatterns, (currIdenticalSet) => {\n    return currIdenticalSet.length > 1;\n  });\n\n  const errors = map(duplicatePatterns, (setOfIdentical: any) => {\n    const tokenTypeNames = map(setOfIdentical, (currType: any) => {\n      return currType.name;\n    });\n\n    const dupPatternSrc = (<any>first(setOfIdentical)).PATTERN;\n    return {\n      message:\n        `The same RegExp pattern ->${dupPatternSrc}<-` +\n        `has been used in all of the following Token Types: ${tokenTypeNames.join(\n          \", \",\n        )} <-`,\n      type: LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n      tokenTypes: setOfIdentical,\n    };\n  });\n\n  return errors;\n}\n\nexport function findInvalidGroupType(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const invalidTypes = filter(tokenTypes, (clazz: any) => {\n    if (!has(clazz, \"GROUP\")) {\n      return false;\n    }\n    const group = clazz.GROUP;\n\n    return group !== Lexer.SKIPPED && group !== Lexer.NA && !isString(group);\n  });\n\n  const errors = map(invalidTypes, (currType) => {\n    return {\n      message:\n        \"Token Type: ->\" +\n        currType.name +\n        \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n      type: LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n      tokenTypes: [currType],\n    };\n  });\n\n  return errors;\n}\n\nexport function findModesThatDoNotExist(\n  tokenTypes: TokenType[],\n  validModes: string[],\n): ILexerDefinitionError[] {\n  const invalidModes = filter(tokenTypes, (clazz: any) => {\n    return (\n      clazz.PUSH_MODE !== undefined && !includes(validModes, clazz.PUSH_MODE)\n    );\n  });\n\n  const errors = map(invalidModes, (tokType) => {\n    const msg =\n      `Token Type: ->${tokType.name}<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->${tokType.PUSH_MODE}<-` +\n      `which does not exist`;\n    return {\n      message: msg,\n      type: LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n      tokenTypes: [tokType],\n    };\n  });\n\n  return errors;\n}\n\nexport function findUnreachablePatterns(\n  tokenTypes: TokenType[],\n): ILexerDefinitionError[] {\n  const errors: ILexerDefinitionError[] = [];\n\n  const canBeTested = reduce(\n    tokenTypes,\n    (result, tokType, idx) => {\n      const pattern = tokType.PATTERN;\n\n      if (pattern === Lexer.NA) {\n        return result;\n      }\n\n      // a more comprehensive validation for all forms of regExps would require\n      // deeper regExp analysis capabilities\n      if (isString(pattern)) {\n        result.push({ str: pattern, idx, tokenType: tokType });\n      } else if (isRegExp(pattern) && noMetaChar(pattern)) {\n        result.push({ str: pattern.source, idx, tokenType: tokType });\n      }\n      return result;\n    },\n    [] as { str: string; idx: number; tokenType: TokenType }[],\n  );\n\n  forEach(tokenTypes, (tokType, testIdx) => {\n    forEach(canBeTested, ({ str, idx, tokenType }) => {\n      if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n        const msg =\n          `Token: ->${tokenType.name}<- can never be matched.\\n` +\n          `Because it appears AFTER the Token Type ->${tokType.name}<-` +\n          `in the lexer's definition.\\n` +\n          `See https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE`;\n        errors.push({\n          message: msg,\n          type: LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n          tokenTypes: [tokType, tokenType],\n        });\n      }\n    });\n  });\n\n  return errors;\n}\n\nfunction testTokenType(str: string, pattern: any): boolean {\n  /* istanbul ignore else */\n  if (isRegExp(pattern)) {\n    const regExpArray = pattern.exec(str);\n    return regExpArray !== null && regExpArray.index === 0;\n  } else if (isFunction(pattern)) {\n    // maintain the API of custom patterns\n    return pattern(str, 0, [], {});\n  } else if (has(pattern, \"exec\")) {\n    // maintain the API of custom patterns\n    return pattern.exec(str, 0, [], {});\n  } else if (typeof pattern === \"string\") {\n    return pattern === str;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nfunction noMetaChar(regExp: RegExp): boolean {\n  //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n  const metaChars = [\n    \".\",\n    \"\\\\\",\n    \"[\",\n    \"]\",\n    \"|\",\n    \"^\",\n    \"$\",\n    \"(\",\n    \")\",\n    \"?\",\n    \"*\",\n    \"+\",\n    \"{\",\n  ];\n  return (\n    find(metaChars, (char) => regExp.source.indexOf(char) !== -1) === undefined\n  );\n}\n\nexport function addStartOfInput(pattern: RegExp): RegExp {\n  const flags = pattern.ignoreCase ? \"i\" : \"\";\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(`^(?:${pattern.source})`, flags);\n}\n\nexport function addStickyFlag(pattern: RegExp): RegExp {\n  const flags = pattern.ignoreCase ? \"iy\" : \"y\";\n  // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n  return new RegExp(`${pattern.source}`, flags);\n}\n\nexport function performRuntimeChecks(\n  lexerDefinition: IMultiModeLexerDefinition,\n  trackLines: boolean,\n  lineTerminatorCharacters: (number | string)[],\n): ILexerDefinitionError[] {\n  const errors: ILexerDefinitionError[] = [];\n\n  // some run time checks to help the end users.\n  if (!has(lexerDefinition, DEFAULT_MODE)) {\n    errors.push({\n      message:\n        \"A MultiMode Lexer cannot be initialized without a <\" +\n        DEFAULT_MODE +\n        \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE,\n    });\n  }\n  if (!has(lexerDefinition, MODES)) {\n    errors.push({\n      message:\n        \"A MultiMode Lexer cannot be initialized without a <\" +\n        MODES +\n        \"> property in its definition\\n\",\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY,\n    });\n  }\n\n  if (\n    has(lexerDefinition, MODES) &&\n    has(lexerDefinition, DEFAULT_MODE) &&\n    !has(lexerDefinition.modes, lexerDefinition.defaultMode)\n  ) {\n    errors.push({\n      message:\n        `A MultiMode Lexer cannot be initialized with a ${DEFAULT_MODE}: <${lexerDefinition.defaultMode}>` +\n        `which does not exist\\n`,\n      type: LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST,\n    });\n  }\n\n  if (has(lexerDefinition, MODES)) {\n    forEach(lexerDefinition.modes, (currModeValue, currModeName) => {\n      forEach(currModeValue, (currTokType, currIdx) => {\n        if (isUndefined(currTokType)) {\n          errors.push({\n            message:\n              `A Lexer cannot be initialized using an undefined Token Type. Mode:` +\n              `<${currModeName}> at index: <${currIdx}>\\n`,\n            type: LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED,\n          });\n        } else if (has(currTokType, \"LONGER_ALT\")) {\n          const longerAlt = isArray(currTokType.LONGER_ALT)\n            ? currTokType.LONGER_ALT\n            : [currTokType.LONGER_ALT];\n          forEach(longerAlt, (currLongerAlt) => {\n            if (\n              !isUndefined(currLongerAlt) &&\n              !includes(currModeValue, currLongerAlt)\n            ) {\n              errors.push({\n                message: `A MultiMode Lexer cannot be initialized with a longer_alt <${currLongerAlt.name}> on token <${currTokType.name}> outside of mode <${currModeName}>\\n`,\n                type: LexerDefinitionErrorType.MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE,\n              });\n            }\n          });\n        }\n      });\n    });\n  }\n\n  return errors;\n}\n\nexport function performWarningRuntimeChecks(\n  lexerDefinition: IMultiModeLexerDefinition,\n  trackLines: boolean,\n  lineTerminatorCharacters: (number | string)[],\n): ILexerDefinitionError[] {\n  const warnings = [];\n  let hasAnyLineBreak = false;\n  const allTokenTypes = compact(flatten(values(lexerDefinition.modes)));\n\n  const concreteTokenTypes = reject(\n    allTokenTypes,\n    (currType) => currType[PATTERN] === Lexer.NA,\n  );\n  const terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n  if (trackLines) {\n    forEach(concreteTokenTypes, (tokType) => {\n      const currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n      if (currIssue !== false) {\n        const message = buildLineBreakIssueMessage(tokType, currIssue);\n        const warningDescriptor = {\n          message,\n          type: currIssue.issue,\n          tokenType: tokType,\n        };\n        warnings.push(warningDescriptor);\n      } else {\n        // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n        if (has(tokType, \"LINE_BREAKS\")) {\n          if (tokType.LINE_BREAKS === true) {\n            hasAnyLineBreak = true;\n          }\n        } else {\n          if (\n            canMatchCharCode(terminatorCharCodes, tokType.PATTERN as RegExp)\n          ) {\n            hasAnyLineBreak = true;\n          }\n        }\n      }\n    });\n  }\n\n  if (trackLines && !hasAnyLineBreak) {\n    warnings.push({\n      message:\n        \"Warning: No LINE_BREAKS Found.\\n\" +\n        \"\\tThis Lexer has been defined to track line and column information,\\n\" +\n        \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" +\n        \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" +\n        \"\\tfor details.\",\n      type: LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS,\n    });\n  }\n  return warnings;\n}\n\nexport function cloneEmptyGroups(emptyGroups: {\n  [groupName: string]: IToken;\n}): { [groupName: string]: IToken } {\n  const clonedResult: any = {};\n  const groupKeys = keys(emptyGroups);\n\n  forEach(groupKeys, (currKey) => {\n    const currGroupValue = emptyGroups[currKey];\n\n    /* istanbul ignore else */\n    if (isArray(currGroupValue)) {\n      clonedResult[currKey] = [];\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  });\n\n  return clonedResult;\n}\n\n// TODO: refactor to avoid duplication\nexport function isCustomPattern(tokenType: TokenType): boolean {\n  const pattern = tokenType.PATTERN;\n  /* istanbul ignore else */\n  if (isRegExp(pattern)) {\n    return false;\n  } else if (isFunction(pattern)) {\n    // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n    return true;\n  } else if (has(pattern, \"exec\")) {\n    // ICustomPattern\n    return true;\n  } else if (isString(pattern)) {\n    return false;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nexport function isShortPattern(pattern: any): number | false {\n  if (isString(pattern) && pattern.length === 1) {\n    return pattern.charCodeAt(0);\n  } else {\n    return false;\n  }\n}\n\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\nexport const LineTerminatorOptimizedTester: ILineTerminatorsTester = {\n  // implements /\\n|\\r\\n?/g.test\n  test: function (text) {\n    const len = text.length;\n    for (let i = this.lastIndex; i < len; i++) {\n      const c = text.charCodeAt(i);\n      if (c === 10) {\n        this.lastIndex = i + 1;\n        return true;\n      } else if (c === 13) {\n        if (text.charCodeAt(i + 1) === 10) {\n          this.lastIndex = i + 2;\n        } else {\n          this.lastIndex = i + 1;\n        }\n        return true;\n      }\n    }\n    return false;\n  },\n\n  lastIndex: 0,\n};\n\nfunction checkLineBreaksIssues(\n  tokType: TokenType,\n  lineTerminatorCharCodes: number[],\n):\n  | {\n      issue:\n        | LexerDefinitionErrorType.IDENTIFY_TERMINATOR\n        | LexerDefinitionErrorType.CUSTOM_LINE_BREAK;\n      errMsg?: string;\n    }\n  | false {\n  if (has(tokType, \"LINE_BREAKS\")) {\n    // if the user explicitly declared the line_breaks option we will respect their choice\n    // and assume it is correct.\n    return false;\n  } else {\n    /* istanbul ignore else */\n    if (isRegExp(tokType.PATTERN)) {\n      try {\n        // TODO: why is the casting suddenly needed?\n        canMatchCharCode(lineTerminatorCharCodes, tokType.PATTERN as RegExp);\n      } catch (e) {\n        /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n        return {\n          issue: LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n          errMsg: (e as Error).message,\n        };\n      }\n      return false;\n    } else if (isString(tokType.PATTERN)) {\n      // string literal patterns can always be analyzed to detect line terminator usage\n      return false;\n    } else if (isCustomPattern(tokType)) {\n      // custom token types\n      return { issue: LexerDefinitionErrorType.CUSTOM_LINE_BREAK };\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n}\n\nexport function buildLineBreakIssueMessage(\n  tokType: TokenType,\n  details: {\n    issue:\n      | LexerDefinitionErrorType.IDENTIFY_TERMINATOR\n      | LexerDefinitionErrorType.CUSTOM_LINE_BREAK;\n    errMsg?: string;\n  },\n): string {\n  /* istanbul ignore else */\n  if (details.issue === LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n    return (\n      \"Warning: unable to identify line terminator usage in pattern.\\n\" +\n      `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n      `\\t Root cause: ${details.errMsg}.\\n` +\n      \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\"\n    );\n  } else if (details.issue === LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n    return (\n      \"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" +\n      `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n      \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\"\n    );\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nfunction getCharCodes(charsOrCodes: (number | string)[]): number[] {\n  const charCodes = map(charsOrCodes, (numOrString) => {\n    if (isString(numOrString)) {\n      return numOrString.charCodeAt(0);\n    } else {\n      return numOrString;\n    }\n  });\n\n  return charCodes;\n}\n\nfunction addToMapOfArrays<T>(\n  map: Record<number, T[]>,\n  key: number,\n  value: T,\n): void {\n  if (map[key] === undefined) {\n    map[key] = [value];\n  } else {\n    map[key].push(value);\n  }\n}\n\nexport const minOptimizationVal = 256;\n\n/**\n * We are mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\nlet charCodeToOptimizedIdxMap: number[] = [];\nexport function charCodeToOptimizedIndex(charCode: number): number {\n  return charCode < minOptimizationVal\n    ? charCode\n    : charCodeToOptimizedIdxMap[charCode];\n}\n\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\nfunction initCharCodeToOptimizedIndexMap() {\n  if (isEmpty(charCodeToOptimizedIdxMap)) {\n    charCodeToOptimizedIdxMap = new Array(65536);\n    for (let i = 0; i < 65536; i++) {\n      charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n    }\n  }\n}\n","export function timer<T>(func: () => T): { time: number; value: T } {\n  const start = new Date().getTime();\n  const val = func();\n  const end = new Date().getTime();\n  const total = end - start;\n  return { time: total, value: val };\n}\n","import {\n  clone,\n  compact,\n  difference,\n  flatten,\n  forEach,\n  has,\n  includes,\n  isArray,\n  isEmpty,\n  map,\n} from \"lodash-es\";\nimport { IToken, TokenType } from \"@chevrotain/types\";\n\nexport function tokenStructuredMatcher(\n  tokInstance: IToken,\n  tokConstructor: TokenType,\n) {\n  const instanceType = tokInstance.tokenTypeIdx;\n  if (instanceType === tokConstructor.tokenTypeIdx) {\n    return true;\n  } else {\n    return (\n      tokConstructor.isParent === true &&\n      tokConstructor.categoryMatchesMap![instanceType] === true\n    );\n  }\n}\n\n// Optimized tokenMatcher in case our grammar does not use token categories\n// Being so tiny it is much more likely to be in-lined and this avoid the function call overhead\nexport function tokenStructuredMatcherNoCategories(\n  token: IToken,\n  tokType: TokenType,\n) {\n  return token.tokenTypeIdx === tokType.tokenTypeIdx;\n}\n\nexport let tokenShortNameIdx = 1;\nexport const tokenIdxToClass: { [tokenIdx: number]: TokenType } = {};\n\nexport function augmentTokenTypes(tokenTypes: TokenType[]): void {\n  // collect the parent Token Types as well.\n  const tokenTypesAndParents = expandCategories(tokenTypes);\n\n  // add required tokenType and categoryMatches properties\n  assignTokenDefaultProps(tokenTypesAndParents);\n\n  // fill up the categoryMatches\n  assignCategoriesMapProp(tokenTypesAndParents);\n  assignCategoriesTokensProp(tokenTypesAndParents);\n\n  forEach(tokenTypesAndParents, (tokType) => {\n    tokType.isParent = tokType.categoryMatches!.length > 0;\n  });\n}\n\nexport function expandCategories(tokenTypes: TokenType[]): TokenType[] {\n  let result = clone(tokenTypes);\n\n  let categories = tokenTypes;\n  let searching = true;\n  while (searching) {\n    categories = compact(\n      flatten(map(categories, (currTokType) => currTokType.CATEGORIES)),\n    );\n\n    const newCategories = difference(categories, result);\n\n    result = result.concat(newCategories);\n\n    if (isEmpty(newCategories)) {\n      searching = false;\n    } else {\n      categories = newCategories;\n    }\n  }\n  return result;\n}\n\nexport function assignTokenDefaultProps(tokenTypes: TokenType[]): void {\n  forEach(tokenTypes, (currTokType) => {\n    if (!hasShortKeyProperty(currTokType)) {\n      tokenIdxToClass[tokenShortNameIdx] = currTokType;\n      (<any>currTokType).tokenTypeIdx = tokenShortNameIdx++;\n    }\n\n    // CATEGORIES? : TokenType | TokenType[]\n    if (\n      hasCategoriesProperty(currTokType) &&\n      !isArray(currTokType.CATEGORIES)\n      // &&\n      // !isUndefined(currTokType.CATEGORIES.PATTERN)\n    ) {\n      currTokType.CATEGORIES = [currTokType.CATEGORIES as unknown as TokenType];\n    }\n\n    if (!hasCategoriesProperty(currTokType)) {\n      currTokType.CATEGORIES = [];\n    }\n\n    if (!hasExtendingTokensTypesProperty(currTokType)) {\n      currTokType.categoryMatches = [];\n    }\n\n    if (!hasExtendingTokensTypesMapProperty(currTokType)) {\n      currTokType.categoryMatchesMap = {};\n    }\n  });\n}\n\nexport function assignCategoriesTokensProp(tokenTypes: TokenType[]): void {\n  forEach(tokenTypes, (currTokType) => {\n    // avoid duplications\n    currTokType.categoryMatches = [];\n    forEach(currTokType.categoryMatchesMap!, (val, key) => {\n      currTokType.categoryMatches!.push(\n        tokenIdxToClass[key as unknown as number].tokenTypeIdx!,\n      );\n    });\n  });\n}\n\nexport function assignCategoriesMapProp(tokenTypes: TokenType[]): void {\n  forEach(tokenTypes, (currTokType) => {\n    singleAssignCategoriesToksMap([], currTokType);\n  });\n}\n\nexport function singleAssignCategoriesToksMap(\n  path: TokenType[],\n  nextNode: TokenType,\n): void {\n  forEach(path, (pathNode) => {\n    nextNode.categoryMatchesMap![pathNode.tokenTypeIdx!] = true;\n  });\n\n  forEach(nextNode.CATEGORIES, (nextCategory) => {\n    const newPath = path.concat(nextNode);\n    // avoids infinite loops due to cyclic categories.\n    if (!includes(newPath, nextCategory)) {\n      singleAssignCategoriesToksMap(newPath, nextCategory);\n    }\n  });\n}\n\nexport function hasShortKeyProperty(tokType: TokenType): boolean {\n  return has(tokType, \"tokenTypeIdx\");\n}\n\nexport function hasCategoriesProperty(tokType: TokenType): boolean {\n  return has(tokType, \"CATEGORIES\");\n}\n\nexport function hasExtendingTokensTypesProperty(tokType: TokenType): boolean {\n  return has(tokType, \"categoryMatches\");\n}\n\nexport function hasExtendingTokensTypesMapProperty(\n  tokType: TokenType,\n): boolean {\n  return has(tokType, \"categoryMatchesMap\");\n}\n\nexport function isTokenType(tokType: TokenType): boolean {\n  return has(tokType, \"tokenTypeIdx\");\n}\n","import { ILexerErrorMessageProvider, IToken } from \"@chevrotain/types\";\n\nexport const defaultLexerErrorProvider: ILexerErrorMessageProvider = {\n  buildUnableToPopLexerModeMessage(token: IToken): string {\n    return `Unable to pop Lexer Mode after encountering Token ->${token.image}<- The Mode Stack is empty`;\n  },\n\n  buildUnexpectedCharactersMessage(\n    fullText: string,\n    startOffset: number,\n    length: number,\n    line?: number,\n    column?: number,\n  ): string {\n    return (\n      `unexpected character: ->${fullText.charAt(\n        startOffset,\n      )}<- at offset: ${startOffset},` + ` skipped ${length} characters.`\n    );\n  },\n};\n","import {\n  analyzeTokenTypes,\n  charCodeToOptimizedIndex,\n  cloneEmptyGroups,\n  DEFAULT_MODE,\n  IAnalyzeResult,\n  IPatternConfig,\n  LineTerminatorOptimizedTester,\n  performRuntimeChecks,\n  performWarningRuntimeChecks,\n  SUPPORT_STICKY,\n  validatePatterns,\n} from \"./lexer.js\";\nimport {\n  assign,\n  clone,\n  forEach,\n  identity,\n  isArray,\n  isEmpty,\n  isUndefined,\n  keys,\n  last,\n  map,\n  noop,\n  reduce,\n  reject,\n} from \"lodash-es\";\nimport { PRINT_WARNING, timer, toFastProperties } from \"@chevrotain/utils\";\nimport { augmentTokenTypes } from \"./tokens.js\";\nimport {\n  CustomPatternMatcherFunc,\n  CustomPatternMatcherReturn,\n  ILexerConfig,\n  ILexerDefinitionError,\n  ILexingError,\n  IMultiModeLexerDefinition,\n  IToken,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { defaultLexerErrorProvider } from \"./lexer_errors_public.js\";\nimport { clearRegExpParserCache } from \"./reg_exp_parser.js\";\n\nexport interface ILexingResult {\n  tokens: IToken[];\n  groups: { [groupName: string]: IToken[] };\n  errors: ILexingError[];\n}\n\nexport enum LexerDefinitionErrorType {\n  MISSING_PATTERN,\n  INVALID_PATTERN,\n  EOI_ANCHOR_FOUND,\n  UNSUPPORTED_FLAGS_FOUND,\n  DUPLICATE_PATTERNS_FOUND,\n  INVALID_GROUP_TYPE_FOUND,\n  PUSH_MODE_DOES_NOT_EXIST,\n  MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE,\n  MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY,\n  MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST,\n  LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED,\n  SOI_ANCHOR_FOUND,\n  EMPTY_MATCH_PATTERN,\n  NO_LINE_BREAKS_FLAGS,\n  UNREACHABLE_PATTERN,\n  IDENTIFY_TERMINATOR,\n  CUSTOM_LINE_BREAK,\n  MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE,\n}\n\nexport interface IRegExpExec {\n  exec: CustomPatternMatcherFunc;\n}\n\nconst DEFAULT_LEXER_CONFIG: Required<ILexerConfig> = {\n  deferDefinitionErrorsHandling: false,\n  positionTracking: \"full\",\n  lineTerminatorsPattern: /\\n|\\r\\n?/g,\n  lineTerminatorCharacters: [\"\\n\", \"\\r\"],\n  ensureOptimizations: false,\n  safeMode: false,\n  errorMessageProvider: defaultLexerErrorProvider,\n  traceInitPerf: false,\n  skipValidations: false,\n  recoveryEnabled: true,\n};\n\nObject.freeze(DEFAULT_LEXER_CONFIG);\n\nexport class Lexer {\n  public static SKIPPED =\n    \"This marks a skipped Token pattern, this means each token identified by it will\" +\n    \"be consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\";\n\n  public static NA = /NOT_APPLICABLE/;\n  public lexerDefinitionErrors: ILexerDefinitionError[] = [];\n  public lexerDefinitionWarning: ILexerDefinitionError[] = [];\n\n  protected patternIdxToConfig: Record<string, IPatternConfig[]> = {};\n  protected charCodeToPatternIdxToConfig: {\n    [modeName: string]: { [charCode: number]: IPatternConfig[] };\n  } = {};\n\n  protected modes: string[] = [];\n  protected defaultMode!: string;\n  protected emptyGroups: { [groupName: string]: IToken } = {};\n\n  private config: Required<ILexerConfig>;\n  private trackStartLines: boolean = true;\n  private trackEndLines: boolean = true;\n  private hasCustom: boolean = false;\n  private canModeBeOptimized: Record<string, boolean> = {};\n\n  private traceInitPerf!: boolean | number;\n  private traceInitMaxIdent!: number;\n  private traceInitIndent: number;\n\n  constructor(\n    protected lexerDefinition: TokenType[] | IMultiModeLexerDefinition,\n    config: ILexerConfig = DEFAULT_LEXER_CONFIG,\n  ) {\n    if (typeof config === \"boolean\") {\n      throw Error(\n        \"The second argument to the Lexer constructor is now an ILexerConfig Object.\\n\" +\n          \"a boolean 2nd argument is no longer supported\",\n      );\n    }\n\n    // todo: defaults func?\n    this.config = assign({}, DEFAULT_LEXER_CONFIG, config) as any;\n\n    const traceInitVal = this.config.traceInitPerf;\n    if (traceInitVal === true) {\n      this.traceInitMaxIdent = Infinity;\n      this.traceInitPerf = true;\n    } else if (typeof traceInitVal === \"number\") {\n      this.traceInitMaxIdent = traceInitVal;\n      this.traceInitPerf = true;\n    }\n    this.traceInitIndent = -1;\n\n    this.TRACE_INIT(\"Lexer Constructor\", () => {\n      let actualDefinition!: IMultiModeLexerDefinition;\n      let hasOnlySingleMode = true;\n      this.TRACE_INIT(\"Lexer Config handling\", () => {\n        if (\n          this.config.lineTerminatorsPattern ===\n          DEFAULT_LEXER_CONFIG.lineTerminatorsPattern\n        ) {\n          // optimized built-in implementation for the defaults definition of lineTerminators\n          this.config.lineTerminatorsPattern = LineTerminatorOptimizedTester;\n        } else {\n          if (\n            this.config.lineTerminatorCharacters ===\n            DEFAULT_LEXER_CONFIG.lineTerminatorCharacters\n          ) {\n            throw Error(\n              \"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\n\" +\n                \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\",\n            );\n          }\n        }\n\n        if (config.safeMode && config.ensureOptimizations) {\n          throw Error(\n            '\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.',\n          );\n        }\n\n        this.trackStartLines = /full|onlyStart/i.test(\n          this.config.positionTracking,\n        );\n        this.trackEndLines = /full/i.test(this.config.positionTracking);\n\n        // Convert SingleModeLexerDefinition into a IMultiModeLexerDefinition.\n        if (isArray(lexerDefinition)) {\n          actualDefinition = {\n            modes: { defaultMode: clone(lexerDefinition) },\n            defaultMode: DEFAULT_MODE,\n          };\n        } else {\n          // no conversion needed, input should already be a IMultiModeLexerDefinition\n          hasOnlySingleMode = false;\n          actualDefinition = clone(<IMultiModeLexerDefinition>lexerDefinition);\n        }\n      });\n\n      if (this.config.skipValidations === false) {\n        this.TRACE_INIT(\"performRuntimeChecks\", () => {\n          this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(\n            performRuntimeChecks(\n              actualDefinition,\n              this.trackStartLines,\n              this.config.lineTerminatorCharacters,\n            ),\n          );\n        });\n\n        this.TRACE_INIT(\"performWarningRuntimeChecks\", () => {\n          this.lexerDefinitionWarning = this.lexerDefinitionWarning.concat(\n            performWarningRuntimeChecks(\n              actualDefinition,\n              this.trackStartLines,\n              this.config.lineTerminatorCharacters,\n            ),\n          );\n        });\n      }\n\n      // for extra robustness to avoid throwing an none informative error message\n      actualDefinition.modes = actualDefinition.modes\n        ? actualDefinition.modes\n        : {};\n\n      // an error of undefined TokenTypes will be detected in \"performRuntimeChecks\" above.\n      // this transformation is to increase robustness in the case of partially invalid lexer definition.\n      forEach(actualDefinition.modes, (currModeValue, currModeName) => {\n        actualDefinition.modes[currModeName] = reject<TokenType>(\n          currModeValue,\n          (currTokType) => isUndefined(currTokType),\n        );\n      });\n\n      const allModeNames = keys(actualDefinition.modes);\n\n      forEach(\n        actualDefinition.modes,\n        (currModDef: TokenType[], currModName) => {\n          this.TRACE_INIT(`Mode: <${currModName}> processing`, () => {\n            this.modes.push(currModName);\n\n            if (this.config.skipValidations === false) {\n              this.TRACE_INIT(`validatePatterns`, () => {\n                this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat(\n                  validatePatterns(currModDef, allModeNames),\n                );\n              });\n            }\n\n            // If definition errors were encountered, the analysis phase may fail unexpectedly/\n            // Considering a lexer with definition errors may never be used, there is no point\n            // to performing the analysis anyhow...\n            if (isEmpty(this.lexerDefinitionErrors)) {\n              augmentTokenTypes(currModDef);\n\n              let currAnalyzeResult!: IAnalyzeResult;\n              this.TRACE_INIT(`analyzeTokenTypes`, () => {\n                currAnalyzeResult = analyzeTokenTypes(currModDef, {\n                  lineTerminatorCharacters:\n                    this.config.lineTerminatorCharacters,\n                  positionTracking: config.positionTracking,\n                  ensureOptimizations: config.ensureOptimizations,\n                  safeMode: config.safeMode,\n                  tracer: this.TRACE_INIT,\n                });\n              });\n\n              this.patternIdxToConfig[currModName] =\n                currAnalyzeResult.patternIdxToConfig;\n\n              this.charCodeToPatternIdxToConfig[currModName] =\n                currAnalyzeResult.charCodeToPatternIdxToConfig;\n\n              this.emptyGroups = assign(\n                {},\n                this.emptyGroups,\n                currAnalyzeResult.emptyGroups,\n              ) as any;\n\n              this.hasCustom = currAnalyzeResult.hasCustom || this.hasCustom;\n\n              this.canModeBeOptimized[currModName] =\n                currAnalyzeResult.canBeOptimized;\n            }\n          });\n        },\n      );\n\n      this.defaultMode = actualDefinition.defaultMode;\n\n      if (\n        !isEmpty(this.lexerDefinitionErrors) &&\n        !this.config.deferDefinitionErrorsHandling\n      ) {\n        const allErrMessages = map(this.lexerDefinitionErrors, (error) => {\n          return error.message;\n        });\n        const allErrMessagesString = allErrMessages.join(\n          \"-----------------------\\n\",\n        );\n        throw new Error(\n          \"Errors detected in definition of Lexer:\\n\" + allErrMessagesString,\n        );\n      }\n\n      // Only print warning if there are no errors, This will avoid pl\n      forEach(this.lexerDefinitionWarning, (warningDescriptor) => {\n        PRINT_WARNING(warningDescriptor.message);\n      });\n\n      this.TRACE_INIT(\"Choosing sub-methods implementations\", () => {\n        // Choose the relevant internal implementations for this specific parser.\n        // These implementations should be in-lined by the JavaScript engine\n        // to provide optimal performance in each scenario.\n        if (SUPPORT_STICKY) {\n          this.chopInput = <any>identity;\n          this.match = this.matchWithTest;\n        } else {\n          this.updateLastIndex = noop;\n          this.match = this.matchWithExec;\n        }\n\n        if (hasOnlySingleMode) {\n          this.handleModes = noop;\n        }\n\n        if (this.trackStartLines === false) {\n          this.computeNewColumn = identity;\n        }\n\n        if (this.trackEndLines === false) {\n          this.updateTokenEndLineColumnLocation = noop;\n        }\n\n        if (/full/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createFullToken;\n        } else if (/onlyStart/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createStartOnlyToken;\n        } else if (/onlyOffset/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createOffsetOnlyToken;\n        } else {\n          throw Error(\n            `Invalid <positionTracking> config option: \"${this.config.positionTracking}\"`,\n          );\n        }\n\n        if (this.hasCustom) {\n          this.addToken = this.addTokenUsingPush;\n          this.handlePayload = this.handlePayloadWithCustom;\n        } else {\n          this.addToken = this.addTokenUsingMemberAccess;\n          this.handlePayload = this.handlePayloadNoCustom;\n        }\n      });\n\n      this.TRACE_INIT(\"Failed Optimization Warnings\", () => {\n        const unOptimizedModes = reduce(\n          this.canModeBeOptimized,\n          (cannotBeOptimized, canBeOptimized, modeName) => {\n            if (canBeOptimized === false) {\n              cannotBeOptimized.push(modeName);\n            }\n            return cannotBeOptimized;\n          },\n          [] as string[],\n        );\n\n        if (config.ensureOptimizations && !isEmpty(unOptimizedModes)) {\n          throw Error(\n            `Lexer Modes: < ${unOptimizedModes.join(\n              \", \",\n            )} > cannot be optimized.\\n` +\n              '\\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\\n' +\n              \"\\t Or inspect the console log for details on how to resolve these issues.\",\n          );\n        }\n      });\n\n      this.TRACE_INIT(\"clearRegExpParserCache\", () => {\n        clearRegExpParserCache();\n      });\n\n      this.TRACE_INIT(\"toFastProperties\", () => {\n        toFastProperties(this);\n      });\n    });\n  }\n\n  public tokenize(\n    text: string,\n    initialMode: string = this.defaultMode,\n  ): ILexingResult {\n    if (!isEmpty(this.lexerDefinitionErrors)) {\n      const allErrMessages = map(this.lexerDefinitionErrors, (error) => {\n        return error.message;\n      });\n      const allErrMessagesString = allErrMessages.join(\n        \"-----------------------\\n\",\n      );\n      throw new Error(\n        \"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" +\n          allErrMessagesString,\n      );\n    }\n\n    return this.tokenizeInternal(text, initialMode);\n  }\n\n  // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n  // This is intentional due to performance considerations.\n  // this method also used quite a bit of `!` none null assertions because it is too optimized\n  // for `tsc` to always understand it is \"safe\"\n  private tokenizeInternal(text: string, initialMode: string): ILexingResult {\n    let i,\n      j,\n      k,\n      matchAltImage,\n      longerAlt,\n      matchedImage: string | null,\n      payload,\n      altPayload,\n      imageLength,\n      group,\n      tokType,\n      newToken: IToken,\n      errLength,\n      droppedChar,\n      msg,\n      match;\n    const orgText = text;\n    const orgLength = orgText.length;\n    let offset = 0;\n    let matchedTokensIndex = 0;\n    // initializing the tokensArray to the \"guessed\" size.\n    // guessing too little will still reduce the number of array re-sizes on pushes.\n    // guessing too large (Tested by guessing x4 too large) may cost a bit more of memory\n    // but would still have a faster runtime by avoiding (All but one) array resizing.\n    const guessedNumberOfTokens = this.hasCustom\n      ? 0 // will break custom token pattern APIs the matchedTokens array will contain undefined elements.\n      : Math.floor(text.length / 10);\n    const matchedTokens = new Array(guessedNumberOfTokens);\n    const errors: ILexingError[] = [];\n    let line = this.trackStartLines ? 1 : undefined;\n    let column = this.trackStartLines ? 1 : undefined;\n    const groups: any = cloneEmptyGroups(this.emptyGroups);\n    const trackLines = this.trackStartLines;\n    const lineTerminatorPattern = this.config.lineTerminatorsPattern;\n\n    let currModePatternsLength = 0;\n    let patternIdxToConfig: IPatternConfig[] = [];\n    let currCharCodeToPatternIdxToConfig: {\n      [charCode: number]: IPatternConfig[];\n    } = [];\n\n    const modeStack: string[] = [];\n\n    const emptyArray: IPatternConfig[] = [];\n    Object.freeze(emptyArray);\n    let getPossiblePatterns!: (charCode: number) => IPatternConfig[];\n\n    function getPossiblePatternsSlow() {\n      return patternIdxToConfig;\n    }\n\n    function getPossiblePatternsOptimized(charCode: number): IPatternConfig[] {\n      const optimizedCharIdx = charCodeToOptimizedIndex(charCode);\n      const possiblePatterns =\n        currCharCodeToPatternIdxToConfig[optimizedCharIdx];\n      if (possiblePatterns === undefined) {\n        return emptyArray;\n      } else {\n        return possiblePatterns;\n      }\n    }\n\n    const pop_mode = (popToken: IToken) => {\n      // TODO: perhaps avoid this error in the edge case there is no more input?\n      if (\n        modeStack.length === 1 &&\n        // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \"transition\"\n        // So no error should occur.\n        popToken.tokenType.PUSH_MODE === undefined\n      ) {\n        // if we try to pop the last mode there lexer will no longer have ANY mode.\n        // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\n        const msg =\n          this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(\n            popToken,\n          );\n\n        errors.push({\n          offset: popToken.startOffset,\n          line: popToken.startLine,\n          column: popToken.startColumn,\n          length: popToken.image.length,\n          message: msg,\n        });\n      } else {\n        modeStack.pop();\n        const newMode = last(modeStack)!;\n        patternIdxToConfig = this.patternIdxToConfig[newMode];\n        currCharCodeToPatternIdxToConfig =\n          this.charCodeToPatternIdxToConfig[newMode];\n        currModePatternsLength = patternIdxToConfig.length;\n        const modeCanBeOptimized =\n          this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n\n        if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n          getPossiblePatterns = getPossiblePatternsOptimized;\n        } else {\n          getPossiblePatterns = getPossiblePatternsSlow;\n        }\n      }\n    };\n\n    function push_mode(this: Lexer, newMode: string) {\n      modeStack.push(newMode);\n      currCharCodeToPatternIdxToConfig =\n        this.charCodeToPatternIdxToConfig[newMode];\n\n      patternIdxToConfig = this.patternIdxToConfig[newMode];\n      currModePatternsLength = patternIdxToConfig.length;\n\n      currModePatternsLength = patternIdxToConfig.length;\n      const modeCanBeOptimized =\n        this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n\n      if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n        getPossiblePatterns = getPossiblePatternsOptimized;\n      } else {\n        getPossiblePatterns = getPossiblePatternsSlow;\n      }\n    }\n\n    // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\n    // seem to matter performance wise.\n    push_mode.call(this, initialMode);\n\n    let currConfig!: IPatternConfig;\n\n    const recoveryEnabled = this.config.recoveryEnabled;\n\n    while (offset < orgLength) {\n      matchedImage = null;\n\n      const nextCharCode = orgText.charCodeAt(offset);\n      const chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode);\n      const chosenPatternsLength = chosenPatternIdxToConfig.length;\n\n      for (i = 0; i < chosenPatternsLength; i++) {\n        currConfig = chosenPatternIdxToConfig[i];\n        const currPattern = currConfig.pattern;\n        payload = null;\n\n        // manually in-lined because > 600 chars won't be in-lined in V8\n        const singleCharCode = currConfig.short;\n        if (singleCharCode !== false) {\n          if (nextCharCode === singleCharCode) {\n            // single character string\n            matchedImage = currPattern as string;\n          }\n        } else if (currConfig.isCustom === true) {\n          match = (currPattern as IRegExpExec).exec(\n            orgText,\n            offset,\n            matchedTokens,\n            groups,\n          );\n          if (match !== null) {\n            matchedImage = match[0];\n            if ((match as CustomPatternMatcherReturn).payload !== undefined) {\n              payload = (match as CustomPatternMatcherReturn).payload;\n            }\n          } else {\n            matchedImage = null;\n          }\n        } else {\n          this.updateLastIndex(currPattern as RegExp, offset);\n          matchedImage = this.match(currPattern as RegExp, text, offset);\n        }\n\n        if (matchedImage !== null) {\n          // even though this pattern matched we must try a another longer alternative.\n          // this can be used to prioritize keywords over identifiers\n          longerAlt = currConfig.longerAlt;\n          if (longerAlt !== undefined) {\n            // TODO: micro optimize, avoid extra prop access\n            // by saving/linking longerAlt on the original config?\n            const longerAltLength = longerAlt.length;\n            for (k = 0; k < longerAltLength; k++) {\n              const longerAltConfig = patternIdxToConfig[longerAlt[k]];\n              const longerAltPattern = longerAltConfig.pattern;\n              altPayload = null;\n\n              // single Char can never be a longer alt so no need to test it.\n              // manually in-lined because > 600 chars won't be in-lined in V8\n              if (longerAltConfig.isCustom === true) {\n                match = (longerAltPattern as IRegExpExec).exec(\n                  orgText,\n                  offset,\n                  matchedTokens,\n                  groups,\n                );\n                if (match !== null) {\n                  matchAltImage = match[0];\n                  if (\n                    (match as CustomPatternMatcherReturn).payload !== undefined\n                  ) {\n                    altPayload = (match as CustomPatternMatcherReturn).payload;\n                  }\n                } else {\n                  matchAltImage = null;\n                }\n              } else {\n                this.updateLastIndex(longerAltPattern as RegExp, offset);\n                matchAltImage = this.match(\n                  longerAltPattern as RegExp,\n                  text,\n                  offset,\n                );\n              }\n\n              if (matchAltImage && matchAltImage.length > matchedImage.length) {\n                matchedImage = matchAltImage;\n                payload = altPayload;\n                currConfig = longerAltConfig;\n                // Exit the loop early after matching one of the longer alternatives\n                // The first matched alternative takes precedence\n                break;\n              }\n            }\n          }\n          break;\n        }\n      }\n\n      // successful match\n      if (matchedImage !== null) {\n        imageLength = matchedImage.length;\n        group = currConfig.group;\n        if (group !== undefined) {\n          tokType = currConfig.tokenTypeIdx;\n          // TODO: \"offset + imageLength\" and the new column may be computed twice in case of \"full\" location information inside\n          // createFullToken method\n          newToken = this.createTokenInstance(\n            matchedImage,\n            offset,\n            tokType,\n            currConfig.tokenType,\n            line,\n            column,\n            imageLength,\n          );\n\n          this.handlePayload(newToken, payload);\n\n          // TODO: optimize NOOP in case there are no special groups?\n          if (group === false) {\n            matchedTokensIndex = this.addToken(\n              matchedTokens,\n              matchedTokensIndex,\n              newToken,\n            );\n          } else {\n            groups[group].push(newToken);\n          }\n        }\n        text = this.chopInput(text, imageLength);\n        offset = offset + imageLength;\n\n        // TODO: with newlines the column may be assigned twice\n        column = this.computeNewColumn(column!, imageLength);\n\n        if (trackLines === true && currConfig.canLineTerminator === true) {\n          let numOfLTsInMatch = 0;\n          let foundTerminator;\n          let lastLTEndOffset: number;\n          lineTerminatorPattern.lastIndex = 0;\n          do {\n            foundTerminator = lineTerminatorPattern.test(matchedImage);\n            if (foundTerminator === true) {\n              lastLTEndOffset = lineTerminatorPattern.lastIndex - 1;\n              numOfLTsInMatch++;\n            }\n          } while (foundTerminator === true);\n\n          if (numOfLTsInMatch !== 0) {\n            line = line! + numOfLTsInMatch;\n            column = imageLength - lastLTEndOffset!;\n            this.updateTokenEndLineColumnLocation(\n              newToken!,\n              group!,\n              lastLTEndOffset!,\n              numOfLTsInMatch,\n              line,\n              column,\n              imageLength,\n            );\n          }\n        }\n        // will be NOOP if no modes present\n        this.handleModes(currConfig, pop_mode, push_mode, newToken!);\n      } else {\n        // error recovery, drop characters until we identify a valid token's start point\n        const errorStartOffset = offset;\n        const errorLine = line;\n        const errorColumn = column;\n        let foundResyncPoint = recoveryEnabled === false;\n\n        while (foundResyncPoint === false && offset < orgLength) {\n          // Identity Func (when sticky flag is enabled)\n          text = this.chopInput(text, 1);\n          offset++;\n          for (j = 0; j < currModePatternsLength; j++) {\n            const currConfig = patternIdxToConfig[j];\n            const currPattern = currConfig.pattern;\n\n            // manually in-lined because > 600 chars won't be in-lined in V8\n            const singleCharCode = currConfig.short;\n            if (singleCharCode !== false) {\n              if (orgText.charCodeAt(offset) === singleCharCode) {\n                // single character string\n                foundResyncPoint = true;\n              }\n            } else if (currConfig.isCustom === true) {\n              foundResyncPoint =\n                (currPattern as IRegExpExec).exec(\n                  orgText,\n                  offset,\n                  matchedTokens,\n                  groups,\n                ) !== null;\n            } else {\n              this.updateLastIndex(currPattern as RegExp, offset);\n              foundResyncPoint = (currPattern as RegExp).exec(text) !== null;\n            }\n\n            if (foundResyncPoint === true) {\n              break;\n            }\n          }\n        }\n\n        errLength = offset - errorStartOffset;\n        column = this.computeNewColumn(column!, errLength);\n        // at this point we either re-synced or reached the end of the input text\n        msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(\n          orgText,\n          errorStartOffset,\n          errLength,\n          errorLine,\n          errorColumn,\n        );\n        errors.push({\n          offset: errorStartOffset,\n          line: errorLine,\n          column: errorColumn,\n          length: errLength,\n          message: msg,\n        });\n\n        if (recoveryEnabled === false) {\n          break;\n        }\n      }\n    }\n\n    // if we do have custom patterns which push directly into the\n    // TODO: custom tokens should not push directly??\n    if (!this.hasCustom) {\n      // if we guessed a too large size for the tokens array this will shrink it to the right size.\n      matchedTokens.length = matchedTokensIndex;\n    }\n\n    return {\n      tokens: matchedTokens,\n      groups: groups,\n      errors: errors,\n    };\n  }\n\n  private handleModes(\n    config: IPatternConfig,\n    pop_mode: (tok: IToken) => void,\n    push_mode: (this: Lexer, pushMode: string) => void,\n    newToken: IToken,\n  ) {\n    if (config.pop === true) {\n      // need to save the PUSH_MODE property as if the mode is popped\n      // patternIdxToPopMode is updated to reflect the new mode after popping the stack\n      const pushMode = config.push;\n      pop_mode(newToken);\n      if (pushMode !== undefined) {\n        push_mode.call(this, pushMode);\n      }\n    } else if (config.push !== undefined) {\n      push_mode.call(this, config.push);\n    }\n  }\n\n  private chopInput(text: string, length: number): string {\n    return text.substring(length);\n  }\n\n  private updateLastIndex(regExp: RegExp, newLastIndex: number): void {\n    regExp.lastIndex = newLastIndex;\n  }\n\n  // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\n  private updateTokenEndLineColumnLocation(\n    newToken: IToken,\n    group: string | false,\n    lastLTIdx: number,\n    numOfLTsInMatch: number,\n    line: number,\n    column: number,\n    imageLength: number,\n  ): void {\n    let lastCharIsLT, fixForEndingInLT;\n    if (group !== undefined) {\n      // a none skipped multi line Token, need to update endLine/endColumn\n      lastCharIsLT = lastLTIdx === imageLength - 1;\n      fixForEndingInLT = lastCharIsLT ? -1 : 0;\n      if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\n        // if a token ends in a LT that last LT only affects the line numbering of following Tokens\n        newToken.endLine = line + fixForEndingInLT;\n        // the last LT in a token does not affect the endColumn either as the [columnStart ... columnEnd)\n        // inclusive to exclusive range.\n        newToken.endColumn = column - 1 + -fixForEndingInLT;\n      }\n      // else single LT in the last character of a token, no need to modify the endLine/EndColumn\n    }\n  }\n\n  private computeNewColumn(oldColumn: number, imageLength: number) {\n    return oldColumn + imageLength;\n  }\n\n  // Place holder, will be replaced by the correct variant according to the locationTracking option at runtime.\n  /* istanbul ignore next - place holder */\n  private createTokenInstance!: (...args: any[]) => IToken;\n\n  private createOffsetOnlyToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType,\n  ) {\n    return {\n      image,\n      startOffset,\n      tokenTypeIdx,\n      tokenType,\n    };\n  }\n\n  private createStartOnlyToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType,\n    startLine: number,\n    startColumn: number,\n  ) {\n    return {\n      image,\n      startOffset,\n      startLine,\n      startColumn,\n      tokenTypeIdx,\n      tokenType,\n    };\n  }\n\n  private createFullToken(\n    image: string,\n    startOffset: number,\n    tokenTypeIdx: number,\n    tokenType: TokenType,\n    startLine: number,\n    startColumn: number,\n    imageLength: number,\n  ): IToken {\n    return {\n      image,\n      startOffset,\n      endOffset: startOffset + imageLength - 1,\n      startLine,\n      endLine: startLine,\n      startColumn,\n      endColumn: startColumn + imageLength - 1,\n      tokenTypeIdx,\n      tokenType,\n    };\n  }\n\n  // Place holder, will be replaced by the correct variant according to the locationTracking option at runtime.\n  /* istanbul ignore next - place holder */\n  private addToken!: (\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken,\n  ) => number;\n\n  private addTokenUsingPush(\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken,\n  ): number {\n    tokenVector.push(tokenToAdd);\n    return index;\n  }\n\n  private addTokenUsingMemberAccess(\n    tokenVector: IToken[],\n    index: number,\n    tokenToAdd: IToken,\n  ): number {\n    tokenVector[index] = tokenToAdd;\n    index++;\n    return index;\n  }\n\n  // Place holder, will be replaced by the correct variant according to the hasCustom flag option at runtime.\n  private handlePayload: (token: IToken, payload: any) => void;\n\n  private handlePayloadNoCustom(token: IToken, payload: any): void {}\n\n  private handlePayloadWithCustom(token: IToken, payload: any): void {\n    if (payload !== null) {\n      token.payload = payload;\n    }\n  }\n\n  // place holder to be replaced with chosen alternative at runtime\n  private match!: (\n    pattern: RegExp,\n    text: string,\n    offset: number,\n  ) => string | null;\n\n  private matchWithTest(\n    pattern: RegExp,\n    text: string,\n    offset: number,\n  ): string | null {\n    const found = pattern.test(text);\n    if (found === true) {\n      return text.substring(offset, pattern.lastIndex);\n    }\n    return null;\n  }\n\n  private matchWithExec(pattern: RegExp, text: string): string | null {\n    const regExpArray = pattern.exec(text);\n    return regExpArray !== null ? regExpArray[0] : null;\n  }\n\n  // Duplicated from the parser's perf trace trait to allow future extraction\n  // of the lexer to a separate package.\n  TRACE_INIT = <T>(phaseDesc: string, phaseImpl: () => T): T => {\n    // No need to optimize this using NOOP pattern because\n    // It is not called in a hot spot...\n    if (this.traceInitPerf === true) {\n      this.traceInitIndent++;\n      const indent = new Array(this.traceInitIndent + 1).join(\"\\t\");\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        console.log(`${indent}--> <${phaseDesc}>`);\n      }\n      const { time, value } = timer(phaseImpl);\n      /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n      const traceMethod = time > 10 ? console.warn : console.log;\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n      }\n      this.traceInitIndent--;\n      return value;\n    } else {\n      return phaseImpl();\n    }\n  };\n}\n","import { has, isString, isUndefined } from \"lodash-es\";\nimport { Lexer } from \"./lexer_public.js\";\nimport { augmentTokenTypes, tokenStructuredMatcher } from \"./tokens.js\";\nimport { IToken, ITokenConfig, TokenType } from \"@chevrotain/types\";\n\nexport function tokenLabel(tokType: TokenType): string {\n  if (hasTokenLabel(tokType)) {\n    return tokType.LABEL;\n  } else {\n    return tokType.name;\n  }\n}\n\nexport function tokenName(tokType: TokenType): string {\n  return tokType.name;\n}\n\nexport function hasTokenLabel(\n  obj: TokenType,\n): obj is TokenType & Pick<Required<TokenType>, \"LABEL\"> {\n  return isString(obj.LABEL) && obj.LABEL !== \"\";\n}\n\nconst PARENT = \"parent\";\nconst CATEGORIES = \"categories\";\nconst LABEL = \"label\";\nconst GROUP = \"group\";\nconst PUSH_MODE = \"push_mode\";\nconst POP_MODE = \"pop_mode\";\nconst LONGER_ALT = \"longer_alt\";\nconst LINE_BREAKS = \"line_breaks\";\nconst START_CHARS_HINT = \"start_chars_hint\";\n\nexport function createToken(config: ITokenConfig): TokenType {\n  return createTokenInternal(config);\n}\n\nfunction createTokenInternal(config: ITokenConfig): TokenType {\n  const pattern = config.pattern;\n\n  const tokenType: TokenType = <any>{};\n  tokenType.name = config.name;\n\n  if (!isUndefined(pattern)) {\n    tokenType.PATTERN = pattern;\n  }\n\n  if (has(config, PARENT)) {\n    throw (\n      \"The parent property is no longer supported.\\n\" +\n      \"See: https://github.com/chevrotain/chevrotain/issues/564#issuecomment-349062346 for details.\"\n    );\n  }\n\n  if (has(config, CATEGORIES)) {\n    // casting to ANY as this will be fixed inside `augmentTokenTypes``\n    tokenType.CATEGORIES = <any>config[CATEGORIES];\n  }\n\n  augmentTokenTypes([tokenType]);\n\n  if (has(config, LABEL)) {\n    tokenType.LABEL = config[LABEL];\n  }\n\n  if (has(config, GROUP)) {\n    tokenType.GROUP = config[GROUP];\n  }\n\n  if (has(config, POP_MODE)) {\n    tokenType.POP_MODE = config[POP_MODE];\n  }\n\n  if (has(config, PUSH_MODE)) {\n    tokenType.PUSH_MODE = config[PUSH_MODE];\n  }\n\n  if (has(config, LONGER_ALT)) {\n    tokenType.LONGER_ALT = config[LONGER_ALT];\n  }\n\n  if (has(config, LINE_BREAKS)) {\n    tokenType.LINE_BREAKS = config[LINE_BREAKS];\n  }\n\n  if (has(config, START_CHARS_HINT)) {\n    tokenType.START_CHARS_HINT = config[START_CHARS_HINT];\n  }\n\n  return tokenType;\n}\n\nexport const EOF = createToken({ name: \"EOF\", pattern: Lexer.NA });\naugmentTokenTypes([EOF]);\n\nexport function createTokenInstance(\n  tokType: TokenType,\n  image: string,\n  startOffset: number,\n  endOffset: number,\n  startLine: number,\n  endLine: number,\n  startColumn: number,\n  endColumn: number,\n): IToken {\n  return {\n    image,\n    startOffset,\n    endOffset,\n    startLine,\n    endLine,\n    startColumn,\n    endColumn,\n    tokenTypeIdx: (<any>tokType).tokenTypeIdx,\n    tokenType: tokType,\n  };\n}\n\nexport function tokenMatcher(token: IToken, tokType: TokenType): boolean {\n  return tokenStructuredMatcher(token, tokType);\n}\n","import { hasTokenLabel, tokenLabel } from \"../scan/tokens_public.js\";\nimport { first, map, reduce } from \"lodash-es\";\nimport {\n  Alternation,\n  getProductionDslName,\n  NonTerminal,\n  Rule,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport {\n  IParserErrorMessageProvider,\n  IProductionWithOccurrence,\n  TokenType,\n} from \"@chevrotain/types\";\nimport {\n  IGrammarResolverErrorMessageProvider,\n  IGrammarValidatorErrorMessageProvider,\n} from \"./grammar/types.js\";\n\nexport const defaultParserErrorProvider: IParserErrorMessageProvider = {\n  buildMismatchTokenMessage({ expected, actual, previous, ruleName }): string {\n    const hasLabel = hasTokenLabel(expected);\n    const expectedMsg = hasLabel\n      ? `--> ${tokenLabel(expected)} <--`\n      : `token of type --> ${expected.name} <--`;\n\n    const msg = `Expecting ${expectedMsg} but found --> '${actual.image}' <--`;\n\n    return msg;\n  },\n\n  buildNotAllInputParsedMessage({ firstRedundant, ruleName }): string {\n    return \"Redundant input, expecting EOF but found: \" + firstRedundant.image;\n  },\n\n  buildNoViableAltMessage({\n    expectedPathsPerAlt,\n    actual,\n    previous,\n    customUserDescription,\n    ruleName,\n  }): string {\n    const errPrefix = \"Expecting: \";\n    // TODO: issue: No Viable Alternative Error may have incomplete details. #502\n    const actualText = first(actual)!.image;\n    const errSuffix = \"\\nbut found: '\" + actualText + \"'\";\n\n    if (customUserDescription) {\n      return errPrefix + customUserDescription + errSuffix;\n    } else {\n      const allLookAheadPaths = reduce(\n        expectedPathsPerAlt,\n        (result, currAltPaths) => result.concat(currAltPaths),\n        [] as TokenType[][],\n      );\n      const nextValidTokenSequences = map(\n        allLookAheadPaths,\n        (currPath) =>\n          `[${map(currPath, (currTokenType) => tokenLabel(currTokenType)).join(\n            \", \",\n          )}]`,\n      );\n      const nextValidSequenceItems = map(\n        nextValidTokenSequences,\n        (itemMsg, idx) => `  ${idx + 1}. ${itemMsg}`,\n      );\n      const calculatedDescription = `one of these possible Token sequences:\\n${nextValidSequenceItems.join(\n        \"\\n\",\n      )}`;\n\n      return errPrefix + calculatedDescription + errSuffix;\n    }\n  },\n\n  buildEarlyExitMessage({\n    expectedIterationPaths,\n    actual,\n    customUserDescription,\n    ruleName,\n  }): string {\n    const errPrefix = \"Expecting: \";\n    // TODO: issue: No Viable Alternative Error may have incomplete details. #502\n    const actualText = first(actual)!.image;\n    const errSuffix = \"\\nbut found: '\" + actualText + \"'\";\n\n    if (customUserDescription) {\n      return errPrefix + customUserDescription + errSuffix;\n    } else {\n      const nextValidTokenSequences = map(\n        expectedIterationPaths,\n        (currPath) =>\n          `[${map(currPath, (currTokenType) => tokenLabel(currTokenType)).join(\n            \",\",\n          )}]`,\n      );\n      const calculatedDescription =\n        `expecting at least one iteration which starts with one of these possible Token sequences::\\n  ` +\n        `<${nextValidTokenSequences.join(\" ,\")}>`;\n\n      return errPrefix + calculatedDescription + errSuffix;\n    }\n  },\n};\n\nObject.freeze(defaultParserErrorProvider);\n\nexport const defaultGrammarResolverErrorProvider: IGrammarResolverErrorMessageProvider =\n  {\n    buildRuleNotFoundError(\n      topLevelRule: Rule,\n      undefinedRule: NonTerminal,\n    ): string {\n      const msg =\n        \"Invalid grammar, reference to a rule which is not defined: ->\" +\n        undefinedRule.nonTerminalName +\n        \"<-\\n\" +\n        \"inside top level rule: ->\" +\n        topLevelRule.name +\n        \"<-\";\n      return msg;\n    },\n  };\n\nexport const defaultGrammarValidatorErrorProvider: IGrammarValidatorErrorMessageProvider =\n  {\n    buildDuplicateFoundError(\n      topLevelRule: Rule,\n      duplicateProds: IProductionWithOccurrence[],\n    ): string {\n      function getExtraProductionArgument(\n        prod: IProductionWithOccurrence,\n      ): string {\n        if (prod instanceof Terminal) {\n          return prod.terminalType.name;\n        } else if (prod instanceof NonTerminal) {\n          return prod.nonTerminalName;\n        } else {\n          return \"\";\n        }\n      }\n\n      const topLevelName = topLevelRule.name;\n      const duplicateProd = first(duplicateProds)!;\n      const index = duplicateProd.idx;\n      const dslName = getProductionDslName(duplicateProd);\n      const extraArgument = getExtraProductionArgument(duplicateProd);\n\n      const hasExplicitIndex = index > 0;\n      let msg = `->${dslName}${hasExplicitIndex ? index : \"\"}<- ${\n        extraArgument ? `with argument: ->${extraArgument}<-` : \"\"\n      }\n                  appears more than once (${\n                    duplicateProds.length\n                  } times) in the top level rule: ->${topLevelName}<-.                  \n                  For further details see: https://chevrotain.io/docs/FAQ.html#NUMERICAL_SUFFIXES \n                  `;\n\n      // white space trimming time! better to trim afterwards as it allows to use WELL formatted multi line template strings...\n      msg = msg.replace(/[ \\t]+/g, \" \");\n      msg = msg.replace(/\\s\\s+/g, \"\\n\");\n\n      return msg;\n    },\n\n    buildNamespaceConflictError(rule: Rule): string {\n      const errMsg =\n        `Namespace conflict found in grammar.\\n` +\n        `The grammar has both a Terminal(Token) and a Non-Terminal(Rule) named: <${rule.name}>.\\n` +\n        `To resolve this make sure each Terminal and Non-Terminal names are unique\\n` +\n        `This is easy to accomplish by using the convention that Terminal names start with an uppercase letter\\n` +\n        `and Non-Terminal names start with a lower case letter.`;\n\n      return errMsg;\n    },\n\n    buildAlternationPrefixAmbiguityError(options: {\n      topLevelRule: Rule;\n      prefixPath: TokenType[];\n      ambiguityIndices: number[];\n      alternation: Alternation;\n    }): string {\n      const pathMsg = map(options.prefixPath, (currTok) =>\n        tokenLabel(currTok),\n      ).join(\", \");\n      const occurrence =\n        options.alternation.idx === 0 ? \"\" : options.alternation.idx;\n      const errMsg =\n        `Ambiguous alternatives: <${options.ambiguityIndices.join(\n          \" ,\",\n        )}> due to common lookahead prefix\\n` +\n        `in <OR${occurrence}> inside <${options.topLevelRule.name}> Rule,\\n` +\n        `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n` +\n        `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#COMMON_PREFIX\\n` +\n        `For Further details.`;\n\n      return errMsg;\n    },\n\n    buildAlternationAmbiguityError(options: {\n      topLevelRule: Rule;\n      prefixPath: TokenType[];\n      ambiguityIndices: number[];\n      alternation: Alternation;\n    }): string {\n      const pathMsg = map(options.prefixPath, (currtok) =>\n        tokenLabel(currtok),\n      ).join(\", \");\n      const occurrence =\n        options.alternation.idx === 0 ? \"\" : options.alternation.idx;\n      let currMessage =\n        `Ambiguous Alternatives Detected: <${options.ambiguityIndices.join(\n          \" ,\",\n        )}> in <OR${occurrence}>` +\n        ` inside <${options.topLevelRule.name}> Rule,\\n` +\n        `<${pathMsg}> may appears as a prefix path in all these alternatives.\\n`;\n\n      currMessage =\n        currMessage +\n        `See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#AMBIGUOUS_ALTERNATIVES\\n` +\n        `For Further details.`;\n      return currMessage;\n    },\n\n    buildEmptyRepetitionError(options: {\n      topLevelRule: Rule;\n      repetition: IProductionWithOccurrence;\n    }): string {\n      let dslName = getProductionDslName(options.repetition);\n      if (options.repetition.idx !== 0) {\n        dslName += options.repetition.idx;\n      }\n\n      const errMsg =\n        `The repetition <${dslName}> within Rule <${options.topLevelRule.name}> can never consume any tokens.\\n` +\n        `This could lead to an infinite loop.`;\n\n      return errMsg;\n    },\n\n    // TODO: remove - `errors_public` from nyc.config.js exclude\n    //       once this method is fully removed from this file\n    buildTokenNameError(options: {\n      tokenType: TokenType;\n      expectedPattern: RegExp;\n    }): string {\n      /* istanbul ignore next */\n      return \"deprecated\";\n    },\n\n    buildEmptyAlternationError(options: {\n      topLevelRule: Rule;\n      alternation: Alternation;\n      emptyChoiceIdx: number;\n    }): string {\n      const errMsg =\n        `Ambiguous empty alternative: <${options.emptyChoiceIdx + 1}>` +\n        ` in <OR${options.alternation.idx}> inside <${options.topLevelRule.name}> Rule.\\n` +\n        `Only the last alternative may be an empty alternative.`;\n\n      return errMsg;\n    },\n\n    buildTooManyAlternativesError(options: {\n      topLevelRule: Rule;\n      alternation: Alternation;\n    }): string {\n      const errMsg =\n        `An Alternation cannot have more than 256 alternatives:\\n` +\n        `<OR${options.alternation.idx}> inside <${\n          options.topLevelRule.name\n        }> Rule.\\n has ${\n          options.alternation.definition.length + 1\n        } alternatives.`;\n\n      return errMsg;\n    },\n\n    buildLeftRecursionError(options: {\n      topLevelRule: Rule;\n      leftRecursionPath: Rule[];\n    }): string {\n      const ruleName = options.topLevelRule.name;\n      const pathNames = map(\n        options.leftRecursionPath,\n        (currRule) => currRule.name,\n      );\n      const leftRecursivePath = `${ruleName} --> ${pathNames\n        .concat([ruleName])\n        .join(\" --> \")}`;\n      const errMsg =\n        `Left Recursion found in grammar.\\n` +\n        `rule: <${ruleName}> can be invoked from itself (directly or indirectly)\\n` +\n        `without consuming any Tokens. The grammar path that causes this is: \\n ${leftRecursivePath}\\n` +\n        ` To fix this refactor your grammar to remove the left recursion.\\n` +\n        `see: https://en.wikipedia.org/wiki/LL_parser#Left_factoring.`;\n\n      return errMsg;\n    },\n\n    // TODO: remove - `errors_public` from nyc.config.js exclude\n    //       once this method is fully removed from this file\n    buildInvalidRuleNameError(options: {\n      topLevelRule: Rule;\n      expectedPattern: RegExp;\n    }): string {\n      /* istanbul ignore next */\n      return \"deprecated\";\n    },\n\n    buildDuplicateRuleNameError(options: {\n      topLevelRule: Rule | string;\n      grammarName: string;\n    }): string {\n      let ruleName;\n      if (options.topLevelRule instanceof Rule) {\n        ruleName = options.topLevelRule.name;\n      } else {\n        ruleName = options.topLevelRule;\n      }\n\n      const errMsg = `Duplicate definition, rule: ->${ruleName}<- is already defined in the grammar: ->${options.grammarName}<-`;\n\n      return errMsg;\n    },\n  };\n","import {\n  IParserUnresolvedRefDefinitionError,\n  ParserDefinitionErrorType,\n} from \"../parser/parser.js\";\nimport { forEach, values } from \"lodash-es\";\nimport { GAstVisitor, NonTerminal, Rule } from \"@chevrotain/gast\";\nimport {\n  IGrammarResolverErrorMessageProvider,\n  IParserDefinitionError,\n} from \"./types.js\";\n\nexport function resolveGrammar(\n  topLevels: Record<string, Rule>,\n  errMsgProvider: IGrammarResolverErrorMessageProvider,\n): IParserDefinitionError[] {\n  const refResolver = new GastRefResolverVisitor(topLevels, errMsgProvider);\n  refResolver.resolveRefs();\n  return refResolver.errors;\n}\n\nexport class GastRefResolverVisitor extends GAstVisitor {\n  public errors: IParserUnresolvedRefDefinitionError[] = [];\n  private currTopLevel: Rule;\n\n  constructor(\n    private nameToTopRule: Record<string, Rule>,\n    private errMsgProvider: IGrammarResolverErrorMessageProvider,\n  ) {\n    super();\n  }\n\n  public resolveRefs(): void {\n    forEach(values(this.nameToTopRule), (prod) => {\n      this.currTopLevel = prod;\n      prod.accept(this);\n    });\n  }\n\n  public visitNonTerminal(node: NonTerminal): void {\n    const ref = this.nameToTopRule[node.nonTerminalName];\n\n    if (!ref) {\n      const msg = this.errMsgProvider.buildRuleNotFoundError(\n        this.currTopLevel,\n        node,\n      );\n      this.errors.push({\n        message: msg,\n        type: ParserDefinitionErrorType.UNRESOLVED_SUBRULE_REF,\n        ruleName: this.currTopLevel.name,\n        unresolvedRefName: node.nonTerminalName,\n      });\n    } else {\n      node.referencedRule = ref;\n    }\n  }\n}\n","/**\n * A specialized version of `baseAggregator` for arrays.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} setter The function to set `accumulator` values.\n * @param {Function} iteratee The iteratee to transform keys.\n * @param {Object} accumulator The initial aggregated object.\n * @returns {Function} Returns `accumulator`.\n */\nfunction arrayAggregator(array, setter, iteratee, accumulator) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    var value = array[index];\n    setter(accumulator, value, iteratee(value), array);\n  }\n  return accumulator;\n}\n\nexport default arrayAggregator;\n","import baseEach from './_baseEach.js';\n\n/**\n * Aggregates elements of `collection` on `accumulator` with keys transformed\n * by `iteratee` and values set by `setter`.\n *\n * @private\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} setter The function to set `accumulator` values.\n * @param {Function} iteratee The iteratee to transform keys.\n * @param {Object} accumulator The initial aggregated object.\n * @returns {Function} Returns `accumulator`.\n */\nfunction baseAggregator(collection, setter, iteratee, accumulator) {\n  baseEach(collection, function(value, key, collection) {\n    setter(accumulator, value, iteratee(value), collection);\n  });\n  return accumulator;\n}\n\nexport default baseAggregator;\n","import arrayAggregator from './_arrayAggregator.js';\nimport baseAggregator from './_baseAggregator.js';\nimport baseIteratee from './_baseIteratee.js';\nimport isArray from './isArray.js';\n\n/**\n * Creates a function like `_.groupBy`.\n *\n * @private\n * @param {Function} setter The function to set accumulator values.\n * @param {Function} [initializer] The accumulator object initializer.\n * @returns {Function} Returns the new aggregator function.\n */\nfunction createAggregator(setter, initializer) {\n  return function(collection, iteratee) {\n    var func = isArray(collection) ? arrayAggregator : baseAggregator,\n        accumulator = initializer ? initializer() : {};\n\n    return func(collection, setter, baseIteratee(iteratee, 2), accumulator);\n  };\n}\n\nexport default createAggregator;\n","import baseAssignValue from './_baseAssignValue.js';\nimport createAggregator from './_createAggregator.js';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Creates an object composed of keys generated from the results of running\n * each element of `collection` thru `iteratee`. The order of grouped values\n * is determined by the order they occur in `collection`. The corresponding\n * value of each key is an array of elements responsible for generating the\n * key. The iteratee is invoked with one argument: (value).\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The iteratee to transform keys.\n * @returns {Object} Returns the composed aggregate object.\n * @example\n *\n * _.groupBy([6.1, 4.2, 6.3], Math.floor);\n * // => { '4': [4.2], '6': [6.1, 6.3] }\n *\n * // The `_.property` iteratee shorthand.\n * _.groupBy(['one', 'two', 'three'], 'length');\n * // => { '3': ['one', 'two'], '5': ['three'] }\n */\nvar groupBy = createAggregator(function(result, value, key) {\n  if (hasOwnProperty.call(result, key)) {\n    result[key].push(value);\n  } else {\n    baseAssignValue(result, key, [value]);\n  }\n});\n\nexport default groupBy;\n","import baseSlice from './_baseSlice.js';\nimport toInteger from './toInteger.js';\n\n/**\n * Creates a slice of `array` with `n` elements dropped from the end.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Array\n * @param {Array} array The array to query.\n * @param {number} [n=1] The number of elements to drop.\n * @param- {Object} [guard] Enables use as an iteratee for methods like `_.map`.\n * @returns {Array} Returns the slice of `array`.\n * @example\n *\n * _.dropRight([1, 2, 3]);\n * // => [1, 2]\n *\n * _.dropRight([1, 2, 3], 2);\n * // => [1]\n *\n * _.dropRight([1, 2, 3], 5);\n * // => []\n *\n * _.dropRight([1, 2, 3], 0);\n * // => [1, 2, 3]\n */\nfunction dropRight(array, n, guard) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return [];\n  }\n  n = (guard || n === undefined) ? 1 : toInteger(n);\n  n = length - n;\n  return baseSlice(array, 0, n < 0 ? 0 : n);\n}\n\nexport default dropRight;\n","import {\n  clone,\n  drop,\n  dropRight,\n  first as _first,\n  forEach,\n  isEmpty,\n  last,\n} from \"lodash-es\";\nimport { first } from \"./first.js\";\nimport { RestWalker } from \"./rest.js\";\nimport { TokenMatcher } from \"../parser/parser.js\";\nimport {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport {\n  IGrammarPath,\n  IProduction,\n  ISyntacticContentAssistPath,\n  IToken,\n  ITokenGrammarPath,\n  TokenType,\n} from \"@chevrotain/types\";\n\nexport abstract class AbstractNextPossibleTokensWalker extends RestWalker {\n  protected possibleTokTypes: TokenType[] = [];\n  protected ruleStack: string[];\n  protected occurrenceStack: number[];\n\n  protected nextProductionName = \"\";\n  protected nextProductionOccurrence = 0;\n  protected found = false;\n  protected isAtEndOfPath = false;\n\n  constructor(\n    protected topProd: Rule,\n    protected path: IGrammarPath,\n  ) {\n    super();\n  }\n\n  startWalking(): TokenType[] {\n    this.found = false;\n\n    if (this.path.ruleStack[0] !== this.topProd.name) {\n      throw Error(\"The path does not start with the walker's top Rule!\");\n    }\n\n    // immutable for the win\n    this.ruleStack = clone(this.path.ruleStack).reverse(); // intelij bug requires assertion\n    this.occurrenceStack = clone(this.path.occurrenceStack).reverse(); // intelij bug requires assertion\n\n    // already verified that the first production is valid, we now seek the 2nd production\n    this.ruleStack.pop();\n    this.occurrenceStack.pop();\n\n    this.updateExpectedNext();\n    this.walk(this.topProd);\n\n    return this.possibleTokTypes;\n  }\n\n  walk(\n    prod: { definition: IProduction[] },\n    prevRest: IProduction[] = [],\n  ): void {\n    // stop scanning once we found the path\n    if (!this.found) {\n      super.walk(prod, prevRest);\n    }\n  }\n\n  walkProdRef(\n    refProd: NonTerminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    // found the next production, need to keep walking in it\n    if (\n      refProd.referencedRule.name === this.nextProductionName &&\n      refProd.idx === this.nextProductionOccurrence\n    ) {\n      const fullRest = currRest.concat(prevRest);\n      this.updateExpectedNext();\n      this.walk(refProd.referencedRule, <any>fullRest);\n    }\n  }\n\n  updateExpectedNext(): void {\n    // need to consume the Terminal\n    if (isEmpty(this.ruleStack)) {\n      // must reset nextProductionXXX to avoid walking down another Top Level production while what we are\n      // really seeking is the last Terminal...\n      this.nextProductionName = \"\";\n      this.nextProductionOccurrence = 0;\n      this.isAtEndOfPath = true;\n    } else {\n      this.nextProductionName = this.ruleStack.pop()!;\n      this.nextProductionOccurrence = this.occurrenceStack.pop()!;\n    }\n  }\n}\n\nexport class NextAfterTokenWalker extends AbstractNextPossibleTokensWalker {\n  private nextTerminalName = \"\";\n  private nextTerminalOccurrence = 0;\n\n  constructor(\n    topProd: Rule,\n    protected path: ITokenGrammarPath,\n  ) {\n    super(topProd, path);\n    this.nextTerminalName = this.path.lastTok.name;\n    this.nextTerminalOccurrence = this.path.lastTokOccurrence;\n  }\n\n  walkTerminal(\n    terminal: Terminal,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      this.isAtEndOfPath &&\n      terminal.terminalType.name === this.nextTerminalName &&\n      terminal.idx === this.nextTerminalOccurrence &&\n      !this.found\n    ) {\n      const fullRest = currRest.concat(prevRest);\n      const restProd = new Alternative({ definition: fullRest });\n      this.possibleTokTypes = first(restProd);\n      this.found = true;\n    }\n  }\n}\n\nexport type AlternativesFirstTokens = TokenType[][];\n\nexport interface IFirstAfterRepetition {\n  token: TokenType | undefined;\n  occurrence: number | undefined;\n  isEndOfRule: boolean | undefined;\n}\n\n/**\n * This walker only \"walks\" a single \"TOP\" level in the Grammar Ast, this means\n * it never \"follows\" production refs\n */\nexport class AbstractNextTerminalAfterProductionWalker extends RestWalker {\n  protected result: IFirstAfterRepetition = {\n    token: undefined,\n    occurrence: undefined,\n    isEndOfRule: undefined,\n  };\n\n  constructor(\n    protected topRule: Rule,\n    protected occurrence: number,\n  ) {\n    super();\n  }\n\n  startWalking(): IFirstAfterRepetition {\n    this.walk(this.topRule);\n    return this.result;\n  }\n}\n\nexport class NextTerminalAfterManyWalker extends AbstractNextTerminalAfterProductionWalker {\n  walkMany(\n    manyProd: Repetition,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (manyProd.idx === this.occurrence) {\n      const firstAfterMany = _first(currRest.concat(prevRest));\n      this.result.isEndOfRule = firstAfterMany === undefined;\n      if (firstAfterMany instanceof Terminal) {\n        this.result.token = firstAfterMany.terminalType;\n        this.result.occurrence = firstAfterMany.idx;\n      }\n    } else {\n      super.walkMany(manyProd, currRest, prevRest);\n    }\n  }\n}\n\nexport class NextTerminalAfterManySepWalker extends AbstractNextTerminalAfterProductionWalker {\n  walkManySep(\n    manySepProd: RepetitionWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (manySepProd.idx === this.occurrence) {\n      const firstAfterManySep = _first(currRest.concat(prevRest));\n      this.result.isEndOfRule = firstAfterManySep === undefined;\n      if (firstAfterManySep instanceof Terminal) {\n        this.result.token = firstAfterManySep.terminalType;\n        this.result.occurrence = firstAfterManySep.idx;\n      }\n    } else {\n      super.walkManySep(manySepProd, currRest, prevRest);\n    }\n  }\n}\n\nexport class NextTerminalAfterAtLeastOneWalker extends AbstractNextTerminalAfterProductionWalker {\n  walkAtLeastOne(\n    atLeastOneProd: RepetitionMandatory,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (atLeastOneProd.idx === this.occurrence) {\n      const firstAfterAtLeastOne = _first(currRest.concat(prevRest));\n      this.result.isEndOfRule = firstAfterAtLeastOne === undefined;\n      if (firstAfterAtLeastOne instanceof Terminal) {\n        this.result.token = firstAfterAtLeastOne.terminalType;\n        this.result.occurrence = firstAfterAtLeastOne.idx;\n      }\n    } else {\n      super.walkAtLeastOne(atLeastOneProd, currRest, prevRest);\n    }\n  }\n}\n\n// TODO: reduce code duplication in the AfterWalkers\nexport class NextTerminalAfterAtLeastOneSepWalker extends AbstractNextTerminalAfterProductionWalker {\n  walkAtLeastOneSep(\n    atleastOneSepProd: RepetitionMandatoryWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (atleastOneSepProd.idx === this.occurrence) {\n      const firstAfterfirstAfterAtLeastOneSep = _first(\n        currRest.concat(prevRest),\n      );\n      this.result.isEndOfRule = firstAfterfirstAfterAtLeastOneSep === undefined;\n      if (firstAfterfirstAfterAtLeastOneSep instanceof Terminal) {\n        this.result.token = firstAfterfirstAfterAtLeastOneSep.terminalType;\n        this.result.occurrence = firstAfterfirstAfterAtLeastOneSep.idx;\n      }\n    } else {\n      super.walkAtLeastOneSep(atleastOneSepProd, currRest, prevRest);\n    }\n  }\n}\n\nexport interface PartialPathAndSuffixes {\n  partialPath: TokenType[];\n  suffixDef: IProduction[];\n}\n\nexport function possiblePathsFrom(\n  targetDef: IProduction[],\n  maxLength: number,\n  currPath: TokenType[] = [],\n): PartialPathAndSuffixes[] {\n  // avoid side effects\n  currPath = clone(currPath);\n  let result: PartialPathAndSuffixes[] = [];\n  let i = 0;\n\n  // TODO: avoid inner funcs\n  function remainingPathWith(nextDef: IProduction[]) {\n    return nextDef.concat(drop(targetDef, i + 1));\n  }\n\n  // TODO: avoid inner funcs\n  function getAlternativesForProd(definition: IProduction[]) {\n    const alternatives = possiblePathsFrom(\n      remainingPathWith(definition),\n      maxLength,\n      currPath,\n    );\n    return result.concat(alternatives);\n  }\n\n  /**\n   * Mandatory productions will halt the loop as the paths computed from their recursive calls will already contain the\n   * following (rest) of the targetDef.\n   *\n   * For optional productions (Option/Repetition/...) the loop will continue to represent the paths that do not include the\n   * the optional production.\n   */\n  while (currPath.length < maxLength && i < targetDef.length) {\n    const prod = targetDef[i];\n\n    /* istanbul ignore else */\n    if (prod instanceof Alternative) {\n      return getAlternativesForProd(prod.definition);\n    } else if (prod instanceof NonTerminal) {\n      return getAlternativesForProd(prod.definition);\n    } else if (prod instanceof Option) {\n      result = getAlternativesForProd(prod.definition);\n    } else if (prod instanceof RepetitionMandatory) {\n      const newDef = prod.definition.concat([\n        new Repetition({\n          definition: prod.definition,\n        }),\n      ]);\n      return getAlternativesForProd(newDef);\n    } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n      const newDef = [\n        new Alternative({ definition: prod.definition }),\n        new Repetition({\n          definition: [new Terminal({ terminalType: prod.separator })].concat(\n            <any>prod.definition,\n          ),\n        }),\n      ];\n      return getAlternativesForProd(newDef);\n    } else if (prod instanceof RepetitionWithSeparator) {\n      const newDef = prod.definition.concat([\n        new Repetition({\n          definition: [new Terminal({ terminalType: prod.separator })].concat(\n            <any>prod.definition,\n          ),\n        }),\n      ]);\n      result = getAlternativesForProd(newDef);\n    } else if (prod instanceof Repetition) {\n      const newDef = prod.definition.concat([\n        new Repetition({\n          definition: prod.definition,\n        }),\n      ]);\n      result = getAlternativesForProd(newDef);\n    } else if (prod instanceof Alternation) {\n      forEach(prod.definition, (currAlt) => {\n        // TODO: this is a limited check for empty alternatives\n        //   It would prevent a common case of infinite loops during parser initialization.\n        //   However **in-directly** empty alternatives may still cause issues.\n        if (isEmpty(currAlt.definition) === false) {\n          result = getAlternativesForProd(currAlt.definition);\n        }\n      });\n      return result;\n    } else if (prod instanceof Terminal) {\n      currPath.push(prod.terminalType);\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n\n    i++;\n  }\n  result.push({\n    partialPath: currPath,\n    suffixDef: drop(targetDef, i),\n  });\n\n  return result;\n}\n\ninterface IPathToExamine {\n  idx: number;\n  def: IProduction[];\n  ruleStack: string[];\n  occurrenceStack: number[];\n}\n\nexport function nextPossibleTokensAfter(\n  initialDef: IProduction[],\n  tokenVector: IToken[],\n  tokMatcher: TokenMatcher,\n  maxLookAhead: number,\n): ISyntacticContentAssistPath[] {\n  const EXIT_NON_TERMINAL: any = \"EXIT_NONE_TERMINAL\";\n  // to avoid creating a new Array each time.\n  const EXIT_NON_TERMINAL_ARR = [EXIT_NON_TERMINAL];\n  const EXIT_ALTERNATIVE: any = \"EXIT_ALTERNATIVE\";\n  let foundCompletePath = false;\n\n  const tokenVectorLength = tokenVector.length;\n  const minimalAlternativesIndex = tokenVectorLength - maxLookAhead - 1;\n\n  const result: ISyntacticContentAssistPath[] = [];\n\n  const possiblePaths: IPathToExamine[] = [];\n  possiblePaths.push({\n    idx: -1,\n    def: initialDef,\n    ruleStack: [],\n    occurrenceStack: [],\n  });\n\n  while (!isEmpty(possiblePaths)) {\n    const currPath = possiblePaths.pop()!;\n\n    // skip alternatives if no more results can be found (assuming deterministic grammar with fixed lookahead)\n    if (currPath === EXIT_ALTERNATIVE) {\n      if (\n        foundCompletePath &&\n        last(possiblePaths)!.idx <= minimalAlternativesIndex\n      ) {\n        // remove irrelevant alternative\n        possiblePaths.pop();\n      }\n      continue;\n    }\n\n    const currDef = currPath.def;\n    const currIdx = currPath.idx;\n    const currRuleStack = currPath.ruleStack;\n    const currOccurrenceStack = currPath.occurrenceStack;\n\n    // For Example: an empty path could exist in a valid grammar in the case of an EMPTY_ALT\n    if (isEmpty(currDef)) {\n      continue;\n    }\n\n    const prod = currDef[0];\n    /* istanbul ignore else */\n    if (prod === EXIT_NON_TERMINAL) {\n      const nextPath = {\n        idx: currIdx,\n        def: drop(currDef),\n        ruleStack: dropRight(currRuleStack),\n        occurrenceStack: dropRight(currOccurrenceStack),\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof Terminal) {\n      /* istanbul ignore else */\n      if (currIdx < tokenVectorLength - 1) {\n        const nextIdx = currIdx + 1;\n        const actualToken = tokenVector[nextIdx];\n        if (tokMatcher!(actualToken, prod.terminalType)) {\n          const nextPath = {\n            idx: nextIdx,\n            def: drop(currDef),\n            ruleStack: currRuleStack,\n            occurrenceStack: currOccurrenceStack,\n          };\n          possiblePaths.push(nextPath);\n        }\n        // end of the line\n      } else if (currIdx === tokenVectorLength - 1) {\n        // IGNORE ABOVE ELSE\n        result.push({\n          nextTokenType: prod.terminalType,\n          nextTokenOccurrence: prod.idx,\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack,\n        });\n        foundCompletePath = true;\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    } else if (prod instanceof NonTerminal) {\n      const newRuleStack = clone(currRuleStack);\n      newRuleStack.push(prod.nonTerminalName);\n\n      const newOccurrenceStack = clone(currOccurrenceStack);\n      newOccurrenceStack.push(prod.idx);\n\n      const nextPath = {\n        idx: currIdx,\n        def: prod.definition.concat(EXIT_NON_TERMINAL_ARR, drop(currDef)),\n        ruleStack: newRuleStack,\n        occurrenceStack: newOccurrenceStack,\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof Option) {\n      // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n      const nextPathWithout = {\n        idx: currIdx,\n        def: drop(currDef),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWithout);\n      // required marker to avoid backtracking paths whose higher priority alternatives already matched\n      possiblePaths.push(EXIT_ALTERNATIVE);\n\n      const nextPathWith = {\n        idx: currIdx,\n        def: prod.definition.concat(drop(currDef)),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWith);\n    } else if (prod instanceof RepetitionMandatory) {\n      // TODO:(THE NEW operators here take a while...) (convert once?)\n      const secondIteration = new Repetition({\n        definition: prod.definition,\n        idx: prod.idx,\n      });\n      const nextDef = prod.definition.concat([secondIteration], drop(currDef));\n      const nextPath = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof RepetitionMandatoryWithSeparator) {\n      // TODO:(THE NEW operators here take a while...) (convert once?)\n      const separatorGast = new Terminal({\n        terminalType: prod.separator,\n      });\n      const secondIteration = new Repetition({\n        definition: [<any>separatorGast].concat(prod.definition),\n        idx: prod.idx,\n      });\n      const nextDef = prod.definition.concat([secondIteration], drop(currDef));\n      const nextPath = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPath);\n    } else if (prod instanceof RepetitionWithSeparator) {\n      // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n      const nextPathWithout = {\n        idx: currIdx,\n        def: drop(currDef),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWithout);\n      // required marker to avoid backtracking paths whose higher priority alternatives already matched\n      possiblePaths.push(EXIT_ALTERNATIVE);\n\n      const separatorGast = new Terminal({\n        terminalType: prod.separator,\n      });\n      const nthRepetition = new Repetition({\n        definition: [<any>separatorGast].concat(prod.definition),\n        idx: prod.idx,\n      });\n      const nextDef = prod.definition.concat([nthRepetition], drop(currDef));\n      const nextPathWith = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWith);\n    } else if (prod instanceof Repetition) {\n      // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n      const nextPathWithout = {\n        idx: currIdx,\n        def: drop(currDef),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWithout);\n      // required marker to avoid backtracking paths whose higher priority alternatives already matched\n      possiblePaths.push(EXIT_ALTERNATIVE);\n\n      // TODO: an empty repetition will cause infinite loops here, will the parser detect this in selfAnalysis?\n      const nthRepetition = new Repetition({\n        definition: prod.definition,\n        idx: prod.idx,\n      });\n      const nextDef = prod.definition.concat([nthRepetition], drop(currDef));\n      const nextPathWith = {\n        idx: currIdx,\n        def: nextDef,\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      };\n      possiblePaths.push(nextPathWith);\n    } else if (prod instanceof Alternation) {\n      // the order of alternatives is meaningful, FILO (Last path will be traversed first).\n      for (let i = prod.definition.length - 1; i >= 0; i--) {\n        const currAlt: any = prod.definition[i];\n        const currAltPath = {\n          idx: currIdx,\n          def: currAlt.definition.concat(drop(currDef)),\n          ruleStack: currRuleStack,\n          occurrenceStack: currOccurrenceStack,\n        };\n        possiblePaths.push(currAltPath);\n        possiblePaths.push(EXIT_ALTERNATIVE);\n      }\n    } else if (prod instanceof Alternative) {\n      possiblePaths.push({\n        idx: currIdx,\n        def: prod.definition.concat(drop(currDef)),\n        ruleStack: currRuleStack,\n        occurrenceStack: currOccurrenceStack,\n      });\n    } else if (prod instanceof Rule) {\n      // last because we should only encounter at most a single one of these per invocation.\n      possiblePaths.push(\n        expandTopLevelRule(prod, currIdx, currRuleStack, currOccurrenceStack),\n      );\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n  return result;\n}\n\nfunction expandTopLevelRule(\n  topRule: Rule,\n  currIdx: number,\n  currRuleStack: string[],\n  currOccurrenceStack: number[],\n): IPathToExamine {\n  const newRuleStack = clone(currRuleStack);\n  newRuleStack.push(topRule.name);\n\n  const newCurrOccurrenceStack = clone(currOccurrenceStack);\n  // top rule is always assumed to have been called with occurrence index 1\n  newCurrOccurrenceStack.push(1);\n\n  return {\n    idx: currIdx,\n    def: topRule.definition,\n    ruleStack: newRuleStack,\n    occurrenceStack: newCurrOccurrenceStack,\n  };\n}\n","import { every, flatten, forEach, has, isEmpty, map, reduce } from \"lodash-es\";\nimport { possiblePathsFrom } from \"./interpreter.js\";\nimport { RestWalker } from \"./rest.js\";\nimport { Predicate, TokenMatcher } from \"../parser/parser.js\";\nimport {\n  tokenStructuredMatcher,\n  tokenStructuredMatcherNoCategories,\n} from \"../../scan/tokens.js\";\nimport {\n  Alternation,\n  Alternative as AlternativeGAST,\n  GAstVisitor,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n} from \"@chevrotain/gast\";\nimport {\n  BaseParser,\n  IOrAlt,\n  IProduction,\n  IProductionWithOccurrence,\n  LookaheadProductionType,\n  LookaheadSequence,\n  Rule,\n  TokenType,\n} from \"@chevrotain/types\";\n\nexport enum PROD_TYPE {\n  OPTION,\n  REPETITION,\n  REPETITION_MANDATORY,\n  REPETITION_MANDATORY_WITH_SEPARATOR,\n  REPETITION_WITH_SEPARATOR,\n  ALTERNATION,\n}\n\nexport function getProdType(\n  prod: IProduction | LookaheadProductionType,\n): PROD_TYPE {\n  /* istanbul ignore else */\n  if (prod instanceof Option || prod === \"Option\") {\n    return PROD_TYPE.OPTION;\n  } else if (prod instanceof Repetition || prod === \"Repetition\") {\n    return PROD_TYPE.REPETITION;\n  } else if (\n    prod instanceof RepetitionMandatory ||\n    prod === \"RepetitionMandatory\"\n  ) {\n    return PROD_TYPE.REPETITION_MANDATORY;\n  } else if (\n    prod instanceof RepetitionMandatoryWithSeparator ||\n    prod === \"RepetitionMandatoryWithSeparator\"\n  ) {\n    return PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR;\n  } else if (\n    prod instanceof RepetitionWithSeparator ||\n    prod === \"RepetitionWithSeparator\"\n  ) {\n    return PROD_TYPE.REPETITION_WITH_SEPARATOR;\n  } else if (prod instanceof Alternation || prod === \"Alternation\") {\n    return PROD_TYPE.ALTERNATION;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nexport function getLookaheadPaths(options: {\n  occurrence: number;\n  rule: Rule;\n  prodType: LookaheadProductionType;\n  maxLookahead: number;\n}): LookaheadSequence[] {\n  const { occurrence, rule, prodType, maxLookahead } = options;\n  const type = getProdType(prodType);\n  if (type === PROD_TYPE.ALTERNATION) {\n    return getLookaheadPathsForOr(occurrence, rule, maxLookahead);\n  } else {\n    return getLookaheadPathsForOptionalProd(\n      occurrence,\n      rule,\n      type,\n      maxLookahead,\n    );\n  }\n}\n\nexport function buildLookaheadFuncForOr(\n  occurrence: number,\n  ruleGrammar: Rule,\n  maxLookahead: number,\n  hasPredicates: boolean,\n  dynamicTokensEnabled: boolean,\n  laFuncBuilder: Function,\n): (orAlts?: IOrAlt<any>[]) => number | undefined {\n  const lookAheadPaths = getLookaheadPathsForOr(\n    occurrence,\n    ruleGrammar,\n    maxLookahead,\n  );\n\n  const tokenMatcher = areTokenCategoriesNotUsed(lookAheadPaths)\n    ? tokenStructuredMatcherNoCategories\n    : tokenStructuredMatcher;\n\n  return laFuncBuilder(\n    lookAheadPaths,\n    hasPredicates,\n    tokenMatcher,\n    dynamicTokensEnabled,\n  );\n}\n\n/**\n *  When dealing with an Optional production (OPTION/MANY/2nd iteration of AT_LEAST_ONE/...) we need to compare\n *  the lookahead \"inside\" the production and the lookahead immediately \"after\" it in the same top level rule (context free).\n *\n *  Example: given a production:\n *  ABC(DE)?DF\n *\n *  The optional '(DE)?' should only be entered if we see 'DE'. a single Token 'D' is not sufficient to distinguish between the two\n *  alternatives.\n *\n *  @returns A Lookahead function which will return true IFF the parser should parse the Optional production.\n */\nexport function buildLookaheadFuncForOptionalProd(\n  occurrence: number,\n  ruleGrammar: Rule,\n  k: number,\n  dynamicTokensEnabled: boolean,\n  prodType: PROD_TYPE,\n  lookaheadBuilder: (\n    lookAheadSequence: LookaheadSequence,\n    tokenMatcher: TokenMatcher,\n    dynamicTokensEnabled: boolean,\n  ) => () => boolean,\n): () => boolean {\n  const lookAheadPaths = getLookaheadPathsForOptionalProd(\n    occurrence,\n    ruleGrammar,\n    prodType,\n    k,\n  );\n\n  const tokenMatcher = areTokenCategoriesNotUsed(lookAheadPaths)\n    ? tokenStructuredMatcherNoCategories\n    : tokenStructuredMatcher;\n\n  return lookaheadBuilder(\n    lookAheadPaths[0],\n    tokenMatcher,\n    dynamicTokensEnabled,\n  );\n}\n\nexport type Alternative = TokenType[][];\n\nexport function buildAlternativesLookAheadFunc(\n  alts: LookaheadSequence[],\n  hasPredicates: boolean,\n  tokenMatcher: TokenMatcher,\n  dynamicTokensEnabled: boolean,\n): (orAlts: IOrAlt<any>[]) => number | undefined {\n  const numOfAlts = alts.length;\n  const areAllOneTokenLookahead = every(alts, (currAlt) => {\n    return every(currAlt, (currPath) => {\n      return currPath.length === 1;\n    });\n  });\n\n  // This version takes into account the predicates as well.\n  if (hasPredicates) {\n    /**\n     * @returns {number} - The chosen alternative index\n     */\n    return function (\n      this: BaseParser,\n      orAlts: IOrAlt<any>[],\n    ): number | undefined {\n      // unfortunately the predicates must be extracted every single time\n      // as they cannot be cached due to references to parameters(vars) which are no longer valid.\n      // note that in the common case of no predicates, no cpu time will be wasted on this (see else block)\n      const predicates: (Predicate | undefined)[] = map(\n        orAlts,\n        (currAlt) => currAlt.GATE,\n      );\n\n      for (let t = 0; t < numOfAlts; t++) {\n        const currAlt = alts[t];\n        const currNumOfPaths = currAlt.length;\n\n        const currPredicate = predicates[t];\n        if (currPredicate !== undefined && currPredicate.call(this) === false) {\n          // if the predicate does not match there is no point in checking the paths\n          continue;\n        }\n        nextPath: for (let j = 0; j < currNumOfPaths; j++) {\n          const currPath = currAlt[j];\n          const currPathLength = currPath.length;\n          for (let i = 0; i < currPathLength; i++) {\n            const nextToken = this.LA(i + 1);\n            if (tokenMatcher(nextToken, currPath[i]) === false) {\n              // mismatch in current path\n              // try the next pth\n              continue nextPath;\n            }\n          }\n          // found a full path that matches.\n          // this will also work for an empty ALT as the loop will be skipped\n          return t;\n        }\n        // none of the paths for the current alternative matched\n        // try the next alternative\n      }\n      // none of the alternatives could be matched\n      return undefined;\n    };\n  } else if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n    // optimized (common) case of all the lookaheads paths requiring only\n    // a single token lookahead. These Optimizations cannot work if dynamically defined Tokens are used.\n    const singleTokenAlts = map(alts, (currAlt) => {\n      return flatten(currAlt);\n    });\n\n    const choiceToAlt = reduce(\n      singleTokenAlts,\n      (result, currAlt, idx) => {\n        forEach(currAlt, (currTokType) => {\n          if (!has(result, currTokType.tokenTypeIdx!)) {\n            result[currTokType.tokenTypeIdx!] = idx;\n          }\n          forEach(currTokType.categoryMatches!, (currExtendingType) => {\n            if (!has(result, currExtendingType)) {\n              result[currExtendingType] = idx;\n            }\n          });\n        });\n        return result;\n      },\n      {} as Record<number, number>,\n    );\n\n    /**\n     * @returns {number} - The chosen alternative index\n     */\n    return function (this: BaseParser): number {\n      const nextToken = this.LA(1);\n      return choiceToAlt[nextToken.tokenTypeIdx];\n    };\n  } else {\n    // optimized lookahead without needing to check the predicates at all.\n    // this causes code duplication which is intentional to improve performance.\n    /**\n     * @returns {number} - The chosen alternative index\n     */\n    return function (this: BaseParser): number | undefined {\n      for (let t = 0; t < numOfAlts; t++) {\n        const currAlt = alts[t];\n        const currNumOfPaths = currAlt.length;\n        nextPath: for (let j = 0; j < currNumOfPaths; j++) {\n          const currPath = currAlt[j];\n          const currPathLength = currPath.length;\n          for (let i = 0; i < currPathLength; i++) {\n            const nextToken = this.LA(i + 1);\n            if (tokenMatcher(nextToken, currPath[i]) === false) {\n              // mismatch in current path\n              // try the next pth\n              continue nextPath;\n            }\n          }\n          // found a full path that matches.\n          // this will also work for an empty ALT as the loop will be skipped\n          return t;\n        }\n        // none of the paths for the current alternative matched\n        // try the next alternative\n      }\n      // none of the alternatives could be matched\n      return undefined;\n    };\n  }\n}\n\nexport function buildSingleAlternativeLookaheadFunction(\n  alt: LookaheadSequence,\n  tokenMatcher: TokenMatcher,\n  dynamicTokensEnabled: boolean,\n): () => boolean {\n  const areAllOneTokenLookahead = every(alt, (currPath) => {\n    return currPath.length === 1;\n  });\n\n  const numOfPaths = alt.length;\n\n  // optimized (common) case of all the lookaheads paths requiring only\n  // a single token lookahead.\n  if (areAllOneTokenLookahead && !dynamicTokensEnabled) {\n    const singleTokensTypes = flatten(alt);\n\n    if (\n      singleTokensTypes.length === 1 &&\n      isEmpty((<any>singleTokensTypes[0]).categoryMatches)\n    ) {\n      const expectedTokenType = singleTokensTypes[0];\n      const expectedTokenUniqueKey = (<any>expectedTokenType).tokenTypeIdx;\n\n      return function (this: BaseParser): boolean {\n        return this.LA(1).tokenTypeIdx === expectedTokenUniqueKey;\n      };\n    } else {\n      const choiceToAlt = reduce(\n        singleTokensTypes,\n        (result, currTokType, idx) => {\n          result[currTokType.tokenTypeIdx!] = true;\n          forEach(currTokType.categoryMatches!, (currExtendingType) => {\n            result[currExtendingType] = true;\n          });\n          return result;\n        },\n        [] as boolean[],\n      );\n\n      return function (this: BaseParser): boolean {\n        const nextToken = this.LA(1);\n        return choiceToAlt[nextToken.tokenTypeIdx] === true;\n      };\n    }\n  } else {\n    return function (this: BaseParser): boolean {\n      nextPath: for (let j = 0; j < numOfPaths; j++) {\n        const currPath = alt[j];\n        const currPathLength = currPath.length;\n        for (let i = 0; i < currPathLength; i++) {\n          const nextToken = this.LA(i + 1);\n          if (tokenMatcher(nextToken, currPath[i]) === false) {\n            // mismatch in current path\n            // try the next pth\n            continue nextPath;\n          }\n        }\n        // found a full path that matches.\n        return true;\n      }\n\n      // none of the paths matched\n      return false;\n    };\n  }\n}\n\nclass RestDefinitionFinderWalker extends RestWalker {\n  private restDef: IProduction[];\n\n  constructor(\n    private topProd: Rule,\n    private targetOccurrence: number,\n    private targetProdType: PROD_TYPE,\n  ) {\n    super();\n  }\n\n  startWalking(): IProduction[] {\n    this.walk(this.topProd);\n    return this.restDef;\n  }\n\n  private checkIsTarget(\n    node: IProductionWithOccurrence,\n    expectedProdType: PROD_TYPE,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): boolean {\n    if (\n      node.idx === this.targetOccurrence &&\n      this.targetProdType === expectedProdType\n    ) {\n      this.restDef = currRest.concat(prevRest);\n      return true;\n    }\n    // performance optimization, do not iterate over the entire Grammar ast after we have found the target\n    return false;\n  }\n\n  walkOption(\n    optionProd: Option,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (!this.checkIsTarget(optionProd, PROD_TYPE.OPTION, currRest, prevRest)) {\n      super.walkOption(optionProd, currRest, prevRest);\n    }\n  }\n\n  walkAtLeastOne(\n    atLeastOneProd: RepetitionMandatory,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      !this.checkIsTarget(\n        atLeastOneProd,\n        PROD_TYPE.REPETITION_MANDATORY,\n        currRest,\n        prevRest,\n      )\n    ) {\n      super.walkOption(atLeastOneProd, currRest, prevRest);\n    }\n  }\n\n  walkAtLeastOneSep(\n    atLeastOneSepProd: RepetitionMandatoryWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      !this.checkIsTarget(\n        atLeastOneSepProd,\n        PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR,\n        currRest,\n        prevRest,\n      )\n    ) {\n      super.walkOption(atLeastOneSepProd, currRest, prevRest);\n    }\n  }\n\n  walkMany(\n    manyProd: Repetition,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      !this.checkIsTarget(manyProd, PROD_TYPE.REPETITION, currRest, prevRest)\n    ) {\n      super.walkOption(manyProd, currRest, prevRest);\n    }\n  }\n\n  walkManySep(\n    manySepProd: RepetitionWithSeparator,\n    currRest: IProduction[],\n    prevRest: IProduction[],\n  ): void {\n    if (\n      !this.checkIsTarget(\n        manySepProd,\n        PROD_TYPE.REPETITION_WITH_SEPARATOR,\n        currRest,\n        prevRest,\n      )\n    ) {\n      super.walkOption(manySepProd, currRest, prevRest);\n    }\n  }\n}\n\n/**\n * Returns the definition of a target production in a top level level rule.\n */\nclass InsideDefinitionFinderVisitor extends GAstVisitor {\n  public result: IProduction[] = [];\n\n  constructor(\n    private targetOccurrence: number,\n    private targetProdType: PROD_TYPE,\n    private targetRef?: any,\n  ) {\n    super();\n  }\n\n  private checkIsTarget(\n    node: { definition: IProduction[] } & IProductionWithOccurrence,\n    expectedProdName: PROD_TYPE,\n  ): void {\n    if (\n      node.idx === this.targetOccurrence &&\n      this.targetProdType === expectedProdName &&\n      (this.targetRef === undefined || node === this.targetRef)\n    ) {\n      this.result = node.definition;\n    }\n  }\n\n  public visitOption(node: Option): void {\n    this.checkIsTarget(node, PROD_TYPE.OPTION);\n  }\n\n  public visitRepetition(node: Repetition): void {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION);\n  }\n\n  public visitRepetitionMandatory(node: RepetitionMandatory): void {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY);\n  }\n\n  public visitRepetitionMandatoryWithSeparator(\n    node: RepetitionMandatoryWithSeparator,\n  ): void {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR);\n  }\n\n  public visitRepetitionWithSeparator(node: RepetitionWithSeparator): void {\n    this.checkIsTarget(node, PROD_TYPE.REPETITION_WITH_SEPARATOR);\n  }\n\n  public visitAlternation(node: Alternation): void {\n    this.checkIsTarget(node, PROD_TYPE.ALTERNATION);\n  }\n}\n\nfunction initializeArrayOfArrays(size: number): any[][] {\n  const result = new Array(size);\n  for (let i = 0; i < size; i++) {\n    result[i] = [];\n  }\n  return result;\n}\n\n/**\n * A sort of hash function between a Path in the grammar and a string.\n * Note that this returns multiple \"hashes\" to support the scenario of token categories.\n * -  A single path with categories may match multiple **actual** paths.\n */\nfunction pathToHashKeys(path: TokenType[]): string[] {\n  let keys = [\"\"];\n  for (let i = 0; i < path.length; i++) {\n    const tokType = path[i];\n    const longerKeys = [];\n    for (let j = 0; j < keys.length; j++) {\n      const currShorterKey = keys[j];\n      longerKeys.push(currShorterKey + \"_\" + tokType.tokenTypeIdx);\n      for (let t = 0; t < tokType.categoryMatches!.length; t++) {\n        const categoriesKeySuffix = \"_\" + tokType.categoryMatches![t];\n        longerKeys.push(currShorterKey + categoriesKeySuffix);\n      }\n    }\n    keys = longerKeys;\n  }\n  return keys;\n}\n\n/**\n * Imperative style due to being called from a hot spot\n */\nfunction isUniquePrefixHash(\n  altKnownPathsKeys: Record<string, boolean>[],\n  searchPathKeys: string[],\n  idx: number,\n): boolean {\n  for (\n    let currAltIdx = 0;\n    currAltIdx < altKnownPathsKeys.length;\n    currAltIdx++\n  ) {\n    // We only want to test vs the other alternatives\n    if (currAltIdx === idx) {\n      continue;\n    }\n    const otherAltKnownPathsKeys = altKnownPathsKeys[currAltIdx];\n    for (let searchIdx = 0; searchIdx < searchPathKeys.length; searchIdx++) {\n      const searchKey = searchPathKeys[searchIdx];\n      if (otherAltKnownPathsKeys[searchKey] === true) {\n        return false;\n      }\n    }\n  }\n  // None of the SearchPathKeys were found in any of the other alternatives\n  return true;\n}\n\nexport function lookAheadSequenceFromAlternatives(\n  altsDefs: IProduction[],\n  k: number,\n): LookaheadSequence[] {\n  const partialAlts = map(altsDefs, (currAlt) =>\n    possiblePathsFrom([currAlt], 1),\n  );\n  const finalResult = initializeArrayOfArrays(partialAlts.length);\n  const altsHashes = map(partialAlts, (currAltPaths) => {\n    const dict: { [key: string]: boolean } = {};\n    forEach(currAltPaths, (item) => {\n      const keys = pathToHashKeys(item.partialPath);\n      forEach(keys, (currKey) => {\n        dict[currKey] = true;\n      });\n    });\n    return dict;\n  });\n  let newData = partialAlts;\n\n  // maxLookahead loop\n  for (let pathLength = 1; pathLength <= k; pathLength++) {\n    const currDataset = newData;\n    newData = initializeArrayOfArrays(currDataset.length);\n\n    // alternatives loop\n    for (let altIdx = 0; altIdx < currDataset.length; altIdx++) {\n      const currAltPathsAndSuffixes = currDataset[altIdx];\n      // paths in current alternative loop\n      for (\n        let currPathIdx = 0;\n        currPathIdx < currAltPathsAndSuffixes.length;\n        currPathIdx++\n      ) {\n        const currPathPrefix = currAltPathsAndSuffixes[currPathIdx].partialPath;\n        const suffixDef = currAltPathsAndSuffixes[currPathIdx].suffixDef;\n        const prefixKeys = pathToHashKeys(currPathPrefix);\n        const isUnique = isUniquePrefixHash(altsHashes, prefixKeys, altIdx);\n        // End of the line for this path.\n        if (isUnique || isEmpty(suffixDef) || currPathPrefix.length === k) {\n          const currAltResult = finalResult[altIdx];\n          // TODO: Can we implement a containsPath using Maps/Dictionaries?\n          if (containsPath(currAltResult, currPathPrefix) === false) {\n            currAltResult.push(currPathPrefix);\n            // Update all new  keys for the current path.\n            for (let j = 0; j < prefixKeys.length; j++) {\n              const currKey = prefixKeys[j];\n              altsHashes[altIdx][currKey] = true;\n            }\n          }\n        }\n        // Expand longer paths\n        else {\n          const newPartialPathsAndSuffixes = possiblePathsFrom(\n            suffixDef,\n            pathLength + 1,\n            currPathPrefix,\n          );\n          newData[altIdx] = newData[altIdx].concat(newPartialPathsAndSuffixes);\n\n          // Update keys for new known paths\n          forEach(newPartialPathsAndSuffixes, (item) => {\n            const prefixKeys = pathToHashKeys(item.partialPath);\n            forEach(prefixKeys, (key) => {\n              altsHashes[altIdx][key] = true;\n            });\n          });\n        }\n      }\n    }\n  }\n\n  return finalResult;\n}\n\nexport function getLookaheadPathsForOr(\n  occurrence: number,\n  ruleGrammar: Rule,\n  k: number,\n  orProd?: Alternation,\n): LookaheadSequence[] {\n  const visitor = new InsideDefinitionFinderVisitor(\n    occurrence,\n    PROD_TYPE.ALTERNATION,\n    orProd,\n  );\n  ruleGrammar.accept(visitor);\n  return lookAheadSequenceFromAlternatives(visitor.result, k);\n}\n\nexport function getLookaheadPathsForOptionalProd(\n  occurrence: number,\n  ruleGrammar: Rule,\n  prodType: PROD_TYPE,\n  k: number,\n): LookaheadSequence[] {\n  const insideDefVisitor = new InsideDefinitionFinderVisitor(\n    occurrence,\n    prodType,\n  );\n  ruleGrammar.accept(insideDefVisitor);\n  const insideDef = insideDefVisitor.result;\n\n  const afterDefWalker = new RestDefinitionFinderWalker(\n    ruleGrammar,\n    occurrence,\n    prodType,\n  );\n  const afterDef = afterDefWalker.startWalking();\n\n  const insideFlat = new AlternativeGAST({ definition: insideDef });\n  const afterFlat = new AlternativeGAST({ definition: afterDef });\n\n  return lookAheadSequenceFromAlternatives([insideFlat, afterFlat], k);\n}\n\nexport function containsPath(\n  alternative: Alternative,\n  searchPath: TokenType[],\n): boolean {\n  compareOtherPath: for (let i = 0; i < alternative.length; i++) {\n    const otherPath = alternative[i];\n    if (otherPath.length !== searchPath.length) {\n      continue;\n    }\n    for (let j = 0; j < otherPath.length; j++) {\n      const searchTok = searchPath[j];\n      const otherTok = otherPath[j];\n\n      const matchingTokens =\n        searchTok === otherTok ||\n        otherTok.categoryMatchesMap![searchTok.tokenTypeIdx!] !== undefined;\n      if (matchingTokens === false) {\n        continue compareOtherPath;\n      }\n    }\n    return true;\n  }\n\n  return false;\n}\n\nexport function isStrictPrefixOfPath(\n  prefix: TokenType[],\n  other: TokenType[],\n): boolean {\n  return (\n    prefix.length < other.length &&\n    every(prefix, (tokType, idx) => {\n      const otherTokType = other[idx];\n      return (\n        tokType === otherTokType ||\n        otherTokType.categoryMatchesMap![tokType.tokenTypeIdx!]\n      );\n    })\n  );\n}\n\nexport function areTokenCategoriesNotUsed(\n  lookAheadPaths: LookaheadSequence[],\n): boolean {\n  return every(lookAheadPaths, (singleAltPaths) =>\n    every(singleAltPaths, (singlePath) =>\n      every(singlePath, (token) => isEmpty(token.categoryMatches!)),\n    ),\n  );\n}\n","import {\n  clone,\n  compact,\n  difference,\n  drop,\n  dropRight,\n  filter,\n  first,\n  flatMap,\n  flatten,\n  forEach,\n  groupBy,\n  includes,\n  isEmpty,\n  map,\n  pickBy,\n  reduce,\n  reject,\n  values,\n} from \"lodash-es\";\nimport {\n  IParserAmbiguousAlternativesDefinitionError,\n  IParserDuplicatesDefinitionError,\n  IParserEmptyAlternativeDefinitionError,\n  ParserDefinitionErrorType,\n} from \"../parser/parser.js\";\nimport {\n  Alternation,\n  Alternative as AlternativeGAST,\n  GAstVisitor,\n  getProductionDslName,\n  isOptionalProd,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport {\n  Alternative,\n  containsPath,\n  getLookaheadPathsForOptionalProd,\n  getLookaheadPathsForOr,\n  getProdType,\n  isStrictPrefixOfPath,\n} from \"./lookahead.js\";\nimport { nextPossibleTokensAfter } from \"./interpreter.js\";\nimport {\n  ILookaheadStrategy,\n  IProduction,\n  IProductionWithOccurrence,\n  Rule,\n  TokenType,\n} from \"@chevrotain/types\";\nimport {\n  IGrammarValidatorErrorMessageProvider,\n  IParserDefinitionError,\n} from \"./types.js\";\nimport { tokenStructuredMatcher } from \"../../scan/tokens.js\";\n\nexport function validateLookahead(options: {\n  lookaheadStrategy: ILookaheadStrategy;\n  rules: Rule[];\n  tokenTypes: TokenType[];\n  grammarName: string;\n}): IParserDefinitionError[] {\n  const lookaheadValidationErrorMessages = options.lookaheadStrategy.validate({\n    rules: options.rules,\n    tokenTypes: options.tokenTypes,\n    grammarName: options.grammarName,\n  });\n  return map(lookaheadValidationErrorMessages, (errorMessage) => ({\n    type: ParserDefinitionErrorType.CUSTOM_LOOKAHEAD_VALIDATION,\n    ...errorMessage,\n  }));\n}\n\nexport function validateGrammar(\n  topLevels: Rule[],\n  tokenTypes: TokenType[],\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n  grammarName: string,\n): IParserDefinitionError[] {\n  const duplicateErrors: IParserDefinitionError[] = flatMap(\n    topLevels,\n    (currTopLevel) =>\n      validateDuplicateProductions(currTopLevel, errMsgProvider),\n  );\n\n  const termsNamespaceConflictErrors = checkTerminalAndNoneTerminalsNameSpace(\n    topLevels,\n    tokenTypes,\n    errMsgProvider,\n  );\n\n  const tooManyAltsErrors = flatMap(topLevels, (curRule) =>\n    validateTooManyAlts(curRule, errMsgProvider),\n  );\n\n  const duplicateRulesError = flatMap(topLevels, (curRule) =>\n    validateRuleDoesNotAlreadyExist(\n      curRule,\n      topLevels,\n      grammarName,\n      errMsgProvider,\n    ),\n  );\n\n  return duplicateErrors.concat(\n    termsNamespaceConflictErrors,\n    tooManyAltsErrors,\n    duplicateRulesError,\n  );\n}\n\nfunction validateDuplicateProductions(\n  topLevelRule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDuplicatesDefinitionError[] {\n  const collectorVisitor = new OccurrenceValidationCollector();\n  topLevelRule.accept(collectorVisitor);\n  const allRuleProductions = collectorVisitor.allProductions;\n\n  const productionGroups = groupBy(\n    allRuleProductions,\n    identifyProductionForDuplicates,\n  );\n\n  const duplicates: any = pickBy(productionGroups, (currGroup) => {\n    return currGroup.length > 1;\n  });\n\n  const errors = map(values(duplicates), (currDuplicates: any) => {\n    const firstProd: any = first(currDuplicates);\n    const msg = errMsgProvider.buildDuplicateFoundError(\n      topLevelRule,\n      currDuplicates,\n    );\n    const dslName = getProductionDslName(firstProd);\n    const defError: IParserDuplicatesDefinitionError = {\n      message: msg,\n      type: ParserDefinitionErrorType.DUPLICATE_PRODUCTIONS,\n      ruleName: topLevelRule.name,\n      dslName: dslName,\n      occurrence: firstProd.idx,\n    };\n\n    const param = getExtraProductionArgument(firstProd);\n    if (param) {\n      defError.parameter = param;\n    }\n\n    return defError;\n  });\n  return errors;\n}\n\nexport function identifyProductionForDuplicates(\n  prod: IProductionWithOccurrence,\n): string {\n  return `${getProductionDslName(prod)}_#_${\n    prod.idx\n  }_#_${getExtraProductionArgument(prod)}`;\n}\n\nfunction getExtraProductionArgument(prod: IProductionWithOccurrence): string {\n  if (prod instanceof Terminal) {\n    return prod.terminalType.name;\n  } else if (prod instanceof NonTerminal) {\n    return prod.nonTerminalName;\n  } else {\n    return \"\";\n  }\n}\n\nexport class OccurrenceValidationCollector extends GAstVisitor {\n  public allProductions: IProductionWithOccurrence[] = [];\n\n  public visitNonTerminal(subrule: NonTerminal): void {\n    this.allProductions.push(subrule);\n  }\n\n  public visitOption(option: Option): void {\n    this.allProductions.push(option);\n  }\n\n  public visitRepetitionWithSeparator(manySep: RepetitionWithSeparator): void {\n    this.allProductions.push(manySep);\n  }\n\n  public visitRepetitionMandatory(atLeastOne: RepetitionMandatory): void {\n    this.allProductions.push(atLeastOne);\n  }\n\n  public visitRepetitionMandatoryWithSeparator(\n    atLeastOneSep: RepetitionMandatoryWithSeparator,\n  ): void {\n    this.allProductions.push(atLeastOneSep);\n  }\n\n  public visitRepetition(many: Repetition): void {\n    this.allProductions.push(many);\n  }\n\n  public visitAlternation(or: Alternation): void {\n    this.allProductions.push(or);\n  }\n\n  public visitTerminal(terminal: Terminal): void {\n    this.allProductions.push(terminal);\n  }\n}\n\nexport function validateRuleDoesNotAlreadyExist(\n  rule: Rule,\n  allRules: Rule[],\n  className: string,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDefinitionError[] {\n  const errors = [];\n  const occurrences = reduce(\n    allRules,\n    (result, curRule) => {\n      if (curRule.name === rule.name) {\n        return result + 1;\n      }\n      return result;\n    },\n    0,\n  );\n  if (occurrences > 1) {\n    const errMsg = errMsgProvider.buildDuplicateRuleNameError({\n      topLevelRule: rule,\n      grammarName: className,\n    });\n    errors.push({\n      message: errMsg,\n      type: ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n      ruleName: rule.name,\n    });\n  }\n\n  return errors;\n}\n\n// TODO: is there anyway to get only the rule names of rules inherited from the super grammars?\n// This is not part of the IGrammarErrorProvider because the validation cannot be performed on\n// The grammar structure, only at runtime.\nexport function validateRuleIsOverridden(\n  ruleName: string,\n  definedRulesNames: string[],\n  className: string,\n): IParserDefinitionError[] {\n  const errors = [];\n  let errMsg;\n\n  if (!includes(definedRulesNames, ruleName)) {\n    errMsg =\n      `Invalid rule override, rule: ->${ruleName}<- cannot be overridden in the grammar: ->${className}<-` +\n      `as it is not defined in any of the super grammars `;\n    errors.push({\n      message: errMsg,\n      type: ParserDefinitionErrorType.INVALID_RULE_OVERRIDE,\n      ruleName: ruleName,\n    });\n  }\n\n  return errors;\n}\n\nexport function validateNoLeftRecursion(\n  topRule: Rule,\n  currRule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n  path: Rule[] = [],\n): IParserDefinitionError[] {\n  const errors: IParserDefinitionError[] = [];\n  const nextNonTerminals = getFirstNoneTerminal(currRule.definition);\n  if (isEmpty(nextNonTerminals)) {\n    return [];\n  } else {\n    const ruleName = topRule.name;\n    const foundLeftRecursion = includes(nextNonTerminals, topRule);\n    if (foundLeftRecursion) {\n      errors.push({\n        message: errMsgProvider.buildLeftRecursionError({\n          topLevelRule: topRule,\n          leftRecursionPath: path,\n        }),\n        type: ParserDefinitionErrorType.LEFT_RECURSION,\n        ruleName: ruleName,\n      });\n    }\n\n    // we are only looking for cyclic paths leading back to the specific topRule\n    // other cyclic paths are ignored, we still need this difference to avoid infinite loops...\n    const validNextSteps = difference(nextNonTerminals, path.concat([topRule]));\n    const errorsFromNextSteps = flatMap(validNextSteps, (currRefRule) => {\n      const newPath = clone(path);\n      newPath.push(currRefRule);\n      return validateNoLeftRecursion(\n        topRule,\n        currRefRule,\n        errMsgProvider,\n        newPath,\n      );\n    });\n\n    return errors.concat(errorsFromNextSteps);\n  }\n}\n\nexport function getFirstNoneTerminal(definition: IProduction[]): Rule[] {\n  let result: Rule[] = [];\n  if (isEmpty(definition)) {\n    return result;\n  }\n  const firstProd = first(definition);\n\n  /* istanbul ignore else */\n  if (firstProd instanceof NonTerminal) {\n    result.push(firstProd.referencedRule);\n  } else if (\n    firstProd instanceof AlternativeGAST ||\n    firstProd instanceof Option ||\n    firstProd instanceof RepetitionMandatory ||\n    firstProd instanceof RepetitionMandatoryWithSeparator ||\n    firstProd instanceof RepetitionWithSeparator ||\n    firstProd instanceof Repetition\n  ) {\n    result = result.concat(\n      getFirstNoneTerminal(<IProduction[]>firstProd.definition),\n    );\n  } else if (firstProd instanceof Alternation) {\n    // each sub definition in alternation is a FLAT\n    result = flatten(\n      map(firstProd.definition, (currSubDef) =>\n        getFirstNoneTerminal((<AlternativeGAST>currSubDef).definition),\n      ),\n    );\n  } else if (firstProd instanceof Terminal) {\n    // nothing to see, move along\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n\n  const isFirstOptional = isOptionalProd(firstProd);\n  const hasMore = definition.length > 1;\n  if (isFirstOptional && hasMore) {\n    const rest = drop(definition);\n    return result.concat(getFirstNoneTerminal(rest));\n  } else {\n    return result;\n  }\n}\n\nclass OrCollector extends GAstVisitor {\n  public alternations: Alternation[] = [];\n\n  public visitAlternation(node: Alternation): void {\n    this.alternations.push(node);\n  }\n}\n\nexport function validateEmptyOrAlternative(\n  topLevelRule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserEmptyAlternativeDefinitionError[] {\n  const orCollector = new OrCollector();\n  topLevelRule.accept(orCollector);\n  const ors = orCollector.alternations;\n\n  const errors = flatMap<Alternation, IParserEmptyAlternativeDefinitionError>(\n    ors,\n    (currOr) => {\n      const exceptLast = dropRight(currOr.definition);\n      return flatMap(exceptLast, (currAlternative, currAltIdx) => {\n        const possibleFirstInAlt = nextPossibleTokensAfter(\n          [currAlternative],\n          [],\n          tokenStructuredMatcher,\n          1,\n        );\n        if (isEmpty(possibleFirstInAlt)) {\n          return [\n            {\n              message: errMsgProvider.buildEmptyAlternationError({\n                topLevelRule: topLevelRule,\n                alternation: currOr,\n                emptyChoiceIdx: currAltIdx,\n              }),\n              type: ParserDefinitionErrorType.NONE_LAST_EMPTY_ALT,\n              ruleName: topLevelRule.name,\n              occurrence: currOr.idx,\n              alternative: currAltIdx + 1,\n            },\n          ];\n        } else {\n          return [];\n        }\n      });\n    },\n  );\n\n  return errors;\n}\n\nexport function validateAmbiguousAlternationAlternatives(\n  topLevelRule: Rule,\n  globalMaxLookahead: number,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserAmbiguousAlternativesDefinitionError[] {\n  const orCollector = new OrCollector();\n  topLevelRule.accept(orCollector);\n  let ors = orCollector.alternations;\n\n  // New Handling of ignoring ambiguities\n  // - https://github.com/chevrotain/chevrotain/issues/869\n  ors = reject(ors, (currOr) => currOr.ignoreAmbiguities === true);\n\n  const errors = flatMap(ors, (currOr: Alternation) => {\n    const currOccurrence = currOr.idx;\n    const actualMaxLookahead = currOr.maxLookahead || globalMaxLookahead;\n    const alternatives = getLookaheadPathsForOr(\n      currOccurrence,\n      topLevelRule,\n      actualMaxLookahead,\n      currOr,\n    );\n    const altsAmbiguityErrors = checkAlternativesAmbiguities(\n      alternatives,\n      currOr,\n      topLevelRule,\n      errMsgProvider,\n    );\n    const altsPrefixAmbiguityErrors = checkPrefixAlternativesAmbiguities(\n      alternatives,\n      currOr,\n      topLevelRule,\n      errMsgProvider,\n    );\n\n    return altsAmbiguityErrors.concat(altsPrefixAmbiguityErrors);\n  });\n\n  return errors;\n}\n\nexport class RepetitionCollector extends GAstVisitor {\n  public allProductions: (IProductionWithOccurrence & {\n    maxLookahead?: number;\n  })[] = [];\n\n  public visitRepetitionWithSeparator(manySep: RepetitionWithSeparator): void {\n    this.allProductions.push(manySep);\n  }\n\n  public visitRepetitionMandatory(atLeastOne: RepetitionMandatory): void {\n    this.allProductions.push(atLeastOne);\n  }\n\n  public visitRepetitionMandatoryWithSeparator(\n    atLeastOneSep: RepetitionMandatoryWithSeparator,\n  ): void {\n    this.allProductions.push(atLeastOneSep);\n  }\n\n  public visitRepetition(many: Repetition): void {\n    this.allProductions.push(many);\n  }\n}\n\nexport function validateTooManyAlts(\n  topLevelRule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDefinitionError[] {\n  const orCollector = new OrCollector();\n  topLevelRule.accept(orCollector);\n  const ors = orCollector.alternations;\n\n  const errors = flatMap(ors, (currOr) => {\n    if (currOr.definition.length > 255) {\n      return [\n        {\n          message: errMsgProvider.buildTooManyAlternativesError({\n            topLevelRule: topLevelRule,\n            alternation: currOr,\n          }),\n          type: ParserDefinitionErrorType.TOO_MANY_ALTS,\n          ruleName: topLevelRule.name,\n          occurrence: currOr.idx,\n        },\n      ];\n    } else {\n      return [];\n    }\n  });\n\n  return errors;\n}\n\nexport function validateSomeNonEmptyLookaheadPath(\n  topLevelRules: Rule[],\n  maxLookahead: number,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDefinitionError[] {\n  const errors: IParserDefinitionError[] = [];\n  forEach(topLevelRules, (currTopRule) => {\n    const collectorVisitor = new RepetitionCollector();\n    currTopRule.accept(collectorVisitor);\n    const allRuleProductions = collectorVisitor.allProductions;\n    forEach(allRuleProductions, (currProd) => {\n      const prodType = getProdType(currProd);\n      const actualMaxLookahead = currProd.maxLookahead || maxLookahead;\n      const currOccurrence = currProd.idx;\n      const paths = getLookaheadPathsForOptionalProd(\n        currOccurrence,\n        currTopRule,\n        prodType,\n        actualMaxLookahead,\n      );\n      const pathsInsideProduction = paths[0];\n      if (isEmpty(flatten(pathsInsideProduction))) {\n        const errMsg = errMsgProvider.buildEmptyRepetitionError({\n          topLevelRule: currTopRule,\n          repetition: currProd,\n        });\n        errors.push({\n          message: errMsg,\n          type: ParserDefinitionErrorType.NO_NON_EMPTY_LOOKAHEAD,\n          ruleName: currTopRule.name,\n        });\n      }\n    });\n  });\n\n  return errors;\n}\n\nexport interface IAmbiguityDescriptor {\n  alts: number[];\n  path: TokenType[];\n}\n\nfunction checkAlternativesAmbiguities(\n  alternatives: Alternative[],\n  alternation: Alternation,\n  rule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserAmbiguousAlternativesDefinitionError[] {\n  const foundAmbiguousPaths: Alternative = [];\n  const identicalAmbiguities = reduce(\n    alternatives,\n    (result, currAlt, currAltIdx) => {\n      // ignore (skip) ambiguities with this alternative\n      if (alternation.definition[currAltIdx].ignoreAmbiguities === true) {\n        return result;\n      }\n\n      forEach(currAlt, (currPath) => {\n        const altsCurrPathAppearsIn = [currAltIdx];\n        forEach(alternatives, (currOtherAlt, currOtherAltIdx) => {\n          if (\n            currAltIdx !== currOtherAltIdx &&\n            containsPath(currOtherAlt, currPath) &&\n            // ignore (skip) ambiguities with this \"other\" alternative\n            alternation.definition[currOtherAltIdx].ignoreAmbiguities !== true\n          ) {\n            altsCurrPathAppearsIn.push(currOtherAltIdx);\n          }\n        });\n\n        if (\n          altsCurrPathAppearsIn.length > 1 &&\n          !containsPath(foundAmbiguousPaths, currPath)\n        ) {\n          foundAmbiguousPaths.push(currPath);\n          result.push({\n            alts: altsCurrPathAppearsIn,\n            path: currPath,\n          });\n        }\n      });\n      return result;\n    },\n    [] as { alts: number[]; path: TokenType[] }[],\n  );\n\n  const currErrors = map(identicalAmbiguities, (currAmbDescriptor) => {\n    const ambgIndices = map(\n      currAmbDescriptor.alts,\n      (currAltIdx) => currAltIdx + 1,\n    );\n\n    const currMessage = errMsgProvider.buildAlternationAmbiguityError({\n      topLevelRule: rule,\n      alternation: alternation,\n      ambiguityIndices: ambgIndices,\n      prefixPath: currAmbDescriptor.path,\n    });\n\n    return {\n      message: currMessage,\n      type: ParserDefinitionErrorType.AMBIGUOUS_ALTS,\n      ruleName: rule.name,\n      occurrence: alternation.idx,\n      alternatives: currAmbDescriptor.alts,\n    };\n  });\n\n  return currErrors;\n}\n\nexport function checkPrefixAlternativesAmbiguities(\n  alternatives: Alternative[],\n  alternation: Alternation,\n  rule: Rule,\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserAmbiguousAlternativesDefinitionError[] {\n  // flatten\n  const pathsAndIndices = reduce(\n    alternatives,\n    (result, currAlt, idx) => {\n      const currPathsAndIdx = map(currAlt, (currPath) => {\n        return { idx: idx, path: currPath };\n      });\n      return result.concat(currPathsAndIdx);\n    },\n    [] as { idx: number; path: TokenType[] }[],\n  );\n\n  const errors = compact(\n    flatMap(pathsAndIndices, (currPathAndIdx) => {\n      const alternativeGast = alternation.definition[currPathAndIdx.idx];\n      // ignore (skip) ambiguities with this alternative\n      if (alternativeGast.ignoreAmbiguities === true) {\n        return [];\n      }\n      const targetIdx = currPathAndIdx.idx;\n      const targetPath = currPathAndIdx.path;\n\n      const prefixAmbiguitiesPathsAndIndices = filter(\n        pathsAndIndices,\n        (searchPathAndIdx) => {\n          // prefix ambiguity can only be created from lower idx (higher priority) path\n          return (\n            // ignore (skip) ambiguities with this \"other\" alternative\n            alternation.definition[searchPathAndIdx.idx].ignoreAmbiguities !==\n              true &&\n            searchPathAndIdx.idx < targetIdx &&\n            // checking for strict prefix because identical lookaheads\n            // will be be detected using a different validation.\n            isStrictPrefixOfPath(searchPathAndIdx.path, targetPath)\n          );\n        },\n      );\n\n      const currPathPrefixErrors = map(\n        prefixAmbiguitiesPathsAndIndices,\n        (currAmbPathAndIdx): IParserAmbiguousAlternativesDefinitionError => {\n          const ambgIndices = [currAmbPathAndIdx.idx + 1, targetIdx + 1];\n          const occurrence = alternation.idx === 0 ? \"\" : alternation.idx;\n\n          const message = errMsgProvider.buildAlternationPrefixAmbiguityError({\n            topLevelRule: rule,\n            alternation: alternation,\n            ambiguityIndices: ambgIndices,\n            prefixPath: currAmbPathAndIdx.path,\n          });\n          return {\n            message: message,\n            type: ParserDefinitionErrorType.AMBIGUOUS_PREFIX_ALTS,\n            ruleName: rule.name,\n            occurrence: occurrence,\n            alternatives: ambgIndices,\n          };\n        },\n      );\n\n      return currPathPrefixErrors;\n    }),\n  );\n\n  return errors;\n}\n\nfunction checkTerminalAndNoneTerminalsNameSpace(\n  topLevels: Rule[],\n  tokenTypes: TokenType[],\n  errMsgProvider: IGrammarValidatorErrorMessageProvider,\n): IParserDefinitionError[] {\n  const errors: IParserDefinitionError[] = [];\n\n  const tokenNames = map(tokenTypes, (currToken) => currToken.name);\n\n  forEach(topLevels, (currRule) => {\n    const currRuleName = currRule.name;\n    if (includes(tokenNames, currRuleName)) {\n      const errMsg = errMsgProvider.buildNamespaceConflictError(currRule);\n\n      errors.push({\n        message: errMsg,\n        type: ParserDefinitionErrorType.CONFLICT_TOKENS_RULES_NAMESPACE,\n        ruleName: currRuleName,\n      });\n    }\n  });\n\n  return errors;\n}\n","import { Rule } from \"@chevrotain/gast\";\nimport { defaults, forEach } from \"lodash-es\";\nimport { resolveGrammar as orgResolveGrammar } from \"../resolver.js\";\nimport { validateGrammar as orgValidateGrammar } from \"../checks.js\";\nimport {\n  defaultGrammarResolverErrorProvider,\n  defaultGrammarValidatorErrorProvider,\n} from \"../../errors_public.js\";\nimport { TokenType } from \"@chevrotain/types\";\nimport {\n  IGrammarResolverErrorMessageProvider,\n  IGrammarValidatorErrorMessageProvider,\n  IParserDefinitionError,\n} from \"../types.js\";\n\ntype ResolveGrammarOpts = {\n  rules: Rule[];\n  errMsgProvider?: IGrammarResolverErrorMessageProvider;\n};\nexport function resolveGrammar(\n  options: ResolveGrammarOpts,\n): IParserDefinitionError[] {\n  const actualOptions: Required<ResolveGrammarOpts> = defaults(options, {\n    errMsgProvider: defaultGrammarResolverErrorProvider,\n  });\n\n  const topRulesTable: { [ruleName: string]: Rule } = {};\n  forEach(options.rules, (rule) => {\n    topRulesTable[rule.name] = rule;\n  });\n  return orgResolveGrammar(topRulesTable, actualOptions.errMsgProvider);\n}\n\nexport function validateGrammar(options: {\n  rules: Rule[];\n  tokenTypes: TokenType[];\n  grammarName: string;\n  errMsgProvider: IGrammarValidatorErrorMessageProvider;\n}): IParserDefinitionError[] {\n  options = defaults(options, {\n    errMsgProvider: defaultGrammarValidatorErrorProvider,\n  });\n\n  return orgValidateGrammar(\n    options.rules,\n    options.tokenTypes,\n    options.errMsgProvider,\n    options.grammarName,\n  );\n}\n","import { includes } from \"lodash-es\";\nimport {\n  IRecognitionException,\n  IRecognizerContext,\n  IToken,\n} from \"@chevrotain/types\";\n\nconst MISMATCHED_TOKEN_EXCEPTION = \"MismatchedTokenException\";\nconst NO_VIABLE_ALT_EXCEPTION = \"NoViableAltException\";\nconst EARLY_EXIT_EXCEPTION = \"EarlyExitException\";\nconst NOT_ALL_INPUT_PARSED_EXCEPTION = \"NotAllInputParsedException\";\n\nconst RECOGNITION_EXCEPTION_NAMES = [\n  MISMATCHED_TOKEN_EXCEPTION,\n  NO_VIABLE_ALT_EXCEPTION,\n  EARLY_EXIT_EXCEPTION,\n  NOT_ALL_INPUT_PARSED_EXCEPTION,\n];\n\nObject.freeze(RECOGNITION_EXCEPTION_NAMES);\n\n// hacks to bypass no support for custom Errors in javascript/typescript\nexport function isRecognitionException(error: Error) {\n  // can't do instanceof on hacked custom js exceptions\n  return includes(RECOGNITION_EXCEPTION_NAMES, error.name);\n}\n\nabstract class RecognitionException\n  extends Error\n  implements IRecognitionException\n{\n  context: IRecognizerContext;\n  resyncedTokens: IToken[] = [];\n\n  protected constructor(\n    message: string,\n    public token: IToken,\n  ) {\n    super(message);\n\n    // fix prototype chain when typescript target is ES5\n    Object.setPrototypeOf(this, new.target.prototype);\n\n    /* istanbul ignore next - V8 workaround to remove constructor from stacktrace when typescript target is ES5 */\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n  }\n}\n\nexport class MismatchedTokenException extends RecognitionException {\n  constructor(\n    message: string,\n    token: IToken,\n    public previousToken: IToken,\n  ) {\n    super(message, token);\n    this.name = MISMATCHED_TOKEN_EXCEPTION;\n  }\n}\n\nexport class NoViableAltException extends RecognitionException {\n  constructor(\n    message: string,\n    token: IToken,\n    public previousToken: IToken,\n  ) {\n    super(message, token);\n    this.name = NO_VIABLE_ALT_EXCEPTION;\n  }\n}\n\nexport class NotAllInputParsedException extends RecognitionException {\n  constructor(message: string, token: IToken) {\n    super(message, token);\n    this.name = NOT_ALL_INPUT_PARSED_EXCEPTION;\n  }\n}\n\nexport class EarlyExitException extends RecognitionException {\n  constructor(\n    message: string,\n    token: IToken,\n    public previousToken: IToken,\n  ) {\n    super(message, token);\n    this.name = EARLY_EXIT_EXCEPTION;\n  }\n}\n","import {\n  createTokenInstance,\n  EOF,\n  tokenMatcher,\n} from \"../../../scan/tokens_public.js\";\nimport {\n  AbstractNextTerminalAfterProductionWalker,\n  IFirstAfterRepetition,\n} from \"../../grammar/interpreter.js\";\nimport {\n  clone,\n  dropRight,\n  find,\n  flatten,\n  has,\n  includes,\n  isEmpty,\n  map,\n} from \"lodash-es\";\nimport {\n  IParserConfig,\n  IToken,\n  ITokenGrammarPath,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { MismatchedTokenException } from \"../../exceptions_public.js\";\nimport { IN } from \"../../constants.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n\nexport const EOF_FOLLOW_KEY: any = {};\n\nexport interface IFollowKey {\n  ruleName: string;\n  idxInCallingRule: number;\n  inRule: string;\n}\n\nexport const IN_RULE_RECOVERY_EXCEPTION = \"InRuleRecoveryException\";\n\nexport class InRuleRecoveryException extends Error {\n  constructor(message: string) {\n    super(message);\n    this.name = IN_RULE_RECOVERY_EXCEPTION;\n  }\n}\n\n/**\n * This trait is responsible for the error recovery and fault tolerant logic\n */\nexport class Recoverable {\n  recoveryEnabled: boolean;\n  firstAfterRepMap: Record<string, IFirstAfterRepetition>;\n  resyncFollows: Record<string, TokenType[]>;\n\n  initRecoverable(config: IParserConfig) {\n    this.firstAfterRepMap = {};\n    this.resyncFollows = {};\n\n    this.recoveryEnabled = has(config, \"recoveryEnabled\")\n      ? (config.recoveryEnabled as boolean) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.recoveryEnabled;\n\n    // performance optimization, NOOP will be inlined which\n    // effectively means that this optional feature does not exist\n    // when not used.\n    if (this.recoveryEnabled) {\n      this.attemptInRepetitionRecovery = attemptInRepetitionRecovery;\n    }\n  }\n\n  public getTokenToInsert(tokType: TokenType): IToken {\n    const tokToInsert = createTokenInstance(\n      tokType,\n      \"\",\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n      NaN,\n    );\n    tokToInsert.isInsertedInRecovery = true;\n    return tokToInsert;\n  }\n\n  public canTokenTypeBeInsertedInRecovery(tokType: TokenType): boolean {\n    return true;\n  }\n\n  public canTokenTypeBeDeletedInRecovery(tokType: TokenType): boolean {\n    return true;\n  }\n\n  tryInRepetitionRecovery(\n    this: MixedInParser,\n    grammarRule: Function,\n    grammarRuleArgs: any[],\n    lookAheadFunc: () => boolean,\n    expectedTokType: TokenType,\n  ): void {\n    // TODO: can the resyncTokenType be cached?\n    const reSyncTokType = this.findReSyncTokenType();\n    const savedLexerState = this.exportLexerState();\n    const resyncedTokens: IToken[] = [];\n    let passedResyncPoint = false;\n\n    const nextTokenWithoutResync = this.LA(1);\n    let currToken = this.LA(1);\n\n    const generateErrorMessage = () => {\n      const previousToken = this.LA(0);\n      // we are preemptively re-syncing before an error has been detected, therefor we must reproduce\n      // the error that would have been thrown\n      const msg = this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: expectedTokType,\n        actual: nextTokenWithoutResync,\n        previous: previousToken,\n        ruleName: this.getCurrRuleFullName(),\n      });\n      const error = new MismatchedTokenException(\n        msg,\n        nextTokenWithoutResync,\n        this.LA(0),\n      );\n      // the first token here will be the original cause of the error, this is not part of the resyncedTokens property.\n      error.resyncedTokens = dropRight(resyncedTokens);\n      this.SAVE_ERROR(error);\n    };\n\n    while (!passedResyncPoint) {\n      // re-synced to a point where we can safely exit the repetition/\n      if (this.tokenMatcher(currToken, expectedTokType)) {\n        generateErrorMessage();\n        return; // must return here to avoid reverting the inputIdx\n      } else if (lookAheadFunc.call(this)) {\n        // we skipped enough tokens so we can resync right back into another iteration of the repetition grammar rule\n        generateErrorMessage();\n        // recursive invocation in other to support multiple re-syncs in the same top level repetition grammar rule\n        grammarRule.apply(this, grammarRuleArgs);\n        return; // must return here to avoid reverting the inputIdx\n      } else if (this.tokenMatcher(currToken, reSyncTokType)) {\n        passedResyncPoint = true;\n      } else {\n        currToken = this.SKIP_TOKEN();\n        this.addToResyncTokens(currToken, resyncedTokens);\n      }\n    }\n\n    // we were unable to find a CLOSER point to resync inside the Repetition, reset the state.\n    // The parsing exception we were trying to prevent will happen in the NEXT parsing step. it may be handled by\n    // \"between rules\" resync recovery later in the flow.\n    this.importLexerState(savedLexerState);\n  }\n\n  shouldInRepetitionRecoveryBeTried(\n    this: MixedInParser,\n    expectTokAfterLastMatch: TokenType,\n    nextTokIdx: number,\n    notStuck: boolean | undefined,\n  ): boolean {\n    // Edge case of arriving from a MANY repetition which is stuck\n    // Attempting recovery in this case could cause an infinite loop\n    if (notStuck === false) {\n      return false;\n    }\n\n    // no need to recover, next token is what we expect...\n    if (this.tokenMatcher(this.LA(1), expectTokAfterLastMatch)) {\n      return false;\n    }\n\n    // error recovery is disabled during backtracking as it can make the parser ignore a valid grammar path\n    // and prefer some backtracking path that includes recovered errors.\n    if (this.isBackTracking()) {\n      return false;\n    }\n\n    // if we can perform inRule recovery (single token insertion or deletion) we always prefer that recovery algorithm\n    // because if it works, it makes the least amount of changes to the input stream (greedy algorithm)\n    //noinspection RedundantIfStatementJS\n    if (\n      this.canPerformInRuleRecovery(\n        expectTokAfterLastMatch,\n        this.getFollowsForInRuleRecovery(expectTokAfterLastMatch, nextTokIdx),\n      )\n    ) {\n      return false;\n    }\n\n    return true;\n  }\n\n  // Error Recovery functionality\n  getFollowsForInRuleRecovery(\n    this: MixedInParser,\n    tokType: TokenType,\n    tokIdxInRule: number,\n  ): TokenType[] {\n    const grammarPath = this.getCurrentGrammarPath(tokType, tokIdxInRule);\n    const follows = this.getNextPossibleTokenTypes(grammarPath);\n    return follows;\n  }\n\n  tryInRuleRecovery(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n    follows: TokenType[],\n  ): IToken {\n    if (this.canRecoverWithSingleTokenInsertion(expectedTokType, follows)) {\n      const tokToInsert = this.getTokenToInsert(expectedTokType);\n      return tokToInsert;\n    }\n\n    if (this.canRecoverWithSingleTokenDeletion(expectedTokType)) {\n      const nextTok = this.SKIP_TOKEN();\n      this.consumeToken();\n      return nextTok;\n    }\n\n    throw new InRuleRecoveryException(\"sad sad panda\");\n  }\n\n  canPerformInRuleRecovery(\n    this: MixedInParser,\n    expectedToken: TokenType,\n    follows: TokenType[],\n  ): boolean {\n    return (\n      this.canRecoverWithSingleTokenInsertion(expectedToken, follows) ||\n      this.canRecoverWithSingleTokenDeletion(expectedToken)\n    );\n  }\n\n  canRecoverWithSingleTokenInsertion(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n    follows: TokenType[],\n  ): boolean {\n    if (!this.canTokenTypeBeInsertedInRecovery(expectedTokType)) {\n      return false;\n    }\n\n    // must know the possible following tokens to perform single token insertion\n    if (isEmpty(follows)) {\n      return false;\n    }\n\n    const mismatchedTok = this.LA(1);\n    const isMisMatchedTokInFollows =\n      find(follows, (possibleFollowsTokType: TokenType) => {\n        return this.tokenMatcher(mismatchedTok, possibleFollowsTokType);\n      }) !== undefined;\n\n    return isMisMatchedTokInFollows;\n  }\n\n  canRecoverWithSingleTokenDeletion(\n    this: MixedInParser,\n    expectedTokType: TokenType,\n  ): boolean {\n    if (!this.canTokenTypeBeDeletedInRecovery(expectedTokType)) {\n      return false;\n    }\n\n    const isNextTokenWhatIsExpected = this.tokenMatcher(\n      this.LA(2),\n      expectedTokType,\n    );\n    return isNextTokenWhatIsExpected;\n  }\n\n  isInCurrentRuleReSyncSet(\n    this: MixedInParser,\n    tokenTypeIdx: TokenType,\n  ): boolean {\n    const followKey = this.getCurrFollowKey();\n    const currentRuleReSyncSet = this.getFollowSetFromFollowKey(followKey);\n    return includes(currentRuleReSyncSet, tokenTypeIdx);\n  }\n\n  findReSyncTokenType(this: MixedInParser): TokenType {\n    const allPossibleReSyncTokTypes = this.flattenFollowSet();\n    // this loop will always terminate as EOF is always in the follow stack and also always (virtually) in the input\n    let nextToken = this.LA(1);\n    let k = 2;\n    while (true) {\n      const foundMatch = find(allPossibleReSyncTokTypes, (resyncTokType) => {\n        const canMatch = tokenMatcher(nextToken, resyncTokType);\n        return canMatch;\n      });\n      if (foundMatch !== undefined) {\n        return foundMatch;\n      }\n      nextToken = this.LA(k);\n      k++;\n    }\n  }\n\n  getCurrFollowKey(this: MixedInParser): IFollowKey {\n    // the length is at least one as we always add the ruleName to the stack before invoking the rule.\n    if (this.RULE_STACK.length === 1) {\n      return EOF_FOLLOW_KEY;\n    }\n    const currRuleShortName = this.getLastExplicitRuleShortName();\n    const currRuleIdx = this.getLastExplicitRuleOccurrenceIndex();\n    const prevRuleShortName = this.getPreviousExplicitRuleShortName();\n\n    return {\n      ruleName: this.shortRuleNameToFullName(currRuleShortName),\n      idxInCallingRule: currRuleIdx,\n      inRule: this.shortRuleNameToFullName(prevRuleShortName),\n    };\n  }\n\n  buildFullFollowKeyStack(this: MixedInParser): IFollowKey[] {\n    const explicitRuleStack = this.RULE_STACK;\n    const explicitOccurrenceStack = this.RULE_OCCURRENCE_STACK;\n\n    return map(explicitRuleStack, (ruleName, idx) => {\n      if (idx === 0) {\n        return EOF_FOLLOW_KEY;\n      }\n      return {\n        ruleName: this.shortRuleNameToFullName(ruleName),\n        idxInCallingRule: explicitOccurrenceStack[idx],\n        inRule: this.shortRuleNameToFullName(explicitRuleStack[idx - 1]),\n      };\n    });\n  }\n\n  flattenFollowSet(this: MixedInParser): TokenType[] {\n    const followStack = map(this.buildFullFollowKeyStack(), (currKey) => {\n      return this.getFollowSetFromFollowKey(currKey);\n    });\n    return <any>flatten(followStack);\n  }\n\n  getFollowSetFromFollowKey(\n    this: MixedInParser,\n    followKey: IFollowKey,\n  ): TokenType[] {\n    if (followKey === EOF_FOLLOW_KEY) {\n      return [EOF];\n    }\n\n    const followName =\n      followKey.ruleName + followKey.idxInCallingRule + IN + followKey.inRule;\n\n    return this.resyncFollows[followName];\n  }\n\n  // It does not make any sense to include a virtual EOF token in the list of resynced tokens\n  // as EOF does not really exist and thus does not contain any useful information (line/column numbers)\n  addToResyncTokens(\n    this: MixedInParser,\n    token: IToken,\n    resyncTokens: IToken[],\n  ): IToken[] {\n    if (!this.tokenMatcher(token, EOF)) {\n      resyncTokens.push(token);\n    }\n    return resyncTokens;\n  }\n\n  reSyncTo(this: MixedInParser, tokType: TokenType): IToken[] {\n    const resyncedTokens: IToken[] = [];\n    let nextTok = this.LA(1);\n    while (this.tokenMatcher(nextTok, tokType) === false) {\n      nextTok = this.SKIP_TOKEN();\n      this.addToResyncTokens(nextTok, resyncedTokens);\n    }\n    // the last token is not part of the error.\n    return dropRight(resyncedTokens);\n  }\n\n  attemptInRepetitionRecovery(\n    this: MixedInParser,\n    prodFunc: Function,\n    args: any[],\n    lookaheadFunc: () => boolean,\n    dslMethodIdx: number,\n    prodOccurrence: number,\n    nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\n    notStuck?: boolean,\n  ): void {\n    // by default this is a NO-OP\n    // The actual implementation is with the function(not method) below\n  }\n\n  getCurrentGrammarPath(\n    this: MixedInParser,\n    tokType: TokenType,\n    tokIdxInRule: number,\n  ): ITokenGrammarPath {\n    const pathRuleStack: string[] = this.getHumanReadableRuleStack();\n    const pathOccurrenceStack: number[] = clone(this.RULE_OCCURRENCE_STACK);\n    const grammarPath: any = {\n      ruleStack: pathRuleStack,\n      occurrenceStack: pathOccurrenceStack,\n      lastTok: tokType,\n      lastTokOccurrence: tokIdxInRule,\n    };\n\n    return grammarPath;\n  }\n  getHumanReadableRuleStack(this: MixedInParser): string[] {\n    return map(this.RULE_STACK, (currShortName) =>\n      this.shortRuleNameToFullName(currShortName),\n    );\n  }\n}\n\nexport function attemptInRepetitionRecovery(\n  this: MixedInParser,\n  prodFunc: Function,\n  args: any[],\n  lookaheadFunc: () => boolean,\n  dslMethodIdx: number,\n  prodOccurrence: number,\n  nextToksWalker: typeof AbstractNextTerminalAfterProductionWalker,\n  notStuck?: boolean,\n): void {\n  const key = this.getKeyForAutomaticLookahead(dslMethodIdx, prodOccurrence);\n  let firstAfterRepInfo = this.firstAfterRepMap[key];\n  if (firstAfterRepInfo === undefined) {\n    const currRuleName = this.getCurrRuleFullName();\n    const ruleGrammar = this.getGAstProductions()[currRuleName];\n    const walker: AbstractNextTerminalAfterProductionWalker =\n      new nextToksWalker(ruleGrammar, prodOccurrence);\n    firstAfterRepInfo = walker.startWalking();\n    this.firstAfterRepMap[key] = firstAfterRepInfo;\n  }\n\n  let expectTokAfterLastMatch = firstAfterRepInfo.token;\n  let nextTokIdx = firstAfterRepInfo.occurrence;\n  const isEndOfRule = firstAfterRepInfo.isEndOfRule;\n\n  // special edge case of a TOP most repetition after which the input should END.\n  // this will force an attempt for inRule recovery in that scenario.\n  if (\n    this.RULE_STACK.length === 1 &&\n    isEndOfRule &&\n    expectTokAfterLastMatch === undefined\n  ) {\n    expectTokAfterLastMatch = EOF;\n    nextTokIdx = 1;\n  }\n\n  // We don't have anything to re-sync to...\n  // this condition was extracted from `shouldInRepetitionRecoveryBeTried` to act as a type-guard\n  if (expectTokAfterLastMatch === undefined || nextTokIdx === undefined) {\n    return;\n  }\n\n  if (\n    this.shouldInRepetitionRecoveryBeTried(\n      expectTokAfterLastMatch,\n      nextTokIdx,\n      notStuck,\n    )\n  ) {\n    // TODO: performance optimization: instead of passing the original args here, we modify\n    // the args param (or create a new one) and make sure the lookahead func is explicitly provided\n    // to avoid searching the cache for it once more.\n    this.tryInRepetitionRecovery(\n      prodFunc,\n      args,\n      lookaheadFunc,\n      expectTokAfterLastMatch,\n    );\n  }\n}\n","// Lookahead keys are 32Bit integers in the form\n// TTTTTTTT-ZZZZZZZZZZZZ-YYYY-XXXXXXXX\n// XXXX -> Occurrence Index bitmap.\n// YYYY -> DSL Method Type bitmap.\n// ZZZZZZZZZZZZZZZ -> Rule short Index bitmap.\n// TTTTTTTTT -> alternation alternative index bitmap\n\nexport const BITS_FOR_METHOD_TYPE = 4;\nexport const BITS_FOR_OCCURRENCE_IDX = 8;\nexport const BITS_FOR_RULE_IDX = 12;\n// TODO: validation, this means that there may at most 2^8 --> 256 alternatives for an alternation.\nexport const BITS_FOR_ALT_IDX = 8;\n\n// short string used as part of mapping keys.\n// being short improves the performance when composing KEYS for maps out of these\n// The 5 - 8 bits (16 possible values, are reserved for the DSL method indices)\nexport const OR_IDX = 1 << BITS_FOR_OCCURRENCE_IDX;\nexport const OPTION_IDX = 2 << BITS_FOR_OCCURRENCE_IDX;\nexport const MANY_IDX = 3 << BITS_FOR_OCCURRENCE_IDX;\nexport const AT_LEAST_ONE_IDX = 4 << BITS_FOR_OCCURRENCE_IDX;\nexport const MANY_SEP_IDX = 5 << BITS_FOR_OCCURRENCE_IDX;\nexport const AT_LEAST_ONE_SEP_IDX = 6 << BITS_FOR_OCCURRENCE_IDX;\n\n// this actually returns a number, but it is always used as a string (object prop key)\nexport function getKeyForAutomaticLookahead(\n  ruleIdx: number,\n  dslMethodIdx: number,\n  occurrence: number,\n): number {\n  return occurrence | dslMethodIdx | ruleIdx;\n}\n\nconst BITS_START_FOR_ALT_IDX = 32 - BITS_FOR_ALT_IDX;\n","import {\n  ILookaheadStrategy,\n  ILookaheadValidationError,\n  IOrAlt,\n  OptionalProductionType,\n  Rule,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { flatMap, isEmpty } from \"lodash-es\";\nimport { defaultGrammarValidatorErrorProvider } from \"../errors_public.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser/parser.js\";\nimport {\n  validateAmbiguousAlternationAlternatives,\n  validateEmptyOrAlternative,\n  validateNoLeftRecursion,\n  validateSomeNonEmptyLookaheadPath,\n} from \"./checks.js\";\nimport {\n  buildAlternativesLookAheadFunc,\n  buildLookaheadFuncForOptionalProd,\n  buildLookaheadFuncForOr,\n  buildSingleAlternativeLookaheadFunction,\n  getProdType,\n} from \"./lookahead.js\";\nimport { IParserDefinitionError } from \"./types.js\";\n\nexport class LLkLookaheadStrategy implements ILookaheadStrategy {\n  readonly maxLookahead: number;\n\n  constructor(options?: { maxLookahead?: number }) {\n    this.maxLookahead =\n      options?.maxLookahead ?? DEFAULT_PARSER_CONFIG.maxLookahead;\n  }\n\n  validate(options: {\n    rules: Rule[];\n    tokenTypes: TokenType[];\n    grammarName: string;\n  }): ILookaheadValidationError[] {\n    const leftRecursionErrors = this.validateNoLeftRecursion(options.rules);\n\n    if (isEmpty(leftRecursionErrors)) {\n      const emptyAltErrors = this.validateEmptyOrAlternatives(options.rules);\n      const ambiguousAltsErrors = this.validateAmbiguousAlternationAlternatives(\n        options.rules,\n        this.maxLookahead,\n      );\n      const emptyRepetitionErrors = this.validateSomeNonEmptyLookaheadPath(\n        options.rules,\n        this.maxLookahead,\n      );\n      const allErrors = [\n        ...leftRecursionErrors,\n        ...emptyAltErrors,\n        ...ambiguousAltsErrors,\n        ...emptyRepetitionErrors,\n      ];\n      return allErrors;\n    }\n    return leftRecursionErrors;\n  }\n\n  validateNoLeftRecursion(rules: Rule[]): IParserDefinitionError[] {\n    return flatMap(rules, (currTopRule) =>\n      validateNoLeftRecursion(\n        currTopRule,\n        currTopRule,\n        defaultGrammarValidatorErrorProvider,\n      ),\n    );\n  }\n\n  validateEmptyOrAlternatives(rules: Rule[]): IParserDefinitionError[] {\n    return flatMap(rules, (currTopRule) =>\n      validateEmptyOrAlternative(\n        currTopRule,\n        defaultGrammarValidatorErrorProvider,\n      ),\n    );\n  }\n\n  validateAmbiguousAlternationAlternatives(\n    rules: Rule[],\n    maxLookahead: number,\n  ): IParserDefinitionError[] {\n    return flatMap(rules, (currTopRule) =>\n      validateAmbiguousAlternationAlternatives(\n        currTopRule,\n        maxLookahead,\n        defaultGrammarValidatorErrorProvider,\n      ),\n    );\n  }\n\n  validateSomeNonEmptyLookaheadPath(\n    rules: Rule[],\n    maxLookahead: number,\n  ): IParserDefinitionError[] {\n    return validateSomeNonEmptyLookaheadPath(\n      rules,\n      maxLookahead,\n      defaultGrammarValidatorErrorProvider,\n    );\n  }\n\n  buildLookaheadForAlternation(options: {\n    prodOccurrence: number;\n    rule: Rule;\n    maxLookahead: number;\n    hasPredicates: boolean;\n    dynamicTokensEnabled: boolean;\n  }): (orAlts?: IOrAlt<any>[] | undefined) => number | undefined {\n    return buildLookaheadFuncForOr(\n      options.prodOccurrence,\n      options.rule,\n      options.maxLookahead,\n      options.hasPredicates,\n      options.dynamicTokensEnabled,\n      buildAlternativesLookAheadFunc,\n    );\n  }\n\n  buildLookaheadForOptional(options: {\n    prodOccurrence: number;\n    prodType: OptionalProductionType;\n    rule: Rule;\n    maxLookahead: number;\n    dynamicTokensEnabled: boolean;\n  }): () => boolean {\n    return buildLookaheadFuncForOptionalProd(\n      options.prodOccurrence,\n      options.rule,\n      options.maxLookahead,\n      options.dynamicTokensEnabled,\n      getProdType(options.prodType),\n      buildSingleAlternativeLookaheadFunction,\n    );\n  }\n}\n","import { forEach, has } from \"lodash-es\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\nimport {\n  ILookaheadStrategy,\n  IParserConfig,\n  OptionalProductionType,\n} from \"@chevrotain/types\";\nimport {\n  AT_LEAST_ONE_IDX,\n  AT_LEAST_ONE_SEP_IDX,\n  getKeyForAutomaticLookahead,\n  MANY_IDX,\n  MANY_SEP_IDX,\n  OPTION_IDX,\n  OR_IDX,\n} from \"../../grammar/keys.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport {\n  Alternation,\n  GAstVisitor,\n  getProductionDslName,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n} from \"@chevrotain/gast\";\nimport { LLkLookaheadStrategy } from \"../../grammar/llk_lookahead.js\";\n\n/**\n * Trait responsible for the lookahead related utilities and optimizations.\n */\nexport class LooksAhead {\n  maxLookahead: number;\n  lookAheadFuncsCache: any;\n  dynamicTokensEnabled: boolean;\n  lookaheadStrategy: ILookaheadStrategy;\n\n  initLooksAhead(config: IParserConfig) {\n    this.dynamicTokensEnabled = has(config, \"dynamicTokensEnabled\")\n      ? (config.dynamicTokensEnabled as boolean) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.dynamicTokensEnabled;\n\n    this.maxLookahead = has(config, \"maxLookahead\")\n      ? (config.maxLookahead as number) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.maxLookahead;\n\n    this.lookaheadStrategy = has(config, \"lookaheadStrategy\")\n      ? (config.lookaheadStrategy as ILookaheadStrategy) // assumes end user provides the correct config value/type\n      : new LLkLookaheadStrategy({ maxLookahead: this.maxLookahead });\n\n    this.lookAheadFuncsCache = new Map();\n  }\n\n  preComputeLookaheadFunctions(this: MixedInParser, rules: Rule[]): void {\n    forEach(rules, (currRule) => {\n      this.TRACE_INIT(`${currRule.name} Rule Lookahead`, () => {\n        const {\n          alternation,\n          repetition,\n          option,\n          repetitionMandatory,\n          repetitionMandatoryWithSeparator,\n          repetitionWithSeparator,\n        } = collectMethods(currRule);\n\n        forEach(alternation, (currProd) => {\n          const prodIdx = currProd.idx === 0 ? \"\" : currProd.idx;\n          this.TRACE_INIT(`${getProductionDslName(currProd)}${prodIdx}`, () => {\n            const laFunc = this.lookaheadStrategy.buildLookaheadForAlternation({\n              prodOccurrence: currProd.idx,\n              rule: currRule,\n              maxLookahead: currProd.maxLookahead || this.maxLookahead,\n              hasPredicates: currProd.hasPredicates,\n              dynamicTokensEnabled: this.dynamicTokensEnabled,\n            });\n\n            const key = getKeyForAutomaticLookahead(\n              this.fullRuleNameToShort[currRule.name],\n              OR_IDX,\n              currProd.idx,\n            );\n            this.setLaFuncCache(key, laFunc);\n          });\n        });\n\n        forEach(repetition, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            MANY_IDX,\n            \"Repetition\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n\n        forEach(option, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            OPTION_IDX,\n            \"Option\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n\n        forEach(repetitionMandatory, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            AT_LEAST_ONE_IDX,\n            \"RepetitionMandatory\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n\n        forEach(repetitionMandatoryWithSeparator, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            AT_LEAST_ONE_SEP_IDX,\n            \"RepetitionMandatoryWithSeparator\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n\n        forEach(repetitionWithSeparator, (currProd) => {\n          this.computeLookaheadFunc(\n            currRule,\n            currProd.idx,\n            MANY_SEP_IDX,\n            \"RepetitionWithSeparator\",\n            currProd.maxLookahead,\n            getProductionDslName(currProd),\n          );\n        });\n      });\n    });\n  }\n\n  computeLookaheadFunc(\n    this: MixedInParser,\n    rule: Rule,\n    prodOccurrence: number,\n    prodKey: number,\n    prodType: OptionalProductionType,\n    prodMaxLookahead: number | undefined,\n    dslMethodName: string,\n  ): void {\n    this.TRACE_INIT(\n      `${dslMethodName}${prodOccurrence === 0 ? \"\" : prodOccurrence}`,\n      () => {\n        const laFunc = this.lookaheadStrategy.buildLookaheadForOptional({\n          prodOccurrence,\n          rule,\n          maxLookahead: prodMaxLookahead || this.maxLookahead,\n          dynamicTokensEnabled: this.dynamicTokensEnabled,\n          prodType,\n        });\n        const key = getKeyForAutomaticLookahead(\n          this.fullRuleNameToShort[rule.name],\n          prodKey,\n          prodOccurrence,\n        );\n        this.setLaFuncCache(key, laFunc);\n      },\n    );\n  }\n\n  // this actually returns a number, but it is always used as a string (object prop key)\n  getKeyForAutomaticLookahead(\n    this: MixedInParser,\n    dslMethodIdx: number,\n    occurrence: number,\n  ): number {\n    const currRuleShortName: any = this.getLastExplicitRuleShortName();\n    return getKeyForAutomaticLookahead(\n      currRuleShortName,\n      dslMethodIdx,\n      occurrence,\n    );\n  }\n\n  getLaFuncFromCache(this: MixedInParser, key: number): Function {\n    return this.lookAheadFuncsCache.get(key);\n  }\n\n  /* istanbul ignore next */\n  setLaFuncCache(this: MixedInParser, key: number, value: Function): void {\n    this.lookAheadFuncsCache.set(key, value);\n  }\n}\n\nclass DslMethodsCollectorVisitor extends GAstVisitor {\n  public dslMethods: {\n    option: Option[];\n    alternation: Alternation[];\n    repetition: Repetition[];\n    repetitionWithSeparator: RepetitionWithSeparator[];\n    repetitionMandatory: RepetitionMandatory[];\n    repetitionMandatoryWithSeparator: RepetitionMandatoryWithSeparator[];\n  } = {\n    option: [],\n    alternation: [],\n    repetition: [],\n    repetitionWithSeparator: [],\n    repetitionMandatory: [],\n    repetitionMandatoryWithSeparator: [],\n  };\n\n  reset() {\n    this.dslMethods = {\n      option: [],\n      alternation: [],\n      repetition: [],\n      repetitionWithSeparator: [],\n      repetitionMandatory: [],\n      repetitionMandatoryWithSeparator: [],\n    };\n  }\n\n  public visitOption(option: Option): void {\n    this.dslMethods.option.push(option);\n  }\n\n  public visitRepetitionWithSeparator(manySep: RepetitionWithSeparator): void {\n    this.dslMethods.repetitionWithSeparator.push(manySep);\n  }\n\n  public visitRepetitionMandatory(atLeastOne: RepetitionMandatory): void {\n    this.dslMethods.repetitionMandatory.push(atLeastOne);\n  }\n\n  public visitRepetitionMandatoryWithSeparator(\n    atLeastOneSep: RepetitionMandatoryWithSeparator,\n  ): void {\n    this.dslMethods.repetitionMandatoryWithSeparator.push(atLeastOneSep);\n  }\n\n  public visitRepetition(many: Repetition): void {\n    this.dslMethods.repetition.push(many);\n  }\n\n  public visitAlternation(or: Alternation): void {\n    this.dslMethods.alternation.push(or);\n  }\n}\n\nconst collectorVisitor = new DslMethodsCollectorVisitor();\nexport function collectMethods(rule: Rule): {\n  option: Option[];\n  alternation: Alternation[];\n  repetition: Repetition[];\n  repetitionWithSeparator: RepetitionWithSeparator[];\n  repetitionMandatory: RepetitionMandatory[];\n  repetitionMandatoryWithSeparator: RepetitionMandatoryWithSeparator[];\n} {\n  collectorVisitor.reset();\n  rule.accept(collectorVisitor);\n  const dslMethods = collectorVisitor.dslMethods;\n  // avoid uncleaned references\n  collectorVisitor.reset();\n  return <any>dslMethods;\n}\n","import { CstNode, CstNodeLocation, IToken } from \"@chevrotain/types\";\n\n/**\n * This nodeLocation tracking is not efficient and should only be used\n * when error recovery is enabled or the Token Vector contains virtual Tokens\n * (e.g, Python Indent/Outdent)\n * As it executes the calculation for every single terminal/nonTerminal\n * and does not rely on the fact the token vector is **sorted**\n */\nexport function setNodeLocationOnlyOffset(\n  currNodeLocation: CstNodeLocation,\n  newLocationInfo: Required<Pick<IToken, \"startOffset\" | \"endOffset\">>,\n): void {\n  // First (valid) update for this cst node\n  if (isNaN(currNodeLocation.startOffset) === true) {\n    // assumption1: Token location information is either NaN or a valid number\n    // assumption2: Token location information is fully valid if it exist\n    // (both start/end offsets exist and are numbers).\n    currNodeLocation.startOffset = newLocationInfo.startOffset;\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n  }\n  // Once the startOffset has been updated with a valid number it should never receive\n  // any farther updates as the Token vector is sorted.\n  // We still have to check this this condition for every new possible location info\n  // because with error recovery enabled we may encounter invalid tokens (NaN location props)\n  else if (currNodeLocation.endOffset! < newLocationInfo.endOffset === true) {\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n  }\n}\n\n/**\n * This nodeLocation tracking is not efficient and should only be used\n * when error recovery is enabled or the Token Vector contains virtual Tokens\n * (e.g, Python Indent/Outdent)\n * As it executes the calculation for every single terminal/nonTerminal\n * and does not rely on the fact the token vector is **sorted**\n */\nexport function setNodeLocationFull(\n  currNodeLocation: CstNodeLocation,\n  newLocationInfo: CstNodeLocation,\n): void {\n  // First (valid) update for this cst node\n  if (isNaN(currNodeLocation.startOffset) === true) {\n    // assumption1: Token location information is either NaN or a valid number\n    // assumption2: Token location information is fully valid if it exist\n    // (all start/end props exist and are numbers).\n    currNodeLocation.startOffset = newLocationInfo.startOffset;\n    currNodeLocation.startColumn = newLocationInfo.startColumn;\n    currNodeLocation.startLine = newLocationInfo.startLine;\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n    currNodeLocation.endColumn = newLocationInfo.endColumn;\n    currNodeLocation.endLine = newLocationInfo.endLine;\n  }\n  // Once the start props has been updated with a valid number it should never receive\n  // any farther updates as the Token vector is sorted.\n  // We still have to check this this condition for every new possible location info\n  // because with error recovery enabled we may encounter invalid tokens (NaN location props)\n  else if (currNodeLocation.endOffset! < newLocationInfo.endOffset! === true) {\n    currNodeLocation.endOffset = newLocationInfo.endOffset;\n    currNodeLocation.endColumn = newLocationInfo.endColumn;\n    currNodeLocation.endLine = newLocationInfo.endLine;\n  }\n}\n\nexport function addTerminalToCst(\n  node: CstNode,\n  token: IToken,\n  tokenTypeName: string,\n): void {\n  if (node.children[tokenTypeName] === undefined) {\n    node.children[tokenTypeName] = [token];\n  } else {\n    node.children[tokenTypeName].push(token);\n  }\n}\n\nexport function addNoneTerminalToCst(\n  node: CstNode,\n  ruleName: string,\n  ruleResult: any,\n): void {\n  if (node.children[ruleName] === undefined) {\n    node.children[ruleName] = [ruleResult];\n  } else {\n    node.children[ruleName].push(ruleResult);\n  }\n}\n","const NAME = \"name\";\n\nexport function defineNameProp(obj: {}, nameValue: string): void {\n  Object.defineProperty(obj, NAME, {\n    enumerable: false,\n    configurable: true,\n    writable: false,\n    value: nameValue,\n  });\n}\n","import {\n  compact,\n  filter,\n  forEach,\n  isArray,\n  isEmpty,\n  isFunction,\n  isUndefined,\n  keys,\n  map,\n} from \"lodash-es\";\nimport { defineNameProp } from \"../../lang/lang_extensions.js\";\nimport { CstNode, ICstVisitor } from \"@chevrotain/types\";\n\nexport function defaultVisit<IN>(ctx: any, param: IN): void {\n  const childrenNames = keys(ctx);\n  const childrenNamesLength = childrenNames.length;\n  for (let i = 0; i < childrenNamesLength; i++) {\n    const currChildName = childrenNames[i];\n    const currChildArray = ctx[currChildName];\n    const currChildArrayLength = currChildArray.length;\n    for (let j = 0; j < currChildArrayLength; j++) {\n      const currChild: any = currChildArray[j];\n      // distinction between Tokens Children and CstNode children\n      if (currChild.tokenTypeIdx === undefined) {\n        this[currChild.name](currChild.children, param);\n      }\n    }\n  }\n  // defaultVisit does not support generic out param\n}\n\nexport function createBaseSemanticVisitorConstructor(\n  grammarName: string,\n  ruleNames: string[],\n): {\n  new (...args: any[]): ICstVisitor<any, any>;\n} {\n  const derivedConstructor: any = function () {};\n\n  // can be overwritten according to:\n  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/\n  // name?redirectlocale=en-US&redirectslug=JavaScript%2FReference%2FGlobal_Objects%2FFunction%2Fname\n  defineNameProp(derivedConstructor, grammarName + \"BaseSemantics\");\n\n  const semanticProto = {\n    visit: function (cstNode: CstNode | CstNode[], param: any) {\n      // enables writing more concise visitor methods when CstNode has only a single child\n      if (isArray(cstNode)) {\n        // A CST Node's children dictionary can never have empty arrays as values\n        // If a key is defined there will be at least one element in the corresponding value array.\n        cstNode = cstNode[0];\n      }\n\n      // enables passing optional CstNodes concisely.\n      if (isUndefined(cstNode)) {\n        return undefined;\n      }\n\n      return this[cstNode.name](cstNode.children, param);\n    },\n\n    validateVisitor: function () {\n      const semanticDefinitionErrors = validateVisitor(this, ruleNames);\n      if (!isEmpty(semanticDefinitionErrors)) {\n        const errorMessages = map(\n          semanticDefinitionErrors,\n          (currDefError) => currDefError.msg,\n        );\n        throw Error(\n          `Errors Detected in CST Visitor <${this.constructor.name}>:\\n\\t` +\n            `${errorMessages.join(\"\\n\\n\").replace(/\\n/g, \"\\n\\t\")}`,\n        );\n      }\n    },\n  };\n\n  derivedConstructor.prototype = semanticProto;\n  derivedConstructor.prototype.constructor = derivedConstructor;\n\n  derivedConstructor._RULE_NAMES = ruleNames;\n\n  return derivedConstructor;\n}\n\nexport function createBaseVisitorConstructorWithDefaults(\n  grammarName: string,\n  ruleNames: string[],\n  baseConstructor: Function,\n): {\n  new (...args: any[]): ICstVisitor<any, any>;\n} {\n  const derivedConstructor: any = function () {};\n\n  // can be overwritten according to:\n  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Function/\n  // name?redirectlocale=en-US&redirectslug=JavaScript%2FReference%2FGlobal_Objects%2FFunction%2Fname\n  defineNameProp(derivedConstructor, grammarName + \"BaseSemanticsWithDefaults\");\n\n  const withDefaultsProto = Object.create(baseConstructor.prototype);\n  forEach(ruleNames, (ruleName) => {\n    withDefaultsProto[ruleName] = defaultVisit;\n  });\n\n  derivedConstructor.prototype = withDefaultsProto;\n  derivedConstructor.prototype.constructor = derivedConstructor;\n\n  return derivedConstructor;\n}\n\nexport enum CstVisitorDefinitionError {\n  REDUNDANT_METHOD,\n  MISSING_METHOD,\n}\n\nexport interface IVisitorDefinitionError {\n  msg: string;\n  type: CstVisitorDefinitionError;\n  methodName: string;\n}\n\nexport function validateVisitor(\n  visitorInstance: ICstVisitor<unknown, unknown>,\n  ruleNames: string[],\n): IVisitorDefinitionError[] {\n  const missingErrors = validateMissingCstMethods(visitorInstance, ruleNames);\n\n  return missingErrors;\n}\n\nexport function validateMissingCstMethods(\n  visitorInstance: ICstVisitor<unknown, unknown>,\n  ruleNames: string[],\n): IVisitorDefinitionError[] {\n  const missingRuleNames = filter(ruleNames, (currRuleName) => {\n    return isFunction((visitorInstance as any)[currRuleName]) === false;\n  });\n\n  const errors: IVisitorDefinitionError[] = map(\n    missingRuleNames,\n    (currRuleName) => {\n      return {\n        msg: `Missing visitor method: <${currRuleName}> on ${<any>(\n          visitorInstance.constructor.name\n        )} CST Visitor.`,\n        type: CstVisitorDefinitionError.MISSING_METHOD,\n        methodName: currRuleName,\n      };\n    },\n  );\n\n  return compact<IVisitorDefinitionError>(errors);\n}\n","import {\n  AtLeastOneSepMethodOpts,\n  ConsumeMethodOpts,\n  CstNode,\n  DSLMethodOpts,\n  DSLMethodOptsWithErr,\n  GrammarAction,\n  IOrAlt,\n  IParserConfig,\n  IProduction,\n  IToken,\n  ManySepMethodOpts,\n  OrMethodOpts,\n  SubruleMethodOpts,\n  TokenType,\n} from \"@chevrotain/types\";\nimport {\n  forEach,\n  has,\n  isArray,\n  isFunction,\n  last as peek,\n  some,\n} from \"lodash-es\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport {\n  Alternation,\n  Alternative,\n  NonTerminal,\n  Option,\n  Repetition,\n  RepetitionMandatory,\n  RepetitionMandatoryWithSeparator,\n  RepetitionWithSeparator,\n  Rule,\n  Terminal,\n} from \"@chevrotain/gast\";\nimport { Lexer } from \"../../../scan/lexer_public.js\";\nimport {\n  augmentTokenTypes,\n  hasShortKeyProperty,\n} from \"../../../scan/tokens.js\";\nimport {\n  createToken,\n  createTokenInstance,\n} from \"../../../scan/tokens_public.js\";\nimport { END_OF_FILE } from \"../parser.js\";\nimport { BITS_FOR_OCCURRENCE_IDX } from \"../../grammar/keys.js\";\nimport { ParserMethodInternal } from \"../types.js\";\n\ntype ProdWithDef = IProduction & { definition?: IProduction[] };\nconst RECORDING_NULL_OBJECT = {\n  description: \"This Object indicates the Parser is during Recording Phase\",\n};\nObject.freeze(RECORDING_NULL_OBJECT);\n\nconst HANDLE_SEPARATOR = true;\nconst MAX_METHOD_IDX = Math.pow(2, BITS_FOR_OCCURRENCE_IDX) - 1;\n\nconst RFT = createToken({ name: \"RECORDING_PHASE_TOKEN\", pattern: Lexer.NA });\naugmentTokenTypes([RFT]);\nconst RECORDING_PHASE_TOKEN = createTokenInstance(\n  RFT,\n  \"This IToken indicates the Parser is in Recording Phase\\n\\t\" +\n    \"\" +\n    \"See: https://chevrotain.io/docs/guide/internals.html#grammar-recording for details\",\n  // Using \"-1\" instead of NaN (as in EOF) because an actual number is less likely to\n  // cause errors if the output of LA or CONSUME would be (incorrectly) used during the recording phase.\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n  -1,\n);\nObject.freeze(RECORDING_PHASE_TOKEN);\n\nconst RECORDING_PHASE_CSTNODE: CstNode = {\n  name:\n    \"This CSTNode indicates the Parser is in Recording Phase\\n\\t\" +\n    \"See: https://chevrotain.io/docs/guide/internals.html#grammar-recording for details\",\n  children: {},\n};\n\n/**\n * This trait handles the creation of the GAST structure for Chevrotain Grammars\n */\nexport class GastRecorder {\n  recordingProdStack: ProdWithDef[];\n  RECORDING_PHASE: boolean;\n\n  initGastRecorder(this: MixedInParser, config: IParserConfig): void {\n    this.recordingProdStack = [];\n    this.RECORDING_PHASE = false;\n  }\n\n  enableRecording(this: MixedInParser): void {\n    this.RECORDING_PHASE = true;\n\n    this.TRACE_INIT(\"Enable Recording\", () => {\n      /**\n       * Warning Dark Voodoo Magic upcoming!\n       * We are \"replacing\" the public parsing DSL methods API\n       * With **new** alternative implementations on the Parser **instance**\n       *\n       * So far this is the only way I've found to avoid performance regressions during parsing time.\n       * - Approx 30% performance regression was measured on Chrome 75 Canary when attempting to replace the \"internal\"\n       *   implementations directly instead.\n       */\n      for (let i = 0; i < 10; i++) {\n        const idx = i > 0 ? i : \"\";\n        this[`CONSUME${idx}` as \"CONSUME\"] = function (arg1, arg2) {\n          return this.consumeInternalRecord(arg1, i, arg2);\n        };\n        this[`SUBRULE${idx}` as \"SUBRULE\"] = function (arg1, arg2) {\n          return this.subruleInternalRecord(arg1, i, arg2) as any;\n        };\n        this[`OPTION${idx}` as \"OPTION\"] = function (arg1) {\n          return this.optionInternalRecord(arg1, i);\n        };\n        this[`OR${idx}` as \"OR\"] = function (arg1) {\n          return this.orInternalRecord(arg1, i);\n        };\n        this[`MANY${idx}` as \"MANY\"] = function (arg1) {\n          this.manyInternalRecord(i, arg1);\n        };\n        this[`MANY_SEP${idx}` as \"MANY_SEP\"] = function (arg1) {\n          this.manySepFirstInternalRecord(i, arg1);\n        };\n        this[`AT_LEAST_ONE${idx}` as \"AT_LEAST_ONE\"] = function (arg1) {\n          this.atLeastOneInternalRecord(i, arg1);\n        };\n        this[`AT_LEAST_ONE_SEP${idx}` as \"AT_LEAST_ONE_SEP\"] = function (arg1) {\n          this.atLeastOneSepFirstInternalRecord(i, arg1);\n        };\n      }\n\n      // DSL methods with the idx(suffix) as an argument\n      this[`consume`] = function (idx, arg1, arg2) {\n        return this.consumeInternalRecord(arg1, idx, arg2);\n      };\n      this[`subrule`] = function (idx, arg1, arg2) {\n        return this.subruleInternalRecord(arg1, idx, arg2) as any;\n      };\n      this[`option`] = function (idx, arg1) {\n        return this.optionInternalRecord(arg1, idx);\n      };\n      this[`or`] = function (idx, arg1) {\n        return this.orInternalRecord(arg1, idx);\n      };\n      this[`many`] = function (idx, arg1) {\n        this.manyInternalRecord(idx, arg1);\n      };\n      this[`atLeastOne`] = function (idx, arg1) {\n        this.atLeastOneInternalRecord(idx, arg1);\n      };\n\n      this.ACTION = this.ACTION_RECORD;\n      this.BACKTRACK = this.BACKTRACK_RECORD;\n      this.LA = this.LA_RECORD;\n    });\n  }\n\n  disableRecording(this: MixedInParser) {\n    this.RECORDING_PHASE = false;\n    // By deleting these **instance** properties, any future invocation\n    // will be deferred to the original methods on the **prototype** object\n    // This seems to get rid of any incorrect optimizations that V8 may\n    // do during the recording phase.\n    this.TRACE_INIT(\"Deleting Recording methods\", () => {\n      const that: any = this;\n\n      for (let i = 0; i < 10; i++) {\n        const idx = i > 0 ? i : \"\";\n        delete that[`CONSUME${idx}`];\n        delete that[`SUBRULE${idx}`];\n        delete that[`OPTION${idx}`];\n        delete that[`OR${idx}`];\n        delete that[`MANY${idx}`];\n        delete that[`MANY_SEP${idx}`];\n        delete that[`AT_LEAST_ONE${idx}`];\n        delete that[`AT_LEAST_ONE_SEP${idx}`];\n      }\n\n      delete that[`consume`];\n      delete that[`subrule`];\n      delete that[`option`];\n      delete that[`or`];\n      delete that[`many`];\n      delete that[`atLeastOne`];\n\n      delete that.ACTION;\n      delete that.BACKTRACK;\n      delete that.LA;\n    });\n  }\n\n  //   Parser methods are called inside an ACTION?\n  //   Maybe try/catch/finally on ACTIONS while disabling the recorders state changes?\n  // @ts-expect-error -- noop place holder\n  ACTION_RECORD<T>(this: MixedInParser, impl: () => T): T {\n    // NO-OP during recording\n  }\n\n  // Executing backtracking logic will break our recording logic assumptions\n  BACKTRACK_RECORD<T>(\n    grammarRule: (...args: any[]) => T,\n    args?: any[],\n  ): () => boolean {\n    return () => true;\n  }\n\n  // LA is part of the official API and may be used for custom lookahead logic\n  // by end users who may forget to wrap it in ACTION or inside a GATE\n  LA_RECORD(howMuch: number): IToken {\n    // We cannot use the RECORD_PHASE_TOKEN here because someone may depend\n    // On LA return EOF at the end of the input so an infinite loop may occur.\n    return END_OF_FILE;\n  }\n\n  topLevelRuleRecord(name: string, def: Function): Rule {\n    try {\n      const newTopLevelRule = new Rule({ definition: [], name: name });\n      newTopLevelRule.name = name;\n      this.recordingProdStack.push(newTopLevelRule);\n      def.call(this);\n      this.recordingProdStack.pop();\n      return newTopLevelRule;\n    } catch (originalError) {\n      if (originalError.KNOWN_RECORDER_ERROR !== true) {\n        try {\n          originalError.message =\n            originalError.message +\n            '\\n\\t This error was thrown during the \"grammar recording phase\" For more info see:\\n\\t' +\n            \"https://chevrotain.io/docs/guide/internals.html#grammar-recording\";\n        } catch (mutabilityError) {\n          // We may not be able to modify the original error object\n          throw originalError;\n        }\n      }\n      throw originalError;\n    }\n  }\n\n  // Implementation of parsing DSL\n  optionInternalRecord<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n    occurrence: number,\n  ): OUT {\n    return recordProd.call(this, Option, actionORMethodDef, occurrence);\n  }\n\n  atLeastOneInternalRecord<OUT>(\n    this: MixedInParser,\n    occurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    recordProd.call(this, RepetitionMandatory, actionORMethodDef, occurrence);\n  }\n\n  atLeastOneSepFirstInternalRecord<OUT>(\n    this: MixedInParser,\n    occurrence: number,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    recordProd.call(\n      this,\n      RepetitionMandatoryWithSeparator,\n      options,\n      occurrence,\n      HANDLE_SEPARATOR,\n    );\n  }\n\n  manyInternalRecord<OUT>(\n    this: MixedInParser,\n    occurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    recordProd.call(this, Repetition, actionORMethodDef, occurrence);\n  }\n\n  manySepFirstInternalRecord<OUT>(\n    this: MixedInParser,\n    occurrence: number,\n    options: ManySepMethodOpts<OUT>,\n  ): void {\n    recordProd.call(\n      this,\n      RepetitionWithSeparator,\n      options,\n      occurrence,\n      HANDLE_SEPARATOR,\n    );\n  }\n\n  orInternalRecord<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n    occurrence: number,\n  ): T {\n    return recordOrProd.call(this, altsOrOpts, occurrence);\n  }\n\n  subruleInternalRecord<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    occurrence: number,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R | CstNode {\n    assertMethodIdxIsValid(occurrence);\n    if (!ruleToCall || has(ruleToCall, \"ruleName\") === false) {\n      const error: any = new Error(\n        `<SUBRULE${getIdxSuffix(occurrence)}> argument is invalid` +\n          ` expecting a Parser method reference but got: <${JSON.stringify(\n            ruleToCall,\n          )}>` +\n          `\\n inside top level rule: <${\n            (<Rule>this.recordingProdStack[0]).name\n          }>`,\n      );\n      error.KNOWN_RECORDER_ERROR = true;\n      throw error;\n    }\n\n    const prevProd: any = peek(this.recordingProdStack);\n    const ruleName = ruleToCall.ruleName;\n    const newNoneTerminal = new NonTerminal({\n      idx: occurrence,\n      nonTerminalName: ruleName,\n      label: options?.LABEL,\n      // The resolving of the `referencedRule` property will be done once all the Rule's GASTs have been created\n      referencedRule: undefined,\n    });\n    prevProd.definition.push(newNoneTerminal);\n\n    return this.outputCst\n      ? RECORDING_PHASE_CSTNODE\n      : <any>RECORDING_NULL_OBJECT;\n  }\n\n  consumeInternalRecord(\n    this: MixedInParser,\n    tokType: TokenType,\n    occurrence: number,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    assertMethodIdxIsValid(occurrence);\n    if (!hasShortKeyProperty(tokType)) {\n      const error: any = new Error(\n        `<CONSUME${getIdxSuffix(occurrence)}> argument is invalid` +\n          ` expecting a TokenType reference but got: <${JSON.stringify(\n            tokType,\n          )}>` +\n          `\\n inside top level rule: <${\n            (<Rule>this.recordingProdStack[0]).name\n          }>`,\n      );\n      error.KNOWN_RECORDER_ERROR = true;\n      throw error;\n    }\n    const prevProd: any = peek(this.recordingProdStack);\n    const newNoneTerminal = new Terminal({\n      idx: occurrence,\n      terminalType: tokType,\n      label: options?.LABEL,\n    });\n    prevProd.definition.push(newNoneTerminal);\n\n    return RECORDING_PHASE_TOKEN;\n  }\n}\n\nfunction recordProd(\n  prodConstructor: any,\n  mainProdArg: any,\n  occurrence: number,\n  handleSep: boolean = false,\n): any {\n  assertMethodIdxIsValid(occurrence);\n  const prevProd: any = peek(this.recordingProdStack);\n  const grammarAction = isFunction(mainProdArg) ? mainProdArg : mainProdArg.DEF;\n\n  const newProd = new prodConstructor({ definition: [], idx: occurrence });\n  if (handleSep) {\n    newProd.separator = mainProdArg.SEP;\n  }\n  if (has(mainProdArg, \"MAX_LOOKAHEAD\")) {\n    newProd.maxLookahead = mainProdArg.MAX_LOOKAHEAD;\n  }\n\n  this.recordingProdStack.push(newProd);\n  grammarAction.call(this);\n  prevProd.definition.push(newProd);\n  this.recordingProdStack.pop();\n\n  return RECORDING_NULL_OBJECT;\n}\n\nfunction recordOrProd(mainProdArg: any, occurrence: number): any {\n  assertMethodIdxIsValid(occurrence);\n  const prevProd: any = peek(this.recordingProdStack);\n  // Only an array of alternatives\n  const hasOptions = isArray(mainProdArg) === false;\n  const alts: IOrAlt<unknown>[] =\n    hasOptions === false ? mainProdArg : mainProdArg.DEF;\n\n  const newOrProd = new Alternation({\n    definition: [],\n    idx: occurrence,\n    ignoreAmbiguities: hasOptions && mainProdArg.IGNORE_AMBIGUITIES === true,\n  });\n  if (has(mainProdArg, \"MAX_LOOKAHEAD\")) {\n    newOrProd.maxLookahead = mainProdArg.MAX_LOOKAHEAD;\n  }\n\n  const hasPredicates = some(alts, (currAlt: any) => isFunction(currAlt.GATE));\n  newOrProd.hasPredicates = hasPredicates;\n\n  prevProd.definition.push(newOrProd);\n\n  forEach(alts, (currAlt) => {\n    const currAltFlat = new Alternative({ definition: [] });\n    newOrProd.definition.push(currAltFlat);\n    if (has(currAlt, \"IGNORE_AMBIGUITIES\")) {\n      currAltFlat.ignoreAmbiguities = currAlt.IGNORE_AMBIGUITIES as boolean; // assumes end user provides the correct config value/type\n    }\n    // **implicit** ignoreAmbiguities due to usage of gate\n    else if (has(currAlt, \"GATE\")) {\n      currAltFlat.ignoreAmbiguities = true;\n    }\n    this.recordingProdStack.push(currAltFlat);\n    currAlt.ALT.call(this);\n    this.recordingProdStack.pop();\n  });\n  return RECORDING_NULL_OBJECT;\n}\n\nfunction getIdxSuffix(idx: number): string {\n  return idx === 0 ? \"\" : `${idx}`;\n}\n\nfunction assertMethodIdxIsValid(idx: number): void {\n  if (idx < 0 || idx > MAX_METHOD_IDX) {\n    const error: any = new Error(\n      // The stack trace will contain all the needed details\n      `Invalid DSL Method idx value: <${idx}>\\n\\t` +\n        `Idx value must be a none negative value smaller than ${\n          MAX_METHOD_IDX + 1\n        }`,\n    );\n    error.KNOWN_RECORDER_ERROR = true;\n    throw error;\n  }\n}\n","import { clone, forEach, has, isEmpty, map, values } from \"lodash-es\";\nimport { toFastProperties } from \"@chevrotain/utils\";\nimport { computeAllProdsFollows } from \"../grammar/follow.js\";\nimport { createTokenInstance, EOF } from \"../../scan/tokens_public.js\";\nimport {\n  defaultGrammarValidatorErrorProvider,\n  defaultParserErrorProvider,\n} from \"../errors_public.js\";\nimport {\n  resolveGrammar,\n  validateGrammar,\n} from \"../grammar/gast/gast_resolver_public.js\";\nimport {\n  CstNode,\n  IParserConfig,\n  IRecognitionException,\n  IRuleConfig,\n  IToken,\n  TokenType,\n  TokenVocabulary,\n} from \"@chevrotain/types\";\nimport { Recoverable } from \"./traits/recoverable.js\";\nimport { LooksAhead } from \"./traits/looksahead.js\";\nimport { TreeBuilder } from \"./traits/tree_builder.js\";\nimport { LexerAdapter } from \"./traits/lexer_adapter.js\";\nimport { RecognizerApi } from \"./traits/recognizer_api.js\";\nimport { RecognizerEngine } from \"./traits/recognizer_engine.js\";\n\nimport { ErrorHandler } from \"./traits/error_handler.js\";\nimport { MixedInParser } from \"./traits/parser_traits.js\";\nimport { ContentAssist } from \"./traits/context_assist.js\";\nimport { GastRecorder } from \"./traits/gast_recorder.js\";\nimport { PerformanceTracer } from \"./traits/perf_tracer.js\";\nimport { applyMixins } from \"./utils/apply_mixins.js\";\nimport { IParserDefinitionError } from \"../grammar/types.js\";\nimport { Rule } from \"@chevrotain/gast\";\nimport { IParserConfigInternal, ParserMethodInternal } from \"./types.js\";\nimport { validateLookahead } from \"../grammar/checks.js\";\n\nexport const END_OF_FILE = createTokenInstance(\n  EOF,\n  \"\",\n  NaN,\n  NaN,\n  NaN,\n  NaN,\n  NaN,\n  NaN,\n);\nObject.freeze(END_OF_FILE);\n\nexport type TokenMatcher = (token: IToken, tokType: TokenType) => boolean;\n\nexport const DEFAULT_PARSER_CONFIG: Required<\n  Omit<IParserConfigInternal, \"lookaheadStrategy\">\n> = Object.freeze({\n  recoveryEnabled: false,\n  maxLookahead: 3,\n  dynamicTokensEnabled: false,\n  outputCst: true,\n  errorMessageProvider: defaultParserErrorProvider,\n  nodeLocationTracking: \"none\",\n  traceInitPerf: false,\n  skipValidations: false,\n});\n\nexport const DEFAULT_RULE_CONFIG: Required<IRuleConfig<any>> = Object.freeze({\n  recoveryValueFunc: () => undefined,\n  resyncEnabled: true,\n});\n\nexport enum ParserDefinitionErrorType {\n  INVALID_RULE_NAME = 0,\n  DUPLICATE_RULE_NAME = 1,\n  INVALID_RULE_OVERRIDE = 2,\n  DUPLICATE_PRODUCTIONS = 3,\n  UNRESOLVED_SUBRULE_REF = 4,\n  LEFT_RECURSION = 5,\n  NONE_LAST_EMPTY_ALT = 6,\n  AMBIGUOUS_ALTS = 7,\n  CONFLICT_TOKENS_RULES_NAMESPACE = 8,\n  INVALID_TOKEN_NAME = 9,\n  NO_NON_EMPTY_LOOKAHEAD = 10,\n  AMBIGUOUS_PREFIX_ALTS = 11,\n  TOO_MANY_ALTS = 12,\n  CUSTOM_LOOKAHEAD_VALIDATION = 13,\n}\n\nexport interface IParserDuplicatesDefinitionError\n  extends IParserDefinitionError {\n  dslName: string;\n  occurrence: number;\n  parameter?: string;\n}\n\nexport interface IParserEmptyAlternativeDefinitionError\n  extends IParserDefinitionError {\n  occurrence: number;\n  alternative: number;\n}\n\nexport interface IParserAmbiguousAlternativesDefinitionError\n  extends IParserDefinitionError {\n  occurrence: number | string;\n  alternatives: number[];\n}\n\nexport interface IParserUnresolvedRefDefinitionError\n  extends IParserDefinitionError {\n  unresolvedRefName: string;\n}\n\nexport interface IParserState {\n  errors: IRecognitionException[];\n  lexerState: any;\n  RULE_STACK: number[];\n  CST_STACK: CstNode[];\n}\n\nexport type Predicate = () => boolean;\n\nexport function EMPTY_ALT(): () => undefined;\nexport function EMPTY_ALT<T>(value: T): () => T;\nexport function EMPTY_ALT(value: any = undefined) {\n  return function () {\n    return value;\n  };\n}\n\nexport class Parser {\n  // Set this flag to true if you don't want the Parser to throw error when problems in it's definition are detected.\n  // (normally during the parser's constructor).\n  // This is a design time flag, it will not affect the runtime error handling of the parser, just design time errors,\n  // for example: duplicate rule names, referencing an unresolved subrule, ect...\n  // This flag should not be enabled during normal usage, it is used in special situations, for example when\n  // needing to display the parser definition errors in some GUI(online playground).\n  static DEFER_DEFINITION_ERRORS_HANDLING: boolean = false;\n\n  /**\n   *  @deprecated use the **instance** method with the same name instead\n   */\n  static performSelfAnalysis(parserInstance: Parser): void {\n    throw Error(\n      \"The **static** `performSelfAnalysis` method has been deprecated.\" +\n        \"\\t\\nUse the **instance** method with the same name instead.\",\n    );\n  }\n\n  public performSelfAnalysis(this: MixedInParser): void {\n    this.TRACE_INIT(\"performSelfAnalysis\", () => {\n      let defErrorsMsgs;\n\n      this.selfAnalysisDone = true;\n      const className = this.className;\n\n      this.TRACE_INIT(\"toFastProps\", () => {\n        // Without this voodoo magic the parser would be x3-x4 slower\n        // It seems it is better to invoke `toFastProperties` **before**\n        // Any manipulations of the `this` object done during the recording phase.\n        toFastProperties(this);\n      });\n\n      this.TRACE_INIT(\"Grammar Recording\", () => {\n        try {\n          this.enableRecording();\n          // Building the GAST\n          forEach(this.definedRulesNames, (currRuleName) => {\n            const wrappedRule = (this as any)[\n              currRuleName\n            ] as ParserMethodInternal<unknown[], unknown>;\n            const originalGrammarAction = wrappedRule[\"originalGrammarAction\"];\n            let recordedRuleGast!: Rule;\n            this.TRACE_INIT(`${currRuleName} Rule`, () => {\n              recordedRuleGast = this.topLevelRuleRecord(\n                currRuleName,\n                originalGrammarAction,\n              );\n            });\n            this.gastProductionsCache[currRuleName] = recordedRuleGast;\n          });\n        } finally {\n          this.disableRecording();\n        }\n      });\n\n      let resolverErrors: IParserDefinitionError[] = [];\n      this.TRACE_INIT(\"Grammar Resolving\", () => {\n        resolverErrors = resolveGrammar({\n          rules: values(this.gastProductionsCache),\n        });\n        this.definitionErrors = this.definitionErrors.concat(resolverErrors);\n      });\n\n      this.TRACE_INIT(\"Grammar Validations\", () => {\n        // only perform additional grammar validations IFF no resolving errors have occurred.\n        // as unresolved grammar may lead to unhandled runtime exceptions in the follow up validations.\n        if (isEmpty(resolverErrors) && this.skipValidations === false) {\n          const validationErrors = validateGrammar({\n            rules: values(this.gastProductionsCache),\n            tokenTypes: values(this.tokensMap),\n            errMsgProvider: defaultGrammarValidatorErrorProvider,\n            grammarName: className,\n          });\n          const lookaheadValidationErrors = validateLookahead({\n            lookaheadStrategy: this.lookaheadStrategy,\n            rules: values(this.gastProductionsCache),\n            tokenTypes: values(this.tokensMap),\n            grammarName: className,\n          });\n          this.definitionErrors = this.definitionErrors.concat(\n            validationErrors,\n            lookaheadValidationErrors,\n          );\n        }\n      });\n\n      // this analysis may fail if the grammar is not perfectly valid\n      if (isEmpty(this.definitionErrors)) {\n        // The results of these computations are not needed unless error recovery is enabled.\n        if (this.recoveryEnabled) {\n          this.TRACE_INIT(\"computeAllProdsFollows\", () => {\n            const allFollows = computeAllProdsFollows(\n              values(this.gastProductionsCache),\n            );\n            this.resyncFollows = allFollows;\n          });\n        }\n\n        this.TRACE_INIT(\"ComputeLookaheadFunctions\", () => {\n          this.lookaheadStrategy.initialize?.({\n            rules: values(this.gastProductionsCache),\n          });\n          this.preComputeLookaheadFunctions(values(this.gastProductionsCache));\n        });\n      }\n\n      if (\n        !Parser.DEFER_DEFINITION_ERRORS_HANDLING &&\n        !isEmpty(this.definitionErrors)\n      ) {\n        defErrorsMsgs = map(\n          this.definitionErrors,\n          (defError) => defError.message,\n        );\n        throw new Error(\n          `Parser Definition Errors detected:\\n ${defErrorsMsgs.join(\n            \"\\n-------------------------------\\n\",\n          )}`,\n        );\n      }\n    });\n  }\n\n  definitionErrors: IParserDefinitionError[] = [];\n  selfAnalysisDone = false;\n  protected skipValidations: boolean;\n\n  constructor(tokenVocabulary: TokenVocabulary, config: IParserConfig) {\n    const that: MixedInParser = this as any;\n    that.initErrorHandler(config);\n    that.initLexerAdapter();\n    that.initLooksAhead(config);\n    that.initRecognizerEngine(tokenVocabulary, config);\n    that.initRecoverable(config);\n    that.initTreeBuilder(config);\n    that.initContentAssist();\n    that.initGastRecorder(config);\n    that.initPerformanceTracer(config);\n\n    if (has(config, \"ignoredIssues\")) {\n      throw new Error(\n        \"The <ignoredIssues> IParserConfig property has been deprecated.\\n\\t\" +\n          \"Please use the <IGNORE_AMBIGUITIES> flag on the relevant DSL method instead.\\n\\t\" +\n          \"See: https://chevrotain.io/docs/guide/resolving_grammar_errors.html#IGNORING_AMBIGUITIES\\n\\t\" +\n          \"For further details.\",\n      );\n    }\n\n    this.skipValidations = has(config, \"skipValidations\")\n      ? (config.skipValidations as boolean) // casting assumes the end user passing the correct type\n      : DEFAULT_PARSER_CONFIG.skipValidations;\n  }\n}\n\napplyMixins(Parser, [\n  Recoverable,\n  LooksAhead,\n  TreeBuilder,\n  LexerAdapter,\n  RecognizerEngine,\n  RecognizerApi,\n  ErrorHandler,\n  ContentAssist,\n  GastRecorder,\n  PerformanceTracer,\n]);\n\nexport class CstParser extends Parser {\n  constructor(\n    tokenVocabulary: TokenVocabulary,\n    config: IParserConfigInternal = DEFAULT_PARSER_CONFIG,\n  ) {\n    const configClone = clone(config);\n    configClone.outputCst = true;\n    super(tokenVocabulary, configClone);\n  }\n}\n\nexport class EmbeddedActionsParser extends Parser {\n  constructor(\n    tokenVocabulary: TokenVocabulary,\n    config: IParserConfigInternal = DEFAULT_PARSER_CONFIG,\n  ) {\n    const configClone = clone(config);\n    configClone.outputCst = false;\n    super(tokenVocabulary, configClone);\n  }\n}\n","export function applyMixins(derivedCtor: any, baseCtors: any[]) {\n  baseCtors.forEach((baseCtor) => {\n    const baseProto = baseCtor.prototype;\n    Object.getOwnPropertyNames(baseProto).forEach((propName) => {\n      if (propName === \"constructor\") {\n        return;\n      }\n\n      const basePropDescriptor = Object.getOwnPropertyDescriptor(\n        baseProto,\n        propName,\n      );\n      // Handle Accessors\n      if (\n        basePropDescriptor &&\n        (basePropDescriptor.get || basePropDescriptor.set)\n      ) {\n        Object.defineProperty(\n          derivedCtor.prototype,\n          propName,\n          basePropDescriptor,\n        );\n      } else {\n        derivedCtor.prototype[propName] = baseCtor.prototype[propName];\n      }\n    });\n  });\n}\n","import {\n  addNoneTerminalToCst,\n  addTerminalToCst,\n  setNodeLocationFull,\n  setNodeLocationOnlyOffset,\n} from \"../../cst/cst.js\";\nimport { has, isUndefined, keys, noop } from \"lodash-es\";\nimport {\n  createBaseSemanticVisitorConstructor,\n  createBaseVisitorConstructorWithDefaults,\n} from \"../../cst/cst_visitor.js\";\nimport {\n  CstNode,\n  CstNodeLocation,\n  ICstVisitor,\n  IParserConfig,\n  IToken,\n  nodeLocationTrackingOptions,\n} from \"@chevrotain/types\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n\n/**\n * This trait is responsible for the CST building logic.\n */\nexport class TreeBuilder {\n  outputCst: boolean;\n  CST_STACK: CstNode[];\n  baseCstVisitorConstructor: Function;\n  baseCstVisitorWithDefaultsConstructor: Function;\n\n  // dynamically assigned Methods\n  setNodeLocationFromNode: (\n    nodeLocation: CstNodeLocation,\n    locationInformation: CstNodeLocation,\n  ) => void;\n  setNodeLocationFromToken: (\n    nodeLocation: CstNodeLocation,\n    locationInformation: CstNodeLocation,\n  ) => void;\n  cstPostRule: (this: MixedInParser, ruleCstNode: CstNode) => void;\n\n  setInitialNodeLocation: (cstNode: CstNode) => void;\n  nodeLocationTracking: nodeLocationTrackingOptions;\n\n  initTreeBuilder(this: MixedInParser, config: IParserConfig) {\n    this.CST_STACK = [];\n\n    // outputCst is no longer exposed/defined in the pubic API\n    this.outputCst = (config as any).outputCst;\n\n    this.nodeLocationTracking = has(config, \"nodeLocationTracking\")\n      ? (config.nodeLocationTracking as nodeLocationTrackingOptions) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.nodeLocationTracking;\n\n    if (!this.outputCst) {\n      this.cstInvocationStateUpdate = noop;\n      this.cstFinallyStateUpdate = noop;\n      this.cstPostTerminal = noop;\n      this.cstPostNonTerminal = noop;\n      this.cstPostRule = noop;\n    } else {\n      if (/full/i.test(this.nodeLocationTracking)) {\n        if (this.recoveryEnabled) {\n          this.setNodeLocationFromToken = setNodeLocationFull;\n          this.setNodeLocationFromNode = setNodeLocationFull;\n          this.cstPostRule = noop;\n          this.setInitialNodeLocation = this.setInitialNodeLocationFullRecovery;\n        } else {\n          this.setNodeLocationFromToken = noop;\n          this.setNodeLocationFromNode = noop;\n          this.cstPostRule = this.cstPostRuleFull;\n          this.setInitialNodeLocation = this.setInitialNodeLocationFullRegular;\n        }\n      } else if (/onlyOffset/i.test(this.nodeLocationTracking)) {\n        if (this.recoveryEnabled) {\n          this.setNodeLocationFromToken = <any>setNodeLocationOnlyOffset;\n          this.setNodeLocationFromNode = <any>setNodeLocationOnlyOffset;\n          this.cstPostRule = noop;\n          this.setInitialNodeLocation =\n            this.setInitialNodeLocationOnlyOffsetRecovery;\n        } else {\n          this.setNodeLocationFromToken = noop;\n          this.setNodeLocationFromNode = noop;\n          this.cstPostRule = this.cstPostRuleOnlyOffset;\n          this.setInitialNodeLocation =\n            this.setInitialNodeLocationOnlyOffsetRegular;\n        }\n      } else if (/none/i.test(this.nodeLocationTracking)) {\n        this.setNodeLocationFromToken = noop;\n        this.setNodeLocationFromNode = noop;\n        this.cstPostRule = noop;\n        this.setInitialNodeLocation = noop;\n      } else {\n        throw Error(\n          `Invalid <nodeLocationTracking> config option: \"${config.nodeLocationTracking}\"`,\n        );\n      }\n    }\n  }\n\n  setInitialNodeLocationOnlyOffsetRecovery(\n    this: MixedInParser,\n    cstNode: any,\n  ): void {\n    cstNode.location = {\n      startOffset: NaN,\n      endOffset: NaN,\n    };\n  }\n\n  setInitialNodeLocationOnlyOffsetRegular(\n    this: MixedInParser,\n    cstNode: any,\n  ): void {\n    cstNode.location = {\n      // without error recovery the starting Location of a new CstNode is guaranteed\n      // To be the next Token's startOffset (for valid inputs).\n      // For invalid inputs there won't be any CSTOutput so this potential\n      // inaccuracy does not matter\n      startOffset: this.LA(1).startOffset,\n      endOffset: NaN,\n    };\n  }\n\n  setInitialNodeLocationFullRecovery(this: MixedInParser, cstNode: any): void {\n    cstNode.location = {\n      startOffset: NaN,\n      startLine: NaN,\n      startColumn: NaN,\n      endOffset: NaN,\n      endLine: NaN,\n      endColumn: NaN,\n    };\n  }\n\n  /**\n     *  @see setInitialNodeLocationOnlyOffsetRegular for explanation why this work\n\n     * @param cstNode\n     */\n  setInitialNodeLocationFullRegular(this: MixedInParser, cstNode: any): void {\n    const nextToken = this.LA(1);\n    cstNode.location = {\n      startOffset: nextToken.startOffset,\n      startLine: nextToken.startLine,\n      startColumn: nextToken.startColumn,\n      endOffset: NaN,\n      endLine: NaN,\n      endColumn: NaN,\n    };\n  }\n\n  cstInvocationStateUpdate(this: MixedInParser, fullRuleName: string): void {\n    const cstNode: CstNode = {\n      name: fullRuleName,\n      children: Object.create(null),\n    };\n\n    this.setInitialNodeLocation(cstNode);\n    this.CST_STACK.push(cstNode);\n  }\n\n  cstFinallyStateUpdate(this: MixedInParser): void {\n    this.CST_STACK.pop();\n  }\n\n  cstPostRuleFull(this: MixedInParser, ruleCstNode: CstNode): void {\n    // casts to `required<CstNodeLocation>` are safe because `cstPostRuleFull` should only be invoked when full location is enabled\n    const prevToken = this.LA(0) as Required<CstNodeLocation>;\n    const loc = ruleCstNode.location as Required<CstNodeLocation>;\n\n    // If this condition is true it means we consumed at least one Token\n    // In this CstNode.\n    if (loc.startOffset <= prevToken.startOffset === true) {\n      loc.endOffset = prevToken.endOffset;\n      loc.endLine = prevToken.endLine;\n      loc.endColumn = prevToken.endColumn;\n    }\n    // \"empty\" CstNode edge case\n    else {\n      loc.startOffset = NaN;\n      loc.startLine = NaN;\n      loc.startColumn = NaN;\n    }\n  }\n\n  cstPostRuleOnlyOffset(this: MixedInParser, ruleCstNode: CstNode): void {\n    const prevToken = this.LA(0);\n    // `location' is not null because `cstPostRuleOnlyOffset` will only be invoked when location tracking is enabled.\n    const loc = ruleCstNode.location!;\n\n    // If this condition is true it means we consumed at least one Token\n    // In this CstNode.\n    if (loc.startOffset <= prevToken.startOffset === true) {\n      loc.endOffset = prevToken.endOffset;\n    }\n    // \"empty\" CstNode edge case\n    else {\n      loc.startOffset = NaN;\n    }\n  }\n\n  cstPostTerminal(\n    this: MixedInParser,\n    key: string,\n    consumedToken: IToken,\n  ): void {\n    const rootCst = this.CST_STACK[this.CST_STACK.length - 1];\n    addTerminalToCst(rootCst, consumedToken, key);\n    // This is only used when **both** error recovery and CST Output are enabled.\n    this.setNodeLocationFromToken(rootCst.location!, <any>consumedToken);\n  }\n\n  cstPostNonTerminal(\n    this: MixedInParser,\n    ruleCstResult: CstNode,\n    ruleName: string,\n  ): void {\n    const preCstNode = this.CST_STACK[this.CST_STACK.length - 1];\n    addNoneTerminalToCst(preCstNode, ruleName, ruleCstResult);\n    // This is only used when **both** error recovery and CST Output are enabled.\n    this.setNodeLocationFromNode(preCstNode.location!, ruleCstResult.location!);\n  }\n\n  getBaseCstVisitorConstructor<IN = any, OUT = any>(\n    this: MixedInParser,\n  ): {\n    new (...args: any[]): ICstVisitor<IN, OUT>;\n  } {\n    if (isUndefined(this.baseCstVisitorConstructor)) {\n      const newBaseCstVisitorConstructor = createBaseSemanticVisitorConstructor(\n        this.className,\n        keys(this.gastProductionsCache),\n      );\n      this.baseCstVisitorConstructor = newBaseCstVisitorConstructor;\n      return newBaseCstVisitorConstructor;\n    }\n\n    return <any>this.baseCstVisitorConstructor;\n  }\n\n  getBaseCstVisitorConstructorWithDefaults<IN = any, OUT = any>(\n    this: MixedInParser,\n  ): {\n    new (...args: any[]): ICstVisitor<IN, OUT>;\n  } {\n    if (isUndefined(this.baseCstVisitorWithDefaultsConstructor)) {\n      const newConstructor = createBaseVisitorConstructorWithDefaults(\n        this.className,\n        keys(this.gastProductionsCache),\n        this.getBaseCstVisitorConstructor(),\n      );\n      this.baseCstVisitorWithDefaultsConstructor = newConstructor;\n      return newConstructor;\n    }\n\n    return <any>this.baseCstVisitorWithDefaultsConstructor;\n  }\n\n  getLastExplicitRuleShortName(this: MixedInParser): number {\n    const ruleStack = this.RULE_STACK;\n    return ruleStack[ruleStack.length - 1];\n  }\n\n  getPreviousExplicitRuleShortName(this: MixedInParser): number {\n    const ruleStack = this.RULE_STACK;\n    return ruleStack[ruleStack.length - 2];\n  }\n\n  getLastExplicitRuleOccurrenceIndex(this: MixedInParser): number {\n    const occurrenceStack = this.RULE_OCCURRENCE_STACK;\n    return occurrenceStack[occurrenceStack.length - 1];\n  }\n}\n","import { END_OF_FILE } from \"../parser.js\";\nimport { IToken } from \"@chevrotain/types\";\nimport { MixedInParser } from \"./parser_traits.js\";\n\n/**\n * Trait responsible abstracting over the interaction with Lexer output (Token vector).\n *\n * This could be generalized to support other kinds of lexers, e.g.\n * - Just in Time Lexing / Lexer-Less parsing.\n * - Streaming Lexer.\n */\nexport class LexerAdapter {\n  tokVector: IToken[];\n  tokVectorLength: number;\n  currIdx: number;\n\n  initLexerAdapter() {\n    this.tokVector = [];\n    this.tokVectorLength = 0;\n    this.currIdx = -1;\n  }\n\n  set input(newInput: IToken[]) {\n    // @ts-ignore - `this parameter` not supported in setters/getters\n    //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n    if (this.selfAnalysisDone !== true) {\n      throw Error(\n        `Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.`,\n      );\n    }\n    // @ts-ignore - `this parameter` not supported in setters/getters\n    //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n    this.reset();\n    this.tokVector = newInput;\n    this.tokVectorLength = newInput.length;\n  }\n\n  get input(): IToken[] {\n    return this.tokVector;\n  }\n\n  // skips a token and returns the next token\n  SKIP_TOKEN(this: MixedInParser): IToken {\n    if (this.currIdx <= this.tokVector.length - 2) {\n      this.consumeToken();\n      return this.LA(1);\n    } else {\n      return END_OF_FILE;\n    }\n  }\n\n  // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n  // or lexers dependent on parser context.\n  LA(this: MixedInParser, howMuch: number): IToken {\n    const soughtIdx = this.currIdx + howMuch;\n    if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n      return END_OF_FILE;\n    } else {\n      return this.tokVector[soughtIdx];\n    }\n  }\n\n  consumeToken(this: MixedInParser) {\n    this.currIdx++;\n  }\n\n  exportLexerState(this: MixedInParser): number {\n    return this.currIdx;\n  }\n\n  importLexerState(this: MixedInParser, newState: number) {\n    this.currIdx = newState;\n  }\n\n  resetLexerState(this: MixedInParser): void {\n    this.currIdx = -1;\n  }\n\n  moveToTerminatedState(this: MixedInParser): void {\n    this.currIdx = this.tokVector.length - 1;\n  }\n\n  getLexerPosition(this: MixedInParser): number {\n    return this.exportLexerState();\n  }\n}\n","import {\n  AtLeastOneSepMethodOpts,\n  ConsumeMethodOpts,\n  DSLMethodOpts,\n  DSLMethodOptsWithErr,\n  GrammarAction,\n  IOrAlt,\n  IParserConfig,\n  IRuleConfig,\n  IToken,\n  ManySepMethodOpts,\n  OrMethodOpts,\n  ParserMethod,\n  SubruleMethodOpts,\n  TokenType,\n  TokenTypeDictionary,\n  TokenVocabulary,\n} from \"@chevrotain/types\";\nimport {\n  clone,\n  every,\n  flatten,\n  has,\n  isArray,\n  isEmpty,\n  isObject,\n  reduce,\n  uniq,\n  values,\n} from \"lodash-es\";\nimport {\n  AT_LEAST_ONE_IDX,\n  AT_LEAST_ONE_SEP_IDX,\n  BITS_FOR_METHOD_TYPE,\n  BITS_FOR_OCCURRENCE_IDX,\n  MANY_IDX,\n  MANY_SEP_IDX,\n  OPTION_IDX,\n  OR_IDX,\n} from \"../../grammar/keys.js\";\nimport {\n  isRecognitionException,\n  MismatchedTokenException,\n  NotAllInputParsedException,\n} from \"../../exceptions_public.js\";\nimport { PROD_TYPE } from \"../../grammar/lookahead.js\";\nimport {\n  AbstractNextTerminalAfterProductionWalker,\n  NextTerminalAfterAtLeastOneSepWalker,\n  NextTerminalAfterAtLeastOneWalker,\n  NextTerminalAfterManySepWalker,\n  NextTerminalAfterManyWalker,\n} from \"../../grammar/interpreter.js\";\nimport { DEFAULT_RULE_CONFIG, IParserState, TokenMatcher } from \"../parser.js\";\nimport { IN_RULE_RECOVERY_EXCEPTION } from \"./recoverable.js\";\nimport { EOF } from \"../../../scan/tokens_public.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport {\n  augmentTokenTypes,\n  isTokenType,\n  tokenStructuredMatcher,\n  tokenStructuredMatcherNoCategories,\n} from \"../../../scan/tokens.js\";\nimport { Rule } from \"@chevrotain/gast\";\nimport { ParserMethodInternal } from \"../types.js\";\n\n/**\n * This trait is responsible for the runtime parsing engine\n * Used by the official API (recognizer_api.ts)\n */\nexport class RecognizerEngine {\n  isBackTrackingStack: boolean[];\n  className: string;\n  RULE_STACK: number[];\n  RULE_OCCURRENCE_STACK: number[];\n  definedRulesNames: string[];\n  tokensMap: { [fqn: string]: TokenType };\n  gastProductionsCache: Record<string, Rule>;\n  shortRuleNameToFull: Record<string, string>;\n  fullRuleNameToShort: Record<string, number>;\n  // The shortName Index must be coded \"after\" the first 8bits to enable building unique lookahead keys\n  ruleShortNameIdx: number;\n  tokenMatcher: TokenMatcher;\n  subruleIdx: number;\n\n  initRecognizerEngine(\n    tokenVocabulary: TokenVocabulary,\n    config: IParserConfig,\n  ) {\n    this.className = this.constructor.name;\n    // TODO: would using an ES6 Map or plain object be faster (CST building scenario)\n    this.shortRuleNameToFull = {};\n    this.fullRuleNameToShort = {};\n    this.ruleShortNameIdx = 256;\n    this.tokenMatcher = tokenStructuredMatcherNoCategories;\n    this.subruleIdx = 0;\n\n    this.definedRulesNames = [];\n    this.tokensMap = {};\n    this.isBackTrackingStack = [];\n    this.RULE_STACK = [];\n    this.RULE_OCCURRENCE_STACK = [];\n    this.gastProductionsCache = {};\n\n    if (has(config, \"serializedGrammar\")) {\n      throw Error(\n        \"The Parser's configuration can no longer contain a <serializedGrammar> property.\\n\" +\n          \"\\tSee: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_6-0-0\\n\" +\n          \"\\tFor Further details.\",\n      );\n    }\n\n    if (isArray(tokenVocabulary)) {\n      // This only checks for Token vocabularies provided as arrays.\n      // That is good enough because the main objective is to detect users of pre-V4.0 APIs\n      // rather than all edge cases of empty Token vocabularies.\n      if (isEmpty(tokenVocabulary as any[])) {\n        throw Error(\n          \"A Token Vocabulary cannot be empty.\\n\" +\n            \"\\tNote that the first argument for the parser constructor\\n\" +\n            \"\\tis no longer a Token vector (since v4.0).\",\n        );\n      }\n\n      if (typeof (tokenVocabulary as any[])[0].startOffset === \"number\") {\n        throw Error(\n          \"The Parser constructor no longer accepts a token vector as the first argument.\\n\" +\n            \"\\tSee: https://chevrotain.io/docs/changes/BREAKING_CHANGES.html#_4-0-0\\n\" +\n            \"\\tFor Further details.\",\n        );\n      }\n    }\n\n    if (isArray(tokenVocabulary)) {\n      this.tokensMap = reduce(\n        tokenVocabulary,\n        (acc, tokType: TokenType) => {\n          acc[tokType.name] = tokType;\n          return acc;\n        },\n        {} as { [tokenName: string]: TokenType },\n      );\n    } else if (\n      has(tokenVocabulary, \"modes\") &&\n      every(flatten(values((<any>tokenVocabulary).modes)), isTokenType)\n    ) {\n      const allTokenTypes = flatten(values((<any>tokenVocabulary).modes));\n      const uniqueTokens = uniq(allTokenTypes);\n      this.tokensMap = <any>reduce(\n        uniqueTokens,\n        (acc, tokType: TokenType) => {\n          acc[tokType.name] = tokType;\n          return acc;\n        },\n        {} as { [tokenName: string]: TokenType },\n      );\n    } else if (isObject(tokenVocabulary)) {\n      this.tokensMap = clone(tokenVocabulary as TokenTypeDictionary);\n    } else {\n      throw new Error(\n        \"<tokensDictionary> argument must be An Array of Token constructors,\" +\n          \" A dictionary of Token constructors or an IMultiModeLexerDefinition\",\n      );\n    }\n\n    // always add EOF to the tokenNames -> constructors map. it is useful to assure all the input has been\n    // parsed with a clear error message (\"expecting EOF but found ...\")\n    this.tokensMap[\"EOF\"] = EOF;\n\n    const allTokenTypes = has(tokenVocabulary, \"modes\")\n      ? flatten(values((<any>tokenVocabulary).modes))\n      : values(tokenVocabulary);\n    const noTokenCategoriesUsed = every(allTokenTypes, (tokenConstructor) =>\n      isEmpty(tokenConstructor.categoryMatches),\n    );\n\n    this.tokenMatcher = noTokenCategoriesUsed\n      ? tokenStructuredMatcherNoCategories\n      : tokenStructuredMatcher;\n\n    // Because ES2015+ syntax should be supported for creating Token classes\n    // We cannot assume that the Token classes were created using the \"extendToken\" utilities\n    // Therefore we must augment the Token classes both on Lexer initialization and on Parser initialization\n    augmentTokenTypes(values(this.tokensMap));\n  }\n\n  defineRule<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleName: string,\n    impl: (...args: ARGS) => R,\n    config: IRuleConfig<R>,\n  ): ParserMethodInternal<ARGS, R> {\n    if (this.selfAnalysisDone) {\n      throw Error(\n        `Grammar rule <${ruleName}> may not be defined after the 'performSelfAnalysis' method has been called'\\n` +\n          `Make sure that all grammar rule definitions are done before 'performSelfAnalysis' is called.`,\n      );\n    }\n    const resyncEnabled: boolean = has(config, \"resyncEnabled\")\n      ? (config.resyncEnabled as boolean) // assumes end user provides the correct config value/type\n      : DEFAULT_RULE_CONFIG.resyncEnabled;\n    const recoveryValueFunc = has(config, \"recoveryValueFunc\")\n      ? (config.recoveryValueFunc as () => R) // assumes end user provides the correct config value/type\n      : DEFAULT_RULE_CONFIG.recoveryValueFunc;\n\n    // performance optimization: Use small integers as keys for the longer human readable \"full\" rule names.\n    // this greatly improves Map access time (as much as 8% for some performance benchmarks).\n    const shortName =\n      this.ruleShortNameIdx << (BITS_FOR_METHOD_TYPE + BITS_FOR_OCCURRENCE_IDX);\n\n    this.ruleShortNameIdx++;\n    this.shortRuleNameToFull[shortName] = ruleName;\n    this.fullRuleNameToShort[ruleName] = shortName;\n\n    let invokeRuleWithTry: ParserMethod<ARGS, R>;\n\n    // Micro optimization, only check the condition **once** on rule definition\n    // instead of **every single** rule invocation.\n    if (this.outputCst === true) {\n      invokeRuleWithTry = function invokeRuleWithTry(\n        this: MixedInParser,\n        ...args: ARGS\n      ): R {\n        try {\n          this.ruleInvocationStateUpdate(shortName, ruleName, this.subruleIdx);\n          impl.apply(this, args);\n          const cst = this.CST_STACK[this.CST_STACK.length - 1];\n          this.cstPostRule(cst);\n          return cst as unknown as R;\n        } catch (e) {\n          return this.invokeRuleCatch(e, resyncEnabled, recoveryValueFunc) as R;\n        } finally {\n          this.ruleFinallyStateUpdate();\n        }\n      };\n    } else {\n      invokeRuleWithTry = function invokeRuleWithTryCst(\n        this: MixedInParser,\n        ...args: ARGS\n      ): R {\n        try {\n          this.ruleInvocationStateUpdate(shortName, ruleName, this.subruleIdx);\n          return impl.apply(this, args);\n        } catch (e) {\n          return this.invokeRuleCatch(e, resyncEnabled, recoveryValueFunc) as R;\n        } finally {\n          this.ruleFinallyStateUpdate();\n        }\n      };\n    }\n\n    const wrappedGrammarRule: ParserMethodInternal<ARGS, R> = Object.assign(\n      invokeRuleWithTry as any,\n      { ruleName, originalGrammarAction: impl },\n    );\n\n    return wrappedGrammarRule;\n  }\n\n  invokeRuleCatch(\n    this: MixedInParser,\n    e: Error,\n    resyncEnabledConfig: boolean,\n    recoveryValueFunc: Function,\n  ): unknown {\n    const isFirstInvokedRule = this.RULE_STACK.length === 1;\n    // note the reSync is always enabled for the first rule invocation, because we must always be able to\n    // reSync with EOF and just output some INVALID ParseTree\n    // during backtracking reSync recovery is disabled, otherwise we can't be certain the backtracking\n    // path is really the most valid one\n    const reSyncEnabled =\n      resyncEnabledConfig && !this.isBackTracking() && this.recoveryEnabled;\n\n    if (isRecognitionException(e)) {\n      const recogError: any = e;\n      if (reSyncEnabled) {\n        const reSyncTokType = this.findReSyncTokenType();\n        if (this.isInCurrentRuleReSyncSet(reSyncTokType)) {\n          recogError.resyncedTokens = this.reSyncTo(reSyncTokType);\n          if (this.outputCst) {\n            const partialCstResult: any =\n              this.CST_STACK[this.CST_STACK.length - 1];\n            partialCstResult.recoveredNode = true;\n            return partialCstResult;\n          } else {\n            return recoveryValueFunc(e);\n          }\n        } else {\n          if (this.outputCst) {\n            const partialCstResult: any =\n              this.CST_STACK[this.CST_STACK.length - 1];\n            partialCstResult.recoveredNode = true;\n            recogError.partialCstResult = partialCstResult;\n          }\n          // to be handled Further up the call stack\n          throw recogError;\n        }\n      } else if (isFirstInvokedRule) {\n        // otherwise a Redundant input error will be created as well and we cannot guarantee that this is indeed the case\n        this.moveToTerminatedState();\n        // the parser should never throw one of its own errors outside its flow.\n        // even if error recovery is disabled\n        return recoveryValueFunc(e);\n      } else {\n        // to be recovered Further up the call stack\n        throw recogError;\n      }\n    } else {\n      // some other Error type which we don't know how to handle (for example a built in JavaScript Error)\n      throw e;\n    }\n  }\n\n  // Implementation of parsing DSL\n  optionInternal<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n    occurrence: number,\n  ): OUT | undefined {\n    const key = this.getKeyForAutomaticLookahead(OPTION_IDX, occurrence);\n    return this.optionInternalLogic(actionORMethodDef, occurrence, key);\n  }\n\n  optionInternalLogic<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n    occurrence: number,\n    key: number,\n  ): OUT | undefined {\n    let lookAheadFunc = this.getLaFuncFromCache(key);\n    let action: GrammarAction<OUT>;\n    if (typeof actionORMethodDef !== \"function\") {\n      action = actionORMethodDef.DEF;\n      const predicate = actionORMethodDef.GATE;\n      // predicate present\n      if (predicate !== undefined) {\n        const orgLookaheadFunction = lookAheadFunc;\n        lookAheadFunc = () => {\n          return predicate.call(this) && orgLookaheadFunction.call(this);\n        };\n      }\n    } else {\n      action = actionORMethodDef;\n    }\n\n    if (lookAheadFunc.call(this) === true) {\n      return action.call(this);\n    }\n    return undefined;\n  }\n\n  atLeastOneInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    const laKey = this.getKeyForAutomaticLookahead(\n      AT_LEAST_ONE_IDX,\n      prodOccurrence,\n    );\n    return this.atLeastOneInternalLogic(\n      prodOccurrence,\n      actionORMethodDef,\n      laKey,\n    );\n  }\n\n  atLeastOneInternalLogic<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n    key: number,\n  ): void {\n    let lookAheadFunc = this.getLaFuncFromCache(key);\n    let action;\n    if (typeof actionORMethodDef !== \"function\") {\n      action = actionORMethodDef.DEF;\n      const predicate = actionORMethodDef.GATE;\n      // predicate present\n      if (predicate !== undefined) {\n        const orgLookaheadFunction = lookAheadFunc;\n        lookAheadFunc = () => {\n          return predicate.call(this) && orgLookaheadFunction.call(this);\n        };\n      }\n    } else {\n      action = actionORMethodDef;\n    }\n\n    if ((<Function>lookAheadFunc).call(this) === true) {\n      let notStuck = this.doSingleRepetition(action);\n      while (\n        (<Function>lookAheadFunc).call(this) === true &&\n        notStuck === true\n      ) {\n        notStuck = this.doSingleRepetition(action);\n      }\n    } else {\n      throw this.raiseEarlyExitException(\n        prodOccurrence,\n        PROD_TYPE.REPETITION_MANDATORY,\n        (<DSLMethodOptsWithErr<OUT>>actionORMethodDef).ERR_MSG,\n      );\n    }\n\n    // note that while it may seem that this can cause an error because by using a recursive call to\n    // AT_LEAST_ONE we change the grammar to AT_LEAST_TWO, AT_LEAST_THREE ... , the possible recursive call\n    // from the tryInRepetitionRecovery(...) will only happen IFF there really are TWO/THREE/.... items.\n\n    // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n    this.attemptInRepetitionRecovery(\n      this.atLeastOneInternal,\n      [prodOccurrence, actionORMethodDef],\n      <any>lookAheadFunc,\n      AT_LEAST_ONE_IDX,\n      prodOccurrence,\n      NextTerminalAfterAtLeastOneWalker,\n    );\n  }\n\n  atLeastOneSepFirstInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    const laKey = this.getKeyForAutomaticLookahead(\n      AT_LEAST_ONE_SEP_IDX,\n      prodOccurrence,\n    );\n    this.atLeastOneSepFirstInternalLogic(prodOccurrence, options, laKey);\n  }\n\n  atLeastOneSepFirstInternalLogic<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    options: AtLeastOneSepMethodOpts<OUT>,\n    key: number,\n  ): void {\n    const action = options.DEF;\n    const separator = options.SEP;\n\n    const firstIterationLookaheadFunc = this.getLaFuncFromCache(key);\n\n    // 1st iteration\n    if (firstIterationLookaheadFunc.call(this) === true) {\n      (<GrammarAction<OUT>>action).call(this);\n\n      //  TODO: Optimization can move this function construction into \"attemptInRepetitionRecovery\"\n      //  because it is only needed in error recovery scenarios.\n      const separatorLookAheadFunc = () => {\n        return this.tokenMatcher(this.LA(1), separator);\n      };\n\n      // 2nd..nth iterations\n      while (this.tokenMatcher(this.LA(1), separator) === true) {\n        // note that this CONSUME will never enter recovery because\n        // the separatorLookAheadFunc checks that the separator really does exist.\n        this.CONSUME(separator);\n        // No need for checking infinite loop here due to consuming the separator.\n        (<GrammarAction<OUT>>action).call(this);\n      }\n\n      // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n      this.attemptInRepetitionRecovery(\n        this.repetitionSepSecondInternal,\n        [\n          prodOccurrence,\n          separator,\n          separatorLookAheadFunc,\n          action,\n          NextTerminalAfterAtLeastOneSepWalker,\n        ],\n        separatorLookAheadFunc,\n        AT_LEAST_ONE_SEP_IDX,\n        prodOccurrence,\n        NextTerminalAfterAtLeastOneSepWalker,\n      );\n    } else {\n      throw this.raiseEarlyExitException(\n        prodOccurrence,\n        PROD_TYPE.REPETITION_MANDATORY_WITH_SEPARATOR,\n        options.ERR_MSG,\n      );\n    }\n  }\n\n  manyInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    const laKey = this.getKeyForAutomaticLookahead(MANY_IDX, prodOccurrence);\n    return this.manyInternalLogic(prodOccurrence, actionORMethodDef, laKey);\n  }\n\n  manyInternalLogic<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n    key: number,\n  ) {\n    let lookaheadFunction = this.getLaFuncFromCache(key);\n    let action;\n    if (typeof actionORMethodDef !== \"function\") {\n      action = actionORMethodDef.DEF;\n      const predicate = actionORMethodDef.GATE;\n      // predicate present\n      if (predicate !== undefined) {\n        const orgLookaheadFunction = lookaheadFunction;\n        lookaheadFunction = () => {\n          return predicate.call(this) && orgLookaheadFunction.call(this);\n        };\n      }\n    } else {\n      action = actionORMethodDef;\n    }\n\n    let notStuck = true;\n    while (lookaheadFunction.call(this) === true && notStuck === true) {\n      notStuck = this.doSingleRepetition(action);\n    }\n\n    // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n    this.attemptInRepetitionRecovery(\n      this.manyInternal,\n      [prodOccurrence, actionORMethodDef],\n      <any>lookaheadFunction,\n      MANY_IDX,\n      prodOccurrence,\n      NextTerminalAfterManyWalker,\n      // The notStuck parameter is only relevant when \"attemptInRepetitionRecovery\"\n      // is invoked from manyInternal, in the MANY_SEP case and AT_LEAST_ONE[_SEP]\n      // An infinite loop cannot occur as:\n      // - Either the lookahead is guaranteed to consume something (Single Token Separator)\n      // - AT_LEAST_ONE by definition is guaranteed to consume something (or error out).\n      notStuck,\n    );\n  }\n\n  manySepFirstInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    options: ManySepMethodOpts<OUT>,\n  ): void {\n    const laKey = this.getKeyForAutomaticLookahead(\n      MANY_SEP_IDX,\n      prodOccurrence,\n    );\n    this.manySepFirstInternalLogic(prodOccurrence, options, laKey);\n  }\n\n  manySepFirstInternalLogic<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    options: ManySepMethodOpts<OUT>,\n    key: number,\n  ): void {\n    const action = options.DEF;\n    const separator = options.SEP;\n    const firstIterationLaFunc = this.getLaFuncFromCache(key);\n\n    // 1st iteration\n    if (firstIterationLaFunc.call(this) === true) {\n      action.call(this);\n\n      const separatorLookAheadFunc = () => {\n        return this.tokenMatcher(this.LA(1), separator);\n      };\n      // 2nd..nth iterations\n      while (this.tokenMatcher(this.LA(1), separator) === true) {\n        // note that this CONSUME will never enter recovery because\n        // the separatorLookAheadFunc checks that the separator really does exist.\n        this.CONSUME(separator);\n        // No need for checking infinite loop here due to consuming the separator.\n        action.call(this);\n      }\n\n      // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n      this.attemptInRepetitionRecovery(\n        this.repetitionSepSecondInternal,\n        [\n          prodOccurrence,\n          separator,\n          separatorLookAheadFunc,\n          action,\n          NextTerminalAfterManySepWalker,\n        ],\n        separatorLookAheadFunc,\n        MANY_SEP_IDX,\n        prodOccurrence,\n        NextTerminalAfterManySepWalker,\n      );\n    }\n  }\n\n  repetitionSepSecondInternal<OUT>(\n    this: MixedInParser,\n    prodOccurrence: number,\n    separator: TokenType,\n    separatorLookAheadFunc: () => boolean,\n    action: GrammarAction<OUT>,\n    nextTerminalAfterWalker: typeof AbstractNextTerminalAfterProductionWalker,\n  ): void {\n    while (separatorLookAheadFunc()) {\n      // note that this CONSUME will never enter recovery because\n      // the separatorLookAheadFunc checks that the separator really does exist.\n      this.CONSUME(separator);\n      action.call(this);\n    }\n\n    // we can only arrive to this function after an error\n    // has occurred (hence the name 'second') so the following\n    // IF will always be entered, its possible to remove it...\n    // however it is kept to avoid confusion and be consistent.\n    // Performance optimization: \"attemptInRepetitionRecovery\" will be defined as NOOP unless recovery is enabled\n    /* istanbul ignore else */\n    this.attemptInRepetitionRecovery(\n      this.repetitionSepSecondInternal,\n      [\n        prodOccurrence,\n        separator,\n        separatorLookAheadFunc,\n        action,\n        nextTerminalAfterWalker,\n      ],\n      separatorLookAheadFunc,\n      AT_LEAST_ONE_SEP_IDX,\n      prodOccurrence,\n      nextTerminalAfterWalker,\n    );\n  }\n\n  doSingleRepetition(this: MixedInParser, action: Function): any {\n    const beforeIteration = this.getLexerPosition();\n    action.call(this);\n    const afterIteration = this.getLexerPosition();\n\n    // This boolean will indicate if this repetition progressed\n    // or if we are \"stuck\" (potential infinite loop in the repetition).\n    return afterIteration > beforeIteration;\n  }\n\n  orInternal<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n    occurrence: number,\n  ): T {\n    const laKey = this.getKeyForAutomaticLookahead(OR_IDX, occurrence);\n    const alts = isArray(altsOrOpts) ? altsOrOpts : altsOrOpts.DEF;\n\n    const laFunc = this.getLaFuncFromCache(laKey);\n    const altIdxToTake = laFunc.call(this, alts);\n    if (altIdxToTake !== undefined) {\n      const chosenAlternative: any = alts[altIdxToTake];\n      return chosenAlternative.ALT.call(this);\n    }\n    this.raiseNoAltException(\n      occurrence,\n      (altsOrOpts as OrMethodOpts<unknown>).ERR_MSG,\n    );\n  }\n\n  ruleFinallyStateUpdate(this: MixedInParser): void {\n    this.RULE_STACK.pop();\n    this.RULE_OCCURRENCE_STACK.pop();\n\n    // NOOP when cst is disabled\n    this.cstFinallyStateUpdate();\n\n    if (this.RULE_STACK.length === 0 && this.isAtEndOfInput() === false) {\n      const firstRedundantTok = this.LA(1);\n      const errMsg = this.errorMessageProvider.buildNotAllInputParsedMessage({\n        firstRedundant: firstRedundantTok,\n        ruleName: this.getCurrRuleFullName(),\n      });\n      this.SAVE_ERROR(\n        new NotAllInputParsedException(errMsg, firstRedundantTok),\n      );\n    }\n  }\n\n  subruleInternal<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    idx: number,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    let ruleResult;\n    try {\n      const args = options !== undefined ? options.ARGS : undefined;\n      this.subruleIdx = idx;\n      ruleResult = ruleToCall.apply(this, args);\n      this.cstPostNonTerminal(\n        ruleResult,\n        options !== undefined && options.LABEL !== undefined\n          ? options.LABEL\n          : ruleToCall.ruleName,\n      );\n      return ruleResult;\n    } catch (e) {\n      throw this.subruleInternalError(e, options, ruleToCall.ruleName);\n    }\n  }\n\n  subruleInternalError(\n    this: MixedInParser,\n    e: any,\n    options: SubruleMethodOpts<unknown[]> | undefined,\n    ruleName: string,\n  ): void {\n    if (isRecognitionException(e) && e.partialCstResult !== undefined) {\n      this.cstPostNonTerminal(\n        e.partialCstResult,\n        options !== undefined && options.LABEL !== undefined\n          ? options.LABEL\n          : ruleName,\n      );\n\n      delete e.partialCstResult;\n    }\n    throw e;\n  }\n\n  consumeInternal(\n    this: MixedInParser,\n    tokType: TokenType,\n    idx: number,\n    options: ConsumeMethodOpts | undefined,\n  ): IToken {\n    let consumedToken!: IToken;\n    try {\n      const nextToken = this.LA(1);\n      if (this.tokenMatcher(nextToken, tokType) === true) {\n        this.consumeToken();\n        consumedToken = nextToken;\n      } else {\n        this.consumeInternalError(tokType, nextToken, options);\n      }\n    } catch (eFromConsumption) {\n      consumedToken = this.consumeInternalRecovery(\n        tokType,\n        idx,\n        eFromConsumption,\n      );\n    }\n\n    this.cstPostTerminal(\n      options !== undefined && options.LABEL !== undefined\n        ? options.LABEL\n        : tokType.name,\n      consumedToken,\n    );\n    return consumedToken;\n  }\n\n  consumeInternalError(\n    this: MixedInParser,\n    tokType: TokenType,\n    nextToken: IToken,\n    options: ConsumeMethodOpts | undefined,\n  ): void {\n    let msg;\n    const previousToken = this.LA(0);\n    if (options !== undefined && options.ERR_MSG) {\n      msg = options.ERR_MSG;\n    } else {\n      msg = this.errorMessageProvider.buildMismatchTokenMessage({\n        expected: tokType,\n        actual: nextToken,\n        previous: previousToken,\n        ruleName: this.getCurrRuleFullName(),\n      });\n    }\n    throw this.SAVE_ERROR(\n      new MismatchedTokenException(msg, nextToken, previousToken),\n    );\n  }\n\n  consumeInternalRecovery(\n    this: MixedInParser,\n    tokType: TokenType,\n    idx: number,\n    eFromConsumption: Error,\n  ): IToken {\n    // no recovery allowed during backtracking, otherwise backtracking may recover invalid syntax and accept it\n    // but the original syntax could have been parsed successfully without any backtracking + recovery\n    if (\n      this.recoveryEnabled &&\n      // TODO: more robust checking of the exception type. Perhaps Typescript extending expressions?\n      eFromConsumption.name === \"MismatchedTokenException\" &&\n      !this.isBackTracking()\n    ) {\n      const follows = this.getFollowsForInRuleRecovery(<any>tokType, idx);\n      try {\n        return this.tryInRuleRecovery(<any>tokType, follows);\n      } catch (eFromInRuleRecovery) {\n        if (eFromInRuleRecovery.name === IN_RULE_RECOVERY_EXCEPTION) {\n          // failed in RuleRecovery.\n          // throw the original error in order to trigger reSync error recovery\n          throw eFromConsumption;\n        } else {\n          throw eFromInRuleRecovery;\n        }\n      }\n    } else {\n      throw eFromConsumption;\n    }\n  }\n\n  saveRecogState(this: MixedInParser): IParserState {\n    // errors is a getter which will clone the errors array\n    const savedErrors = this.errors;\n    const savedRuleStack = clone(this.RULE_STACK);\n    return {\n      errors: savedErrors,\n      lexerState: this.exportLexerState(),\n      RULE_STACK: savedRuleStack,\n      CST_STACK: this.CST_STACK,\n    };\n  }\n\n  reloadRecogState(this: MixedInParser, newState: IParserState) {\n    this.errors = newState.errors;\n    this.importLexerState(newState.lexerState);\n    this.RULE_STACK = newState.RULE_STACK;\n  }\n\n  ruleInvocationStateUpdate(\n    this: MixedInParser,\n    shortName: number,\n    fullName: string,\n    idxInCallingRule: number,\n  ): void {\n    this.RULE_OCCURRENCE_STACK.push(idxInCallingRule);\n    this.RULE_STACK.push(shortName);\n    // NOOP when cst is disabled\n    this.cstInvocationStateUpdate(fullName);\n  }\n\n  isBackTracking(this: MixedInParser): boolean {\n    return this.isBackTrackingStack.length !== 0;\n  }\n\n  getCurrRuleFullName(this: MixedInParser): string {\n    const shortName = this.getLastExplicitRuleShortName();\n    return this.shortRuleNameToFull[shortName];\n  }\n\n  shortRuleNameToFullName(this: MixedInParser, shortName: number) {\n    return this.shortRuleNameToFull[shortName];\n  }\n\n  public isAtEndOfInput(this: MixedInParser): boolean {\n    return this.tokenMatcher(this.LA(1), EOF);\n  }\n\n  public reset(this: MixedInParser): void {\n    this.resetLexerState();\n    this.subruleIdx = 0;\n    this.isBackTrackingStack = [];\n    this.errors = [];\n    this.RULE_STACK = [];\n    // TODO: extract a specific reset for TreeBuilder trait\n    this.CST_STACK = [];\n    this.RULE_OCCURRENCE_STACK = [];\n  }\n}\n","import {\n  AtLeastOneSepMethodOpts,\n  ConsumeMethodOpts,\n  DSLMethodOpts,\n  DSLMethodOptsWithErr,\n  GrammarAction,\n  IOrAlt,\n  IRuleConfig,\n  ISerializedGast,\n  IToken,\n  ManySepMethodOpts,\n  OrMethodOpts,\n  SubruleMethodOpts,\n  TokenType,\n} from \"@chevrotain/types\";\nimport { includes, values } from \"lodash-es\";\nimport { isRecognitionException } from \"../../exceptions_public.js\";\nimport { DEFAULT_RULE_CONFIG, ParserDefinitionErrorType } from \"../parser.js\";\nimport { defaultGrammarValidatorErrorProvider } from \"../../errors_public.js\";\nimport { validateRuleIsOverridden } from \"../../grammar/checks.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { Rule, serializeGrammar } from \"@chevrotain/gast\";\nimport { IParserDefinitionError } from \"../../grammar/types.js\";\nimport { ParserMethodInternal } from \"../types.js\";\n\n/**\n * This trait is responsible for implementing the public API\n * for defining Chevrotain parsers, i.e:\n * - CONSUME\n * - RULE\n * - OPTION\n * - ...\n */\nexport class RecognizerApi {\n  ACTION<T>(this: MixedInParser, impl: () => T): T {\n    return impl.call(this);\n  }\n\n  consume(\n    this: MixedInParser,\n    idx: number,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, idx, options);\n  }\n\n  subrule<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    idx: number,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, idx, options);\n  }\n\n  option<OUT>(\n    this: MixedInParser,\n    idx: number,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, idx);\n  }\n\n  or(\n    this: MixedInParser,\n    idx: number,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<any>,\n  ): any {\n    return this.orInternal(altsOrOpts, idx);\n  }\n\n  many(\n    this: MixedInParser,\n    idx: number,\n    actionORMethodDef: GrammarAction<any> | DSLMethodOpts<any>,\n  ): void {\n    return this.manyInternal(idx, actionORMethodDef);\n  }\n\n  atLeastOne(\n    this: MixedInParser,\n    idx: number,\n    actionORMethodDef: GrammarAction<any> | DSLMethodOptsWithErr<any>,\n  ): void {\n    return this.atLeastOneInternal(idx, actionORMethodDef);\n  }\n\n  CONSUME(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 0, options);\n  }\n\n  CONSUME1(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 1, options);\n  }\n\n  CONSUME2(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 2, options);\n  }\n\n  CONSUME3(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 3, options);\n  }\n\n  CONSUME4(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 4, options);\n  }\n\n  CONSUME5(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 5, options);\n  }\n\n  CONSUME6(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 6, options);\n  }\n\n  CONSUME7(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 7, options);\n  }\n\n  CONSUME8(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 8, options);\n  }\n\n  CONSUME9(\n    this: MixedInParser,\n    tokType: TokenType,\n    options?: ConsumeMethodOpts,\n  ): IToken {\n    return this.consumeInternal(tokType, 9, options);\n  }\n\n  SUBRULE<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 0, options);\n  }\n\n  SUBRULE1<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 1, options);\n  }\n\n  SUBRULE2<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 2, options);\n  }\n\n  SUBRULE3<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 3, options);\n  }\n\n  SUBRULE4<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 4, options);\n  }\n\n  SUBRULE5<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 5, options);\n  }\n\n  SUBRULE6<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 6, options);\n  }\n\n  SUBRULE7<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 7, options);\n  }\n\n  SUBRULE8<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 8, options);\n  }\n\n  SUBRULE9<ARGS extends unknown[], R>(\n    this: MixedInParser,\n    ruleToCall: ParserMethodInternal<ARGS, R>,\n    options?: SubruleMethodOpts<ARGS>,\n  ): R {\n    return this.subruleInternal(ruleToCall, 9, options);\n  }\n\n  OPTION<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 0);\n  }\n\n  OPTION1<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 1);\n  }\n\n  OPTION2<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 2);\n  }\n\n  OPTION3<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 3);\n  }\n\n  OPTION4<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 4);\n  }\n\n  OPTION5<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 5);\n  }\n\n  OPTION6<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 6);\n  }\n\n  OPTION7<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 7);\n  }\n\n  OPTION8<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 8);\n  }\n\n  OPTION9<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): OUT | undefined {\n    return this.optionInternal(actionORMethodDef, 9);\n  }\n\n  OR<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 0);\n  }\n\n  OR1<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 1);\n  }\n\n  OR2<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 2);\n  }\n\n  OR3<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 3);\n  }\n\n  OR4<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 4);\n  }\n\n  OR5<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 5);\n  }\n\n  OR6<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 6);\n  }\n\n  OR7<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 7);\n  }\n\n  OR8<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 8);\n  }\n\n  OR9<T>(\n    this: MixedInParser,\n    altsOrOpts: IOrAlt<any>[] | OrMethodOpts<unknown>,\n  ): T {\n    return this.orInternal(altsOrOpts, 9);\n  }\n\n  MANY<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(0, actionORMethodDef);\n  }\n\n  MANY1<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(1, actionORMethodDef);\n  }\n\n  MANY2<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(2, actionORMethodDef);\n  }\n\n  MANY3<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(3, actionORMethodDef);\n  }\n\n  MANY4<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(4, actionORMethodDef);\n  }\n\n  MANY5<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(5, actionORMethodDef);\n  }\n\n  MANY6<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(6, actionORMethodDef);\n  }\n\n  MANY7<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(7, actionORMethodDef);\n  }\n\n  MANY8<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(8, actionORMethodDef);\n  }\n\n  MANY9<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOpts<OUT>,\n  ): void {\n    this.manyInternal(9, actionORMethodDef);\n  }\n\n  MANY_SEP<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(0, options);\n  }\n\n  MANY_SEP1<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(1, options);\n  }\n\n  MANY_SEP2<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(2, options);\n  }\n\n  MANY_SEP3<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(3, options);\n  }\n\n  MANY_SEP4<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(4, options);\n  }\n\n  MANY_SEP5<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(5, options);\n  }\n\n  MANY_SEP6<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(6, options);\n  }\n\n  MANY_SEP7<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(7, options);\n  }\n\n  MANY_SEP8<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(8, options);\n  }\n\n  MANY_SEP9<OUT>(this: MixedInParser, options: ManySepMethodOpts<OUT>): void {\n    this.manySepFirstInternal(9, options);\n  }\n\n  AT_LEAST_ONE<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(0, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE1<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    return this.atLeastOneInternal(1, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE2<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(2, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE3<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(3, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE4<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(4, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE5<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(5, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE6<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(6, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE7<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(7, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE8<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(8, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE9<OUT>(\n    this: MixedInParser,\n    actionORMethodDef: GrammarAction<OUT> | DSLMethodOptsWithErr<OUT>,\n  ): void {\n    this.atLeastOneInternal(9, actionORMethodDef);\n  }\n\n  AT_LEAST_ONE_SEP<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(0, options);\n  }\n\n  AT_LEAST_ONE_SEP1<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(1, options);\n  }\n\n  AT_LEAST_ONE_SEP2<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(2, options);\n  }\n\n  AT_LEAST_ONE_SEP3<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(3, options);\n  }\n\n  AT_LEAST_ONE_SEP4<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(4, options);\n  }\n\n  AT_LEAST_ONE_SEP5<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(5, options);\n  }\n\n  AT_LEAST_ONE_SEP6<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(6, options);\n  }\n\n  AT_LEAST_ONE_SEP7<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(7, options);\n  }\n\n  AT_LEAST_ONE_SEP8<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(8, options);\n  }\n\n  AT_LEAST_ONE_SEP9<OUT>(\n    this: MixedInParser,\n    options: AtLeastOneSepMethodOpts<OUT>,\n  ): void {\n    this.atLeastOneSepFirstInternal(9, options);\n  }\n\n  RULE<T>(\n    this: MixedInParser,\n    name: string,\n    implementation: (...implArgs: any[]) => T,\n    config: IRuleConfig<T> = DEFAULT_RULE_CONFIG,\n  ): (idxInCallingRule?: number, ...args: any[]) => T | any {\n    if (includes(this.definedRulesNames, name)) {\n      const errMsg =\n        defaultGrammarValidatorErrorProvider.buildDuplicateRuleNameError({\n          topLevelRule: name,\n          grammarName: this.className,\n        });\n\n      const error = {\n        message: errMsg,\n        type: ParserDefinitionErrorType.DUPLICATE_RULE_NAME,\n        ruleName: name,\n      };\n      this.definitionErrors.push(error);\n    }\n\n    this.definedRulesNames.push(name);\n\n    const ruleImplementation = this.defineRule(name, implementation, config);\n    (this as any)[name] = ruleImplementation;\n    return ruleImplementation;\n  }\n\n  OVERRIDE_RULE<T>(\n    this: MixedInParser,\n    name: string,\n    impl: (...implArgs: any[]) => T,\n    config: IRuleConfig<T> = DEFAULT_RULE_CONFIG,\n  ): (idxInCallingRule?: number, ...args: any[]) => T {\n    const ruleErrors: IParserDefinitionError[] = validateRuleIsOverridden(\n      name,\n      this.definedRulesNames,\n      this.className,\n    );\n    this.definitionErrors = this.definitionErrors.concat(ruleErrors);\n\n    const ruleImplementation = this.defineRule(name, impl, config);\n    (this as any)[name] = ruleImplementation;\n    return ruleImplementation;\n  }\n\n  BACKTRACK<T>(\n    this: MixedInParser,\n    grammarRule: (...args: any[]) => T,\n    args?: any[],\n  ): () => boolean {\n    return function () {\n      // save org state\n      this.isBackTrackingStack.push(1);\n      const orgState = this.saveRecogState();\n      try {\n        grammarRule.apply(this, args);\n        // if no exception was thrown we have succeed parsing the rule.\n        return true;\n      } catch (e) {\n        if (isRecognitionException(e)) {\n          return false;\n        } else {\n          throw e;\n        }\n      } finally {\n        this.reloadRecogState(orgState);\n        this.isBackTrackingStack.pop();\n      }\n    };\n  }\n\n  // GAST export APIs\n  public getGAstProductions(this: MixedInParser): Record<string, Rule> {\n    return this.gastProductionsCache;\n  }\n\n  public getSerializedGastProductions(this: MixedInParser): ISerializedGast[] {\n    return serializeGrammar(values(this.gastProductionsCache));\n  }\n}\n","import {\n  IParserConfig,\n  IParserErrorMessageProvider,\n  IRecognitionException,\n} from \"@chevrotain/types\";\nimport {\n  EarlyExitException,\n  isRecognitionException,\n  NoViableAltException,\n} from \"../../exceptions_public.js\";\nimport { clone, has } from \"lodash-es\";\nimport {\n  getLookaheadPathsForOptionalProd,\n  getLookaheadPathsForOr,\n  PROD_TYPE,\n} from \"../../grammar/lookahead.js\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n\n/**\n * Trait responsible for runtime parsing errors.\n */\nexport class ErrorHandler {\n  _errors: IRecognitionException[];\n  errorMessageProvider: IParserErrorMessageProvider;\n\n  initErrorHandler(config: IParserConfig) {\n    this._errors = [];\n    this.errorMessageProvider = has(config, \"errorMessageProvider\")\n      ? (config.errorMessageProvider as IParserErrorMessageProvider) // assumes end user provides the correct config value/type\n      : DEFAULT_PARSER_CONFIG.errorMessageProvider;\n  }\n\n  SAVE_ERROR(\n    this: MixedInParser,\n    error: IRecognitionException,\n  ): IRecognitionException {\n    if (isRecognitionException(error)) {\n      error.context = {\n        ruleStack: this.getHumanReadableRuleStack(),\n        ruleOccurrenceStack: clone(this.RULE_OCCURRENCE_STACK),\n      };\n      this._errors.push(error);\n      return error;\n    } else {\n      throw Error(\n        \"Trying to save an Error which is not a RecognitionException\",\n      );\n    }\n  }\n\n  get errors(): IRecognitionException[] {\n    return clone(this._errors);\n  }\n\n  set errors(newErrors: IRecognitionException[]) {\n    this._errors = newErrors;\n  }\n\n  // TODO: consider caching the error message computed information\n  raiseEarlyExitException(\n    this: MixedInParser,\n    occurrence: number,\n    prodType: PROD_TYPE,\n    userDefinedErrMsg: string | undefined,\n  ): never {\n    const ruleName = this.getCurrRuleFullName();\n    const ruleGrammar = this.getGAstProductions()[ruleName];\n    const lookAheadPathsPerAlternative = getLookaheadPathsForOptionalProd(\n      occurrence,\n      ruleGrammar,\n      prodType,\n      this.maxLookahead,\n    );\n    const insideProdPaths = lookAheadPathsPerAlternative[0];\n    const actualTokens = [];\n    for (let i = 1; i <= this.maxLookahead; i++) {\n      actualTokens.push(this.LA(i));\n    }\n    const msg = this.errorMessageProvider.buildEarlyExitMessage({\n      expectedIterationPaths: insideProdPaths,\n      actual: actualTokens,\n      previous: this.LA(0),\n      customUserDescription: userDefinedErrMsg,\n      ruleName: ruleName,\n    });\n\n    throw this.SAVE_ERROR(new EarlyExitException(msg, this.LA(1), this.LA(0)));\n  }\n\n  // TODO: consider caching the error message computed information\n  raiseNoAltException(\n    this: MixedInParser,\n    occurrence: number,\n    errMsgTypes: string | undefined,\n  ): never {\n    const ruleName = this.getCurrRuleFullName();\n    const ruleGrammar = this.getGAstProductions()[ruleName];\n    // TODO: getLookaheadPathsForOr can be slow for large enough maxLookahead and certain grammars, consider caching ?\n    const lookAheadPathsPerAlternative = getLookaheadPathsForOr(\n      occurrence,\n      ruleGrammar,\n      this.maxLookahead,\n    );\n\n    const actualTokens = [];\n    for (let i = 1; i <= this.maxLookahead; i++) {\n      actualTokens.push(this.LA(i));\n    }\n    const previousToken = this.LA(0);\n\n    const errMsg = this.errorMessageProvider.buildNoViableAltMessage({\n      expectedPathsPerAlt: lookAheadPathsPerAlternative,\n      actual: actualTokens,\n      previous: previousToken,\n      customUserDescription: errMsgTypes,\n      ruleName: this.getCurrRuleFullName(),\n    });\n\n    throw this.SAVE_ERROR(\n      new NoViableAltException(errMsg, this.LA(1), previousToken),\n    );\n  }\n}\n","import {\n  ISyntacticContentAssistPath,\n  IToken,\n  ITokenGrammarPath,\n  TokenType,\n} from \"@chevrotain/types\";\nimport {\n  NextAfterTokenWalker,\n  nextPossibleTokensAfter,\n} from \"../../grammar/interpreter.js\";\nimport { first, isUndefined } from \"lodash-es\";\nimport { MixedInParser } from \"./parser_traits.js\";\n\nexport class ContentAssist {\n  initContentAssist() {}\n\n  public computeContentAssist(\n    this: MixedInParser,\n    startRuleName: string,\n    precedingInput: IToken[],\n  ): ISyntacticContentAssistPath[] {\n    const startRuleGast = this.gastProductionsCache[startRuleName];\n\n    if (isUndefined(startRuleGast)) {\n      throw Error(`Rule ->${startRuleName}<- does not exist in this grammar.`);\n    }\n\n    return nextPossibleTokensAfter(\n      [startRuleGast],\n      precedingInput,\n      this.tokenMatcher,\n      this.maxLookahead,\n    );\n  }\n\n  // TODO: should this be a member method or a utility? it does not have any state or usage of 'this'...\n  // TODO: should this be more explicitly part of the public API?\n  public getNextPossibleTokenTypes(\n    this: MixedInParser,\n    grammarPath: ITokenGrammarPath,\n  ): TokenType[] {\n    const topRuleName = first(grammarPath.ruleStack)!;\n    const gastProductions = this.getGAstProductions();\n    const topProduction = gastProductions[topRuleName];\n    const nextPossibleTokenTypes = new NextAfterTokenWalker(\n      topProduction,\n      grammarPath,\n    ).startWalking();\n    return nextPossibleTokenTypes;\n  }\n}\n","import { IParserConfig } from \"@chevrotain/types\";\nimport { has } from \"lodash-es\";\nimport { timer } from \"@chevrotain/utils\";\nimport { MixedInParser } from \"./parser_traits.js\";\nimport { DEFAULT_PARSER_CONFIG } from \"../parser.js\";\n\n/**\n * Trait responsible for runtime parsing errors.\n */\nexport class PerformanceTracer {\n  traceInitPerf: boolean | number;\n  traceInitMaxIdent: number;\n  traceInitIndent: number;\n\n  initPerformanceTracer(config: IParserConfig) {\n    if (has(config, \"traceInitPerf\")) {\n      const userTraceInitPerf = config.traceInitPerf;\n      const traceIsNumber = typeof userTraceInitPerf === \"number\";\n      this.traceInitMaxIdent = traceIsNumber\n        ? <number>userTraceInitPerf\n        : Infinity;\n      this.traceInitPerf = traceIsNumber\n        ? userTraceInitPerf > 0\n        : (userTraceInitPerf as boolean); // assumes end user provides the correct config value/type\n    } else {\n      this.traceInitMaxIdent = 0;\n      this.traceInitPerf = DEFAULT_PARSER_CONFIG.traceInitPerf;\n    }\n\n    this.traceInitIndent = -1;\n  }\n\n  TRACE_INIT<T>(this: MixedInParser, phaseDesc: string, phaseImpl: () => T): T {\n    // No need to optimize this using NOOP pattern because\n    // It is not called in a hot spot...\n    if (this.traceInitPerf === true) {\n      this.traceInitIndent++;\n      const indent = new Array(this.traceInitIndent + 1).join(\"\\t\");\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        console.log(`${indent}--> <${phaseDesc}>`);\n      }\n      const { time, value } = timer(phaseImpl);\n      /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n      const traceMethod = time > 10 ? console.warn : console.log;\n      if (this.traceInitIndent < this.traceInitMaxIdent) {\n        traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n      }\n      this.traceInitIndent--;\n      return value;\n    } else {\n      return phaseImpl();\n    }\n  }\n}\n","/**\n * The base implementation of `_.lt` which doesn't coerce arguments.\n *\n * @private\n * @param {*} value The value to compare.\n * @param {*} other The other value to compare.\n * @returns {boolean} Returns `true` if `value` is less than `other`,\n *  else `false`.\n */\nfunction baseLt(value, other) {\n  return value < other;\n}\n\nexport default baseLt;\n","import {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  MermaidGeneratedSharedModule,\n  PieGeneratedModule,\n  __name\n} from \"./chunk-4KMFLZZN.mjs\";\n\n// src/language/pie/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/pie/tokenBuilder.ts\nvar PieTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"PieTokenBuilder\");\n  }\n  constructor() {\n    super([\"pie\", \"showData\"]);\n  }\n};\n\n// src/language/pie/valueConverter.ts\nvar PieValueConverter = class extends AbstractMermaidValueConverter {\n  static {\n    __name(this, \"PieValueConverter\");\n  }\n  runCustomConverter(rule, input, _cstNode) {\n    if (rule.name !== \"PIE_SECTION_LABEL\") {\n      return void 0;\n    }\n    return input.replace(/\"/g, \"\").trim();\n  }\n};\n\n// src/language/pie/module.ts\nvar PieModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new PieTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new PieValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createPieServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Pie = inject(\n    createDefaultCoreModule({ shared }),\n    PieGeneratedModule,\n    PieModule\n  );\n  shared.ServiceRegistry.register(Pie);\n  return { shared, Pie };\n}\n__name(createPieServices, \"createPieServices\");\n\nexport {\n  PieModule,\n  createPieServices\n};\n","import type { Character, IRegExpAST, RegExpFlags } from \"../types\";\n\nexport function cc(char: string): number {\n  return char.charCodeAt(0);\n}\n\nexport function insertToSet<T>(item: T | T[], set: T[]) {\n  if (Array.isArray(item)) {\n    item.forEach(function (subItem) {\n      set.push(subItem);\n    });\n  } else {\n    set.push(item);\n  }\n}\n\nexport function addFlag(\n  flagObj: RegExpFlags,\n  flagKey: keyof Omit<RegExpFlags, keyof IRegExpAST>,\n) {\n  if (flagObj[flagKey] === true) {\n    throw \"duplicate flag \" + flagKey;\n  }\n\n  const x: boolean = flagObj[flagKey];\n  flagObj[flagKey] = true;\n}\n\nexport function ASSERT_EXISTS<T = Object>(obj: any): obj is T {\n  // istanbul ignore next\n  if (obj === undefined) {\n    throw Error(\"Internal Error - Should never get here!\");\n  }\n  return true;\n}\n\n// istanbul ignore next\nexport function ASSERT_NEVER_REACH_HERE(): any {\n  throw Error(\"Internal Error - Should never get here!\");\n}\n\nexport function isCharacter(obj: { type: string }): obj is Character {\n  return obj[\"type\"] === \"Character\";\n}\n","import { cc } from \"./utils.js\";\n\nexport const digitsCharCodes: number[] = [];\nfor (let i = cc(\"0\"); i <= cc(\"9\"); i++) {\n  digitsCharCodes.push(i);\n}\n\nexport const wordCharCodes: number[] = [cc(\"_\")].concat(digitsCharCodes);\nfor (let i = cc(\"a\"); i <= cc(\"z\"); i++) {\n  wordCharCodes.push(i);\n}\n\nfor (let i = cc(\"A\"); i <= cc(\"Z\"); i++) {\n  wordCharCodes.push(i);\n}\n\n// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp#character-classes\nexport const whitespaceCodes: number[] = [\n  cc(\" \"),\n  cc(\"\\f\"),\n  cc(\"\\n\"),\n  cc(\"\\r\"),\n  cc(\"\\t\"),\n  cc(\"\\v\"),\n  cc(\"\\t\"),\n  cc(\"\\u00a0\"),\n  cc(\"\\u1680\"),\n  cc(\"\\u2000\"),\n  cc(\"\\u2001\"),\n  cc(\"\\u2002\"),\n  cc(\"\\u2003\"),\n  cc(\"\\u2004\"),\n  cc(\"\\u2005\"),\n  cc(\"\\u2006\"),\n  cc(\"\\u2007\"),\n  cc(\"\\u2008\"),\n  cc(\"\\u2009\"),\n  cc(\"\\u200a\"),\n  cc(\"\\u2028\"),\n  cc(\"\\u2029\"),\n  cc(\"\\u202f\"),\n  cc(\"\\u205f\"),\n  cc(\"\\u3000\"),\n  cc(\"\\ufeff\"),\n];\n","import type {\n  Alternative,\n  Assertion,\n  Atom,\n  Character,\n  Disjunction,\n  Group,\n  GroupBackReference,\n  Location,\n  Quantifier,\n  Range,\n  RegExpFlags,\n  RegExpPattern,\n  Set,\n  Term,\n} from \"../types\";\nimport {\n  addFlag,\n  ASSERT_EXISTS,\n  ASSERT_NEVER_REACH_HERE,\n  cc,\n  insertToSet,\n  isCharacter,\n} from \"./utils.js\";\nimport {\n  digitsCharCodes,\n  whitespaceCodes,\n  wordCharCodes,\n} from \"./character-classes.js\";\n\n// consts and utilities\nconst hexDigitPattern = /[0-9a-fA-F]/;\nconst decimalPattern = /[0-9]/;\nconst decimalPatternNoZero = /[1-9]/;\n\n// https://hackernoon.com/the-madness-of-parsing-real-world-javascript-regexps-d9ee336df983\n// https://www.ecma-international.org/ecma-262/8.0/index.html#prod-Pattern\nexport class RegExpParser {\n  protected idx: number = 0;\n  protected input: string = \"\";\n  protected groupIdx: number = 0;\n\n  protected saveState() {\n    return {\n      idx: this.idx,\n      input: this.input,\n      groupIdx: this.groupIdx,\n    };\n  }\n\n  protected restoreState(newState: {\n    idx: number;\n    input: string;\n    groupIdx: number;\n  }) {\n    this.idx = newState.idx;\n    this.input = newState.input;\n    this.groupIdx = newState.groupIdx;\n  }\n\n  public pattern(input: string): RegExpPattern {\n    // parser state\n    this.idx = 0;\n    this.input = input;\n    this.groupIdx = 0;\n\n    this.consumeChar(\"/\");\n    const value = this.disjunction();\n    this.consumeChar(\"/\");\n\n    const flags: RegExpFlags = {\n      type: \"Flags\",\n      loc: { begin: this.idx, end: input.length },\n      global: false,\n      ignoreCase: false,\n      multiLine: false,\n      unicode: false,\n      sticky: false,\n    };\n\n    while (this.isRegExpFlag()) {\n      switch (this.popChar()) {\n        case \"g\":\n          addFlag(flags, \"global\");\n          break;\n        case \"i\":\n          addFlag(flags, \"ignoreCase\");\n          break;\n        case \"m\":\n          addFlag(flags, \"multiLine\");\n          break;\n        case \"u\":\n          addFlag(flags, \"unicode\");\n          break;\n        case \"y\":\n          addFlag(flags, \"sticky\");\n          break;\n      }\n    }\n\n    if (this.idx !== this.input.length) {\n      throw Error(\"Redundant input: \" + this.input.substring(this.idx));\n    }\n    return {\n      type: \"Pattern\",\n      flags: flags,\n      value: value,\n      loc: this.loc(0),\n    };\n  }\n\n  protected disjunction(): Disjunction {\n    const alts = [];\n    const begin = this.idx;\n\n    alts.push(this.alternative());\n\n    while (this.peekChar() === \"|\") {\n      this.consumeChar(\"|\");\n      alts.push(this.alternative());\n    }\n\n    return { type: \"Disjunction\", value: alts, loc: this.loc(begin) };\n  }\n\n  protected alternative(): Alternative {\n    const terms = [];\n    const begin = this.idx;\n\n    while (this.isTerm()) {\n      terms.push(this.term());\n    }\n\n    return { type: \"Alternative\", value: terms, loc: this.loc(begin) };\n  }\n\n  protected term(): Term {\n    if (this.isAssertion()) {\n      return this.assertion();\n    } else {\n      return this.atom();\n    }\n  }\n\n  protected assertion(): Assertion {\n    const begin = this.idx;\n    switch (this.popChar()) {\n      case \"^\":\n        return {\n          type: \"StartAnchor\",\n          loc: this.loc(begin),\n        };\n      case \"$\":\n        return { type: \"EndAnchor\", loc: this.loc(begin) };\n      // '\\b' or '\\B'\n      case \"\\\\\":\n        switch (this.popChar()) {\n          case \"b\":\n            return {\n              type: \"WordBoundary\",\n              loc: this.loc(begin),\n            };\n          case \"B\":\n            return {\n              type: \"NonWordBoundary\",\n              loc: this.loc(begin),\n            };\n        }\n        // istanbul ignore next\n        throw Error(\"Invalid Assertion Escape\");\n      // '(?=' or '(?!'\n      case \"(\":\n        this.consumeChar(\"?\");\n\n        let type: \"Lookahead\" | \"NegativeLookahead\" | undefined;\n        switch (this.popChar()) {\n          case \"=\":\n            type = \"Lookahead\";\n            break;\n          case \"!\":\n            type = \"NegativeLookahead\";\n            break;\n        }\n        ASSERT_EXISTS(type);\n\n        const disjunction = this.disjunction();\n\n        this.consumeChar(\")\");\n\n        return {\n          type: type!,\n          value: disjunction,\n          loc: this.loc(begin),\n        };\n    }\n    // istanbul ignore next\n    return ASSERT_NEVER_REACH_HERE();\n  }\n\n  protected quantifier(\n    isBacktracking: boolean = false,\n  ): Quantifier | undefined {\n    let range: Partial<Quantifier> | undefined = undefined;\n    const begin = this.idx;\n    switch (this.popChar()) {\n      case \"*\":\n        range = {\n          atLeast: 0,\n          atMost: Infinity,\n        };\n        break;\n      case \"+\":\n        range = {\n          atLeast: 1,\n          atMost: Infinity,\n        };\n        break;\n      case \"?\":\n        range = {\n          atLeast: 0,\n          atMost: 1,\n        };\n        break;\n      case \"{\":\n        const atLeast = this.integerIncludingZero();\n        switch (this.popChar()) {\n          case \"}\":\n            range = {\n              atLeast: atLeast,\n              atMost: atLeast,\n            };\n            break;\n          case \",\":\n            let atMost;\n            if (this.isDigit()) {\n              atMost = this.integerIncludingZero();\n              range = {\n                atLeast: atLeast,\n                atMost: atMost,\n              };\n            } else {\n              range = {\n                atLeast: atLeast,\n                atMost: Infinity,\n              };\n            }\n            this.consumeChar(\"}\");\n            break;\n        }\n        // throwing exceptions from \"ASSERT_EXISTS\" during backtracking\n        // causes severe performance degradations\n        if (isBacktracking === true && range === undefined) {\n          return undefined;\n        }\n        ASSERT_EXISTS(range);\n        break;\n    }\n\n    // throwing exceptions from \"ASSERT_EXISTS\" during backtracking\n    // causes severe performance degradations\n    if (isBacktracking === true && range === undefined) {\n      return undefined;\n    }\n\n    // istanbul ignore else\n    if (ASSERT_EXISTS(range)) {\n      if (this.peekChar(0) === \"?\") {\n        this.consumeChar(\"?\");\n        range.greedy = false;\n      } else {\n        range.greedy = true;\n      }\n\n      range.type = \"Quantifier\";\n      range.loc = this.loc(begin);\n      return range as Quantifier;\n    }\n  }\n\n  protected atom(): Atom {\n    let atom: Omit<Atom, \"loc\" | \"type\"> | undefined;\n    const begin = this.idx;\n    switch (this.peekChar()) {\n      case \".\":\n        atom = this.dotAll();\n        break;\n      case \"\\\\\":\n        atom = this.atomEscape();\n        break;\n      case \"[\":\n        atom = this.characterClass();\n        break;\n      case \"(\":\n        atom = this.group();\n        break;\n    }\n\n    if (atom === undefined && this.isPatternCharacter()) {\n      atom = this.patternCharacter();\n    }\n\n    // istanbul ignore else\n    if (ASSERT_EXISTS<Atom>(atom)) {\n      atom.loc = this.loc(begin);\n\n      if (this.isQuantifier()) {\n        atom.quantifier = this.quantifier();\n      }\n\n      return atom;\n    }\n\n    // istanbul ignore next\n    return ASSERT_NEVER_REACH_HERE();\n  }\n\n  protected dotAll(): Omit<Set, \"loc\"> {\n    this.consumeChar(\".\");\n    return {\n      type: \"Set\",\n      complement: true,\n      value: [cc(\"\\n\"), cc(\"\\r\"), cc(\"\\u2028\"), cc(\"\\u2029\")],\n    };\n  }\n\n  protected atomEscape(): Omit<GroupBackReference | Set | Character, \"loc\"> {\n    this.consumeChar(\"\\\\\");\n\n    switch (this.peekChar()) {\n      case \"1\":\n      case \"2\":\n      case \"3\":\n      case \"4\":\n      case \"5\":\n      case \"6\":\n      case \"7\":\n      case \"8\":\n      case \"9\":\n        return this.decimalEscapeAtom();\n      case \"d\":\n      case \"D\":\n      case \"s\":\n      case \"S\":\n      case \"w\":\n      case \"W\":\n        return this.characterClassEscape();\n      case \"f\":\n      case \"n\":\n      case \"r\":\n      case \"t\":\n      case \"v\":\n        return this.controlEscapeAtom();\n      case \"c\":\n        return this.controlLetterEscapeAtom();\n      case \"0\":\n        return this.nulCharacterAtom();\n      case \"x\":\n        return this.hexEscapeSequenceAtom();\n      case \"u\":\n        return this.regExpUnicodeEscapeSequenceAtom();\n      default:\n        return this.identityEscapeAtom();\n    }\n  }\n\n  protected decimalEscapeAtom(): Omit<GroupBackReference, \"loc\"> {\n    const value = this.positiveInteger();\n\n    return { type: \"GroupBackReference\", value: value };\n  }\n\n  protected characterClassEscape(): Omit<Set, \"loc\"> {\n    let set: (number | Range)[] | undefined;\n    let complement = false;\n    switch (this.popChar()) {\n      case \"d\":\n        set = digitsCharCodes;\n        break;\n      case \"D\":\n        set = digitsCharCodes;\n        complement = true;\n        break;\n      case \"s\":\n        set = whitespaceCodes;\n        break;\n      case \"S\":\n        set = whitespaceCodes;\n        complement = true;\n        break;\n      case \"w\":\n        set = wordCharCodes;\n        break;\n      case \"W\":\n        set = wordCharCodes;\n        complement = true;\n        break;\n    }\n\n    // istanbul ignore else\n    if (ASSERT_EXISTS(set)) {\n      return { type: \"Set\", value: set, complement: complement };\n    }\n    // istanbul ignore next\n    return ASSERT_NEVER_REACH_HERE();\n  }\n\n  protected controlEscapeAtom(): Omit<Character, \"loc\"> {\n    let escapeCode;\n    switch (this.popChar()) {\n      case \"f\":\n        escapeCode = cc(\"\\f\");\n        break;\n      case \"n\":\n        escapeCode = cc(\"\\n\");\n        break;\n      case \"r\":\n        escapeCode = cc(\"\\r\");\n        break;\n      case \"t\":\n        escapeCode = cc(\"\\t\");\n        break;\n      case \"v\":\n        escapeCode = cc(\"\\v\");\n        break;\n    }\n\n    // istanbul ignore else\n    if (ASSERT_EXISTS(escapeCode)) {\n      return { type: \"Character\", value: escapeCode };\n    }\n    // istanbul ignore next\n    return ASSERT_NEVER_REACH_HERE();\n  }\n\n  protected controlLetterEscapeAtom(): Omit<Character, \"loc\"> {\n    this.consumeChar(\"c\");\n    const letter = this.popChar();\n    if (/[a-zA-Z]/.test(letter) === false) {\n      throw Error(\"Invalid \");\n    }\n\n    const letterCode = letter.toUpperCase().charCodeAt(0) - 64;\n    return { type: \"Character\", value: letterCode };\n  }\n\n  protected nulCharacterAtom(): Omit<Character, \"loc\"> {\n    // TODO implement '[lookahead ∉ DecimalDigit]'\n    // TODO: for the deprecated octal escape sequence\n    this.consumeChar(\"0\");\n    return { type: \"Character\", value: cc(\"\\0\") };\n  }\n\n  protected hexEscapeSequenceAtom(): Omit<Character, \"loc\"> {\n    this.consumeChar(\"x\");\n    return this.parseHexDigits(2);\n  }\n\n  protected regExpUnicodeEscapeSequenceAtom(): Omit<Character, \"loc\"> {\n    this.consumeChar(\"u\");\n    return this.parseHexDigits(4);\n  }\n\n  protected identityEscapeAtom(): Omit<Character, \"loc\"> {\n    // TODO: implement \"SourceCharacter but not UnicodeIDContinue\"\n    // // http://unicode.org/reports/tr31/#Specific_Character_Adjustments\n    const escapedChar = this.popChar();\n    return { type: \"Character\", value: cc(escapedChar) };\n  }\n\n  protected classPatternCharacterAtom(): Omit<Character, \"loc\"> {\n    switch (this.peekChar()) {\n      // istanbul ignore next\n      case \"\\n\":\n      // istanbul ignore next\n      case \"\\r\":\n      // istanbul ignore next\n      case \"\\u2028\":\n      // istanbul ignore next\n      case \"\\u2029\":\n      // istanbul ignore next\n      case \"\\\\\":\n      // istanbul ignore next\n      case \"]\":\n        throw Error(\"TBD\");\n      default:\n        const nextChar = this.popChar();\n        return { type: \"Character\", value: cc(nextChar) };\n    }\n  }\n\n  protected characterClass(): Omit<Set, \"loc\"> {\n    const set: (number | Range)[] = [];\n    let complement = false;\n    this.consumeChar(\"[\");\n    if (this.peekChar(0) === \"^\") {\n      this.consumeChar(\"^\");\n      complement = true;\n    }\n\n    while (this.isClassAtom()) {\n      const from = this.classAtom();\n      const isFromSingleChar = from.type === \"Character\";\n      if (isCharacter(from) && this.isRangeDash()) {\n        this.consumeChar(\"-\");\n        const to = this.classAtom();\n        const isToSingleChar = to.type === \"Character\";\n\n        // a range can only be used when both sides are single characters\n        if (isCharacter(to)) {\n          if (to.value < from.value) {\n            throw Error(\"Range out of order in character class\");\n          }\n          set.push({ from: from.value, to: to.value });\n        } else {\n          // literal dash\n          insertToSet(from.value, set);\n          set.push(cc(\"-\"));\n          insertToSet(to.value, set);\n        }\n      } else {\n        insertToSet(from.value, set);\n      }\n    }\n\n    this.consumeChar(\"]\");\n\n    return { type: \"Set\", complement: complement, value: set };\n  }\n\n  protected classAtom(): Omit<Character | Set, \"loc\"> {\n    switch (this.peekChar()) {\n      // istanbul ignore next\n      case \"]\":\n      // istanbul ignore next\n      case \"\\n\":\n      // istanbul ignore next\n      case \"\\r\":\n      // istanbul ignore next\n      case \"\\u2028\":\n      // istanbul ignore next\n      case \"\\u2029\":\n        throw Error(\"TBD\");\n      case \"\\\\\":\n        return this.classEscape();\n      default:\n        return this.classPatternCharacterAtom();\n    }\n  }\n\n  protected classEscape(): Omit<Character | Set, \"loc\"> {\n    this.consumeChar(\"\\\\\");\n    switch (this.peekChar()) {\n      // Matches a backspace.\n      // (Not to be confused with \\b word boundary outside characterClass)\n      case \"b\":\n        this.consumeChar(\"b\");\n        return { type: \"Character\", value: cc(\"\\u0008\") };\n      case \"d\":\n      case \"D\":\n      case \"s\":\n      case \"S\":\n      case \"w\":\n      case \"W\":\n        return this.characterClassEscape();\n      case \"f\":\n      case \"n\":\n      case \"r\":\n      case \"t\":\n      case \"v\":\n        return this.controlEscapeAtom();\n      case \"c\":\n        return this.controlLetterEscapeAtom();\n      case \"0\":\n        return this.nulCharacterAtom();\n      case \"x\":\n        return this.hexEscapeSequenceAtom();\n      case \"u\":\n        return this.regExpUnicodeEscapeSequenceAtom();\n      default:\n        return this.identityEscapeAtom();\n    }\n  }\n\n  protected group(): Omit<Group, \"loc\"> {\n    let capturing = true;\n    this.consumeChar(\"(\");\n    switch (this.peekChar(0)) {\n      case \"?\":\n        this.consumeChar(\"?\");\n        this.consumeChar(\":\");\n        capturing = false;\n        break;\n      default:\n        this.groupIdx++;\n        break;\n    }\n    const value = this.disjunction();\n    this.consumeChar(\")\");\n\n    const groupAst: Omit<Group, \"loc\"> = {\n      type: \"Group\",\n      capturing: capturing,\n      value: value,\n    };\n\n    if (capturing) {\n      groupAst[\"idx\"] = this.groupIdx;\n    }\n\n    return groupAst;\n  }\n\n  protected positiveInteger(): number {\n    let number = this.popChar();\n\n    // istanbul ignore next - can't ever get here due to previous lookahead checks\n    // still implementing this error checking in case this ever changes.\n    if (decimalPatternNoZero.test(number) === false) {\n      throw Error(\"Expecting a positive integer\");\n    }\n\n    while (decimalPattern.test(this.peekChar(0))) {\n      number += this.popChar();\n    }\n\n    return parseInt(number, 10);\n  }\n\n  protected integerIncludingZero(): number {\n    let number = this.popChar();\n    if (decimalPattern.test(number) === false) {\n      throw Error(\"Expecting an integer\");\n    }\n\n    while (decimalPattern.test(this.peekChar(0))) {\n      number += this.popChar();\n    }\n\n    return parseInt(number, 10);\n  }\n\n  protected patternCharacter(): Omit<Character, \"loc\"> {\n    const nextChar = this.popChar();\n    switch (nextChar) {\n      // istanbul ignore next\n      case \"\\n\":\n      // istanbul ignore next\n      case \"\\r\":\n      // istanbul ignore next\n      case \"\\u2028\":\n      // istanbul ignore next\n      case \"\\u2029\":\n      // istanbul ignore next\n      case \"^\":\n      // istanbul ignore next\n      case \"$\":\n      // istanbul ignore next\n      case \"\\\\\":\n      // istanbul ignore next\n      case \".\":\n      // istanbul ignore next\n      case \"*\":\n      // istanbul ignore next\n      case \"+\":\n      // istanbul ignore next\n      case \"?\":\n      // istanbul ignore next\n      case \"(\":\n      // istanbul ignore next\n      case \")\":\n      // istanbul ignore next\n      case \"[\":\n      // istanbul ignore next\n      case \"|\":\n        // istanbul ignore next\n        throw Error(\"TBD\");\n      default:\n        return { type: \"Character\", value: cc(nextChar) };\n    }\n  }\n  protected isRegExpFlag(): boolean {\n    switch (this.peekChar(0)) {\n      case \"g\":\n      case \"i\":\n      case \"m\":\n      case \"u\":\n      case \"y\":\n        return true;\n      default:\n        return false;\n    }\n  }\n\n  protected isRangeDash(): boolean {\n    return this.peekChar() === \"-\" && this.isClassAtom(1);\n  }\n\n  protected isDigit(): boolean {\n    return decimalPattern.test(this.peekChar(0));\n  }\n\n  protected isClassAtom(howMuch = 0): boolean {\n    switch (this.peekChar(howMuch)) {\n      case \"]\":\n      case \"\\n\":\n      case \"\\r\":\n      case \"\\u2028\":\n      case \"\\u2029\":\n        return false;\n      default:\n        return true;\n    }\n  }\n\n  protected isTerm() {\n    return this.isAtom() || this.isAssertion();\n  }\n\n  protected isAtom(): boolean {\n    if (this.isPatternCharacter()) {\n      return true;\n    }\n\n    switch (this.peekChar(0)) {\n      case \".\":\n      case \"\\\\\": // atomEscape\n      case \"[\": // characterClass\n      // TODO: isAtom must be called before isAssertion - disambiguate\n      case \"(\": // group\n        return true;\n      default:\n        return false;\n    }\n  }\n\n  protected isAssertion(): boolean {\n    switch (this.peekChar(0)) {\n      case \"^\":\n      case \"$\":\n        return true;\n      // '\\b' or '\\B'\n      case \"\\\\\":\n        switch (this.peekChar(1)) {\n          case \"b\":\n          case \"B\":\n            return true;\n          default:\n            return false;\n        }\n      // '(?=' or '(?!'\n      case \"(\":\n        return (\n          this.peekChar(1) === \"?\" &&\n          (this.peekChar(2) === \"=\" || this.peekChar(2) === \"!\")\n        );\n      default:\n        return false;\n    }\n  }\n\n  protected isQuantifier(): boolean {\n    const prevState = this.saveState();\n    try {\n      return this.quantifier(true) !== undefined;\n    } catch (e) {\n      return false;\n    } finally {\n      this.restoreState(prevState);\n    }\n  }\n\n  protected isPatternCharacter(): boolean {\n    switch (this.peekChar()) {\n      case \"^\":\n      case \"$\":\n      case \"\\\\\":\n      case \".\":\n      case \"*\":\n      case \"+\":\n      case \"?\":\n      case \"(\":\n      case \")\":\n      case \"[\":\n      case \"|\":\n      case \"/\":\n      case \"\\n\":\n      case \"\\r\":\n      case \"\\u2028\":\n      case \"\\u2029\":\n        return false;\n      default:\n        return true;\n    }\n  }\n\n  protected parseHexDigits(howMany: number): Omit<Character, \"loc\"> {\n    let hexString = \"\";\n    for (let i = 0; i < howMany; i++) {\n      const hexChar = this.popChar();\n      if (hexDigitPattern.test(hexChar) === false) {\n        throw Error(\"Expecting a HexDecimal digits\");\n      }\n      hexString += hexChar;\n    }\n    const charCode = parseInt(hexString, 16);\n    return { type: \"Character\", value: charCode };\n  }\n\n  protected peekChar(howMuch = 0): string {\n    return this.input[this.idx + howMuch];\n  }\n\n  protected popChar(): string {\n    const nextChar = this.peekChar(0);\n    this.consumeChar(undefined);\n    return nextChar;\n  }\n\n  protected consumeChar(char: string | undefined): void {\n    if (char !== undefined && this.input[this.idx] !== char) {\n      throw Error(\n        \"Expected: '\" +\n          char +\n          \"' but found: '\" +\n          this.input[this.idx] +\n          \"' at offset: \" +\n          this.idx,\n      );\n    }\n\n    if (this.idx >= this.input.length) {\n      throw Error(\"Unexpected end of input\");\n    }\n    this.idx++;\n  }\n\n  protected loc(begin: number): Location {\n    return { begin: begin, end: this.idx };\n  }\n}\n","import type {\n  Alternative,\n  Assertion,\n  Character,\n  Disjunction,\n  Group,\n  GroupBackReference,\n  IRegExpAST,\n  Quantifier,\n  RegExpAstPart,\n  RegExpFlags,\n  RegExpPattern,\n  Set,\n} from \"../types\";\n\nexport class BaseRegExpVisitor {\n  public visitChildren(node: IRegExpAST) {\n    for (const key in node) {\n      const child = (node as any)[key];\n      /* istanbul ignore else */\n      if (node.hasOwnProperty(key)) {\n        if (child.type !== undefined) {\n          this.visit(child);\n        } else if (Array.isArray(child)) {\n          child.forEach((subChild) => {\n            this.visit(subChild);\n          }, this);\n        }\n      }\n    }\n  }\n\n  public visit(node: RegExpAstPart): void {\n    switch (node.type) {\n      case \"Pattern\":\n        this.visitPattern(node);\n        break;\n      case \"Flags\":\n        this.visitFlags(node);\n        break;\n      case \"Disjunction\":\n        this.visitDisjunction(node);\n        break;\n      case \"Alternative\":\n        this.visitAlternative(node);\n        break;\n      case \"StartAnchor\":\n        this.visitStartAnchor(node);\n        break;\n      case \"EndAnchor\":\n        this.visitEndAnchor(node);\n        break;\n      case \"WordBoundary\":\n        this.visitWordBoundary(node);\n        break;\n      case \"NonWordBoundary\":\n        this.visitNonWordBoundary(node);\n        break;\n      case \"Lookahead\":\n        this.visitLookahead(node);\n        break;\n      case \"NegativeLookahead\":\n        this.visitNegativeLookahead(node);\n        break;\n      case \"Character\":\n        this.visitCharacter(node);\n        break;\n      case \"Set\":\n        this.visitSet(node);\n        break;\n      case \"Group\":\n        this.visitGroup(node);\n        break;\n      case \"GroupBackReference\":\n        this.visitGroupBackReference(node);\n        break;\n      case \"Quantifier\":\n        this.visitQuantifier(node);\n        break;\n    }\n\n    this.visitChildren(node);\n  }\n\n  public visitPattern(node: RegExpPattern): void {}\n\n  public visitFlags(node: RegExpFlags): void {}\n\n  public visitDisjunction(node: Disjunction): void {}\n\n  public visitAlternative(node: Alternative): void {}\n\n  // Assertion\n  public visitStartAnchor(node: Assertion): void {}\n\n  public visitEndAnchor(node: Assertion): void {}\n\n  public visitWordBoundary(node: Assertion): void {}\n\n  public visitNonWordBoundary(node: Assertion): void {}\n\n  public visitLookahead(node: Assertion): void {}\n\n  public visitNegativeLookahead(node: Assertion): void {}\n\n  // atoms\n  public visitCharacter(node: Character): void {}\n\n  public visitSet(node: Set): void {}\n\n  public visitGroup(node: Group): void {}\n\n  public visitGroupBackReference(node: GroupBackReference): void {}\n\n  public visitQuantifier(node: Quantifier): void {}\n}\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { IToken } from '@chevrotain/types';\r\nimport type { Range } from 'vscode-languageserver-types';\r\nimport type { CstNode, CompositeCstNode, LeafCstNode } from '../syntax-tree.js';\r\nimport type { DocumentSegment } from '../workspace/documents.js';\r\nimport type { Stream, TreeStream } from './stream.js';\r\nimport { isCompositeCstNode, isLeafCstNode, isRootCstNode } from '../syntax-tree.js';\r\nimport { TreeStreamImpl } from './stream.js';\r\n\r\n/**\r\n * Create a stream of all CST nodes that are directly and indirectly contained in the given root node,\r\n * including the root node itself.\r\n */\r\nexport function streamCst(node: CstNode): TreeStream<CstNode> {\r\n    return new TreeStreamImpl(node, element => {\r\n        if (isCompositeCstNode(element)) {\r\n            return element.content;\r\n        } else {\r\n            return [];\r\n        }\r\n    }, { includeRoot: true });\r\n}\r\n\r\n/**\r\n * Create a stream of all leaf nodes that are directly and indirectly contained in the given root node.\r\n */\r\nexport function flattenCst(node: CstNode): Stream<LeafCstNode> {\r\n    return streamCst(node).filter(isLeafCstNode);\r\n}\r\n\r\n/**\r\n * Determines whether the specified cst node is a child of the specified parent node.\r\n */\r\nexport function isChildNode(child: CstNode, parent: CstNode): boolean {\r\n    while (child.container) {\r\n        child = child.container;\r\n        if (child === parent) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}\r\n\r\nexport function tokenToRange(token: IToken): Range {\r\n    // Chevrotain uses 1-based indices everywhere\r\n    // So we subtract 1 from every value to align with the LSP\r\n    return {\r\n        start: {\r\n            character: token.startColumn! - 1,\r\n            line: token.startLine! - 1\r\n        },\r\n        end: {\r\n            character: token.endColumn!, // endColumn uses the correct index\r\n            line: token.endLine! - 1\r\n        }\r\n    };\r\n}\r\n\r\nexport function toDocumentSegment(node: CstNode): DocumentSegment;\r\nexport function toDocumentSegment(node?: CstNode): DocumentSegment | undefined;\r\nexport function toDocumentSegment(node?: CstNode): DocumentSegment | undefined {\r\n    if (!node) {\r\n        return undefined;\r\n    }\r\n    const { offset, end, range } = node;\r\n    return {\r\n        range,\r\n        offset,\r\n        end,\r\n        length: end - offset\r\n    };\r\n}\r\n\r\nexport enum RangeComparison {\r\n    Before = 0,\r\n    After = 1,\r\n    OverlapFront = 2,\r\n    OverlapBack = 3,\r\n    Inside = 4,\r\n    Outside = 5,\r\n}\r\n\r\nexport function compareRange(range: Range, to: Range): RangeComparison {\r\n    if (range.end.line < to.start.line || (range.end.line === to.start.line && range.end.character <= to.start.character)) {\r\n        return RangeComparison.Before;\r\n    } else if (range.start.line > to.end.line || (range.start.line === to.end.line && range.start.character >= to.end.character)) {\r\n        return RangeComparison.After;\r\n    }\r\n    const startInside = range.start.line > to.start.line || (range.start.line === to.start.line && range.start.character >= to.start.character);\r\n    const endInside = range.end.line < to.end.line || (range.end.line === to.end.line && range.end.character <= to.end.character);\r\n    if (startInside && endInside) {\r\n        return RangeComparison.Inside;\r\n    } else if (startInside) {\r\n        return RangeComparison.OverlapBack;\r\n    } else if (endInside) {\r\n        return RangeComparison.OverlapFront;\r\n    } else {\r\n        return RangeComparison.Outside;\r\n    }\r\n}\r\n\r\nexport function inRange(range: Range, to: Range): boolean {\r\n    const comparison = compareRange(range, to);\r\n    return comparison > RangeComparison.After;\r\n}\r\n\r\n// The \\p{L} regex matches any unicode letter character, i.e. characters from non-english alphabets\r\n// Together with \\w it matches any kind of character which can commonly appear in IDs\r\nexport const DefaultNameRegexp = /^[\\w\\p{L}]$/u;\r\n\r\n/**\r\n * Performs `findLeafNodeAtOffset` with a minor difference: When encountering a character that matches the `nameRegexp` argument,\r\n * it will instead return the leaf node at the `offset - 1` position.\r\n *\r\n * For LSP services, users expect that the declaration of an element is available if the cursor is directly after the element.\r\n */\r\nexport function findDeclarationNodeAtOffset(cstNode: CstNode | undefined, offset: number, nameRegexp = DefaultNameRegexp): LeafCstNode | undefined {\r\n    if (cstNode) {\r\n        if (offset > 0) {\r\n            const localOffset = offset - cstNode.offset;\r\n            const textAtOffset = cstNode.text.charAt(localOffset);\r\n            if (!nameRegexp.test(textAtOffset)) {\r\n                offset--;\r\n            }\r\n        }\r\n        return findLeafNodeAtOffset(cstNode, offset);\r\n    }\r\n    return undefined;\r\n}\r\n\r\nexport function findCommentNode(cstNode: CstNode | undefined, commentNames: string[]): CstNode | undefined {\r\n    if (cstNode) {\r\n        const previous = getPreviousNode(cstNode, true);\r\n        if (previous && isCommentNode(previous, commentNames)) {\r\n            return previous;\r\n        }\r\n        if (isRootCstNode(cstNode)) {\r\n            // Go from the first non-hidden node through all nodes in reverse order\r\n            // We do this to find the comment node which directly precedes the root node\r\n            const endIndex = cstNode.content.findIndex(e => !e.hidden);\r\n            for (let i = endIndex - 1; i >= 0; i--) {\r\n                const child = cstNode.content[i];\r\n                if (isCommentNode(child, commentNames)) {\r\n                    return child;\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return undefined;\r\n}\r\n\r\nexport function isCommentNode(cstNode: CstNode, commentNames: string[]): boolean {\r\n    return isLeafCstNode(cstNode) && commentNames.includes(cstNode.tokenType.name);\r\n}\r\n\r\n/**\r\n * Finds the leaf CST node at the specified 0-based string offset.\r\n * Note that the given offset will be within the range of the returned leaf node.\r\n *\r\n * If the offset does not point to a CST node (but just white space), this method will return `undefined`.\r\n *\r\n * @param node The CST node to search through.\r\n * @param offset The specified offset.\r\n * @returns The CST node at the specified offset.\r\n */\r\nexport function findLeafNodeAtOffset(node: CstNode, offset: number): LeafCstNode | undefined {\r\n    if (isLeafCstNode(node)) {\r\n        return node;\r\n    } else if (isCompositeCstNode(node)) {\r\n        const searchResult = binarySearch(node, offset, false);\r\n        if (searchResult) {\r\n            return findLeafNodeAtOffset(searchResult, offset);\r\n        }\r\n    }\r\n    return undefined;\r\n}\r\n\r\n/**\r\n * Finds the leaf CST node at the specified 0-based string offset.\r\n * If no CST node exists at the specified position, it will return the leaf node before it.\r\n *\r\n * If there is no leaf node before the specified offset, this method will return `undefined`.\r\n *\r\n * @param node The CST node to search through.\r\n * @param offset The specified offset.\r\n * @returns The CST node closest to the specified offset.\r\n */\r\nexport function findLeafNodeBeforeOffset(node: CstNode, offset: number): LeafCstNode | undefined {\r\n    if (isLeafCstNode(node)) {\r\n        return node;\r\n    } else if (isCompositeCstNode(node)) {\r\n        const searchResult = binarySearch(node, offset, true);\r\n        if (searchResult) {\r\n            return findLeafNodeBeforeOffset(searchResult, offset);\r\n        }\r\n    }\r\n    return undefined;\r\n}\r\n\r\nfunction binarySearch(node: CompositeCstNode, offset: number, closest: boolean): CstNode | undefined {\r\n    let left = 0;\r\n    let right = node.content.length - 1;\r\n    let closestNode: CstNode | undefined = undefined;\r\n\r\n    while (left <= right) {\r\n        const middle = Math.floor((left + right) / 2);\r\n        const middleNode = node.content[middle];\r\n\r\n        if (middleNode.offset <= offset && middleNode.end > offset) {\r\n            // Found an exact match\r\n            return middleNode;\r\n        }\r\n\r\n        if (middleNode.end <= offset) {\r\n            // Update the closest node (less than offset) and move to the right half\r\n            closestNode = closest ? middleNode : undefined;\r\n            left = middle + 1;\r\n        } else {\r\n            // Move to the left half\r\n            right = middle - 1;\r\n        }\r\n    }\r\n\r\n    return closestNode;\r\n}\r\n\r\nexport function getPreviousNode(node: CstNode, hidden = true): CstNode | undefined {\r\n    while (node.container) {\r\n        const parent = node.container;\r\n        let index = parent.content.indexOf(node);\r\n        while (index > 0) {\r\n            index--;\r\n            const previous = parent.content[index];\r\n            if (hidden || !previous.hidden) {\r\n                return previous;\r\n            }\r\n        }\r\n        node = parent;\r\n    }\r\n    return undefined;\r\n}\r\n\r\nexport function getNextNode(node: CstNode, hidden = true): CstNode | undefined {\r\n    while (node.container) {\r\n        const parent = node.container;\r\n        let index = parent.content.indexOf(node);\r\n        const last = parent.content.length - 1;\r\n        while (index < last) {\r\n            index++;\r\n            const next = parent.content[index];\r\n            if (hidden || !next.hidden) {\r\n                return next;\r\n            }\r\n        }\r\n        node = parent;\r\n    }\r\n    return undefined;\r\n}\r\n\r\nexport function getStartlineNode(node: CstNode): CstNode {\r\n    if (node.range.start.character === 0) {\r\n        return node;\r\n    }\r\n    const line = node.range.start.line;\r\n    let last = node;\r\n    let index: number | undefined;\r\n    while (node.container) {\r\n        const parent = node.container;\r\n        const selfIndex = index ?? parent.content.indexOf(node);\r\n        if (selfIndex === 0) {\r\n            node = parent;\r\n            index = undefined;\r\n        } else {\r\n            index = selfIndex - 1;\r\n            node = parent.content[index];\r\n        }\r\n        if (node.range.start.line !== line) {\r\n            break;\r\n        }\r\n        last = node;\r\n    }\r\n    return last;\r\n}\r\n\r\nexport function getInteriorNodes(start: CstNode, end: CstNode): CstNode[] {\r\n    const commonParent = getCommonParent(start, end);\r\n    if (!commonParent) {\r\n        return [];\r\n    }\r\n    return commonParent.parent.content.slice(commonParent.a + 1, commonParent.b);\r\n}\r\n\r\nfunction getCommonParent(a: CstNode, b: CstNode): CommonParent | undefined {\r\n    const aParents = getParentChain(a);\r\n    const bParents = getParentChain(b);\r\n    let current: CommonParent | undefined;\r\n    for (let i = 0; i < aParents.length && i < bParents.length; i++) {\r\n        const aParent = aParents[i];\r\n        const bParent = bParents[i];\r\n        if (aParent.parent === bParent.parent) {\r\n            current = {\r\n                parent: aParent.parent,\r\n                a: aParent.index,\r\n                b: bParent.index\r\n            };\r\n        } else {\r\n            break;\r\n        }\r\n    }\r\n    return current;\r\n}\r\n\r\ninterface CommonParent {\r\n    parent: CompositeCstNode\r\n    a: number\r\n    b: number\r\n}\r\n\r\nfunction getParentChain(node: CstNode): ParentLink[] {\r\n    const chain: ParentLink[] = [];\r\n    while (node.container) {\r\n        const parent = node.container;\r\n        const index = parent.content.indexOf(node);\r\n        chain.push({\r\n            parent,\r\n            index\r\n        });\r\n        node = parent;\r\n    }\r\n    return chain.reverse();\r\n}\r\n\r\ninterface ParentLink {\r\n    parent: CompositeCstNode\r\n    index: number\r\n}\r\n","import toFinite from './toFinite.js';\n\n/**\n * Converts `value` to an integer.\n *\n * **Note:** This method is loosely based on\n * [`ToInteger`](http://www.ecma-international.org/ecma-262/7.0/#sec-tointeger).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {number} Returns the converted integer.\n * @example\n *\n * _.toInteger(3.2);\n * // => 3\n *\n * _.toInteger(Number.MIN_VALUE);\n * // => 0\n *\n * _.toInteger(Infinity);\n * // => 1.7976931348623157e+308\n *\n * _.toInteger('3.2');\n * // => 3\n */\nfunction toInteger(value) {\n  var result = toFinite(value),\n      remainder = result % 1;\n\n  return result === result ? (remainder ? result - remainder : result) : 0;\n}\n\nexport default toInteger;\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { CustomPatternMatcherFunc, ILexingError, TokenPattern, TokenType, TokenVocabulary } from 'chevrotain';\r\nimport type { AbstractRule, Grammar, Keyword, TerminalRule } from '../languages/generated/ast.js';\r\nimport type { Stream } from '../utils/stream.js';\r\nimport { Lexer } from 'chevrotain';\r\nimport { isKeyword, isParserRule, isTerminalRule } from '../languages/generated/ast.js';\r\nimport { streamAllContents } from '../utils/ast-utils.js';\r\nimport { getAllReachableRules, terminalRegex } from '../utils/grammar-utils.js';\r\nimport { getCaseInsensitivePattern, isWhitespace, partialMatches } from '../utils/regexp-utils.js';\r\nimport { stream } from '../utils/stream.js';\r\n\r\nexport interface TokenBuilderOptions {\r\n    caseInsensitive?: boolean\r\n}\r\n\r\nexport interface TokenBuilder {\r\n    buildTokens(grammar: Grammar, options?: TokenBuilderOptions): TokenVocabulary;\r\n    /**\r\n     * Produces a lexing report for the given text that was just tokenized using the tokens provided by this builder.\r\n     *\r\n     * @param text The text that was tokenized.\r\n     */\r\n    flushLexingReport?(text: string): LexingReport;\r\n}\r\n\r\n/**\r\n * A custom lexing report that can be produced by the token builder during the lexing process.\r\n * Adopters need to ensure that the any custom fields are serializable so they can be sent across worker threads.\r\n */\r\nexport interface LexingReport {\r\n    diagnostics: LexingDiagnostic[];\r\n}\r\n\r\nexport type LexingDiagnosticSeverity = 'error' | 'warning' | 'info' | 'hint';\r\n\r\nexport interface LexingDiagnostic extends ILexingError {\r\n    severity?: LexingDiagnosticSeverity;\r\n}\r\n\r\nexport class DefaultTokenBuilder implements TokenBuilder {\r\n    /**\r\n     * The list of diagnostics stored during the lexing process of a single text.\r\n     */\r\n    protected diagnostics: LexingDiagnostic[] = [];\r\n\r\n    buildTokens(grammar: Grammar, options?: TokenBuilderOptions): TokenVocabulary {\r\n        const reachableRules = stream(getAllReachableRules(grammar, false));\r\n        const terminalTokens: TokenType[] = this.buildTerminalTokens(reachableRules);\r\n        const tokens: TokenType[] = this.buildKeywordTokens(reachableRules, terminalTokens, options);\r\n\r\n        terminalTokens.forEach(terminalToken => {\r\n            const pattern = terminalToken.PATTERN;\r\n            if (typeof pattern === 'object' && pattern && 'test' in pattern && isWhitespace(pattern)) {\r\n                tokens.unshift(terminalToken);\r\n            } else {\r\n                tokens.push(terminalToken);\r\n            }\r\n        });\r\n        // We don't need to add the EOF token explicitly.\r\n        // It is automatically available at the end of the token stream.\r\n        return tokens;\r\n    }\r\n\r\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\r\n    flushLexingReport(text: string): LexingReport {\r\n        return { diagnostics: this.popDiagnostics() };\r\n    }\r\n\r\n    protected popDiagnostics(): LexingDiagnostic[] {\r\n        const diagnostics = [...this.diagnostics];\r\n        this.diagnostics = [];\r\n        return diagnostics;\r\n    }\r\n\r\n    protected buildTerminalTokens(rules: Stream<AbstractRule>): TokenType[] {\r\n        return rules.filter(isTerminalRule).filter(e => !e.fragment)\r\n            .map(terminal => this.buildTerminalToken(terminal)).toArray();\r\n    }\r\n\r\n    protected buildTerminalToken(terminal: TerminalRule): TokenType {\r\n        const regex = terminalRegex(terminal);\r\n        const pattern = this.requiresCustomPattern(regex) ? this.regexPatternFunction(regex) : regex;\r\n        const tokenType: TokenType = {\r\n            name: terminal.name,\r\n            PATTERN: pattern,\r\n        };\r\n        if (typeof pattern === 'function') {\r\n            tokenType.LINE_BREAKS = true;\r\n        }\r\n        if (terminal.hidden) {\r\n            // Only skip tokens that are able to accept whitespace\r\n            tokenType.GROUP = isWhitespace(regex) ? Lexer.SKIPPED : 'hidden';\r\n        }\r\n        return tokenType;\r\n    }\r\n\r\n    protected requiresCustomPattern(regex: RegExp): boolean {\r\n        if (regex.flags.includes('u') || regex.flags.includes('s')) {\r\n            // Unicode and dotall regexes are not supported by Chevrotain.\r\n            return true;\r\n        } else if (regex.source.includes('?<=') || regex.source.includes('?<!')) {\r\n            // Negative and positive lookbehind are not supported by Chevrotain yet.\r\n            return true;\r\n        } else {\r\n            return false;\r\n        }\r\n    }\r\n\r\n    protected regexPatternFunction(regex: RegExp): CustomPatternMatcherFunc {\r\n        const stickyRegex = new RegExp(regex, regex.flags + 'y');\r\n        return (text, offset) => {\r\n            stickyRegex.lastIndex = offset;\r\n            const execResult = stickyRegex.exec(text);\r\n            return execResult;\r\n        };\r\n    }\r\n\r\n    protected buildKeywordTokens(rules: Stream<AbstractRule>, terminalTokens: TokenType[], options?: TokenBuilderOptions): TokenType[] {\r\n        return rules\r\n            // We filter by parser rules, since keywords in terminal rules get transformed into regex and are not actual tokens\r\n            .filter(isParserRule)\r\n            .flatMap(rule => streamAllContents(rule).filter(isKeyword))\r\n            .distinct(e => e.value).toArray()\r\n            // Sort keywords by descending length\r\n            .sort((a, b) => b.value.length - a.value.length)\r\n            .map(keyword => this.buildKeywordToken(keyword, terminalTokens, Boolean(options?.caseInsensitive)));\r\n    }\r\n\r\n    protected buildKeywordToken(keyword: Keyword, terminalTokens: TokenType[], caseInsensitive: boolean): TokenType {\r\n        const keywordPattern = this.buildKeywordPattern(keyword, caseInsensitive);\r\n        const tokenType: TokenType = {\r\n            name: keyword.value,\r\n            PATTERN: keywordPattern,\r\n            LONGER_ALT: this.findLongerAlt(keyword, terminalTokens)\r\n        };\r\n\r\n        if (typeof keywordPattern === 'function') {\r\n            tokenType.LINE_BREAKS = true;\r\n        }\r\n\r\n        return tokenType;\r\n    }\r\n\r\n    protected buildKeywordPattern(keyword: Keyword, caseInsensitive: boolean): TokenPattern {\r\n        return caseInsensitive ?\r\n            new RegExp(getCaseInsensitivePattern(keyword.value)) :\r\n            keyword.value;\r\n    }\r\n\r\n    protected findLongerAlt(keyword: Keyword, terminalTokens: TokenType[]): TokenType[] {\r\n        return terminalTokens.reduce((longerAlts: TokenType[], token) => {\r\n            const pattern = token?.PATTERN as RegExp;\r\n            if (pattern?.source && partialMatches('^' + pattern.source + '$', keyword.value)) {\r\n                longerAlts.push(token);\r\n            }\r\n            return longerAlts;\r\n        }, []);\r\n    }\r\n}\r\n","import {\n  AbstractMermaidTokenBuilder,\n  CommonValueConverter,\n  MermaidGeneratedSharedModule,\n  PacketGeneratedModule,\n  __name\n} from \"./chunk-4KMFLZZN.mjs\";\n\n// src/language/packet/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/packet/tokenBuilder.ts\nvar PacketTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"PacketTokenBuilder\");\n  }\n  constructor() {\n    super([\"packet\"]);\n  }\n};\n\n// src/language/packet/module.ts\nvar PacketModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new PacketTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new CommonValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createPacketServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Packet = inject(\n    createDefaultCoreModule({ shared }),\n    PacketGeneratedModule,\n    PacketModule\n  );\n  shared.ServiceRegistry.register(Packet);\n  return { shared, Packet };\n}\n__name(createPacketServices, \"createPacketServices\");\n\nexport {\n  PacketModule,\n  createPacketServices\n};\n","import baseIteratee from './_baseIteratee.js';\nimport isArrayLike from './isArrayLike.js';\nimport keys from './keys.js';\n\n/**\n * Creates a `_.find` or `_.findLast` function.\n *\n * @private\n * @param {Function} findIndexFunc The function to find the collection index.\n * @returns {Function} Returns the new find function.\n */\nfunction createFind(findIndexFunc) {\n  return function(collection, predicate, fromIndex) {\n    var iterable = Object(collection);\n    if (!isArrayLike(collection)) {\n      var iteratee = baseIteratee(predicate, 3);\n      collection = keys(collection);\n      predicate = function(key) { return iteratee(iterable[key], key, iterable); };\n    }\n    var index = findIndexFunc(collection, predicate, fromIndex);\n    return index > -1 ? iterable[iteratee ? collection[index] : index] : undefined;\n  };\n}\n\nexport default createFind;\n","import baseFindIndex from './_baseFindIndex.js';\nimport baseIteratee from './_baseIteratee.js';\nimport toInteger from './toInteger.js';\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * This method is like `_.find` except that it returns the index of the first\n * element `predicate` returns truthy for instead of the element itself.\n *\n * @static\n * @memberOf _\n * @since 1.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param {number} [fromIndex=0] The index to search from.\n * @returns {number} Returns the index of the found element, else `-1`.\n * @example\n *\n * var users = [\n *   { 'user': 'barney',  'active': false },\n *   { 'user': 'fred',    'active': false },\n *   { 'user': 'pebbles', 'active': true }\n * ];\n *\n * _.findIndex(users, function(o) { return o.user == 'barney'; });\n * // => 0\n *\n * // The `_.matches` iteratee shorthand.\n * _.findIndex(users, { 'user': 'fred', 'active': false });\n * // => 1\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.findIndex(users, ['active', false]);\n * // => 0\n *\n * // The `_.property` iteratee shorthand.\n * _.findIndex(users, 'active');\n * // => 2\n */\nfunction findIndex(array, predicate, fromIndex) {\n  var length = array == null ? 0 : array.length;\n  if (!length) {\n    return -1;\n  }\n  var index = fromIndex == null ? 0 : toInteger(fromIndex);\n  if (index < 0) {\n    index = nativeMax(length + index, 0);\n  }\n  return baseFindIndex(array, baseIteratee(predicate, 3), index);\n}\n\nexport default findIndex;\n","import createFind from './_createFind.js';\nimport findIndex from './findIndex.js';\n\n/**\n * Iterates over elements of `collection`, returning the first element\n * `predicate` returns truthy for. The predicate is invoked with three\n * arguments: (value, index|key, collection).\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to inspect.\n * @param {Function} [predicate=_.identity] The function invoked per iteration.\n * @param {number} [fromIndex=0] The index to search from.\n * @returns {*} Returns the matched element, else `undefined`.\n * @example\n *\n * var users = [\n *   { 'user': 'barney',  'age': 36, 'active': true },\n *   { 'user': 'fred',    'age': 40, 'active': false },\n *   { 'user': 'pebbles', 'age': 1,  'active': true }\n * ];\n *\n * _.find(users, function(o) { return o.age < 40; });\n * // => object for 'barney'\n *\n * // The `_.matches` iteratee shorthand.\n * _.find(users, { 'age': 1, 'active': true });\n * // => object for 'pebbles'\n *\n * // The `_.matchesProperty` iteratee shorthand.\n * _.find(users, ['active', false]);\n * // => object for 'fred'\n *\n * // The `_.property` iteratee shorthand.\n * _.find(users, 'active');\n * // => object for 'barney'\n */\nvar find = createFind(findIndex);\n\nexport default find;\n","/******************************************************************************\r\n * Copyright 2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { URI } from '../utils/uri-utils.js';\r\n\r\nexport interface FileSystemNode {\r\n    readonly isFile: boolean;\r\n    readonly isDirectory: boolean;\r\n    readonly uri: URI;\r\n}\r\n\r\nexport type FileSystemFilter = (node: FileSystemNode) => boolean;\r\n\r\n/**\r\n * Provides methods to interact with an abstract file system. The default implementation is based on the node.js `fs` API.\r\n */\r\nexport interface FileSystemProvider {\r\n    /**\r\n     * Reads a document asynchronously from a given URI.\r\n     * @returns The string content of the file with the specified URI.\r\n     */\r\n    readFile(uri: URI): Promise<string>;\r\n    /**\r\n     * Reads the directory information for the given URI.\r\n     * @returns The list of file system entries that are contained within the specified directory.\r\n     */\r\n    readDirectory(uri: URI): Promise<FileSystemNode[]>;\r\n}\r\n\r\nexport class EmptyFileSystemProvider implements FileSystemProvider {\r\n\r\n    readFile(): Promise<string> {\r\n        throw new Error('No file system is available.');\r\n    }\r\n\r\n    async readDirectory(): Promise<FileSystemNode[]> {\r\n        return [];\r\n    }\r\n\r\n}\r\n\r\nexport const EmptyFileSystem = {\r\n    fileSystemProvider: () => new EmptyFileSystemProvider()\r\n};\r\n","\"use strict\";\n/* --------------------------------------------------------------------------------------------\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License. See License.txt in the project root for license information.\n * ------------------------------------------------------------------------------------------ */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.stringArray = exports.array = exports.func = exports.error = exports.number = exports.string = exports.boolean = void 0;\nfunction boolean(value) {\n    return value === true || value === false;\n}\nexports.boolean = boolean;\nfunction string(value) {\n    return typeof value === 'string' || value instanceof String;\n}\nexports.string = string;\nfunction number(value) {\n    return typeof value === 'number' || value instanceof Number;\n}\nexports.number = number;\nfunction error(value) {\n    return value instanceof Error;\n}\nexports.error = error;\nfunction func(value) {\n    return typeof value === 'function';\n}\nexports.func = func;\nfunction array(value) {\n    return Array.isArray(value);\n}\nexports.array = array;\nfunction stringArray(value) {\n    return array(value) && value.every(elem => string(elem));\n}\nexports.stringArray = stringArray;\n","\"use strict\";\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.CancellationTokenSource = exports.CancellationToken = void 0;\nconst ral_1 = require(\"./ral\");\nconst Is = require(\"./is\");\nconst events_1 = require(\"./events\");\nvar CancellationToken;\n(function (CancellationToken) {\n    CancellationToken.None = Object.freeze({\n        isCancellationRequested: false,\n        onCancellationRequested: events_1.Event.None\n    });\n    CancellationToken.Cancelled = Object.freeze({\n        isCancellationRequested: true,\n        onCancellationRequested: events_1.Event.None\n    });\n    function is(value) {\n        const candidate = value;\n        return candidate && (candidate === CancellationToken.None\n            || candidate === CancellationToken.Cancelled\n            || (Is.boolean(candidate.isCancellationRequested) && !!candidate.onCancellationRequested));\n    }\n    CancellationToken.is = is;\n})(CancellationToken || (exports.CancellationToken = CancellationToken = {}));\nconst shortcutEvent = Object.freeze(function (callback, context) {\n    const handle = (0, ral_1.default)().timer.setTimeout(callback.bind(context), 0);\n    return { dispose() { handle.dispose(); } };\n});\nclass MutableToken {\n    constructor() {\n        this._isCancelled = false;\n    }\n    cancel() {\n        if (!this._isCancelled) {\n            this._isCancelled = true;\n            if (this._emitter) {\n                this._emitter.fire(undefined);\n                this.dispose();\n            }\n        }\n    }\n    get isCancellationRequested() {\n        return this._isCancelled;\n    }\n    get onCancellationRequested() {\n        if (this._isCancelled) {\n            return shortcutEvent;\n        }\n        if (!this._emitter) {\n            this._emitter = new events_1.Emitter();\n        }\n        return this._emitter.event;\n    }\n    dispose() {\n        if (this._emitter) {\n            this._emitter.dispose();\n            this._emitter = undefined;\n        }\n    }\n}\nclass CancellationTokenSource {\n    get token() {\n        if (!this._token) {\n            // be lazy and create the token only when\n            // actually needed\n            this._token = new MutableToken();\n        }\n        return this._token;\n    }\n    cancel() {\n        if (!this._token) {\n            // save an object by returning the default\n            // cancelled token when cancellation happens\n            // before someone asks for the token\n            this._token = CancellationToken.Cancelled;\n        }\n        else {\n            this._token.cancel();\n        }\n    }\n    dispose() {\n        if (!this._token) {\n            // ensure to initialize with an empty token if we had none\n            this._token = CancellationToken.None;\n        }\n        else if (this._token instanceof MutableToken) {\n            // actually dispose\n            this._token.dispose();\n        }\n    }\n}\nexports.CancellationTokenSource = CancellationTokenSource;\n","import {\n  AbstractMermaidTokenBuilder,\n  CommonValueConverter,\n  GitGraphGeneratedModule,\n  MermaidGeneratedSharedModule,\n  __name\n} from \"./chunk-4KMFLZZN.mjs\";\n\n// src/language/gitGraph/module.ts\nimport {\n  inject,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  EmptyFileSystem\n} from \"langium\";\n\n// src/language/gitGraph/tokenBuilder.ts\nvar GitGraphTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"GitGraphTokenBuilder\");\n  }\n  constructor() {\n    super([\"gitGraph\"]);\n  }\n};\n\n// src/language/gitGraph/module.ts\nvar GitGraphModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new GitGraphTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new CommonValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createGitGraphServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const GitGraph = inject(\n    createDefaultCoreModule({ shared }),\n    GitGraphGeneratedModule,\n    GitGraphModule\n  );\n  shared.ServiceRegistry.register(GitGraph);\n  return { shared, GitGraph };\n}\n__name(createGitGraphServices, \"createGitGraphServices\");\n\nexport {\n  GitGraphModule,\n  createGitGraphServices\n};\n","/******************************************************************************\r\n * Copyright 2023 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { createDefaultCoreModule, createDefaultSharedCoreModule } from '../default-module.js';\r\nimport type { Module } from '../dependency-injection.js';\r\nimport { inject } from '../dependency-injection.js';\r\nimport * as ast from '../languages/generated/ast.js';\r\nimport type { LangiumCoreServices, LangiumSharedCoreServices, PartialLangiumCoreServices, PartialLangiumSharedCoreServices } from '../services.js';\r\nimport type { Mutable } from '../syntax-tree.js';\r\nimport { EmptyFileSystem } from '../workspace/file-system-provider.js';\r\nimport { URI } from './uri-utils.js';\r\n\r\nconst minimalGrammarModule: Module<LangiumCoreServices, PartialLangiumCoreServices> = {\r\n    Grammar: () => undefined as unknown as ast.Grammar,\r\n    LanguageMetaData: () => ({\r\n        caseInsensitive: false,\r\n        fileExtensions: ['.langium'],\r\n        languageId: 'langium'\r\n    })\r\n};\r\n\r\nconst minimalSharedGrammarModule: Module<LangiumSharedCoreServices, PartialLangiumSharedCoreServices> = {\r\n    AstReflection: () => new ast.LangiumGrammarAstReflection()\r\n};\r\n\r\nfunction createMinimalGrammarServices(): LangiumCoreServices {\r\n    const shared = inject(\r\n        createDefaultSharedCoreModule(EmptyFileSystem),\r\n        minimalSharedGrammarModule\r\n    );\r\n    const grammar = inject(\r\n        createDefaultCoreModule({ shared }),\r\n        minimalGrammarModule\r\n    );\r\n    shared.ServiceRegistry.register(grammar);\r\n    return grammar;\r\n}\r\n\r\n/**\r\n * Load a Langium grammar for your language from a JSON string. This is used by several services,\r\n * most notably the parser builder which interprets the grammar to create a parser.\r\n */\r\nexport function loadGrammarFromJson(json: string): ast.Grammar {\r\n    const services = createMinimalGrammarServices();\r\n    const astNode = services.serializer.JsonSerializer.deserialize(json) as Mutable<ast.Grammar>;\r\n    services.shared.workspace.LangiumDocumentFactory.fromModel(astNode, URI.parse(`memory://${astNode.name ?? 'grammar'}.langium`));\r\n    return astNode;\r\n}\r\n","var __defProp = Object.defineProperty;\nvar __name = (target, value) => __defProp(target, \"name\", { value, configurable: true });\n\n// src/language/generated/ast.ts\nimport { AbstractAstReflection } from \"langium\";\nvar Statement = \"Statement\";\nvar Architecture = \"Architecture\";\nfunction isArchitecture(item) {\n  return reflection.isInstance(item, Architecture);\n}\n__name(isArchitecture, \"isArchitecture\");\nvar Axis = \"Axis\";\nvar Branch = \"Branch\";\nfunction isBranch(item) {\n  return reflection.isInstance(item, Branch);\n}\n__name(isBranch, \"isBranch\");\nvar Checkout = \"Checkout\";\nvar CherryPicking = \"CherryPicking\";\nvar ClassDefStatement = \"ClassDefStatement\";\nvar Commit = \"Commit\";\nfunction isCommit(item) {\n  return reflection.isInstance(item, Commit);\n}\n__name(isCommit, \"isCommit\");\nvar Curve = \"Curve\";\nvar Edge = \"Edge\";\nvar Entry = \"Entry\";\nvar GitGraph = \"GitGraph\";\nfunction isGitGraph(item) {\n  return reflection.isInstance(item, GitGraph);\n}\n__name(isGitGraph, \"isGitGraph\");\nvar Group = \"Group\";\nvar Info = \"Info\";\nfunction isInfo(item) {\n  return reflection.isInstance(item, Info);\n}\n__name(isInfo, \"isInfo\");\nvar Item = \"Item\";\nvar Junction = \"Junction\";\nvar Merge = \"Merge\";\nfunction isMerge(item) {\n  return reflection.isInstance(item, Merge);\n}\n__name(isMerge, \"isMerge\");\nvar Option = \"Option\";\nvar Packet = \"Packet\";\nfunction isPacket(item) {\n  return reflection.isInstance(item, Packet);\n}\n__name(isPacket, \"isPacket\");\nvar PacketBlock = \"PacketBlock\";\nfunction isPacketBlock(item) {\n  return reflection.isInstance(item, PacketBlock);\n}\n__name(isPacketBlock, \"isPacketBlock\");\nvar Pie = \"Pie\";\nfunction isPie(item) {\n  return reflection.isInstance(item, Pie);\n}\n__name(isPie, \"isPie\");\nvar PieSection = \"PieSection\";\nfunction isPieSection(item) {\n  return reflection.isInstance(item, PieSection);\n}\n__name(isPieSection, \"isPieSection\");\nvar Radar = \"Radar\";\nvar Service = \"Service\";\nvar Treemap = \"Treemap\";\nfunction isTreemap(item) {\n  return reflection.isInstance(item, Treemap);\n}\n__name(isTreemap, \"isTreemap\");\nvar TreemapRow = \"TreemapRow\";\nvar Direction = \"Direction\";\nvar Leaf = \"Leaf\";\nvar Section = \"Section\";\nvar MermaidAstReflection = class extends AbstractAstReflection {\n  static {\n    __name(this, \"MermaidAstReflection\");\n  }\n  getAllTypes() {\n    return [Architecture, Axis, Branch, Checkout, CherryPicking, ClassDefStatement, Commit, Curve, Direction, Edge, Entry, GitGraph, Group, Info, Item, Junction, Leaf, Merge, Option, Packet, PacketBlock, Pie, PieSection, Radar, Section, Service, Statement, Treemap, TreemapRow];\n  }\n  computeIsSubtype(subtype, supertype) {\n    switch (subtype) {\n      case Branch:\n      case Checkout:\n      case CherryPicking:\n      case Commit:\n      case Merge: {\n        return this.isSubtype(Statement, supertype);\n      }\n      case Direction: {\n        return this.isSubtype(GitGraph, supertype);\n      }\n      case Leaf:\n      case Section: {\n        return this.isSubtype(Item, supertype);\n      }\n      default: {\n        return false;\n      }\n    }\n  }\n  getReferenceType(refInfo) {\n    const referenceId = `${refInfo.container.$type}:${refInfo.property}`;\n    switch (referenceId) {\n      case \"Entry:axis\": {\n        return Axis;\n      }\n      default: {\n        throw new Error(`${referenceId} is not a valid reference id.`);\n      }\n    }\n  }\n  getTypeMetaData(type) {\n    switch (type) {\n      case Architecture: {\n        return {\n          name: Architecture,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"edges\", defaultValue: [] },\n            { name: \"groups\", defaultValue: [] },\n            { name: \"junctions\", defaultValue: [] },\n            { name: \"services\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Axis: {\n        return {\n          name: Axis,\n          properties: [\n            { name: \"label\" },\n            { name: \"name\" }\n          ]\n        };\n      }\n      case Branch: {\n        return {\n          name: Branch,\n          properties: [\n            { name: \"name\" },\n            { name: \"order\" }\n          ]\n        };\n      }\n      case Checkout: {\n        return {\n          name: Checkout,\n          properties: [\n            { name: \"branch\" }\n          ]\n        };\n      }\n      case CherryPicking: {\n        return {\n          name: CherryPicking,\n          properties: [\n            { name: \"id\" },\n            { name: \"parent\" },\n            { name: \"tags\", defaultValue: [] }\n          ]\n        };\n      }\n      case ClassDefStatement: {\n        return {\n          name: ClassDefStatement,\n          properties: [\n            { name: \"className\" },\n            { name: \"styleText\" }\n          ]\n        };\n      }\n      case Commit: {\n        return {\n          name: Commit,\n          properties: [\n            { name: \"id\" },\n            { name: \"message\" },\n            { name: \"tags\", defaultValue: [] },\n            { name: \"type\" }\n          ]\n        };\n      }\n      case Curve: {\n        return {\n          name: Curve,\n          properties: [\n            { name: \"entries\", defaultValue: [] },\n            { name: \"label\" },\n            { name: \"name\" }\n          ]\n        };\n      }\n      case Edge: {\n        return {\n          name: Edge,\n          properties: [\n            { name: \"lhsDir\" },\n            { name: \"lhsGroup\", defaultValue: false },\n            { name: \"lhsId\" },\n            { name: \"lhsInto\", defaultValue: false },\n            { name: \"rhsDir\" },\n            { name: \"rhsGroup\", defaultValue: false },\n            { name: \"rhsId\" },\n            { name: \"rhsInto\", defaultValue: false },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Entry: {\n        return {\n          name: Entry,\n          properties: [\n            { name: \"axis\" },\n            { name: \"value\" }\n          ]\n        };\n      }\n      case GitGraph: {\n        return {\n          name: GitGraph,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"statements\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Group: {\n        return {\n          name: Group,\n          properties: [\n            { name: \"icon\" },\n            { name: \"id\" },\n            { name: \"in\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Info: {\n        return {\n          name: Info,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Item: {\n        return {\n          name: Item,\n          properties: [\n            { name: \"classSelector\" },\n            { name: \"name\" }\n          ]\n        };\n      }\n      case Junction: {\n        return {\n          name: Junction,\n          properties: [\n            { name: \"id\" },\n            { name: \"in\" }\n          ]\n        };\n      }\n      case Merge: {\n        return {\n          name: Merge,\n          properties: [\n            { name: \"branch\" },\n            { name: \"id\" },\n            { name: \"tags\", defaultValue: [] },\n            { name: \"type\" }\n          ]\n        };\n      }\n      case Option: {\n        return {\n          name: Option,\n          properties: [\n            { name: \"name\" },\n            { name: \"value\", defaultValue: false }\n          ]\n        };\n      }\n      case Packet: {\n        return {\n          name: Packet,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"blocks\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case PacketBlock: {\n        return {\n          name: PacketBlock,\n          properties: [\n            { name: \"bits\" },\n            { name: \"end\" },\n            { name: \"label\" },\n            { name: \"start\" }\n          ]\n        };\n      }\n      case Pie: {\n        return {\n          name: Pie,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"sections\", defaultValue: [] },\n            { name: \"showData\", defaultValue: false },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case PieSection: {\n        return {\n          name: PieSection,\n          properties: [\n            { name: \"label\" },\n            { name: \"value\" }\n          ]\n        };\n      }\n      case Radar: {\n        return {\n          name: Radar,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"axes\", defaultValue: [] },\n            { name: \"curves\", defaultValue: [] },\n            { name: \"options\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Service: {\n        return {\n          name: Service,\n          properties: [\n            { name: \"icon\" },\n            { name: \"iconText\" },\n            { name: \"id\" },\n            { name: \"in\" },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Treemap: {\n        return {\n          name: Treemap,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"title\" },\n            { name: \"TreemapRows\", defaultValue: [] }\n          ]\n        };\n      }\n      case TreemapRow: {\n        return {\n          name: TreemapRow,\n          properties: [\n            { name: \"indent\" },\n            { name: \"item\" }\n          ]\n        };\n      }\n      case Direction: {\n        return {\n          name: Direction,\n          properties: [\n            { name: \"accDescr\" },\n            { name: \"accTitle\" },\n            { name: \"dir\" },\n            { name: \"statements\", defaultValue: [] },\n            { name: \"title\" }\n          ]\n        };\n      }\n      case Leaf: {\n        return {\n          name: Leaf,\n          properties: [\n            { name: \"classSelector\" },\n            { name: \"name\" },\n            { name: \"value\" }\n          ]\n        };\n      }\n      case Section: {\n        return {\n          name: Section,\n          properties: [\n            { name: \"classSelector\" },\n            { name: \"name\" }\n          ]\n        };\n      }\n      default: {\n        return {\n          name: type,\n          properties: []\n        };\n      }\n    }\n  }\n};\nvar reflection = new MermaidAstReflection();\n\n// src/language/generated/grammar.ts\nimport { loadGrammarFromJson } from \"langium\";\nvar loadedInfoGrammar;\nvar InfoGrammar = /* @__PURE__ */ __name(() => loadedInfoGrammar ?? (loadedInfoGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Info\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Info\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"info\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"showInfo\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[],\"cardinality\":\"*\"}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[],\"cardinality\":\"?\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"}},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[],\"types\":[],\"usedGrammars\":[]}`)), \"InfoGrammar\");\nvar loadedPacketGrammar;\nvar PacketGrammar = /* @__PURE__ */ __name(() => loadedPacketGrammar ?? (loadedPacketGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Packet\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Packet\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"packet\"},{\"$type\":\"Keyword\",\"value\":\"packet-beta\"}]},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"blocks\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}],\"cardinality\":\"*\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"PacketBlock\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"start\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"-\"},{\"$type\":\"Assignment\",\"feature\":\"end\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}],\"cardinality\":\"?\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"+\"},{\"$type\":\"Assignment\",\"feature\":\"bits\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}]}]},{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"}},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[],\"types\":[],\"usedGrammars\":[]}`)), \"PacketGrammar\");\nvar loadedPieGrammar;\nvar PieGrammar = /* @__PURE__ */ __name(() => loadedPieGrammar ?? (loadedPieGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Pie\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Pie\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"pie\"},{\"$type\":\"Assignment\",\"feature\":\"showData\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"showData\"},\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"sections\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}],\"cardinality\":\"*\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"PieSection\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"}},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[],\"types\":[],\"usedGrammars\":[]}`)), \"PieGrammar\");\nvar loadedArchitectureGrammar;\nvar ArchitectureGrammar = /* @__PURE__ */ __name(() => loadedArchitectureGrammar ?? (loadedArchitectureGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Architecture\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Architecture\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@23\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Keyword\",\"value\":\"architecture-beta\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@23\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}],\"cardinality\":\"*\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Statement\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"groups\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"services\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"junctions\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"edges\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"LeftPort\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\":\"},{\"$type\":\"Assignment\",\"feature\":\"lhsDir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"RightPort\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"rhsDir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\":\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Arrow\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"lhsInto\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"--\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"-\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@29\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\"-\"}]}]},{\"$type\":\"Assignment\",\"feature\":\"rhsInto\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Group\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"group\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"icon\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@28\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@29\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Service\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"service\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"iconText\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@21\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"icon\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@28\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@29\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Junction\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"junction\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"in\"},{\"$type\":\"Assignment\",\"feature\":\"in\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Edge\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"lhsId\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"lhsGroup\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"rhsId\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"rhsGroup\",\"operator\":\"?=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_DIRECTION\",\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"L\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"R\"}}]},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"T\"}}]},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"B\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_GROUP\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\{group\\\\\\\\}/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARROW_INTO\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/<|>/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@23\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"}},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_ICON\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\([\\\\\\\\w-:]+\\\\\\\\)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ARCH_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\[[\\\\\\\\w ]+\\\\\\\\]/\"},\"fragment\":false,\"hidden\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[],\"types\":[],\"usedGrammars\":[]}`)), \"ArchitectureGrammar\");\nvar loadedGitGraphGrammar;\nvar GitGraphGrammar = /* @__PURE__ */ __name(() => loadedGitGraphGrammar ?? (loadedGitGraphGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"GitGraph\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"GitGraph\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"Keyword\",\"value\":\":\"}]},{\"$type\":\"Keyword\",\"value\":\"gitGraph:\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"gitGraph\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]},{\"$type\":\"Keyword\",\"value\":\":\"}]}]},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"statements\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Statement\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Direction\",\"definition\":{\"$type\":\"Assignment\",\"feature\":\"dir\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"LR\"},{\"$type\":\"Keyword\",\"value\":\"TB\"},{\"$type\":\"Keyword\",\"value\":\"BT\"}]}},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Commit\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"commit\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"msg:\",\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"message\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"type:\"},{\"$type\":\"Assignment\",\"feature\":\"type\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"NORMAL\"},{\"$type\":\"Keyword\",\"value\":\"REVERSE\"},{\"$type\":\"Keyword\",\"value\":\"HIGHLIGHT\"}]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Branch\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"branch\"},{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@24\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"order:\"},{\"$type\":\"Assignment\",\"feature\":\"order\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]}}],\"cardinality\":\"?\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Merge\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"merge\"},{\"$type\":\"Assignment\",\"feature\":\"branch\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@24\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]}},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"type:\"},{\"$type\":\"Assignment\",\"feature\":\"type\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"NORMAL\"},{\"$type\":\"Keyword\",\"value\":\"REVERSE\"},{\"$type\":\"Keyword\",\"value\":\"HIGHLIGHT\"}]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Checkout\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"checkout\"},{\"$type\":\"Keyword\",\"value\":\"switch\"}]},{\"$type\":\"Assignment\",\"feature\":\"branch\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@24\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"CherryPicking\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"cherry-pick\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"id:\"},{\"$type\":\"Assignment\",\"feature\":\"id\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"tag:\"},{\"$type\":\"Assignment\",\"feature\":\"tags\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"parent:\"},{\"$type\":\"Assignment\",\"feature\":\"parent\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"}},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"name\":\"REFERENCE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\w([-\\\\\\\\./\\\\\\\\w]*[-\\\\\\\\w])?/\"},\"fragment\":false,\"hidden\":false}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"interfaces\":[],\"types\":[],\"usedGrammars\":[]}`)), \"GitGraphGrammar\");\nvar loadedRadarGrammar;\nvar RadarGrammar = /* @__PURE__ */ __name(() => loadedRadarGrammar ?? (loadedRadarGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Radar\",\"imports\":[],\"rules\":[{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Radar\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"radar-beta\"},{\"$type\":\"Keyword\",\"value\":\"radar-beta:\"},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"radar-beta\"},{\"$type\":\"Keyword\",\"value\":\":\"}]}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"axis\"},{\"$type\":\"Assignment\",\"feature\":\"axes\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"Assignment\",\"feature\":\"axes\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"curve\"},{\"$type\":\"Assignment\",\"feature\":\"curves\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"Assignment\",\"feature\":\"curves\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"options\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"Assignment\",\"feature\":\"options\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}],\"cardinality\":\"*\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Label\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\"[\"},{\"$type\":\"Assignment\",\"feature\":\"label\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]}},{\"$type\":\"Keyword\",\"value\":\"]\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Axis\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[],\"cardinality\":\"?\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Curve\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@1\"},\"arguments\":[],\"cardinality\":\"?\"},{\"$type\":\"Keyword\",\"value\":\"{\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]},{\"$type\":\"Keyword\",\"value\":\"}\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"Entries\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]}}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Keyword\",\"value\":\",\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"},{\"$type\":\"Assignment\",\"feature\":\"entries\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@5\"},\"arguments\":[]}}],\"cardinality\":\"*\"},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"*\"}]}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"DetailedEntry\",\"returnType\":{\"$ref\":\"#/interfaces@0\"},\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"axis\",\"operator\":\"=\",\"terminal\":{\"$type\":\"CrossReference\",\"type\":{\"$ref\":\"#/rules@2\"},\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},\"deprecatedSyntax\":false}},{\"$type\":\"Keyword\",\"value\":\":\",\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"NumberEntry\",\"returnType\":{\"$ref\":\"#/interfaces@0\"},\"definition\":{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Option\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"showLegend\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@11\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"ticks\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"max\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"min\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}}]},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"Keyword\",\"value\":\"graticule\"}},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]}}]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"GRATICULE\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"circle\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"polygon\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"EOL\",\"dataType\":\"string\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[],\"cardinality\":\"+\"},{\"$type\":\"EndOfFile\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@12\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@13\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]}}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"FLOAT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9]+\\\\\\\\.[0-9]+(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"INT\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/0|[1-9][0-9]*(?!\\\\\\\\.)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"number\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"}},{\"$type\":\"TerminalRuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"([^\\\\\"\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*\\\\\"|'([^'\\\\\\\\\\\\\\\\]|\\\\\\\\\\\\\\\\.)*'/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"string\"},\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\w]([-\\\\\\\\w]*\\\\\\\\w)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NEWLINE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WHITESPACE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"YAML\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/---[\\\\\\\\t ]*\\\\\\\\r?\\\\\\\\n(?:[\\\\\\\\S\\\\\\\\s]*?\\\\\\\\r?\\\\\\\\n)?---(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"DIRECTIVE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%{[\\\\\\\\S\\\\\\\\s]*?}%%(?:\\\\\\\\r?\\\\\\\\n|(?!\\\\\\\\S))/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"SINGLE_LINE_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*%%[^\\\\\\\\n\\\\\\\\r]*/\"},\"fragment\":false}],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Entry\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"axis\",\"isOptional\":true,\"type\":{\"$type\":\"ReferenceType\",\"referenceType\":{\"$type\":\"SimpleType\",\"typeRef\":{\"$ref\":\"#/rules@2\"}}}},{\"$type\":\"TypeAttribute\",\"name\":\"value\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"number\"},\"isOptional\":false}],\"superTypes\":[]}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"types\":[],\"usedGrammars\":[]}`)), \"RadarGrammar\");\nvar loadedTreemapGrammar;\nvar TreemapGrammar = /* @__PURE__ */ __name(() => loadedTreemapGrammar ?? (loadedTreemapGrammar = loadGrammarFromJson(`{\"$type\":\"Grammar\",\"isDeclared\":true,\"name\":\"Treemap\",\"rules\":[{\"$type\":\"ParserRule\",\"fragment\":true,\"name\":\"TitleAndAccessibilities\",\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"accDescr\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@2\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"accTitle\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@3\"},\"arguments\":[]}},{\"$type\":\"Assignment\",\"feature\":\"title\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@4\"},\"arguments\":[]}}],\"cardinality\":\"+\"},\"definesHiddenTokens\":false,\"entry\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"BOOLEAN\",\"type\":{\"$type\":\"ReturnType\",\"name\":\"boolean\"},\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"true\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"false\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_DESCR\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accDescr(?:[\\\\\\\\t ]*:([^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)|\\\\\\\\s*{([^}]*)})/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ACC_TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*accTitle[\\\\\\\\t ]*:(?:[^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[^\\\\\\\\n\\\\\\\\r]*)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"TITLE\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[\\\\\\\\t ]*title(?:[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*?(?=%%)|[\\\\\\\\t ][^\\\\\\\\n\\\\\\\\r]*|)/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"entry\":true,\"name\":\"Treemap\",\"returnType\":{\"$ref\":\"#/interfaces@4\"},\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@6\"},\"arguments\":[]},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@0\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"TreemapRows\",\"operator\":\"+=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@14\"},\"arguments\":[]}}],\"cardinality\":\"*\"}]},\"definesHiddenTokens\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"TREEMAP_KEYWORD\",\"definition\":{\"$type\":\"TerminalAlternatives\",\"elements\":[{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"treemap-beta\"}},{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\"treemap\"}}]},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"CLASS_DEF\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/classDef\\\\\\\\s+([a-zA-Z_][a-zA-Z0-9_]+)(?:\\\\\\\\s+([^;\\\\\\\\r\\\\\\\\n]*))?(?:;)?/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"STYLE_SEPARATOR\",\"definition\":{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\":::\"}},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"SEPARATOR\",\"definition\":{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\":\"}},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"COMMA\",\"definition\":{\"$type\":\"CharacterRange\",\"left\":{\"$type\":\"Keyword\",\"value\":\",\"}},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"WS\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[ \\\\\\\\t]+/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"ML_COMMENT\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\%\\\\\\\\%[^\\\\\\\\n]*/\"},\"fragment\":false},{\"$type\":\"TerminalRule\",\"hidden\":true,\"name\":\"NL\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\\\\r?\\\\\\\\n/\"},\"fragment\":false},{\"$type\":\"ParserRule\",\"name\":\"TreemapRow\",\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"indent\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[]},\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"item\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@16\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@15\"},\"arguments\":[]}]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"ClassDef\",\"dataType\":\"string\",\"definition\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@7\"},\"arguments\":[]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Item\",\"returnType\":{\"$ref\":\"#/interfaces@0\"},\"definition\":{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@18\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@17\"},\"arguments\":[]}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Section\",\"returnType\":{\"$ref\":\"#/interfaces@1\"},\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@23\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"classSelector\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}],\"cardinality\":\"?\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"ParserRule\",\"name\":\"Leaf\",\"returnType\":{\"$ref\":\"#/interfaces@2\"},\"definition\":{\"$type\":\"Group\",\"elements\":[{\"$type\":\"Assignment\",\"feature\":\"name\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@23\"},\"arguments\":[]}},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[],\"cardinality\":\"?\"},{\"$type\":\"Alternatives\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@9\"},\"arguments\":[]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@10\"},\"arguments\":[]}]},{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@19\"},\"arguments\":[],\"cardinality\":\"?\"},{\"$type\":\"Assignment\",\"feature\":\"value\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@22\"},\"arguments\":[]}},{\"$type\":\"Group\",\"elements\":[{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@8\"},\"arguments\":[]},{\"$type\":\"Assignment\",\"feature\":\"classSelector\",\"operator\":\"=\",\"terminal\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@20\"},\"arguments\":[]}}],\"cardinality\":\"?\"}]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"INDENTATION\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[ \\\\\\\\t]{1,}/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"ID2\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[a-zA-Z_][a-zA-Z0-9_]*/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"TerminalRule\",\"name\":\"NUMBER2\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/[0-9_\\\\\\\\.\\\\\\\\,]+/\"},\"fragment\":false,\"hidden\":false},{\"$type\":\"ParserRule\",\"name\":\"MyNumber\",\"dataType\":\"number\",\"definition\":{\"$type\":\"RuleCall\",\"rule\":{\"$ref\":\"#/rules@21\"},\"arguments\":[]},\"definesHiddenTokens\":false,\"entry\":false,\"fragment\":false,\"hiddenTokens\":[],\"parameters\":[],\"wildcard\":false},{\"$type\":\"TerminalRule\",\"name\":\"STRING2\",\"definition\":{\"$type\":\"RegexToken\",\"regex\":\"/\\\\\"[^\\\\\"]*\\\\\"|'[^']*'/\"},\"fragment\":false,\"hidden\":false}],\"interfaces\":[{\"$type\":\"Interface\",\"name\":\"Item\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"name\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"},\"isOptional\":false},{\"$type\":\"TypeAttribute\",\"name\":\"classSelector\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]},{\"$type\":\"Interface\",\"name\":\"Section\",\"superTypes\":[{\"$ref\":\"#/interfaces@0\"}],\"attributes\":[]},{\"$type\":\"Interface\",\"name\":\"Leaf\",\"superTypes\":[{\"$ref\":\"#/interfaces@0\"}],\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"value\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"number\"},\"isOptional\":false}]},{\"$type\":\"Interface\",\"name\":\"ClassDefStatement\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"className\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"},\"isOptional\":false},{\"$type\":\"TypeAttribute\",\"name\":\"styleText\",\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"},\"isOptional\":false}],\"superTypes\":[]},{\"$type\":\"Interface\",\"name\":\"Treemap\",\"attributes\":[{\"$type\":\"TypeAttribute\",\"name\":\"TreemapRows\",\"type\":{\"$type\":\"ArrayType\",\"elementType\":{\"$type\":\"SimpleType\",\"typeRef\":{\"$ref\":\"#/rules@14\"}}},\"isOptional\":false},{\"$type\":\"TypeAttribute\",\"name\":\"title\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accTitle\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}},{\"$type\":\"TypeAttribute\",\"name\":\"accDescr\",\"isOptional\":true,\"type\":{\"$type\":\"SimpleType\",\"primitiveType\":\"string\"}}],\"superTypes\":[]}],\"definesHiddenTokens\":false,\"hiddenTokens\":[],\"imports\":[],\"types\":[],\"usedGrammars\":[],\"$comment\":\"/**\\\\n * Treemap grammar for Langium\\\\n * Converted from mindmap grammar\\\\n *\\\\n * The ML_COMMENT and NL hidden terminals handle whitespace, comments, and newlines\\\\n * before the treemap keyword, allowing for empty lines and comments before the\\\\n * treemap declaration.\\\\n */\"}`)), \"TreemapGrammar\");\n\n// src/language/generated/module.ts\nvar InfoLanguageMetaData = {\n  languageId: \"info\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar PacketLanguageMetaData = {\n  languageId: \"packet\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar PieLanguageMetaData = {\n  languageId: \"pie\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar ArchitectureLanguageMetaData = {\n  languageId: \"architecture\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar GitGraphLanguageMetaData = {\n  languageId: \"gitGraph\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar RadarLanguageMetaData = {\n  languageId: \"radar\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar TreemapLanguageMetaData = {\n  languageId: \"treemap\",\n  fileExtensions: [\".mmd\", \".mermaid\"],\n  caseInsensitive: false,\n  mode: \"production\"\n};\nvar MermaidGeneratedSharedModule = {\n  AstReflection: /* @__PURE__ */ __name(() => new MermaidAstReflection(), \"AstReflection\")\n};\nvar InfoGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => InfoGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => InfoLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar PacketGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => PacketGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => PacketLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar PieGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => PieGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => PieLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar ArchitectureGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => ArchitectureGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => ArchitectureLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar GitGraphGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => GitGraphGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => GitGraphLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar RadarGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => RadarGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => RadarLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\nvar TreemapGeneratedModule = {\n  Grammar: /* @__PURE__ */ __name(() => TreemapGrammar(), \"Grammar\"),\n  LanguageMetaData: /* @__PURE__ */ __name(() => TreemapLanguageMetaData, \"LanguageMetaData\"),\n  parser: {}\n};\n\n// src/language/common/valueConverter.ts\nimport { DefaultValueConverter } from \"langium\";\n\n// src/language/common/matcher.ts\nvar accessibilityDescrRegex = /accDescr(?:[\\t ]*:([^\\n\\r]*)|\\s*{([^}]*)})/;\nvar accessibilityTitleRegex = /accTitle[\\t ]*:([^\\n\\r]*)/;\nvar titleRegex = /title([\\t ][^\\n\\r]*|)/;\n\n// src/language/common/valueConverter.ts\nvar rulesRegexes = {\n  ACC_DESCR: accessibilityDescrRegex,\n  ACC_TITLE: accessibilityTitleRegex,\n  TITLE: titleRegex\n};\nvar AbstractMermaidValueConverter = class extends DefaultValueConverter {\n  static {\n    __name(this, \"AbstractMermaidValueConverter\");\n  }\n  runConverter(rule, input, cstNode) {\n    let value = this.runCommonConverter(rule, input, cstNode);\n    if (value === void 0) {\n      value = this.runCustomConverter(rule, input, cstNode);\n    }\n    if (value === void 0) {\n      return super.runConverter(rule, input, cstNode);\n    }\n    return value;\n  }\n  runCommonConverter(rule, input, _cstNode) {\n    const regex = rulesRegexes[rule.name];\n    if (regex === void 0) {\n      return void 0;\n    }\n    const match = regex.exec(input);\n    if (match === null) {\n      return void 0;\n    }\n    if (match[1] !== void 0) {\n      return match[1].trim().replace(/[\\t ]{2,}/gm, \" \");\n    }\n    if (match[2] !== void 0) {\n      return match[2].replace(/^\\s*/gm, \"\").replace(/\\s+$/gm, \"\").replace(/[\\t ]{2,}/gm, \" \").replace(/[\\n\\r]{2,}/gm, \"\\n\");\n    }\n    return void 0;\n  }\n};\nvar CommonValueConverter = class extends AbstractMermaidValueConverter {\n  static {\n    __name(this, \"CommonValueConverter\");\n  }\n  runCustomConverter(_rule, _input, _cstNode) {\n    return void 0;\n  }\n};\n\n// src/language/common/tokenBuilder.ts\nimport { DefaultTokenBuilder } from \"langium\";\nvar AbstractMermaidTokenBuilder = class extends DefaultTokenBuilder {\n  static {\n    __name(this, \"AbstractMermaidTokenBuilder\");\n  }\n  constructor(keywords) {\n    super();\n    this.keywords = new Set(keywords);\n  }\n  buildKeywordTokens(rules, terminalTokens, options) {\n    const tokenTypes = super.buildKeywordTokens(rules, terminalTokens, options);\n    tokenTypes.forEach((tokenType) => {\n      if (this.keywords.has(tokenType.name) && tokenType.PATTERN !== void 0) {\n        tokenType.PATTERN = new RegExp(tokenType.PATTERN.toString() + \"(?:(?=%%)|(?!\\\\S))\");\n      }\n    });\n    return tokenTypes;\n  }\n};\nvar CommonTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"CommonTokenBuilder\");\n  }\n};\n\nexport {\n  __name,\n  Statement,\n  Architecture,\n  isArchitecture,\n  Branch,\n  isBranch,\n  Commit,\n  isCommit,\n  GitGraph,\n  isGitGraph,\n  Info,\n  isInfo,\n  Merge,\n  isMerge,\n  Packet,\n  isPacket,\n  PacketBlock,\n  isPacketBlock,\n  Pie,\n  isPie,\n  PieSection,\n  isPieSection,\n  Radar,\n  Treemap,\n  isTreemap,\n  MermaidGeneratedSharedModule,\n  InfoGeneratedModule,\n  PacketGeneratedModule,\n  PieGeneratedModule,\n  ArchitectureGeneratedModule,\n  GitGraphGeneratedModule,\n  RadarGeneratedModule,\n  TreemapGeneratedModule,\n  AbstractMermaidValueConverter,\n  CommonValueConverter,\n  AbstractMermaidTokenBuilder,\n  CommonTokenBuilder\n};\n","import arrayMap from './_arrayMap.js';\nimport baseIteratee from './_baseIteratee.js';\nimport baseMap from './_baseMap.js';\nimport isArray from './isArray.js';\n\n/**\n * Creates an array of values by running each element in `collection` thru\n * `iteratee`. The iteratee is invoked with three arguments:\n * (value, index|key, collection).\n *\n * Many lodash methods are guarded to work as iteratees for methods like\n * `_.every`, `_.filter`, `_.map`, `_.mapValues`, `_.reject`, and `_.some`.\n *\n * The guarded methods are:\n * `ary`, `chunk`, `curry`, `curryRight`, `drop`, `dropRight`, `every`,\n * `fill`, `invert`, `parseInt`, `random`, `range`, `rangeRight`, `repeat`,\n * `sampleSize`, `slice`, `some`, `sortBy`, `split`, `take`, `takeRight`,\n * `template`, `trim`, `trimEnd`, `trimStart`, and `words`\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new mapped array.\n * @example\n *\n * function square(n) {\n *   return n * n;\n * }\n *\n * _.map([4, 8], square);\n * // => [16, 64]\n *\n * _.map({ 'a': 4, 'b': 8 }, square);\n * // => [16, 64] (iteration order is not guaranteed)\n *\n * var users = [\n *   { 'user': 'barney' },\n *   { 'user': 'fred' }\n * ];\n *\n * // The `_.property` iteratee shorthand.\n * _.map(users, 'user');\n * // => ['barney', 'fred']\n */\nfunction map(collection, iteratee) {\n  var func = isArray(collection) ? arrayMap : baseMap;\n  return func(collection, baseIteratee(iteratee, 3));\n}\n\nexport default map;\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\n/**\r\n * A stream is a read-only sequence of values. While the contents of an array can be accessed\r\n * both sequentially and randomly (via index), a stream allows only sequential access.\r\n *\r\n * The advantage of this is that a stream can be evaluated lazily, so it does not require\r\n * to store intermediate values. This can boost performance when a large sequence is\r\n * processed via filtering, mapping etc. and accessed at most once. However, lazy\r\n * evaluation means that all processing is repeated when you access the sequence multiple\r\n * times; in such a case, it may be better to store the resulting sequence into an array.\r\n */\r\nexport interface Stream<T> extends Iterable<T> {\r\n\r\n    /**\r\n     * Returns an iterator for this stream. This is the same as calling the `Symbol.iterator` function property.\r\n     */\r\n    iterator(): IterableIterator<T>;\r\n\r\n    /**\r\n     * Determines whether this stream contains no elements.\r\n     */\r\n    isEmpty(): boolean;\r\n\r\n    /**\r\n     * Determines the number of elements in this stream.\r\n     */\r\n    count(): number;\r\n\r\n    /**\r\n     * Collects all elements of this stream into an array.\r\n     */\r\n    toArray(): T[];\r\n\r\n    /**\r\n     * Collects all elements of this stream into a Set.\r\n     */\r\n    toSet(): Set<T>;\r\n\r\n    /**\r\n     * Collects all elements of this stream into a Map, applying the provided functions to determine keys and values.\r\n     *\r\n     * @param keyFn The function to derive map keys. If omitted, the stream elements are used as keys.\r\n     * @param valueFn The function to derive map values. If omitted, the stream elements are used as values.\r\n     */\r\n    toMap<K = T, V = T>(keyFn?: (e: T) => K, valueFn?: (e: T) => V): Map<K, V>;\r\n\r\n    /**\r\n     * Returns a string representation of a stream.\r\n     */\r\n    toString(): string;\r\n\r\n    /**\r\n     * Combines two streams by returning a new stream that yields all elements of this stream and the other stream.\r\n     *\r\n     * @param other Stream to be concatenated with this one.\r\n     */\r\n    concat<T2>(other: Iterable<T2>): Stream<T | T2>;\r\n\r\n    /**\r\n     * Adds all elements of the stream into a string, separated by the specified separator string.\r\n     *\r\n     * @param separator A string used to separate one element of the stream from the next in the resulting string.\r\n     *        If omitted, the steam elements are separated with a comma.\r\n     */\r\n    join(separator?: string): string\r\n\r\n    /**\r\n     * Returns the index of the first occurrence of a value in the stream, or -1 if it is not present.\r\n     *\r\n     * @param searchElement The value to locate in the array.\r\n     * @param fromIndex The stream index at which to begin the search. If fromIndex is omitted, the search\r\n     *        starts at index 0.\r\n     */\r\n    indexOf(searchElement: T, fromIndex?: number): number;\r\n\r\n    /**\r\n     * Determines whether all members of the stream satisfy the specified test.\r\n     *\r\n     * @param predicate This method calls the predicate function for each element in the stream until the\r\n     *        predicate returns a value which is coercible to the Boolean value `false`, or until the end\r\n     *        of the stream.\r\n     */\r\n    every<S extends T>(predicate: (value: T) => value is S): this is Stream<S>;\r\n    every(predicate: (value: T) => unknown): boolean;\r\n\r\n    /**\r\n     * Determines whether any member of the stream satisfies the specified test.\r\n     *\r\n     * @param predicate This method calls the predicate function for each element in the stream until the\r\n     *        predicate returns a value which is coercible to the Boolean value `true`, or until the end\r\n     *        of the stream.\r\n     */\r\n    some(predicate: (value: T) => unknown): boolean;\r\n\r\n    /**\r\n     * Performs the specified action for each element in the stream.\r\n     *\r\n     * @param callbackfn Function called once for each element in the stream.\r\n     */\r\n    forEach(callbackfn: (value: T, index: number) => void): void;\r\n\r\n    /**\r\n     * Returns a stream that yields the results of calling the specified callback function on each element\r\n     * of the stream. The function is called when the resulting stream elements are actually accessed, so\r\n     * accessing the resulting stream multiple times means the function is also called multiple times for\r\n     * each element of the stream.\r\n     *\r\n     * @param callbackfn Lazily evaluated function mapping stream elements.\r\n     */\r\n    map<U>(callbackfn: (value: T) => U): Stream<U>;\r\n\r\n    /**\r\n     * Returns the elements of the stream that meet the condition specified in a callback function.\r\n     * The function is called when the resulting stream elements are actually accessed, so accessing the\r\n     * resulting stream multiple times means the function is also called multiple times for each element\r\n     * of the stream.\r\n     *\r\n     * @param predicate Lazily evaluated function checking a condition on stream elements.\r\n     */\r\n    filter<S extends T>(predicate: (value: T) => value is S): Stream<S>;\r\n    filter(predicate: (value: T) => unknown): Stream<T>;\r\n\r\n    /**\r\n     * Returns the elements of the stream that are _non-nullable_, which means they are neither `undefined`\r\n     * nor `null`.\r\n     */\r\n    nonNullable(): Stream<NonNullable<T>>;\r\n\r\n    /**\r\n     * Calls the specified callback function for all elements in the stream. The return value of the\r\n     * callback function is the accumulated result, and is provided as an argument in the next call to\r\n     * the callback function.\r\n     *\r\n     * @param callbackfn This method calls the function once for each element in the stream, providing\r\n     *        the previous and current values of the reduction.\r\n     * @param initialValue If specified, `initialValue` is used as the initial value to start the\r\n     *        accumulation. The first call to the function provides this value as an argument instead\r\n     *        of a stream value.\r\n     */\r\n    reduce(callbackfn: (previousValue: T, currentValue: T) => T): T | undefined;\r\n    reduce<U = T>(callbackfn: (previousValue: U, currentValue: T) => U, initialValue: U): U;\r\n\r\n    /**\r\n     * Calls the specified callback function for all elements in the stream, in descending order.\r\n     * The return value of the callback function is the accumulated result, and is provided as an\r\n     * argument in the next call to the callback function.\r\n     *\r\n     * @param callbackfn This method calls the function once for each element in the stream, providing\r\n     *        the previous and current values of the reduction.\r\n     * @param initialValue If specified, `initialValue` is used as the initial value to start the\r\n     *        accumulation. The first call to the function provides this value as an argument instead\r\n     *        of an array value.\r\n     */\r\n    reduceRight(callbackfn: (previousValue: T, currentValue: T) => T): T | undefined;\r\n    reduceRight<U = T>(callbackfn: (previousValue: U, currentValue: T) => U, initialValue: U): U;\r\n\r\n    /**\r\n     * Returns the value of the first element in the stream that meets the condition, or `undefined`\r\n     * if there is no such element.\r\n     *\r\n     * @param predicate This method calls `predicate` once for each element of the stream, in ascending\r\n     *        order, until it finds one where `predicate` returns a value which is coercible to the\r\n     *        Boolean value `true`.\r\n     */\r\n    find<S extends T>(predicate: (value: T) => value is S): S | undefined;\r\n    find(predicate: (value: T) => unknown): T | undefined;\r\n\r\n    /**\r\n     * Returns the index of the first element in the stream that meets the condition, or `-1`\r\n     * if there is no such element.\r\n     *\r\n     * @param predicate This method calls `predicate` once for each element of the stream, in ascending\r\n     *        order, until it finds one where `predicate` returns a value which is coercible to the\r\n     *        Boolean value `true`.\r\n     */\r\n    findIndex(predicate: (value: T) => unknown): number;\r\n\r\n    /**\r\n     * Determines whether the stream includes a certain element, returning `true` or `false` as appropriate.\r\n     *\r\n     * @param searchElement The element to search for.\r\n     */\r\n    includes(searchElement: T): boolean;\r\n\r\n    /**\r\n     * Calls a defined callback function on each element of the stream and then flattens the result into\r\n     * a new stream. This is identical to a `map` followed by `flat` with depth 1.\r\n     *\r\n     * @param callbackfn Lazily evaluated function mapping stream elements.\r\n     */\r\n    flatMap<U>(callbackfn: (value: T) => U | Iterable<U>): Stream<U>;\r\n\r\n    /**\r\n     * Returns a new stream with all sub-stream or sub-array elements concatenated into it recursively up\r\n     * to the specified depth.\r\n     *\r\n     * @param depth The maximum recursion depth. Defaults to 1.\r\n     */\r\n    flat<D extends number = 1>(depth?: D): FlatStream<T, D>;\r\n\r\n    /**\r\n     * Returns the first element in the stream, or `undefined` if the stream is empty.\r\n     */\r\n    head(): T | undefined;\r\n\r\n    /**\r\n     * Returns a stream that skips the first `skipCount` elements from this stream.\r\n     *\r\n     * @param skipCount The number of elements to skip. If this is larger than the number of elements in\r\n     *        the stream, an empty stream is returned. Defaults to 1.\r\n     */\r\n    tail(skipCount?: number): Stream<T>;\r\n\r\n    /**\r\n     * Returns a stream consisting of the elements of this stream, truncated to be no longer than `maxSize`\r\n     * in length.\r\n     *\r\n     * @param maxSize The number of elements the stream should be limited to\r\n     */\r\n    limit(maxSize: number): Stream<T>;\r\n\r\n    /**\r\n     * Returns a stream containing only the distinct elements from this stream.\r\n     * Equality is determined with the same rules as a standard `Set`.\r\n     *\r\n     * @param by A function returning the key used to check equality with a previous stream element.\r\n     *        If omitted, the stream elements themselves are used for comparison.\r\n     */\r\n    distinct<Key = T>(by?: (element: T) => Key): Stream<T>;\r\n\r\n    /**\r\n     * Returns a stream that contains all elements that don't exist in the {@link other} iterable.\r\n     * Equality is determined with the same rules as a standard `Set`.\r\n     * @param other The elements that should be exluded from this stream.\r\n     * @param key A function returning the key used to check quality.\r\n     *        If omitted, the stream elements themselves are used for comparison.\r\n     */\r\n    exclude<Key = T>(other: Iterable<T>, key?: (element: T) => Key): Stream<T>;\r\n\r\n}\r\n\r\nexport type FlatStream<T, Depth extends number> = {\r\n    'done': Stream<T>,\r\n    'recur': T extends Iterable<infer Content>\r\n        ? FlatStream<Content, MinusOne<Depth>>\r\n        : Stream<T>\r\n}[Depth extends 0 ? 'done' : 'recur'];\r\n\r\nexport type MinusOne<N extends number> = [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20][N];\r\n\r\n/**\r\n * The default implementation of `Stream` works with two input functions:\r\n *  - The first function creates the initial state of an iteration.\r\n *  - The second function gets the current state as argument and returns an `IteratorResult`.\r\n */\r\nexport class StreamImpl<S, T> implements Stream<T> {\r\n    protected readonly startFn: () => S;\r\n    protected readonly nextFn: (state: S) => IteratorResult<T>;\r\n\r\n    constructor(startFn: () => S, nextFn: (state: S) => IteratorResult<T, undefined>) {\r\n        this.startFn = startFn;\r\n        this.nextFn = nextFn;\r\n    }\r\n\r\n    iterator(): IterableIterator<T> {\r\n        const iterator = {\r\n            state: this.startFn(),\r\n            next: () => this.nextFn(iterator.state),\r\n            [Symbol.iterator]: () => iterator\r\n        };\r\n        return iterator;\r\n    }\r\n\r\n    [Symbol.iterator](): Iterator<T> {\r\n        return this.iterator();\r\n    }\r\n\r\n    isEmpty(): boolean {\r\n        const iterator = this.iterator();\r\n        return Boolean(iterator.next().done);\r\n    }\r\n\r\n    count(): number {\r\n        const iterator = this.iterator();\r\n        let count = 0;\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            count++;\r\n            next = iterator.next();\r\n        }\r\n        return count;\r\n    }\r\n\r\n    toArray(): T[] {\r\n        const result: T[] = [];\r\n        const iterator = this.iterator();\r\n        let next: IteratorResult<T>;\r\n        do {\r\n            next = iterator.next();\r\n            if (next.value !== undefined) {\r\n                result.push(next.value);\r\n            }\r\n        } while (!next.done);\r\n        return result;\r\n    }\r\n\r\n    toSet(): Set<T> {\r\n        return new Set(this);\r\n    }\r\n\r\n    toMap<K = T, V = T>(keyFn?: (e: T) => K, valueFn?: (e: T) => V): Map<K, V> {\r\n        const entryStream = this.map(element => <[K, V]>[\r\n            keyFn ? keyFn(element) : element,\r\n            valueFn ? valueFn(element) : element\r\n        ]);\r\n        return new Map(entryStream);\r\n    }\r\n\r\n    toString(): string {\r\n        return this.join();\r\n    }\r\n\r\n    concat<T2>(other: Iterable<T2>): Stream<T | T2> {\r\n        return new StreamImpl<{ first: S, firstDone: boolean, iterator: Iterator<T2, unknown, undefined> }, T | T2>(\r\n            () => ({ first: this.startFn(), firstDone: false, iterator: other[Symbol.iterator]() }),\r\n            state => {\r\n                let result: IteratorResult<T | T2>;\r\n                if (!state.firstDone) {\r\n                    do {\r\n                        result = this.nextFn(state.first);\r\n                        if (!result.done) {\r\n                            return result;\r\n                        }\r\n                    } while (!result.done);\r\n                    state.firstDone = true;\r\n                }\r\n                do {\r\n                    result = state.iterator.next();\r\n                    if (!result.done) {\r\n                        return result;\r\n                    }\r\n                } while (!result.done);\r\n                return DONE_RESULT;\r\n            }\r\n        );\r\n    }\r\n\r\n    join(separator = ','): string {\r\n        const iterator = this.iterator();\r\n        let value = '';\r\n        let result: IteratorResult<T>;\r\n        let addSeparator = false;\r\n        do {\r\n            result = iterator.next();\r\n            if (!result.done) {\r\n                if (addSeparator) {\r\n                    value += separator;\r\n                }\r\n                value += toString(result.value);\r\n            }\r\n            addSeparator = true;\r\n        } while (!result.done);\r\n        return value;\r\n    }\r\n\r\n    indexOf(searchElement: T, fromIndex = 0): number {\r\n        const iterator = this.iterator();\r\n        let index = 0;\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            if (index >= fromIndex && next.value === searchElement) {\r\n                return index;\r\n            }\r\n            next = iterator.next();\r\n            index++;\r\n        }\r\n        return -1;\r\n    }\r\n\r\n    // In the following definition the '& this' part in the return type is important\r\n    // _and_ the order within 'Stream<U> & this' is crucial!\r\n    // Otherwise Typescript would infer the type of 'this' as 'StreamImpl<S, T> & Stream<U>'\r\n    // (or '<subClass of StreamImpl<S, T> & Stream<U>') and usages like\r\n    // ```\r\n    //  const stream = new StreamImpl(...);\r\n    //  ... stream.every(<typeGuard>) & stream....\r\n    // ```\r\n    // cannot benefit from '<typeGuard>', as Typescript would priorize the signatures\r\n    // of 'StreamImpl<S, T>' (i.e. those of 'Stream<T>') over those of 'Stream<U>'.\r\n    // With the order of 'Stream<U> & this' the signatures of 'Stream<U>' get precedence.\r\n    every<U extends T>(predicate: (value: T) => value is U): this is Stream<U> & this;\r\n    every(predicate: (value: T) => unknown): boolean;\r\n    every(predicate: (value: T) => unknown): boolean {\r\n        const iterator = this.iterator();\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            if (!predicate(next.value)) {\r\n                return false;\r\n            }\r\n            next = iterator.next();\r\n        }\r\n        return true;\r\n    }\r\n\r\n    some(predicate: (value: T) => unknown): boolean {\r\n        const iterator = this.iterator();\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            if (predicate(next.value)) {\r\n                return true;\r\n            }\r\n            next = iterator.next();\r\n        }\r\n        return false;\r\n    }\r\n\r\n    forEach(callbackfn: (value: T, index: number) => void): void {\r\n        const iterator = this.iterator();\r\n        let index = 0;\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            callbackfn(next.value, index);\r\n            next = iterator.next();\r\n            index++;\r\n        }\r\n    }\r\n\r\n    map<U>(callbackfn: (value: T) => U): Stream<U> {\r\n        return new StreamImpl<S, U>(\r\n            this.startFn,\r\n            (state) => {\r\n                const { done, value } = this.nextFn(state);\r\n                if (done) {\r\n                    return DONE_RESULT;\r\n                } else {\r\n                    return { done: false, value: callbackfn(value) };\r\n                }\r\n            }\r\n        );\r\n    }\r\n\r\n    // for remarks on the return type definition refer to 'every<U extends T>(...)'\r\n    filter<U extends T>(predicate: (value: T) => value is U): Stream<U> & this;\r\n    filter(predicate: (value: T) => unknown): Stream<T> & this;\r\n    filter(predicate: (value: T) => unknown): Stream<T> {\r\n        return new StreamImpl<S, T>(\r\n            this.startFn,\r\n            state => {\r\n                let result: IteratorResult<T>;\r\n                do {\r\n                    result = this.nextFn(state);\r\n                    if (!result.done && predicate(result.value)) {\r\n                        return result;\r\n                    }\r\n                } while (!result.done);\r\n                return DONE_RESULT;\r\n            }\r\n        );\r\n    }\r\n\r\n    nonNullable(): Stream<NonNullable<T>> {\r\n        return this.filter(e => e !== undefined && e !== null) as Stream<NonNullable<T>>;\r\n    }\r\n\r\n    reduce(callbackfn: (previousValue: T, currentValue: T) => T): T | undefined;\r\n    reduce<U = T>(callbackfn: (previousValue: U, currentValue: T) => U, initialValue: U): U;\r\n    reduce<U>(callbackfn: (previousValue: U | T, currentValue: T) => U, initialValue?: U): U | T | undefined {\r\n        const iterator = this.iterator();\r\n        let previousValue: U | T | undefined = initialValue;\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            if (previousValue === undefined) {\r\n                previousValue = next.value;\r\n            } else {\r\n                previousValue = callbackfn(previousValue, next.value);\r\n            }\r\n            next = iterator.next();\r\n        }\r\n        return previousValue;\r\n    }\r\n\r\n    reduceRight(callbackfn: (previousValue: T, currentValue: T) => T): T | undefined;\r\n    reduceRight<U = T>(callbackfn: (previousValue: U, currentValue: T) => U, initialValue: U): U;\r\n    reduceRight<U>(callbackfn: (previousValue: U | T, currentValue: T) => U, initialValue?: U): U | T | undefined {\r\n        return this.recursiveReduce(this.iterator(), callbackfn, initialValue);\r\n    }\r\n\r\n    protected recursiveReduce<U>(iterator: Iterator<T>, callbackfn: (previousValue: U | T, currentValue: T) => U, initialValue?: U): U | T | undefined {\r\n        const next = iterator.next();\r\n        if (next.done) {\r\n            return initialValue;\r\n        }\r\n        const previousValue = this.recursiveReduce(iterator, callbackfn, initialValue);\r\n        if (previousValue === undefined) {\r\n            return next.value;\r\n        }\r\n        return callbackfn(previousValue, next.value);\r\n    }\r\n\r\n    find<S extends T>(predicate: (value: T) => value is S): S | undefined;\r\n    find(predicate: (value: T) => unknown): T | undefined;\r\n    find(predicate: (value: T) => unknown): T | undefined {\r\n        const iterator = this.iterator();\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            if (predicate(next.value)) {\r\n                return next.value;\r\n            }\r\n            next = iterator.next();\r\n        }\r\n        return undefined;\r\n    }\r\n\r\n    findIndex(predicate: (value: T) => unknown): number {\r\n        const iterator = this.iterator();\r\n        let index = 0;\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            if (predicate(next.value)) {\r\n                return index;\r\n            }\r\n            next = iterator.next();\r\n            index++;\r\n        }\r\n        return -1;\r\n    }\r\n\r\n    includes(searchElement: T): boolean {\r\n        const iterator = this.iterator();\r\n        let next = iterator.next();\r\n        while (!next.done) {\r\n            if (next.value === searchElement) {\r\n                return true;\r\n            }\r\n            next = iterator.next();\r\n        }\r\n        return false;\r\n    }\r\n\r\n    flatMap<U>(callbackfn: (value: T) => U | Iterable<U>): Stream<U> {\r\n        type FlatMapState = { this: S, iterator?: Iterator<U, undefined> }\r\n        return new StreamImpl<FlatMapState, U>(\r\n            () => ({ this: this.startFn() }),\r\n            (state) => {\r\n                do {\r\n                    if (state.iterator) {\r\n                        const next = state.iterator.next();\r\n                        if (next.done) {\r\n                            state.iterator = undefined;\r\n                        } else {\r\n                            return next;\r\n                        }\r\n                    }\r\n                    const { done, value } = this.nextFn(state.this);\r\n                    if (!done) {\r\n                        const mapped = callbackfn(value);\r\n                        if (isIterable(mapped)) {\r\n                            state.iterator = mapped[Symbol.iterator]();\r\n                        } else {\r\n                            return { done: false, value: mapped };\r\n                        }\r\n                    }\r\n                } while (state.iterator);\r\n                return DONE_RESULT;\r\n            }\r\n        );\r\n    }\r\n\r\n    flat<D extends number = 1>(depth?: D): FlatStream<T, D> {\r\n        if (depth === undefined) {\r\n            depth = 1 as D;\r\n        }\r\n        if (depth <= 0) {\r\n            return this as unknown as FlatStream<T, D>;\r\n        }\r\n        const stream = depth > 1 ? this.flat(depth - 1) as unknown as StreamImpl<S, T> : this;\r\n        type FlatMapState = { this: S, iterator?: Iterator<T, undefined> }\r\n        return new StreamImpl<FlatMapState, T>(\r\n            () => ({ this: stream.startFn() }),\r\n            (state) => {\r\n                do {\r\n                    if (state.iterator) {\r\n                        const next = state.iterator.next();\r\n                        if (next.done) {\r\n                            state.iterator = undefined;\r\n                        } else {\r\n                            return next;\r\n                        }\r\n                    }\r\n                    const { done, value } = stream.nextFn(state.this);\r\n                    if (!done) {\r\n                        if (isIterable(value)) {\r\n                            state.iterator = value[Symbol.iterator]() as Iterator<T>;\r\n                        } else {\r\n                            return { done: false, value: value };\r\n                        }\r\n                    }\r\n                } while (state.iterator);\r\n                return DONE_RESULT;\r\n            }\r\n        ) as unknown as FlatStream<T, D>;\r\n    }\r\n\r\n    head(): T | undefined {\r\n        const iterator = this.iterator();\r\n        const result = iterator.next();\r\n        if (result.done) {\r\n            return undefined;\r\n        }\r\n        return result.value;\r\n    }\r\n\r\n    tail(skipCount = 1): Stream<T> {\r\n        return new StreamImpl<S, T>(\r\n            () => {\r\n                const state = this.startFn();\r\n                for (let i = 0; i < skipCount; i++) {\r\n                    const next = this.nextFn(state);\r\n                    if (next.done) {\r\n                        return state;\r\n                    }\r\n                }\r\n                return state;\r\n            },\r\n            this.nextFn\r\n        );\r\n    }\r\n\r\n    limit(maxSize: number): Stream<T> {\r\n        return new StreamImpl<{ size: number, state: S }, T>(\r\n            () => ({ size: 0, state: this.startFn() }),\r\n            state => {\r\n                state.size++;\r\n                if (state.size > maxSize) {\r\n                    return DONE_RESULT;\r\n                }\r\n                return this.nextFn(state.state);\r\n            }\r\n        );\r\n    }\r\n\r\n    distinct<Key = T>(by?: (element: T) => Key): Stream<T> {\r\n        return new StreamImpl<{ set: Set<Key | T>, internalState: S }, T>(\r\n            () => ({ set: new Set<Key | T>(), internalState: this.startFn() }),\r\n            state => {\r\n                let result: IteratorResult<T>;\r\n                do {\r\n                    result = this.nextFn(state.internalState);\r\n                    if (!result.done) {\r\n                        const value = by ? by(result.value) : result.value;\r\n                        if (!state.set.has(value)) {\r\n                            state.set.add(value);\r\n                            return result;\r\n                        }\r\n                    }\r\n                } while (!result.done);\r\n                return DONE_RESULT;\r\n            }\r\n        );\r\n    }\r\n\r\n    exclude<Key = T>(other: Iterable<T>, key?: (element: T) => Key): Stream<T> {\r\n        const otherKeySet = new Set<Key | T>();\r\n        for (const item of other) {\r\n            const value = key ? key(item) : item;\r\n            otherKeySet.add(value);\r\n        }\r\n        return this.filter(e => {\r\n            const ownKey = key ? key(e) : e;\r\n            return !otherKeySet.has(ownKey);\r\n        });\r\n    }\r\n}\r\n\r\nfunction toString(item: unknown): string {\r\n    if (typeof item === 'string') {\r\n        return item as string;\r\n    }\r\n    if (typeof item === 'undefined') {\r\n        return 'undefined';\r\n    }\r\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n    if (typeof (item as any).toString === 'function') {\r\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\r\n        return (item as any).toString();\r\n    }\r\n    return Object.prototype.toString.call(item);\r\n}\r\n\r\nfunction isIterable<T>(obj: unknown): obj is Iterable<T> {\r\n    return !!obj && typeof (obj as Iterable<T>)[Symbol.iterator] === 'function';\r\n}\r\n\r\n/**\r\n * An empty stream of any type.\r\n */\r\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\r\nexport const EMPTY_STREAM: Stream<any> = new StreamImpl<undefined, any>(() => undefined, () => DONE_RESULT);\r\n\r\n/**\r\n * Use this `IteratorResult` when implementing a `StreamImpl` to indicate that there are no more elements in the stream.\r\n */\r\nexport const DONE_RESULT: IteratorReturnResult<undefined> = Object.freeze({ done: true, value: undefined });\r\n\r\n/**\r\n * Create a stream from one or more iterables or array-likes.\r\n */\r\nexport function stream<T>(...collections: Array<Iterable<T> | ArrayLike<T>>): Stream<T> {\r\n    if (collections.length === 1) {\r\n        const collection = collections[0];\r\n        if (collection instanceof StreamImpl) {\r\n            return collection as Stream<T>;\r\n        }\r\n        if (isIterable(collection)) {\r\n            return new StreamImpl<Iterator<T, undefined>, T>(\r\n                () => collection[Symbol.iterator](),\r\n                (iterator) => iterator.next()\r\n            );\r\n        }\r\n        if (typeof collection.length === 'number') {\r\n            return new StreamImpl<{ index: number }, T>(\r\n                () => ({ index: 0 }),\r\n                (state) => {\r\n                    if (state.index < collection.length) {\r\n                        return { done: false, value: collection[state.index++] };\r\n                    } else {\r\n                        return DONE_RESULT;\r\n                    }\r\n                }\r\n            );\r\n        }\r\n    }\r\n    if (collections.length > 1) {\r\n        type State = { collIndex: number, iterator?: Iterator<T, undefined>, array?: ArrayLike<T>, arrIndex: number };\r\n        return new StreamImpl<State, T>(\r\n            () => ({ collIndex: 0, arrIndex: 0 }),\r\n            (state) => {\r\n                do {\r\n                    if (state.iterator) {\r\n                        const next = state.iterator.next();\r\n                        if (!next.done) {\r\n                            return next;\r\n                        }\r\n                        state.iterator = undefined;\r\n                    }\r\n                    if (state.array) {\r\n                        if (state.arrIndex < state.array.length) {\r\n                            return { done: false, value: state.array[state.arrIndex++] };\r\n                        }\r\n                        state.array = undefined;\r\n                        state.arrIndex = 0;\r\n                    }\r\n                    if (state.collIndex < collections.length) {\r\n                        const collection = collections[state.collIndex++];\r\n                        if (isIterable(collection)) {\r\n                            state.iterator = collection[Symbol.iterator]();\r\n                        } else if (collection && typeof collection.length === 'number') {\r\n                            state.array = collection;\r\n                        }\r\n                    }\r\n                } while (state.iterator || state.array || state.collIndex < collections.length);\r\n                return DONE_RESULT;\r\n            }\r\n        );\r\n    }\r\n    return EMPTY_STREAM;\r\n}\r\n\r\n/**\r\n * A tree iterator adds the ability to prune the current iteration.\r\n */\r\nexport interface TreeIterator<T> extends IterableIterator<T> {\r\n    /**\r\n     * Skip the whole subtree below the last returned element. The iteration continues as if that\r\n     * element had no children.\r\n     */\r\n    prune(): void\r\n}\r\n\r\n/**\r\n * A tree stream is used to stream the elements of a tree, for example an AST or CST.\r\n */\r\nexport interface TreeStream<T> extends Stream<T> {\r\n    iterator(): TreeIterator<T>\r\n}\r\n\r\n/**\r\n * The default implementation of `TreeStream` takes a root element and a function that computes the\r\n * children of its argument. Whether the root node included in the stream is controlled with the\r\n * `includeRoot` option, which defaults to `false`.\r\n */\r\nexport class TreeStreamImpl<T>\r\n    extends StreamImpl<{ iterators: Array<Iterator<T>>, pruned: boolean }, T>\r\n    implements TreeStream<T> {\r\n\r\n    constructor(root: T, children: (node: T) => Iterable<T>, options?: { includeRoot?: boolean }) {\r\n        super(\r\n            () => ({\r\n                iterators: options?.includeRoot ? [[root][Symbol.iterator]()] : [children(root)[Symbol.iterator]()],\r\n                pruned: false\r\n            }),\r\n            state => {\r\n                if (state.pruned) {\r\n                    state.iterators.pop();\r\n                    state.pruned = false;\r\n                }\r\n                while (state.iterators.length > 0) {\r\n                    const iterator = state.iterators[state.iterators.length - 1];\r\n                    const next = iterator.next();\r\n                    if (next.done) {\r\n                        state.iterators.pop();\r\n                    } else {\r\n                        state.iterators.push(children(next.value)[Symbol.iterator]());\r\n                        return next;\r\n                    }\r\n                }\r\n                return DONE_RESULT;\r\n            }\r\n        );\r\n    }\r\n\r\n    override iterator(): TreeIterator<T> {\r\n        const iterator = {\r\n            state: this.startFn(),\r\n            next: () => this.nextFn(iterator.state),\r\n            prune: () => {\r\n                iterator.state.pruned = true;\r\n            },\r\n            [Symbol.iterator]: () => iterator\r\n        };\r\n        return iterator;\r\n    }\r\n}\r\n\r\n/**\r\n * A set of utility functions that reduce a stream to a single value.\r\n */\r\nexport namespace Reduction {\r\n\r\n    /**\r\n     * Compute the sum of a number stream.\r\n     */\r\n    export function sum(stream: Stream<number>): number {\r\n        return stream.reduce((a, b) => a + b, 0);\r\n    }\r\n\r\n    /**\r\n     * Compute the product of a number stream.\r\n     */\r\n    export function product(stream: Stream<number>): number {\r\n        return stream.reduce((a, b) => a * b, 0);\r\n    }\r\n\r\n    /**\r\n     * Compute the minimum of a number stream. Returns `undefined` if the stream is empty.\r\n     */\r\n    export function min(stream: Stream<number>): number | undefined {\r\n        return stream.reduce((a, b) => Math.min(a, b));\r\n    }\r\n\r\n    /**\r\n     * Compute the maximum of a number stream. Returns `undefined` if the stream is empty.\r\n     */\r\n    export function max(stream: Stream<number>): number | undefined {\r\n        return stream.reduce((a, b) => Math.max(a, b));\r\n    }\r\n\r\n}\r\n","import baseFlatten from './_baseFlatten.js';\nimport map from './map.js';\n\n/**\n * Creates a flattened array of values by running each element in `collection`\n * thru `iteratee` and flattening the mapped results. The iteratee is invoked\n * with three arguments: (value, index|key, collection).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Collection\n * @param {Array|Object} collection The collection to iterate over.\n * @param {Function} [iteratee=_.identity] The function invoked per iteration.\n * @returns {Array} Returns the new flattened array.\n * @example\n *\n * function duplicate(n) {\n *   return [n, n];\n * }\n *\n * _.flatMap([1, 2], duplicate);\n * // => [1, 1, 2, 2]\n */\nfunction flatMap(collection, iteratee) {\n  return baseFlatten(map(collection, iteratee), 1);\n}\n\nexport default flatMap;\n","/******************************************************************************\r\n * Copyright 2021-2022 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport { assertUnreachable } from '../utils/errors.js';\r\nimport * as ast from '../languages/generated/ast.js';\r\nimport type { AstNode, CstNode } from '../syntax-tree.js';\r\nimport { isCompositeCstNode } from '../syntax-tree.js';\r\nimport { getContainerOfType, streamAllContents } from './ast-utils.js';\r\nimport { streamCst } from './cst-utils.js';\r\nimport { escapeRegExp, isWhitespace } from './regexp-utils.js';\r\n\r\n/**\r\n * Returns the entry rule of the given grammar, if any. If the grammar file does not contain an entry rule,\r\n * the result is `undefined`.\r\n */\r\nexport function getEntryRule(grammar: ast.Grammar): ast.ParserRule | undefined {\r\n    return grammar.rules.find(e => ast.isParserRule(e) && e.entry) as ast.ParserRule;\r\n}\r\n\r\n/**\r\n * Returns all hidden terminal rules of the given grammar, if any.\r\n */\r\nexport function getHiddenRules(grammar: ast.Grammar) {\r\n    return grammar.rules.filter((e): e is ast.TerminalRule => ast.isTerminalRule(e) && e.hidden);\r\n}\r\n\r\n/**\r\n * Returns all rules that can be reached from the topmost rules of the specified grammar (entry and hidden terminal rules).\r\n *\r\n * @param grammar The grammar that contains all rules\r\n * @param allTerminals Whether or not to include terminals that are referenced only by other terminals\r\n * @returns A list of referenced parser and terminal rules. If the grammar contains no entry rule,\r\n *      this function returns all rules of the specified grammar.\r\n */\r\nexport function getAllReachableRules(grammar: ast.Grammar, allTerminals: boolean): Set<ast.AbstractRule> {\r\n    const ruleNames = new Set<string>();\r\n    const entryRule = getEntryRule(grammar);\r\n    if (!entryRule) {\r\n        return new Set(grammar.rules);\r\n    }\r\n\r\n    const topMostRules = [entryRule as ast.AbstractRule].concat(getHiddenRules(grammar));\r\n    for (const rule of topMostRules) {\r\n        ruleDfs(rule, ruleNames, allTerminals);\r\n    }\r\n\r\n    const rules = new Set<ast.AbstractRule>();\r\n    for (const rule of grammar.rules) {\r\n        if (ruleNames.has(rule.name) || (ast.isTerminalRule(rule) && rule.hidden)) {\r\n            rules.add(rule);\r\n        }\r\n    }\r\n    return rules;\r\n}\r\n\r\nfunction ruleDfs(rule: ast.AbstractRule, visitedSet: Set<string>, allTerminals: boolean): void {\r\n    visitedSet.add(rule.name);\r\n    streamAllContents(rule).forEach(node => {\r\n        if (ast.isRuleCall(node) || (allTerminals && ast.isTerminalRuleCall(node))) {\r\n            const refRule = node.rule.ref;\r\n            if (refRule && !visitedSet.has(refRule.name)) {\r\n                ruleDfs(refRule, visitedSet, allTerminals);\r\n            }\r\n        }\r\n    });\r\n}\r\n\r\n/**\r\n * Determines the grammar expression used to parse a cross-reference (usually a reference to a terminal rule).\r\n * A cross-reference can declare this expression explicitly in the form `[Type : Terminal]`, but if `Terminal`\r\n * is omitted, this function attempts to infer it from the name of the referenced `Type` (using `findNameAssignment`).\r\n *\r\n * Returns the grammar expression used to parse the given cross-reference, or `undefined` if it is not declared\r\n * and cannot be inferred.\r\n */\r\nexport function getCrossReferenceTerminal(crossRef: ast.CrossReference): ast.AbstractElement | undefined {\r\n    if (crossRef.terminal) {\r\n        return crossRef.terminal;\r\n    } else if (crossRef.type.ref) {\r\n        const nameAssigment = findNameAssignment(crossRef.type.ref);\r\n        return nameAssigment?.terminal;\r\n    }\r\n    return undefined;\r\n}\r\n\r\n/**\r\n * Determines whether the given terminal rule represents a comment. This is true if the rule is marked\r\n * as `hidden` and it does not match white space. This means every hidden token (i.e. excluded from the AST)\r\n * that contains visible characters is considered a comment.\r\n */\r\nexport function isCommentTerminal(terminalRule: ast.TerminalRule): boolean {\r\n    return terminalRule.hidden && !isWhitespace(terminalRegex(terminalRule));\r\n}\r\n\r\n/**\r\n * Find all CST nodes within the given node that contribute to the specified property.\r\n *\r\n * @param node A CST node in which to look for property assignments. If this is undefined, the result is an empty array.\r\n * @param property A property name of the constructed AST node. If this is undefined, the result is an empty array.\r\n */\r\nexport function findNodesForProperty(node: CstNode | undefined, property: string | undefined): CstNode[] {\r\n    if (!node || !property) {\r\n        return [];\r\n    }\r\n    return findNodesForPropertyInternal(node, property, node.astNode, true);\r\n}\r\n\r\n/**\r\n * Find a single CST node within the given node that contributes to the specified property.\r\n *\r\n * @param node A CST node in which to look for property assignments. If this is undefined, the result is `undefined`.\r\n * @param property A property name of the constructed AST node. If this is undefined, the result is `undefined`.\r\n * @param index If no index is specified or the index is less than zero, the first found node is returned. If the\r\n *        specified index exceeds the number of assignments to the property, the last found node is returned. Otherwise,\r\n *        the node with the specified index is returned.\r\n */\r\nexport function findNodeForProperty(node: CstNode | undefined, property: string | undefined, index?: number): CstNode | undefined {\r\n    if (!node || !property) {\r\n        return undefined;\r\n    }\r\n    const nodes = findNodesForPropertyInternal(node, property, node.astNode, true);\r\n    if (nodes.length === 0) {\r\n        return undefined;\r\n    }\r\n    if (index !== undefined) {\r\n        index = Math.max(0, Math.min(index, nodes.length - 1));\r\n    } else {\r\n        index = 0;\r\n    }\r\n    return nodes[index];\r\n}\r\n\r\nfunction findNodesForPropertyInternal(node: CstNode, property: string, element: AstNode | undefined, first: boolean): CstNode[] {\r\n    if (!first) {\r\n        const nodeFeature = getContainerOfType(node.grammarSource, ast.isAssignment);\r\n        if (nodeFeature && nodeFeature.feature === property) {\r\n            return [node];\r\n        }\r\n    }\r\n    if (isCompositeCstNode(node) && node.astNode === element) {\r\n        return node.content.flatMap(e => findNodesForPropertyInternal(e, property, element, false));\r\n    }\r\n    return [];\r\n}\r\n\r\n/**\r\n * Find all CST nodes within the given node that correspond to the specified keyword.\r\n *\r\n * @param node A CST node in which to look for keywords. If this is undefined, the result is an empty array.\r\n * @param keyword A keyword as specified in the grammar.\r\n */\r\nexport function findNodesForKeyword(node: CstNode | undefined, keyword: string): CstNode[] {\r\n    if (!node) {\r\n        return [];\r\n    }\r\n    return findNodesForKeywordInternal(node, keyword, node?.astNode);\r\n}\r\n\r\n/**\r\n * Find a single CST node within the given node that corresponds to the specified keyword.\r\n *\r\n * @param node A CST node in which to look for keywords. If this is undefined, the result is `undefined`.\r\n * @param keyword A keyword as specified in the grammar.\r\n * @param index If no index is specified or the index is less than zero, the first found node is returned. If the\r\n *        specified index exceeds the number of keyword occurrences, the last found node is returned. Otherwise,\r\n *        the node with the specified index is returned.\r\n */\r\nexport function findNodeForKeyword(node: CstNode | undefined, keyword: string, index?: number): CstNode | undefined {\r\n    if (!node) {\r\n        return undefined;\r\n    }\r\n    const nodes = findNodesForKeywordInternal(node, keyword, node?.astNode);\r\n    if (nodes.length === 0) {\r\n        return undefined;\r\n    }\r\n    if (index !== undefined) {\r\n        index = Math.max(0, Math.min(index, nodes.length - 1));\r\n    } else {\r\n        index = 0;\r\n    }\r\n    return nodes[index];\r\n}\r\n\r\nexport function findNodesForKeywordInternal(node: CstNode, keyword: string, element: AstNode | undefined): CstNode[] {\r\n    if (node.astNode !== element) {\r\n        return [];\r\n    }\r\n    if (ast.isKeyword(node.grammarSource) && node.grammarSource.value === keyword) {\r\n        return [node];\r\n    }\r\n    const treeIterator = streamCst(node).iterator();\r\n    let result: IteratorResult<CstNode>;\r\n    const keywordNodes: CstNode[] = [];\r\n    do {\r\n        result = treeIterator.next();\r\n        if (!result.done) {\r\n            const childNode = result.value;\r\n            if (childNode.astNode === element) {\r\n                if (ast.isKeyword(childNode.grammarSource) && childNode.grammarSource.value === keyword) {\r\n                    keywordNodes.push(childNode);\r\n                }\r\n            } else {\r\n                treeIterator.prune();\r\n            }\r\n        }\r\n    } while (!result.done);\r\n    return keywordNodes;\r\n}\r\n\r\n/**\r\n * If the given CST node was parsed in the context of a property assignment, the respective `Assignment` grammar\r\n * node is returned. If no assignment is found, the result is `undefined`.\r\n *\r\n * @param cstNode A CST node for which to find a property assignment.\r\n */\r\nexport function findAssignment(cstNode: CstNode): ast.Assignment | undefined {\r\n    const astNode = cstNode.astNode;\r\n    // Only search until the ast node of the parent cst node is no longer the original ast node\r\n    // This would make us jump to a preceding rule call, which contains only unrelated assignments\r\n    while (astNode === cstNode.container?.astNode) {\r\n        const assignment = getContainerOfType(cstNode.grammarSource, ast.isAssignment);\r\n        if (assignment) {\r\n            return assignment;\r\n        }\r\n        cstNode = cstNode.container;\r\n    }\r\n    return undefined;\r\n}\r\n\r\n/**\r\n * Find an assignment to the `name` property for the given grammar type. This requires the `type` to be inferred\r\n * from a parser rule, and that rule must contain an assignment to the `name` property. In all other cases,\r\n * this function returns `undefined`.\r\n */\r\nexport function findNameAssignment(type: ast.AbstractType): ast.Assignment | undefined {\r\n    let startNode: AstNode = type;\r\n    if (ast.isInferredType(startNode)) {\r\n        // for inferred types, the location to start searching for the name-assignment is different\r\n        if (ast.isAction(startNode.$container)) {\r\n            // a type which is explicitly inferred by an action: investigate the sibbling of the Action node, i.e. start searching at the Action's parent\r\n            startNode = startNode.$container.$container!;\r\n        } else if (ast.isParserRule(startNode.$container)) {\r\n            // investigate the parser rule with the explicitly inferred type\r\n            startNode = startNode.$container;\r\n        } else {\r\n            assertUnreachable(startNode.$container);\r\n        }\r\n    }\r\n    return findNameAssignmentInternal(type, startNode, new Map());\r\n}\r\n\r\nfunction findNameAssignmentInternal(type: ast.AbstractType, startNode: AstNode, cache: Map<ast.AbstractType, ast.Assignment | undefined>): ast.Assignment | undefined {\r\n    // the cache is only required to prevent infinite loops\r\n    function go(node: AstNode, refType: ast.AbstractType): ast.Assignment | undefined {\r\n        let childAssignment: ast.Assignment | undefined = undefined;\r\n        const parentAssignment = getContainerOfType(node, ast.isAssignment);\r\n        // No parent assignment implies unassigned rule call\r\n        if (!parentAssignment) {\r\n            childAssignment = findNameAssignmentInternal(refType, refType, cache);\r\n        }\r\n        cache.set(type, childAssignment);\r\n        return childAssignment;\r\n    }\r\n\r\n    if (cache.has(type)) {\r\n        return cache.get(type);\r\n    }\r\n    cache.set(type, undefined);\r\n    for (const node of streamAllContents(startNode)) {\r\n        if (ast.isAssignment(node) && node.feature.toLowerCase() === 'name') {\r\n            cache.set(type, node);\r\n            return node;\r\n        } else if (ast.isRuleCall(node) && ast.isParserRule(node.rule.ref)) {\r\n            return go(node, node.rule.ref);\r\n        } else if (ast.isSimpleType(node) && node.typeRef?.ref) {\r\n            return go(node, node.typeRef.ref);\r\n        }\r\n    }\r\n    return undefined;\r\n}\r\n\r\nexport function getActionAtElement(element: ast.AbstractElement): ast.Action | undefined {\r\n    const parent = element.$container;\r\n    if (ast.isGroup(parent)) {\r\n        const elements = parent.elements;\r\n        const index = elements.indexOf(element);\r\n        for (let i = index - 1; i >= 0; i--) {\r\n            const item = elements[i];\r\n            if (ast.isAction(item)) {\r\n                return item;\r\n            } else {\r\n                const action = streamAllContents(elements[i]).find(ast.isAction);\r\n                if (action) {\r\n                    return action;\r\n                }\r\n            }\r\n        }\r\n    }\r\n    if (ast.isAbstractElement(parent)) {\r\n        return getActionAtElement(parent);\r\n    } else {\r\n        return undefined;\r\n    }\r\n}\r\n\r\nexport type Cardinality = '?' | '*' | '+' | undefined;\r\nexport type Operator = '=' | '+=' | '?=' | undefined;\r\n\r\nexport function isOptionalCardinality(cardinality?: Cardinality, element?: ast.AbstractElement): boolean {\r\n    return cardinality === '?' || cardinality === '*' || (ast.isGroup(element) && Boolean(element.guardCondition));\r\n}\r\n\r\nexport function isArrayCardinality(cardinality?: Cardinality): boolean {\r\n    return cardinality === '*' || cardinality === '+';\r\n}\r\n\r\nexport function isArrayOperator(operator?: Operator): boolean {\r\n    return operator === '+=';\r\n}\r\n\r\n/**\r\n * Determines whether the given parser rule is a _data type rule_, meaning that it has a\r\n * primitive return type like `number`, `boolean`, etc.\r\n */\r\nexport function isDataTypeRule(rule: ast.ParserRule): boolean {\r\n    return isDataTypeRuleInternal(rule, new Set());\r\n}\r\n\r\nfunction isDataTypeRuleInternal(rule: ast.ParserRule, visited: Set<ast.ParserRule>): boolean {\r\n    if (visited.has(rule)) {\r\n        return true;\r\n    } else {\r\n        visited.add(rule);\r\n    }\r\n    for (const node of streamAllContents(rule)) {\r\n        if (ast.isRuleCall(node)) {\r\n            if (!node.rule.ref) {\r\n                // RuleCall to unresolved rule. Don't assume `rule` is a DataType rule.\r\n                return false;\r\n            }\r\n            if (ast.isParserRule(node.rule.ref) && !isDataTypeRuleInternal(node.rule.ref, visited)) {\r\n                return false;\r\n            }\r\n        } else if (ast.isAssignment(node)) {\r\n            return false;\r\n        } else if (ast.isAction(node)) {\r\n            return false;\r\n        }\r\n    }\r\n    return Boolean(rule.definition);\r\n}\r\n\r\nexport function isDataType(type: ast.Type): boolean {\r\n    return isDataTypeInternal(type.type, new Set());\r\n}\r\n\r\nfunction isDataTypeInternal(type: ast.TypeDefinition, visited: Set<ast.TypeDefinition>): boolean {\r\n    if (visited.has(type)) {\r\n        return true;\r\n    } else {\r\n        visited.add(type);\r\n    }\r\n    if (ast.isArrayType(type)) {\r\n        return false;\r\n    } else if (ast.isReferenceType(type)) {\r\n        return false;\r\n    } else if (ast.isUnionType(type)) {\r\n        return type.types.every(e => isDataTypeInternal(e, visited));\r\n    } else if (ast.isSimpleType(type)) {\r\n        if (type.primitiveType !== undefined) {\r\n            return true;\r\n        } else if (type.stringType !== undefined) {\r\n            return true;\r\n        } else if (type.typeRef !== undefined) {\r\n            const ref = type.typeRef.ref;\r\n            if (ast.isType(ref)) {\r\n                return isDataTypeInternal(ref.type, visited);\r\n            } else {\r\n                return false;\r\n            }\r\n        } else {\r\n            return false;\r\n        }\r\n    } else {\r\n        return false;\r\n    }\r\n}\r\n\r\nexport function getExplicitRuleType(rule: ast.ParserRule): string | undefined {\r\n    if (rule.inferredType) {\r\n        return rule.inferredType.name;\r\n    } else if (rule.dataType) {\r\n        return rule.dataType;\r\n    } else if (rule.returnType) {\r\n        const refType = rule.returnType.ref;\r\n        if (refType) {\r\n            // check if we need to check Action as return type\r\n            if (ast.isParserRule(refType)) {\r\n                return refType.name;\r\n            } else if (ast.isInterface(refType) || ast.isType(refType)) {\r\n                return refType.name;\r\n            }\r\n        }\r\n    }\r\n    return undefined;\r\n}\r\n\r\nexport function getTypeName(type: ast.AbstractType | ast.Action): string {\r\n    if (ast.isParserRule(type)) {\r\n        return isDataTypeRule(type) ? type.name : getExplicitRuleType(type) ?? type.name;\r\n    } else if (ast.isInterface(type) || ast.isType(type) || ast.isReturnType(type)) {\r\n        return type.name;\r\n    } else if (ast.isAction(type)) {\r\n        const actionType = getActionType(type);\r\n        if (actionType) {\r\n            return actionType;\r\n        }\r\n    } else if (ast.isInferredType(type)) {\r\n        return type.name;\r\n    }\r\n    throw new Error('Cannot get name of Unknown Type');\r\n}\r\n\r\nexport function getActionType(action: ast.Action): string | undefined {\r\n    if (action.inferredType) {\r\n        return action.inferredType.name;\r\n    } else if (action.type?.ref) {\r\n        return getTypeName(action.type.ref);\r\n    }\r\n    return undefined; // not inferring and not referencing a valid type\r\n}\r\n\r\n/**\r\n * This function is used at development time (for code generation and the internal type system) to get the type of the AST node produced by the given rule.\r\n * For data type rules, the name of the rule is returned,\r\n * e.g. \"INT_value returns number: MY_INT;\" returns \"INT_value\".\r\n * @param rule the given rule\r\n * @returns the name of the AST node type of the rule\r\n */\r\nexport function getRuleTypeName(rule: ast.AbstractRule): string {\r\n    if (ast.isTerminalRule(rule)) {\r\n        return rule.type?.name ?? 'string';\r\n    } else {\r\n        return isDataTypeRule(rule) ? rule.name : getExplicitRuleType(rule) ?? rule.name;\r\n    }\r\n}\r\n\r\n/**\r\n * This function is used at runtime to get the actual type of the values produced by the given rule at runtime.\r\n * For data type rules, the name of the declared return type of the rule is returned (if any),\r\n * e.g. \"INT_value returns number: MY_INT;\" returns \"number\".\r\n * @param rule the given rule\r\n * @returns the name of the type of the produced values of the rule at runtime\r\n */\r\nexport function getRuleType(rule: ast.AbstractRule): string {\r\n    if (ast.isTerminalRule(rule)) {\r\n        return rule.type?.name ?? 'string';\r\n    } else {\r\n        return getExplicitRuleType(rule) ?? rule.name;\r\n    }\r\n}\r\n\r\nexport function terminalRegex(terminalRule: ast.TerminalRule): RegExp {\r\n    const flags: Flags = {\r\n        s: false,\r\n        i: false,\r\n        u: false\r\n    };\r\n    const source = abstractElementToRegex(terminalRule.definition, flags);\r\n    const flagText = Object.entries(flags).filter(([, value]) => value).map(([name]) => name).join('');\r\n    return new RegExp(source, flagText);\r\n}\r\n\r\n// Using [\\s\\S]* allows to match everything, compared to . which doesn't match line terminators\r\nconst WILDCARD = /[\\s\\S]/.source;\r\n\r\ntype Flags = {\r\n    s: boolean;\r\n    i: boolean;\r\n    u: boolean;\r\n}\r\n\r\nfunction abstractElementToRegex(element: ast.AbstractElement, flags?: Flags): string {\r\n    if (ast.isTerminalAlternatives(element)) {\r\n        return terminalAlternativesToRegex(element);\r\n    } else if (ast.isTerminalGroup(element)) {\r\n        return terminalGroupToRegex(element);\r\n    } else if (ast.isCharacterRange(element)) {\r\n        return characterRangeToRegex(element);\r\n    } else if (ast.isTerminalRuleCall(element)) {\r\n        const rule = element.rule.ref;\r\n        if (!rule) {\r\n            throw new Error('Missing rule reference.');\r\n        }\r\n        return withCardinality(abstractElementToRegex(rule.definition), {\r\n            cardinality: element.cardinality,\r\n            lookahead: element.lookahead\r\n        });\r\n    } else if (ast.isNegatedToken(element)) {\r\n        return negateTokenToRegex(element);\r\n    } else if (ast.isUntilToken(element)) {\r\n        return untilTokenToRegex(element);\r\n    } else if (ast.isRegexToken(element)) {\r\n        const lastSlash = element.regex.lastIndexOf('/');\r\n        const source = element.regex.substring(1, lastSlash);\r\n        const regexFlags = element.regex.substring(lastSlash + 1);\r\n        if (flags) {\r\n            flags.i = regexFlags.includes('i');\r\n            flags.s = regexFlags.includes('s');\r\n            flags.u = regexFlags.includes('u');\r\n        }\r\n        return withCardinality(source, {\r\n            cardinality: element.cardinality,\r\n            lookahead: element.lookahead,\r\n            wrap: false\r\n        });\r\n    } else if (ast.isWildcard(element)) {\r\n        return withCardinality(WILDCARD, {\r\n            cardinality: element.cardinality,\r\n            lookahead: element.lookahead\r\n        });\r\n    } else {\r\n        throw new Error(`Invalid terminal element: ${element?.$type}`);\r\n    }\r\n}\r\n\r\nfunction terminalAlternativesToRegex(alternatives: ast.TerminalAlternatives): string {\r\n    return withCardinality(alternatives.elements.map(e => abstractElementToRegex(e)).join('|'), {\r\n        cardinality: alternatives.cardinality,\r\n        lookahead: alternatives.lookahead\r\n    });\r\n}\r\n\r\nfunction terminalGroupToRegex(group: ast.TerminalGroup): string {\r\n    return withCardinality(group.elements.map(e => abstractElementToRegex(e)).join(''), {\r\n        cardinality: group.cardinality,\r\n        lookahead: group.lookahead\r\n    });\r\n}\r\n\r\nfunction untilTokenToRegex(until: ast.UntilToken): string {\r\n    return withCardinality(`${WILDCARD}*?${abstractElementToRegex(until.terminal)}`, {\r\n        cardinality: until.cardinality,\r\n        lookahead: until.lookahead\r\n    });\r\n}\r\n\r\nfunction negateTokenToRegex(negate: ast.NegatedToken): string {\r\n    return withCardinality(`(?!${abstractElementToRegex(negate.terminal)})${WILDCARD}*?`, {\r\n        cardinality: negate.cardinality,\r\n        lookahead: negate.lookahead\r\n    });\r\n}\r\n\r\nfunction characterRangeToRegex(range: ast.CharacterRange): string {\r\n    if (range.right) {\r\n        return withCardinality(`[${keywordToRegex(range.left)}-${keywordToRegex(range.right)}]`, {\r\n            cardinality: range.cardinality,\r\n            lookahead: range.lookahead,\r\n            wrap: false\r\n        });\r\n    }\r\n    return withCardinality(keywordToRegex(range.left), {\r\n        cardinality: range.cardinality,\r\n        lookahead: range.lookahead,\r\n        wrap: false\r\n    });\r\n}\r\n\r\nfunction keywordToRegex(keyword: ast.Keyword): string {\r\n    return escapeRegExp(keyword.value);\r\n}\r\n\r\nfunction withCardinality(regex: string, options: {\r\n    cardinality?: string\r\n    wrap?: boolean\r\n    lookahead?: string\r\n}): string {\r\n    if (options.wrap !== false || options.lookahead) {\r\n        regex = `(${options.lookahead ?? ''}${regex})`;\r\n    }\r\n    if (options.cardinality) {\r\n        return `${regex}${options.cardinality}`;\r\n    }\r\n    return regex;\r\n}\r\n","import {\n  GitGraphModule,\n  createGitGraphServices\n} from \"./chunks/mermaid-parser.core/chunk-BN7GFLIU.mjs\";\nimport {\n  InfoModule,\n  createInfoServices\n} from \"./chunks/mermaid-parser.core/chunk-T44TD3VJ.mjs\";\nimport {\n  PacketModule,\n  createPacketServices\n} from \"./chunks/mermaid-parser.core/chunk-KMC2YHZD.mjs\";\nimport {\n  PieModule,\n  createPieServices\n} from \"./chunks/mermaid-parser.core/chunk-WFWHJNB7.mjs\";\nimport {\n  ArchitectureModule,\n  createArchitectureServices\n} from \"./chunks/mermaid-parser.core/chunk-JEIROHC2.mjs\";\nimport {\n  RadarModule,\n  createRadarServices\n} from \"./chunks/mermaid-parser.core/chunk-WFRQ32O7.mjs\";\nimport {\n  TreemapModule,\n  createTreemapServices\n} from \"./chunks/mermaid-parser.core/chunk-XRWGC2XP.mjs\";\nimport {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  Architecture,\n  ArchitectureGeneratedModule,\n  Branch,\n  Commit,\n  CommonTokenBuilder,\n  CommonValueConverter,\n  GitGraph,\n  GitGraphGeneratedModule,\n  Info,\n  InfoGeneratedModule,\n  Merge,\n  MermaidGeneratedSharedModule,\n  Packet,\n  PacketBlock,\n  PacketGeneratedModule,\n  Pie,\n  PieGeneratedModule,\n  PieSection,\n  Radar,\n  RadarGeneratedModule,\n  Statement,\n  Treemap,\n  TreemapGeneratedModule,\n  __name,\n  isArchitecture,\n  isBranch,\n  isCommit,\n  isGitGraph,\n  isInfo,\n  isMerge,\n  isPacket,\n  isPacketBlock,\n  isPie,\n  isPieSection,\n  isTreemap\n} from \"./chunks/mermaid-parser.core/chunk-4KMFLZZN.mjs\";\n\n// src/parse.ts\nvar parsers = {};\nvar initializers = {\n  info: /* @__PURE__ */ __name(async () => {\n    const { createInfoServices: createInfoServices2 } = await import(\"./chunks/mermaid-parser.core/info-63CPKGFF.mjs\");\n    const parser = createInfoServices2().Info.parser.LangiumParser;\n    parsers.info = parser;\n  }, \"info\"),\n  packet: /* @__PURE__ */ __name(async () => {\n    const { createPacketServices: createPacketServices2 } = await import(\"./chunks/mermaid-parser.core/packet-HUATNLJX.mjs\");\n    const parser = createPacketServices2().Packet.parser.LangiumParser;\n    parsers.packet = parser;\n  }, \"packet\"),\n  pie: /* @__PURE__ */ __name(async () => {\n    const { createPieServices: createPieServices2 } = await import(\"./chunks/mermaid-parser.core/pie-WTHONI2E.mjs\");\n    const parser = createPieServices2().Pie.parser.LangiumParser;\n    parsers.pie = parser;\n  }, \"pie\"),\n  architecture: /* @__PURE__ */ __name(async () => {\n    const { createArchitectureServices: createArchitectureServices2 } = await import(\"./chunks/mermaid-parser.core/architecture-O4VJ6CD3.mjs\");\n    const parser = createArchitectureServices2().Architecture.parser.LangiumParser;\n    parsers.architecture = parser;\n  }, \"architecture\"),\n  gitGraph: /* @__PURE__ */ __name(async () => {\n    const { createGitGraphServices: createGitGraphServices2 } = await import(\"./chunks/mermaid-parser.core/gitGraph-ZV4HHKMB.mjs\");\n    const parser = createGitGraphServices2().GitGraph.parser.LangiumParser;\n    parsers.gitGraph = parser;\n  }, \"gitGraph\"),\n  radar: /* @__PURE__ */ __name(async () => {\n    const { createRadarServices: createRadarServices2 } = await import(\"./chunks/mermaid-parser.core/radar-NJJJXTRR.mjs\");\n    const parser = createRadarServices2().Radar.parser.LangiumParser;\n    parsers.radar = parser;\n  }, \"radar\"),\n  treemap: /* @__PURE__ */ __name(async () => {\n    const { createTreemapServices: createTreemapServices2 } = await import(\"./chunks/mermaid-parser.core/treemap-75Q7IDZK.mjs\");\n    const parser = createTreemapServices2().Treemap.parser.LangiumParser;\n    parsers.treemap = parser;\n  }, \"treemap\")\n};\nasync function parse(diagramType, text) {\n  const initializer = initializers[diagramType];\n  if (!initializer) {\n    throw new Error(`Unknown diagram type: ${diagramType}`);\n  }\n  if (!parsers[diagramType]) {\n    await initializer();\n  }\n  const parser = parsers[diagramType];\n  const result = parser.parse(text);\n  if (result.lexerErrors.length > 0 || result.parserErrors.length > 0) {\n    throw new MermaidParseError(result);\n  }\n  return result.value;\n}\n__name(parse, \"parse\");\nvar MermaidParseError = class extends Error {\n  constructor(result) {\n    const lexerErrors = result.lexerErrors.map((err) => err.message).join(\"\\n\");\n    const parserErrors = result.parserErrors.map((err) => err.message).join(\"\\n\");\n    super(`Parsing failed: ${lexerErrors} ${parserErrors}`);\n    this.result = result;\n  }\n  static {\n    __name(this, \"MermaidParseError\");\n  }\n};\nexport {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  Architecture,\n  ArchitectureGeneratedModule,\n  ArchitectureModule,\n  Branch,\n  Commit,\n  CommonTokenBuilder,\n  CommonValueConverter,\n  GitGraph,\n  GitGraphGeneratedModule,\n  GitGraphModule,\n  Info,\n  InfoGeneratedModule,\n  InfoModule,\n  Merge,\n  MermaidGeneratedSharedModule,\n  MermaidParseError,\n  Packet,\n  PacketBlock,\n  PacketGeneratedModule,\n  PacketModule,\n  Pie,\n  PieGeneratedModule,\n  PieModule,\n  PieSection,\n  Radar,\n  RadarGeneratedModule,\n  RadarModule,\n  Statement,\n  Treemap,\n  TreemapGeneratedModule,\n  TreemapModule,\n  createArchitectureServices,\n  createGitGraphServices,\n  createInfoServices,\n  createPacketServices,\n  createPieServices,\n  createRadarServices,\n  createTreemapServices,\n  isArchitecture,\n  isBranch,\n  isCommit,\n  isGitGraph,\n  isInfo,\n  isMerge,\n  isPacket,\n  isPacketBlock,\n  isPie,\n  isPieSection,\n  isTreemap,\n  parse\n};\n","import isSymbol from './isSymbol.js';\n\n/**\n * The base implementation of methods like `_.max` and `_.min` which accepts a\n * `comparator` to determine the extremum value.\n *\n * @private\n * @param {Array} array The array to iterate over.\n * @param {Function} iteratee The iteratee invoked per iteration.\n * @param {Function} comparator The comparator used to compare values.\n * @returns {*} Returns the extremum value.\n */\nfunction baseExtremum(array, iteratee, comparator) {\n  var index = -1,\n      length = array.length;\n\n  while (++index < length) {\n    var value = array[index],\n        current = iteratee(value);\n\n    if (current != null && (computed === undefined\n          ? (current === current && !isSymbol(current))\n          : comparator(current, computed)\n        )) {\n      var computed = current,\n          result = value;\n    }\n  }\n  return result;\n}\n\nexport default baseExtremum;\n","import {\n  AbstractMermaidTokenBuilder,\n  AbstractMermaidValueConverter,\n  ArchitectureGeneratedModule,\n  MermaidGeneratedSharedModule,\n  __name\n} from \"./chunk-4KMFLZZN.mjs\";\n\n// src/language/architecture/module.ts\nimport {\n  EmptyFileSystem,\n  createDefaultCoreModule,\n  createDefaultSharedCoreModule,\n  inject\n} from \"langium\";\n\n// src/language/architecture/tokenBuilder.ts\nvar ArchitectureTokenBuilder = class extends AbstractMermaidTokenBuilder {\n  static {\n    __name(this, \"ArchitectureTokenBuilder\");\n  }\n  constructor() {\n    super([\"architecture\"]);\n  }\n};\n\n// src/language/architecture/valueConverter.ts\nvar ArchitectureValueConverter = class extends AbstractMermaidValueConverter {\n  static {\n    __name(this, \"ArchitectureValueConverter\");\n  }\n  runCustomConverter(rule, input, _cstNode) {\n    if (rule.name === \"ARCH_ICON\") {\n      return input.replace(/[()]/g, \"\").trim();\n    } else if (rule.name === \"ARCH_TEXT_ICON\") {\n      return input.replace(/[\"()]/g, \"\");\n    } else if (rule.name === \"ARCH_TITLE\") {\n      return input.replace(/[[\\]]/g, \"\").trim();\n    }\n    return void 0;\n  }\n};\n\n// src/language/architecture/module.ts\nvar ArchitectureModule = {\n  parser: {\n    TokenBuilder: /* @__PURE__ */ __name(() => new ArchitectureTokenBuilder(), \"TokenBuilder\"),\n    ValueConverter: /* @__PURE__ */ __name(() => new ArchitectureValueConverter(), \"ValueConverter\")\n  }\n};\nfunction createArchitectureServices(context = EmptyFileSystem) {\n  const shared = inject(\n    createDefaultSharedCoreModule(context),\n    MermaidGeneratedSharedModule\n  );\n  const Architecture = inject(\n    createDefaultCoreModule({ shared }),\n    ArchitectureGeneratedModule,\n    ArchitectureModule\n  );\n  shared.ServiceRegistry.register(Architecture);\n  return { shared, Architecture };\n}\n__name(createArchitectureServices, \"createArchitectureServices\");\n\nexport {\n  ArchitectureModule,\n  createArchitectureServices\n};\n","/******************************************************************************\r\n * Copyright 2021 TypeFox GmbH\r\n * This program and the accompanying materials are made available under the\r\n * terms of the MIT License, which is available in the project root.\r\n ******************************************************************************/\r\n\r\nimport type { AbstractElement, AbstractRule } from '../languages/generated/ast.js';\r\nimport type { CstNode } from '../syntax-tree.js';\r\nimport { isCrossReference, isRuleCall } from '../languages/generated/ast.js';\r\nimport { getCrossReferenceTerminal, getRuleType } from '../utils/grammar-utils.js';\r\n\r\n/**\r\n * Language-specific service for converting string values from the source text format into a value to be held in the AST.\r\n */\r\nexport interface ValueConverter {\r\n    /**\r\n     * Converts a string value from the source text format into a value to be held in the AST.\r\n     */\r\n    convert(input: string, cstNode: CstNode): ValueType;\r\n}\r\n\r\nexport type ValueType = string | number | boolean | bigint | Date;\r\n\r\nexport class DefaultValueConverter implements ValueConverter {\r\n\r\n    convert(input: string, cstNode: CstNode): ValueType {\r\n        let feature: AbstractElement | undefined = cstNode.grammarSource;\r\n        if (isCrossReference(feature)) {\r\n            feature = getCrossReferenceTerminal(feature);\r\n        }\r\n        if (isRuleCall(feature)) {\r\n            const rule = feature.rule.ref;\r\n            if (!rule) {\r\n                throw new Error('This cst node was not parsed by a rule.');\r\n            }\r\n            return this.runConverter(rule, input, cstNode);\r\n        }\r\n        return input;\r\n    }\r\n\r\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\r\n    protected runConverter(rule: AbstractRule, input: string, cstNode: CstNode): ValueType {\r\n        switch (rule.name.toUpperCase()) {\r\n            case 'INT': return ValueConverter.convertInt(input);\r\n            case 'STRING': return ValueConverter.convertString(input);\r\n            case 'ID': return ValueConverter.convertID(input);\r\n        }\r\n        switch (getRuleType(rule)?.toLowerCase()) {\r\n            case 'number': return ValueConverter.convertNumber(input);\r\n            case 'boolean': return ValueConverter.convertBoolean(input);\r\n            case 'bigint': return ValueConverter.convertBigint(input);\r\n            case 'date': return ValueConverter.convertDate(input);\r\n            default: return input;\r\n        }\r\n    }\r\n}\r\n\r\nexport namespace ValueConverter {\r\n\r\n    export function convertString(input: string): string {\r\n        let result = '';\r\n        for (let i = 1; i < input.length - 1; i++) {\r\n            const c = input.charAt(i);\r\n            if (c === '\\\\') {\r\n                const c1 = input.charAt(++i);\r\n                result += convertEscapeCharacter(c1);\r\n            } else {\r\n                result += c;\r\n            }\r\n        }\r\n        return result;\r\n    }\r\n\r\n    function convertEscapeCharacter(char: string): string {\r\n        switch (char) {\r\n            case 'b': return '\\b';\r\n            case 'f': return '\\f';\r\n            case 'n': return '\\n';\r\n            case 'r': return '\\r';\r\n            case 't': return '\\t';\r\n            case 'v': return '\\v';\r\n            case '0': return '\\0';\r\n            default: return char;\r\n        }\r\n    }\r\n\r\n    export function convertID(input: string): string {\r\n        if (input.charAt(0) === '^') {\r\n            return input.substring(1);\r\n        } else {\r\n            return input;\r\n        }\r\n    }\r\n\r\n    export function convertInt(input: string): number {\r\n        return parseInt(input);\r\n    }\r\n\r\n    export function convertBigint(input: string): bigint {\r\n        return BigInt(input);\r\n    }\r\n\r\n    export function convertDate(input: string): Date {\r\n        return new Date(input);\r\n    }\r\n\r\n    export function convertNumber(input: string): number {\r\n        return Number(input);\r\n    }\r\n\r\n    export function convertBoolean(input: string): boolean {\r\n        return input.toLowerCase() === 'true';\r\n    }\r\n\r\n}\r\n"],"names":["TreemapTokenBuilder","_Class","AbstractMermaidTokenBuilder","constructor","super","__name","classDefRegex","TreemapValueConverter","_Class2","AbstractMermaidValueConverter","runCustomConverter","rule","input","_cstNode","name","parseFloat","replace","substring","length","match","exec","$type","className","styleText","registerValidationChecks","services","validator","validation","TreemapValidator","registry","ValidationRegistry","checks","Treemap","checkSingleRoot","bind","register","_Class3","doc","accept","rootNodeIndentation","row","TreemapRows","item","indent","parseInt","node","property","TreemapModule","parser","TokenBuilder","ValueConverter","createTreemapServices","context","arguments","undefined","EmptyFileSystem","shared","inject","createDefaultSharedCoreModule","MermaidGeneratedSharedModule","createDefaultCoreModule","TreemapGeneratedModule","ServiceRegistry","value","isArray","isObjectLike","baseGetTag","Object","defineProperty","exports","Emitter","Event","ral_1","require","_disposable","dispose","None","CallbackList","add","callback","bucket","this","_callbacks","_contexts","push","Array","remove","foundCallbackWithDifferentContext","i","len","splice","Error","invoke","ret","callbacks","slice","contexts","_len","args","_key","apply","e","default","console","error","isEmpty","_options","event","_event","listener","thisArgs","disposables","onFirstListenerAdd","result","_noop","onLastListenerRemove","fire","call","array","baseExtremum","identity","baseLt","t","TypeError","JSON","stringify","r","n","o","s","h","charCodeAt","a","lastIndexOf","resolve","process","cwd","normalize","isAbsolute","join","relative","c","f","u","l","g","_makeLong","dirname","basename","extname","format","dir","root","base","ext","parse","sep","delimiter","win32","posix","d","enumerable","get","prototype","hasOwnProperty","Symbol","toStringTag","platform","navigator","userAgent","indexOf","scheme","concat","authority","path","query","fragment","test","isUri","fsPath","with","toString","_defineProperty","m","C","file","from","y","toJSON","revive","_formatted","external","_fsPath","_sep","$mid","encodeURIComponent","charAt","substr","p","toLowerCase","String","fromCharCode","v","decodeURIComponent","_unused","b","w","A","x","P","joinPath","resolvePath","_len2","_key2","collection","iteratee","index","isArrayLike","baseEach","key","object","hasPath","baseHas","_ral","RAL","install","ral","objectProto","baseRest","sources","guard","isIterateeCall","source","props","keysIn","propsIndex","propsLength","eq","baseFlatten","RadarTokenBuilder","RadarModule","CommonValueConverter","createRadarServices","Radar","RadarGeneratedModule","customizer","isObject","castPath","lastIndex","nested","toKey","newValue","objValue","isIndex","assignValue","paths","predicate","baseGet","baseSet","ErrorWithLocation","message","range","start","line","character","assertUnreachable","_","buildATNKey","type","occurrence","AbstractTransition","target","isEpsilon","AtomTransition","tokenType","EpsilonTransition","RuleTransition","ruleStart","followState","createATN","rules","atn","decisionMap","decisionStates","ruleToStartState","Map","ruleToStopState","states","ruleLength","newState","stop","set","createRuleStartAndStopATNStates","ruleBlock","block","buildRuleHandle","atom","production","Terminal","tokenRef","terminalType","NonTerminal","currentRule","nonTerminal","referencedRule","left","right","addTransition","ruleRef","Alternation","alternation","defineDecisionState","alts","map","definition","handle","makeAlts","Option","option","optional","end","epsilon","idx","Repetition","repetition","starState","star","RepetitionWithSeparator","separator","repetitionSep","RepetitionMandatory","plusState","plus","repetitionMandatory","RepetitionMandatoryWithSeparator","repetitionMandatorySep","handles","filter","altsLength","transition","transitions","isRuleTransition","ruleTransition","next","removeState","first","last","makeBlock","blkStart","blkEnd","loop","loopback","entry","loopEnd","state","decision","alt","getProdType","partial","assign","epsilonOnlyTransitions","nextTokenWithinRule","stateNumber","DFA_ERROR","ATNConfigSet","configs","size","finalize","config","getATNConfigKey","elements","k","stack","baseUniq","baseIteratee","createDFACache","startState","predicateSet","existing","atnStartState","PredicateSet","predicates","is","EMPTY_PREDICATES","LLStarLookaheadStrategy","LLkLookaheadStrategy","options","logging","_a","log","initialize","dfas","decisionLength","decisionToDFA","initATNSimulator","validateAmbiguousAlternationAlternatives","validateEmptyOrAlternatives","buildLookaheadForAlternation","prodOccurrence","hasPredicates","dynamicTokensEnabled","decisionIndex","partialAlts","getLookaheadPaths","maxLookahead","prodType","currAlt","isLL1Sequence","choiceToAlt","reduce","forEach","currTokType","tokenTypeIdx","categoryMatches","currExtendingType","orAlts","nextToken","LA","prediction","gate","GATE","adaptivePredict","buildLookaheadForOptional","singleTokensTypes","flatten","expectedTokenUniqueKey","sequences","allowEmpty","fullSet","Set","altSet","tokType","indices","has","dfaCaches","dfa","addDFAState","newDFAState","computeStartState","performLookahead","s0","previousD","getExistingTargetState","computeLookaheadTarget","buildAdaptivePredictError","isAcceptState","token","lookahead","reach","intermediate","skippedStopStates","transitionLength","getReachableTarget","closure","hasConfigInRuleStopState","computeReachSet","addDFAEdge","predictedAlt","getUniqueAlt","uniqueAlt","allConfigsInRuleStopStates","altSets","configToAlts","getConflictingAltSets","values","keys","hasConflictingAltSet","hasStateAssociatedWithOneAlt","hasConflictTerminatingPrediction","min","reportLookaheadAmbiguity","ambiguityIndices","prefixPath","atnState","pathMsg","currtok","tokenLabel","currMessage","prod","getProductionDslName","topLevelRule","buildAmbiguityError","previous","current","nextTransitions","flatMap","actualToken","possibleTokenTypes","uniqBy","tokenPath","edges","tokenMatcher","to","mapKey","numberOfTransitions","atnStack","pop","getEpsilonTarget","DocumentUri","URI","integer","uinteger","Position","Range","Location","LocationLink","Color","ColorInformation","ColorPresentation","FoldingRangeKind","FoldingRange","DiagnosticRelatedInformation","DiagnosticSeverity","DiagnosticTag","CodeDescription","Diagnostic","Command","TextEdit","ChangeAnnotation","ChangeAnnotationIdentifier","AnnotatedTextEdit","TextDocumentEdit","CreateFile","RenameFile","DeleteFile","WorkspaceEdit","TextDocumentIdentifier","VersionedTextDocumentIdentifier","OptionalVersionedTextDocumentIdentifier","TextDocumentItem","MarkupKind","MarkupContent","CompletionItemKind","InsertTextFormat","CompletionItemTag","InsertReplaceEdit","InsertTextMode","CompletionItemLabelDetails","CompletionItem","CompletionList","MarkedString","Hover","ParameterInformation","SignatureInformation","DocumentHighlightKind","DocumentHighlight","SymbolKind","SymbolTag","SymbolInformation","WorkspaceSymbol","DocumentSymbol","CodeActionKind","CodeActionTriggerKind","CodeActionContext","CodeAction","CodeLens","FormattingOptions","DocumentLink","SelectionRange","SemanticTokenTypes","SemanticTokenModifiers","SemanticTokens","InlineValueText","InlineValueVariableLookup","InlineValueEvaluatableExpression","InlineValueContext","InlayHintKind","InlayHintLabelPart","InlayHint","StringValue","InlineCompletionItem","InlineCompletionList","InlineCompletionTriggerKind","SelectedCompletionInfo","InlineCompletionContext","WorkspaceFolder","MIN_VALUE","MAX_VALUE","create","Number","candidate","Is","objectLiteral","one","two","three","four","uri","string","targetUri","targetRange","targetSelectionRange","originSelectionRange","red","green","blue","alpha","numberRange","color","label","textEdit","additionalTextEdits","typedArray","Comment","Imports","Region","startLine","endLine","startCharacter","endCharacter","kind","collapsedText","defined","location","Warning","Information","Hint","Unnecessary","Deprecated","href","severity","code","relatedInformation","number","codeDescription","title","command","newText","insert","position","del","needsConfirmation","description","boolean","annotation","annotationId","textDocument","edits","overwrite","ignoreIfExists","oldUri","newUri","recursive","ignoreIfNotExists","changes","documentChanges","every","change","version","languageId","text","PlainText","Markdown","Text","Method","Function","Constructor","Field","Variable","Class","Interface","Module","Property","Unit","Value","Enum","Keyword","Snippet","File","Reference","Folder","EnumMember","Constant","Struct","Operator","TypeParameter","asIs","adjustIndentation","detail","items","isIncomplete","fromPlainText","plainText","language","contents","documentation","parameters","Read","Write","Namespace","Package","Boolean","Key","Null","containerName","selectionRange","children","deprecated","tags","Empty","QuickFix","Refactor","RefactorExtract","RefactorInline","RefactorRewrite","Source","SourceOrganizeImports","SourceFixAll","Invoked","Automatic","diagnostics","only","triggerKind","kindOrCommandOrEdit","checkKind","edit","isPreferred","data","tabSize","insertSpaces","parent","resultId","variableName","caseSensitiveLookup","expression","frameId","stoppedLocation","Type","Parameter","tooltip","textEdits","paddingLeft","paddingRight","createSnippet","insertText","filterText","selectedCompletionInfo","TextDocument","mergeSort","compare","leftIdx","rightIdx","content","FullTextDocument","lineCount","func","getText","positionAt","offsetAt","applyEdits","document","sortedEdits","diff","lastModifiedOffset","startOffset","endOffset","_uri","_languageId","_version","_content","_lineOffsets","update","getLineOffsets","lineOffsets","isLineStart","ch","offset","Math","max","low","high","mid","floor","lineOffset","nextLineOffset","check","CstNodeBuilder","nodeStack","rootNode","buildRootNode","RootCstNodeImpl","buildCompositeNode","feature","compositeNode","CompositeCstNodeImpl","grammarSource","buildLeafNode","leafNode","LeafCstNodeImpl","image","tokenToRange","removeNode","container","addHiddenNodes","tokens","nodes","added","unshift","construct","astNode","$cstNode","AbstractCstNode","hidden","_astNode","_b","element","fullText","_offset","_length","_hidden","_tokenType","_range","CstNodeContainer","firstNonHiddenNode","lastNonHiddenNode","firstNode","lastNode","_rangeCache","firstRange","lastRange","child","setPrototypeOf","addParents","count","_len3","_key3","_text","DatatypeSymbol","isDataTypeNode","withRuleSuffix","endsWith","AbstractLangiumParser","_unorderedGroups","allRules","lexer","Lexer","LanguageMetaData","mode","wrapper","ChevrotainWrapper","ParserConfig","skipValidations","errorMessageProvider","ParserErrorMessageProvider","alternatives","choices","wrapOr","wrapOption","many","wrapMany","atLeastOne","wrapAtLeastOne","getRule","isRecording","IS_RECORDING","unorderedGroups","getRuleStack","RULE_STACK","wrapSelfAnalysis","LangiumParser","nodeBuilder","assignmentMap","linker","references","Linker","converter","astReflection","AstReflection","impl","computeRuleType","ruleMethod","DEFINE_RULE","startImplementation","mainRule","isDataTypeRule","explicit","getExplicitRuleType","lexerResult","tokenize","clear","lexerErrors","errors","lexerReport","report","parserErrors","implementation","createNode","err","extractHiddenTokens","hiddenTokens","consume","wrapConsume","isValidToken","assignment","isCrossRef","getAssignment","convertedValue","isKeyword","convert","operator","isInsertedInRecovery","isNaN","subrule","cstNode","subruleResult","wrapSubrule","performSubruleAssignment","newItem","assignWithoutOverride","action","obj","linkContentToContainer","assignMandatoryProperties","getContainerOfType","isAssignment","isCrossReference","terminal","buildReference","existingValue","entries","targetCstNode","definitionErrors","AbstractParserErrorMessageProvider","buildMismatchTokenMessage","defaultParserErrorProvider","buildNotAllInputParsedMessage","buildNoViableAltMessage","buildEarlyExitMessage","LangiumParserErrorMessageProvider","_ref","expected","actual","expectedMsg","LABEL","_ref2","firstRedundant","LangiumCompletionParser","elementStack","lastElementStack","nextTokenIndex","stackSize","resetState","tokenIndex","keepStackSize","resetStackSize","removeUnexpectedElements","currIdx","before","after","defaultConfig","recoveryEnabled","nodeLocationTracking","EmbeddedActionsParser","useDefaultLookahead","lookaheadStrategy","RECORDING_PHASE","RULE","performSelfAnalysis","ARGS","or","createParser","grammar","parserContext","reachable","getAllReachableRules","parserRules","stream","isParserRule","ctx","buildElement","buildRules","ruleNames","method","ignoreGuard","keyword","buildKeyword","isAction","actionType","getTypeName","buildAction","buildCrossReference","isRuleCall","ruleCall","ref","namedArgs","buildPredicate","ruleArgs","ruleTarget","buildRuleCallPredicate","isTerminalRule","getToken","$refText","buildRuleCall","isAlternatives","methods","predicatedMethod","ALT","getGuardCondition","buildAlternatives","isUnorderedGroup","group","orIdx","idFunc","groupIdx","lParser","stackId","groupState","trackedAlternatives","wrapped","wrap","delete","buildUnorderedGroup","isGroup","buildGroup","isEndOfFile","EOF","cardinality","condition","isDisjunction","isConjunction","isNegation","isParameterReference","parameter","isBooleanLiteral","true","guardCondition","crossRef","terminalRule","findNameAssignment","assignTerminal","EMPTY_ALT","DEF","$container","ruleName","getRuleName","createLangiumParser","Grammar","prepareLangiumParser","lastTick","globalInterruptionPeriod","OperationCancelled","isOperationCancelled","async","interruptAndCheck","CancellationToken","performance","now","Promise","setImmediate","setTimeout","isCancellationRequested","Deferred","promise","reject","arg","isIncremental","getWellformedRange","addedLineOffsets","computeLineOffsets","isFull","ensureBeforeEOL","isEOL","rangeLength","isAtLineStart","textOffset","char","getWellformedEdit","spans","DocumentState","DefaultLangiumDocumentFactory","serviceRegistry","textDocuments","workspace","TextDocuments","fileSystemProvider","FileSystemProvider","fromUri","cancellationToken","readFile","createAsync","fromTextDocument","fromString","fromModel","model","$model","parseResult","createLangiumDocument","cancelToken","parseAsync","Parsed","textDocumentGetter","createTextDocumentGetter","$document","oldText","getServices","AsyncParser","textDoc","DefaultLangiumDocuments","documentMap","langiumDocumentFactory","LangiumDocumentFactory","all","addDocument","uriString","getDocument","getOrCreateDocument","createDocument","then","hasDocument","invalidateDocument","langiumDoc","unlink","Changed","precomputedScopes","deleteDocument","ref_resolving","DefaultLinker","reflection","langiumDocuments","LangiumDocuments","scopeProvider","ScopeProvider","astNodeLocator","AstNodeLocator","link","streamAst","streamReferences","doLink","refInfo","reference","getCandidate","isLinkingError","_nodeDescription","documentUri","linkedNode","loadAstNode","createLinkingError","errorMessage","getScope","getElement","refNode","refText","$refNode","isAstNode","isAstNodeDescription","findRootNode","refData","getLinkedNode","ComputedScopes","descr","getAstNodePath","$nodeDescription","nodeDescription","getAstNode","targetDescription","warn","referenceType","getReferenceType","DefaultNameProvider","getName","isNamed","getNameNode","findNodeForProperty","UriUtils","Utils","equals","fromPath","toPath","fromParts","split","toParts","repeat","DefaultReferences","nameProvider","NameProvider","IndexManager","nodeLocator","findDeclaration","sourceCstNode","findAssignment","nodeElem","isReference","nameNode","isChildNode","findDeclarationNode","targetNode","findReferences","refs","includeDeclaration","getReferenceToSelf","indexReferences","findAllReferences","sourceUri","sourcePath","targetPath","segment","toDocumentSegment","local","MultiMap","Reduction","sum","addAll","callbackfn","iterator","flat","entriesGroupedByKey","BiMap","inverse","getKey","DefaultScopeComputation","descriptions","AstNodeDescriptionProvider","computeExports","computeExportsForNode","parentNode","streamContents","exportNode","createDescription","computeLocalScopes","scopes","streamAllContents","processNode","StreamScope","outerScope","caseInsensitive","getAllElements","find","MapScope","localName","elementStream","DisposableCache","toDispose","isDisposed","onDispose","disposable","throwIfDisposed","SimpleCache","cache","provider","ContextCache","contextKey","cacheForContext","contextCache","documentCache","WorkspaceCache","sharedServices","DocumentBuilder","onBuildPhase","onUpdate","_changed","deleted","DefaultScopeProvider","indexManager","globalScopeCache","precomputed","currentNode","allDescriptions","desc","isSubtype","getGlobalScope","createScope","createScopeForNodes","nonNullable","_context","allElements","isIntermediateReference","DefaultJsonSerializer","ignoreProperties","commentProvider","CommentProvider","serialize","serializeOptions","specificReplacer","replacer","defaultReplacer","currentDocument","space","deserialize","deserializeOptions","linkNode","sourceText","textRegions","comments","uriConverter","refValue","targetDocument","$ref","$error","addAstNodeRegionWithAssignmentsTo","$textRegion","documentURI","_c","$sourceText","_d","comment","getComment","$comment","createDocumentSegment","assignments","startsWith","propertyAssignments","findNodesForProperty","containerProperty","containerIndex","propertyName","reviveReference","mutable","$containerProperty","$containerIndex","getRefNode","fragmentIndex","DefaultServiceRegistry","fileExtensionMap","languageIdMap","fileExtensions","singleton","hasServices","diagnosticData","ValidationCategory","DocumentValidator","entriesBefore","entriesAfter","checksRecord","thisObj","category","wrapValidationException","addEntry","handleException","functionality","messageContext","messageDetails","subtype","getAllSubTypes","getChecks","categories","includes","registerBeforeDocument","checkBefore","wrapPreparationException","registerAfterDocument","checkAfter","checksBefore","checksAfter","DefaultDocumentValidator","validationRegistry","metadata","validateDocument","processLexingErrors","stopAfterLexingErrors","some","LexingError","processParsingErrors","stopAfterParsingErrors","ParsingError","processLinkingErrors","stopAfterLinkingErrors","LinkingError","validateAst","lexerDiagnostics","lexerDiagnostic","diagnostic","toDiagnosticSeverity","column","toDiagnosticData","getSource","parserError","previousToken","endColumn","linkingError","info","containerType","toDiagnostic","validationItems","acceptor","validateAstBefore","validateAstNodes","validateAstAfter","getDiagnosticRange","findNodeForKeyword","LexingWarning","LexingInfo","LexingHint","DefaultAstNodeDescriptionProvider","nameNodeSegment","nameSegmentGetter","nameSegment","selectionSegment","DefaultReferenceDescriptionProvider","createDescriptions","targetNodeDescr","refCstNode","docUri","DefaultAstNodeLocator","segmentSeparator","indexSeparator","containerPath","newSegment","getPathSegment","previousValue","currentValue","propertyIndex","arrayIndex","Disposable","DefaultConfigurationProvider","_ready","settings","workspaceConfig","onConfigurationSectionUpdateEmitter","ready","params","capabilities","configuration","initialized","languages","section","lang","toSectionName","fetchConfiguration","configToUpdate","conf","updateSectionConfiguration","updateConfiguration","getConfiguration","sectionName","onConfigurationSectionUpdate","DefaultDocumentBuilder","updateBuildOptions","updateListeners","buildPhaseListeners","documentPhaseListeners","buildState","documentBuildWaiters","currentState","build","documents","Validated","IndexedReferences","previousCategories","validationChecks","completed","emitUpdate","buildDocuments","changed","deletedUri","changedUri","newDocument","allChangedUris","toSet","shouldRelink","rebuildDocuments","sortDocuments","Linked","toArray","hasTextDocument","changedUris","isAffected","prepareBuild","runCancelable","IndexedContent","updateContent","scopeComputation","ScopeComputation","updateReferences","toBeValidated","shouldValidate","validate","targetState","filtered","notifyDocumentPhase","targetStateDocs","notifyBuildPhase","onDocumentPhase","waitUntil","uriOrToken","buildDisposable","cancelDisposable","onCancellationRequested","listenersCopy","getBuildOptions","validationSetting","newCategories","DefaultIndexManager","symbolIndex","symbolByTypeIndex","referenceIndex","astNodePath","targetDocUri","docRefs","refDescr","nodeType","uris","documentUris","getFileDescriptions","indexData","ReferenceDescriptionProvider","DefaultWorkspaceManager","initialBuildOptions","documentBuilder","mutex","WorkspaceLock","workspaceFolders","folders","_params","write","initializeWorkspace","performStartup","collector","loadAdditionalDocuments","wf","getRootFolder","traverseFolder","_folders","_collector","workspaceFolder","folderPath","readDirectory","includeEntry","isDirectory","isFile","_workspaceFolder","DefaultLexerErrorMessageProvider","buildUnexpectedCharactersMessage","defaultLexerErrorProvider","buildUnableToPopLexerModeMessage","DefaultLexer","LexerErrorMessageProvider","tokenBuilder","buildTokens","tokenTypes","toTokenTypeDictionary","lexerTokens","isTokenTypeDictionary","chevrotainLexer","ChevrotainLexer","positionTracking","chevrotainResult","groups","flushLexingReport","isIMultiModeLexerDefinition","modes","res","tokenVocabulary","isTokenTypeArray","parseJSDoc","opts","currentLine","currentCharacter","lines","lastCharacter","skipWhitespace","tagRegex","tagMatch","fullMatch","rest","inlineTagMatches","matchAll","inlineTagRegex","buildInlineTokens","getLines","normalizeOptions","startPosition","JSDocCommentImpl","parseJSDocElement","parseJSDocComment","NEWLINE_REGEXP","lineIndex","characterIndex","matchIndex","startContent","tagName","endContent","nonWhitespaceRegex","whitespaceEndRegex","parseJSDocTag","parseJSDocText","JSDocLineImpl","inlines","appendEmptyLine","firstToken","lastToken","parseJSDocInline","JSDocTextImpl","parseJSDocLine","inline","tagToken","docLine","JSDocTagImpl","normalizeOption","escaped","escapeRegExp","RegExp","getTag","getAllTags","getTags","fillNewlines","trim","toMarkdown","renderTag","toMarkdownDefault","rendered","tag","display","displayStart","renderedLink","renderLink","renderLinkDefault","renderInlineTag","marker","JSDocDocumentationProvider","getDocumentation","normalizedOptions","firstRegex","lastRegex","isJSDoc","documentationLinkRenderer","documentationTagRenderer","findNameInPrecomputedScopes","findNameInGlobalScope","_node","_tag","DefaultCommentProvider","grammarConfig","GrammarConfig","isAstNodeWithComment","findCommentNode","multilineCommentRules","DefaultAsyncParser","syncParser","_cancelToken","DefaultWorkspaceLock","previousTokenSource","CancellationTokenSource","writeQueue","readQueue","done","cancelWrite","tokenSource","enqueue","read","queue","deferred","performNextOperation","shift","cancel","DefaultHydrator","grammarElementIdMap","tokenTypeIdMap","dehydrate","dehydrateLexerReport","dehydrateAstNode","createDehyrationContext","astNodes","cstNodes","streamCst","dehydrateCstNode","arr","dehydrateReference","isRootCstNode","getGrammarElementId","isCompositeCstNode","isLeafCstNode","startColumn","hydrate","createHydrationContext","hydrateCstNode","hydrateAstNode","cst","hydrateCstLeafNode","setParent","hydrateReference","num","cstNodeObj","getGrammarElement","hydrated","getTokenType","createGrammarElementIdMap","id","isAbstractElement","DocumentationProvider","isCommentTerminal","isMultilineComment","terminalRegex","nameRegexp","DefaultNameRegexp","createGrammarConfig","CompletionParser","createCompletionParser","DefaultValueConverter","DefaultTokenBuilder","References","serializer","Hydrator","JsonSerializer","WorkspaceManager","ConfigurationProvider","regexpParser","RegExpParser","TerminalRegExpVisitor","BaseRegExpVisitor","isStarting","endRegexpStack","multiline","endRegex","reset","regex","startRegexp","visitGroup","quantifier","visitCharacter","escapedChar","visitSet","loc","begin","visitChildren","visitor","regexp","visit","pattern","whitespaceCharacters","isWhitespace","ws","getCaseInsensitivePattern","letter","toUpperCase","partialMatches","re","tmp","appendRaw","nbChars","appendOptional","unicode","flags","partialRegExp","baseClone","reWhitespace","reTrimStart","trimmedEndIndex","reIsBadHex","reIsBinary","reIsOctal","freeParseInt","isSymbol","other","valueOf","baseTrim","isBinary","INFINITY","toNumber","AbstractRule","AbstractType","Condition","TypeDefinition","ValueLiteral","AbstractElement","isInstance","ArrayLiteral","ArrayType","BooleanLiteral","Conjunction","Disjunction","GrammarImport","InferredType","isInferredType","isInterface","NamedArgument","Negation","NumberLiteral","ParameterReference","ParserRule","ReferenceType","ReturnType","isReturnType","SimpleType","isSimpleType","StringLiteral","TerminalRule","isType","TypeAttribute","UnionType","Action","Alternatives","Assignment","CharacterRange","isCharacterRange","CrossReference","EndOfFile","Group","NegatedToken","isNegatedToken","RegexToken","isRegexToken","RuleCall","TerminalAlternatives","isTerminalAlternatives","TerminalGroup","isTerminalGroup","TerminalRuleCall","isTerminalRuleCall","UnorderedGroup","UntilToken","isUntilToken","Wildcard","isWildcard","LangiumGrammarAstReflection","AbstractAstReflection","getAllTypes","computeIsSubtype","supertype","referenceId","getTypeMetaData","properties","defaultValue","module1","module2","module3","module4","module5","module6","module7","module8","module9","_inject","_merge","merge","m1","m2","isProxy","module","injector","proxy","Proxy","deleteProperty","prop","_resolve","getOwnPropertyDescriptor","ownKeys","getOwnPropertyNames","__requested__","cause","value2","value1","subtypes","allSubtypes","allTypes","types","possibleSubType","InfoTokenBuilder","InfoModule","createInfoServices","Info","InfoGeneratedModule","typePredicate","StreamImpl","keyIndex","isAstNodeInRange","DONE_RESULT","TreeStreamImpl","includeRoot","nodeRange","inRange","typeMetaData","genericNode","copyDefaultValue","propertyType","toFastProperties","toBecomeFast","FakeConstructor","fakeInstance","fakeAccess","bar","toInteger","baseSlice","createAssigner","isPrototype","copyObject","arrayMap","getAllKeysIn","basePickBy","nodeIsRegExp","nodeUtil","isRegExp","baseUnary","baseIsRegExp","isString","AbstractProduction","_definition","pickBy","Rule","orgText","Alternative","ignoreAmbiguities","serializeProduction","convertDefinition","serializedNonTerminal","nonTerminalName","serializedTerminal","terminalLabel","PATTERN","GAstVisitor","nodeAny","visitNonTerminal","visitAlternative","visitOption","visitRepetitionMandatory","visitRepetitionMandatoryWithSeparator","visitRepetitionWithSeparator","visitRepetition","visitAlternation","visitTerminal","visitRule","arraySome","baseSome","nativeMax","fromIndex","baseIndexOf","arrayEvery","baseEvery","isOptionalProd","alreadyVisited","subProd","RestWalker","walk","prevRest","currRest","drop","walkProdRef","walkTerminal","walkFlat","walkOption","walkAtLeastOne","walkAtLeastOneSep","walkManySep","walkMany","walkOr","refProd","flatProd","fullOrRest","optionProd","atLeastOneProd","fullAtLeastOneRest","atLeastOneSepProd","fullAtLeastOneSepRest","restForRepetitionWithSeparator","manyProd","fullManyRest","manySepProd","fullManySepRest","orProd","prodWrapper","repSepProd","isSequenceProd","firstSet","seq","currSubProd","nextSubProdIdx","hasInnerProdsRemaining","isLastInnerProdOptional","uniq","firstForSequence","isBranchingProd","allAlternativesFirsts","innerProd","firstForBranching","IN","ResyncFollowsWalker","topProd","follows","startWalking","followName","inner","occurenceInParent","fullRest","t_in_topProd_follows","arrayFilter","baseFilter","negate","comparator","arrayIncludes","isCommon","valuesLength","arrayIncludesWith","cacheHas","SetCache","outer","computed","valuesIndex","isArrayLikeObject","baseDifference","resIndex","PRINT_ERROR","msg","PRINT_WARNING","regExpAstCache","regExpParser","getRegExpAst","regExp","regExpStr","regExpAst","complementErrorMessage","failedOptimizationPrefixMsg","getOptimizedStartCodesIndices","ensureOptimizations","ast","firstCharOptimizedIndices","ignoreCase","msgSuffix","terms","term","addOptimizedIdxToResult","complement","rangeCode","minOptimizationVal","minUnOptVal","maxUnOptVal","minOptIdx","charCodeToOptimizedIndex","maxOptIdx","currOptIdx","isOptionalQuantifier","atLeast","isWholeOptional","optimizedCharIdx","upperChar","lowerChar","handleIgnoreCase","findCode","setNode","targetCharCodes","codeOrRange","targetCode","CharCodeFinder","found","visitLookahead","visitNegativeLookahead","canMatchCharCode","charCodes","charCodeFinder","DEFAULT_MODE","MODES","SUPPORT_STICKY","sticky","analyzeTokenTypes","tracer","defaults","useSticky","debug","safeMode","lineTerminatorCharacters","onlyRelevantTypes","charCodeToOptimizedIdxMap","initCharCodeToOptimizedIndexMap","currType","NA","allTransformedPatterns","patternIdxToType","patternIdxToGroup","patternIdxToLongerAltIdxArr","patternIdxToPushMode","patternIdxToPopMode","patternIdxToCanLineTerminator","patternIdxToIsCustom","patternIdxToShort","emptyGroups","patternIdxToConfig","hasCustom","currPattern","regExpSource","addStickyFlag","addStartOfInput","isFunction","escapedRegExpString","wrappedRegExp","clazz","groupName","GROUP","SKIPPED","isUndefined","longerAltType","LONGER_ALT","PUSH_MODE","lineTerminatorCharCodes","getCharCodes","LINE_BREAKS","checkLineBreaksIssues","isCustomPattern","isShortPattern","acc","longerAlt","canLineTerminator","isCustom","short","canBeOptimized","charCodeToPatternIdxToConfig","optimizedIdx","addToMapOfArrays","START_CHARS_HINT","lastOptimizedIdx","charOrInt","currOptimizedIdx","optimizedCodes","validatePatterns","validModesNames","missingResult","tokenTypesWithMissingPattern","LexerDefinitionErrorType","MISSING_PATTERN","valid","difference","findMissingPatterns","invalidResult","tokenTypesWithInvalidPattern","INVALID_PATTERN","findInvalidPatterns","validTokenTypes","withRegExpPatterns","EndAnchorFinder","visitEndAnchor","invalidRegex","regexpAst","endAnchorVisitor","end_of_input","EOI_ANCHOR_FOUND","findEndOfInputAnchor","StartAnchorFinder","visitStartAnchor","startAnchorVisitor","start_of_input","SOI_ANCHOR_FOUND","findStartOfInputAnchor","invalidFlags","global","UNSUPPORTED_FLAGS_FOUND","findUnsupportedFlags","identicalPatterns","outerType","innerType","compact","duplicatePatterns","currIdenticalSet","setOfIdentical","tokenTypeNames","dupPatternSrc","DUPLICATE_PATTERNS_FOUND","findDuplicatePatterns","matchesEmptyString","EMPTY_MATCH_PATTERN","findEmptyMatchRegExps","validateRegExpPattern","invalidTypes","INVALID_GROUP_TYPE_FOUND","findInvalidGroupType","validModes","invalidModes","PUSH_MODE_DOES_NOT_EXIST","findModesThatDoNotExist","canBeTested","str","metaChars","noMetaChar","testIdx","regExpArray","testTokenType","UNREACHABLE_PATTERN","findUnreachablePatterns","performWarningRuntimeChecks","lexerDefinition","trackLines","warnings","hasAnyLineBreak","allTokenTypes","concreteTokenTypes","terminatorCharCodes","currIssue","details","issue","IDENTIFY_TERMINATOR","errMsg","CUSTOM_LINE_BREAK","buildLineBreakIssueMessage","warningDescriptor","NO_LINE_BREAKS_FLAGS","LineTerminatorOptimizedTester","charsOrCodes","numOrString","charCode","timer","Date","getTime","val","time","tokenStructuredMatcher","tokInstance","tokConstructor","instanceType","isParent","categoryMatchesMap","tokenStructuredMatcherNoCategories","tokenShortNameIdx","tokenIdxToClass","augmentTokenTypes","tokenTypesAndParents","clone","searching","CATEGORIES","expandCategories","hasShortKeyProperty","hasCategoriesProperty","hasExtendingTokensTypesMapProperty","assignTokenDefaultProps","singleAssignCategoriesToksMap","assignCategoriesMapProp","assignCategoriesTokensProp","nextNode","pathNode","nextCategory","newPath","isTokenType","DEFAULT_LEXER_CONFIG","deferDefinitionErrorsHandling","lineTerminatorsPattern","traceInitPerf","freeze","lexerDefinitionErrors","lexerDefinitionWarning","trackStartLines","trackEndLines","canModeBeOptimized","TRACE_INIT","phaseDesc","phaseImpl","traceInitIndent","traceInitMaxIdent","traceMethod","traceInitVal","Infinity","actualDefinition","hasOnlySingleMode","defaultMode","MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE","MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY","MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST","currModeValue","currModeName","LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED","currLongerAlt","MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE","performRuntimeChecks","allModeNames","currModDef","currModName","currAnalyzeResult","allErrMessagesString","chopInput","matchWithTest","updateLastIndex","noop","matchWithExec","handleModes","computeNewColumn","updateTokenEndLineColumnLocation","createTokenInstance","createFullToken","createStartOnlyToken","createOffsetOnlyToken","addToken","addTokenUsingPush","handlePayload","handlePayloadWithCustom","addTokenUsingMemberAccess","handlePayloadNoCustom","unOptimizedModes","cannotBeOptimized","modeName","initialMode","tokenizeInternal","j","matchAltImage","matchedImage","payload","altPayload","imageLength","newToken","errLength","orgLength","matchedTokensIndex","guessedNumberOfTokens","matchedTokens","clonedResult","groupKeys","currKey","currGroupValue","cloneEmptyGroups","lineTerminatorPattern","currModePatternsLength","currCharCodeToPatternIdxToConfig","modeStack","emptyArray","getPossiblePatterns","getPossiblePatternsSlow","getPossiblePatternsOptimized","possiblePatterns","pop_mode","popToken","newMode","modeCanBeOptimized","push_mode","currConfig","nextCharCode","chosenPatternIdxToConfig","chosenPatternsLength","singleCharCode","longerAltLength","longerAltConfig","longerAltPattern","foundTerminator","lastLTEndOffset","numOfLTsInMatch","errorStartOffset","errorLine","errorColumn","foundResyncPoint","pushMode","newLastIndex","lastLTIdx","lastCharIsLT","fixForEndingInLT","oldColumn","tokenVector","tokenToAdd","hasTokenLabel","PARENT","POP_MODE","createToken","createTokenInternal","_ref3","expectedPathsPerAlt","customUserDescription","errPrefix","errSuffix","allLookAheadPaths","currAltPaths","nextValidTokenSequences","currPath","currTokenType","nextValidSequenceItems","itemMsg","_ref4","expectedIterationPaths","defaultGrammarResolverErrorProvider","buildRuleNotFoundError","undefinedRule","defaultGrammarValidatorErrorProvider","buildDuplicateFoundError","duplicateProds","topLevelName","duplicateProd","dslName","extraArgument","hasExplicitIndex","buildNamespaceConflictError","buildAlternationPrefixAmbiguityError","currTok","buildAlternationAmbiguityError","buildEmptyRepetitionError","buildTokenNameError","buildEmptyAlternationError","emptyChoiceIdx","buildTooManyAlternativesError","buildLeftRecursionError","pathNames","leftRecursionPath","currRule","leftRecursivePath","buildInvalidRuleNameError","buildDuplicateRuleNameError","grammarName","GastRefResolverVisitor","nameToTopRule","errMsgProvider","resolveRefs","currTopLevel","ParserDefinitionErrorType","UNRESOLVED_SUBRULE_REF","unresolvedRefName","setter","accumulator","initializer","arrayAggregator","baseAggregator","createAggregator","baseAssignValue","AbstractNextPossibleTokensWalker","possibleTokTypes","nextProductionName","nextProductionOccurrence","isAtEndOfPath","ruleStack","reverse","occurrenceStack","updateExpectedNext","NextAfterTokenWalker","nextTerminalName","nextTerminalOccurrence","lastTok","lastTokOccurrence","restProd","AbstractNextTerminalAfterProductionWalker","topRule","isEndOfRule","NextTerminalAfterManyWalker","firstAfterMany","_first","NextTerminalAfterManySepWalker","firstAfterManySep","NextTerminalAfterAtLeastOneWalker","firstAfterAtLeastOne","NextTerminalAfterAtLeastOneSepWalker","atleastOneSepProd","firstAfterfirstAfterAtLeastOneSep","possiblePathsFrom","targetDef","maxLength","getAlternativesForProd","newDef","partialPath","suffixDef","nextPossibleTokensAfter","initialDef","tokMatcher","maxLookAhead","EXIT_NON_TERMINAL","EXIT_NON_TERMINAL_ARR","EXIT_ALTERNATIVE","foundCompletePath","tokenVectorLength","minimalAlternativesIndex","possiblePaths","def","currDef","currRuleStack","currOccurrenceStack","nextPath","dropRight","nextIdx","nextTokenType","nextTokenOccurrence","newRuleStack","newOccurrenceStack","nextPathWithout","nextPathWith","secondIteration","separatorGast","nthRepetition","currAltPath","expandTopLevelRule","newCurrOccurrenceStack","PROD_TYPE","OPTION","REPETITION","REPETITION_MANDATORY","REPETITION_MANDATORY_WITH_SEPARATOR","REPETITION_WITH_SEPARATOR","ALTERNATION","getLookaheadPathsForOr","getLookaheadPathsForOptionalProd","buildAlternativesLookAheadFunc","numOfAlts","areAllOneTokenLookahead","currNumOfPaths","currPredicate","currPathLength","singleTokenAlts","buildSingleAlternativeLookaheadFunction","numOfPaths","RestDefinitionFinderWalker","targetOccurrence","targetProdType","restDef","checkIsTarget","expectedProdType","InsideDefinitionFinderVisitor","targetRef","expectedProdName","initializeArrayOfArrays","pathToHashKeys","longerKeys","currShorterKey","categoriesKeySuffix","isUniquePrefixHash","altKnownPathsKeys","searchPathKeys","currAltIdx","otherAltKnownPathsKeys","searchIdx","lookAheadSequenceFromAlternatives","altsDefs","finalResult","altsHashes","dict","newData","pathLength","currDataset","altIdx","currAltPathsAndSuffixes","currPathIdx","currPathPrefix","prefixKeys","currAltResult","containsPath","newPartialPathsAndSuffixes","ruleGrammar","insideDefVisitor","insideDef","afterDef","AlternativeGAST","alternative","searchPath","compareOtherPath","otherPath","searchTok","otherTok","areTokenCategoriesNotUsed","lookAheadPaths","singleAltPaths","singlePath","validateGrammar","topLevels","duplicateErrors","collectorVisitor","OccurrenceValidationCollector","allRuleProductions","allProductions","productionGroups","groupBy","identifyProductionForDuplicates","duplicates","currGroup","currDuplicates","firstProd","defError","DUPLICATE_PRODUCTIONS","param","getExtraProductionArgument","validateDuplicateProductions","termsNamespaceConflictErrors","tokenNames","currToken","currRuleName","CONFLICT_TOKENS_RULES_NAMESPACE","checkTerminalAndNoneTerminalsNameSpace","tooManyAltsErrors","curRule","orCollector","OrCollector","ors","alternations","currOr","TOO_MANY_ALTS","validateTooManyAlts","duplicateRulesError","occurrences","DUPLICATE_RULE_NAME","validateRuleDoesNotAlreadyExist","manySep","atLeastOneSep","validateNoLeftRecursion","nextNonTerminals","getFirstNoneTerminal","LEFT_RECURSION","validNextSteps","errorsFromNextSteps","currRefRule","currSubDef","isFirstOptional","hasMore","globalMaxLookahead","currOccurrence","actualMaxLookahead","altsAmbiguityErrors","foundAmbiguousPaths","identicalAmbiguities","altsCurrPathAppearsIn","currOtherAlt","currOtherAltIdx","currErrors","currAmbDescriptor","ambgIndices","AMBIGUOUS_ALTS","checkAlternativesAmbiguities","altsPrefixAmbiguityErrors","pathsAndIndices","currPathsAndIdx","currPathAndIdx","targetIdx","prefixAmbiguitiesPathsAndIndices","searchPathAndIdx","prefix","otherTokType","currAmbPathAndIdx","AMBIGUOUS_PREFIX_ALTS","checkPrefixAlternativesAmbiguities","RepetitionCollector","resolveGrammar","actualOptions","topRulesTable","refResolver","orgResolveGrammar","MISMATCHED_TOKEN_EXCEPTION","NO_VIABLE_ALT_EXCEPTION","EARLY_EXIT_EXCEPTION","NOT_ALL_INPUT_PARSED_EXCEPTION","RECOGNITION_EXCEPTION_NAMES","isRecognitionException","RecognitionException","resyncedTokens","captureStackTrace","MismatchedTokenException","NoViableAltException","NotAllInputParsedException","EarlyExitException","EOF_FOLLOW_KEY","IN_RULE_RECOVERY_EXCEPTION","InRuleRecoveryException","attemptInRepetitionRecovery","prodFunc","lookaheadFunc","dslMethodIdx","nextToksWalker","notStuck","getKeyForAutomaticLookahead","firstAfterRepInfo","firstAfterRepMap","getCurrRuleFullName","getGAstProductions","expectTokAfterLastMatch","nextTokIdx","shouldInRepetitionRecoveryBeTried","tryInRepetitionRecovery","AT_LEAST_ONE_IDX","MANY_SEP_IDX","AT_LEAST_ONE_SEP_IDX","ruleIdx","DEFAULT_PARSER_CONFIG","leftRecursionErrors","emptyAltErrors","ambiguousAltsErrors","emptyRepetitionErrors","validateSomeNonEmptyLookaheadPath","currTopRule","exceptLast","currAlternative","possibleFirstInAlt","NONE_LAST_EMPTY_ALT","validateEmptyOrAlternative","topLevelRules","currProd","pathsInsideProduction","NO_NON_EMPTY_LOOKAHEAD","laFuncBuilder","buildLookaheadFuncForOr","lookaheadBuilder","buildLookaheadFuncForOptionalProd","dslMethods","repetitionWithSeparator","repetitionMandatoryWithSeparator","setNodeLocationOnlyOffset","currNodeLocation","newLocationInfo","setNodeLocationFull","defineNameProp","nameValue","configurable","writable","defaultVisit","childrenNames","childrenNamesLength","currChildArray","currChildArrayLength","currChild","createBaseSemanticVisitorConstructor","derivedConstructor","semanticProto","validateVisitor","semanticDefinitionErrors","visitorInstance","missingErrors","missingRuleNames","CstVisitorDefinitionError","MISSING_METHOD","methodName","validateMissingCstMethods","errorMessages","currDefError","_RULE_NAMES","RECORDING_NULL_OBJECT","HANDLE_SEPARATOR","MAX_METHOD_IDX","pow","RFT","RECORDING_PHASE_TOKEN","RECORDING_PHASE_CSTNODE","recordProd","prodConstructor","mainProdArg","handleSep","assertMethodIdxIsValid","prevProd","peek","recordingProdStack","grammarAction","newProd","SEP","MAX_LOOKAHEAD","recordOrProd","hasOptions","newOrProd","IGNORE_AMBIGUITIES","currAltFlat","getIdxSuffix","KNOWN_RECORDER_ERROR","END_OF_FILE","NaN","outputCst","DEFAULT_RULE_CONFIG","recoveryValueFunc","resyncEnabled","derivedCtor","Parser","parserInstance","defErrorsMsgs","selfAnalysisDone","enableRecording","definedRulesNames","originalGrammarAction","recordedRuleGast","topLevelRuleRecord","gastProductionsCache","disableRecording","resolverErrors","validationErrors","tokensMap","orgValidateGrammar","lookaheadValidationErrors","lookaheadValidationErrorMessages","CUSTOM_LOOKAHEAD_VALIDATION","validateLookahead","allFollows","topProductions","reSyncFollows","currRefsFollow","computeAllProdsFollows","resyncFollows","preComputeLookaheadFunctions","DEFER_DEFINITION_ERRORS_HANDLING","that","initErrorHandler","initLexerAdapter","initLooksAhead","initRecognizerEngine","initRecoverable","initTreeBuilder","initContentAssist","initGastRecorder","initPerformanceTracer","getTokenToInsert","tokToInsert","canTokenTypeBeInsertedInRecovery","canTokenTypeBeDeletedInRecovery","grammarRule","grammarRuleArgs","lookAheadFunc","expectedTokType","reSyncTokType","findReSyncTokenType","savedLexerState","exportLexerState","passedResyncPoint","nextTokenWithoutResync","generateErrorMessage","SAVE_ERROR","SKIP_TOKEN","addToResyncTokens","importLexerState","isBackTracking","canPerformInRuleRecovery","getFollowsForInRuleRecovery","tokIdxInRule","grammarPath","getCurrentGrammarPath","getNextPossibleTokenTypes","tryInRuleRecovery","canRecoverWithSingleTokenInsertion","canRecoverWithSingleTokenDeletion","nextTok","consumeToken","expectedToken","mismatchedTok","possibleFollowsTokType","isInCurrentRuleReSyncSet","followKey","getCurrFollowKey","currentRuleReSyncSet","getFollowSetFromFollowKey","allPossibleReSyncTokTypes","flattenFollowSet","foundMatch","resyncTokType","currRuleShortName","getLastExplicitRuleShortName","currRuleIdx","getLastExplicitRuleOccurrenceIndex","prevRuleShortName","getPreviousExplicitRuleShortName","shortRuleNameToFullName","idxInCallingRule","inRule","buildFullFollowKeyStack","explicitRuleStack","explicitOccurrenceStack","RULE_OCCURRENCE_STACK","followStack","resyncTokens","reSyncTo","getHumanReadableRuleStack","currShortName","lookAheadFuncsCache","collectMethods","prodIdx","laFunc","fullRuleNameToShort","setLaFuncCache","computeLookaheadFunc","prodKey","prodMaxLookahead","dslMethodName","getLaFuncFromCache","CST_STACK","setNodeLocationFromToken","setNodeLocationFromNode","cstPostRule","setInitialNodeLocation","setInitialNodeLocationFullRecovery","cstPostRuleFull","setInitialNodeLocationFullRegular","setInitialNodeLocationOnlyOffsetRecovery","cstPostRuleOnlyOffset","setInitialNodeLocationOnlyOffsetRegular","cstInvocationStateUpdate","cstFinallyStateUpdate","cstPostTerminal","cstPostNonTerminal","fullRuleName","ruleCstNode","prevToken","consumedToken","rootCst","tokenTypeName","ruleCstResult","preCstNode","ruleResult","addNoneTerminalToCst","getBaseCstVisitorConstructor","baseCstVisitorConstructor","newBaseCstVisitorConstructor","getBaseCstVisitorConstructorWithDefaults","baseCstVisitorWithDefaultsConstructor","newConstructor","baseConstructor","withDefaultsProto","createBaseVisitorConstructorWithDefaults","tokVector","tokVectorLength","newInput","howMuch","soughtIdx","resetLexerState","moveToTerminatedState","getLexerPosition","shortRuleNameToFull","ruleShortNameIdx","subruleIdx","isBackTrackingStack","uniqueTokens","noTokenCategoriesUsed","tokenConstructor","defineRule","shortName","BITS_FOR_METHOD_TYPE","invokeRuleWithTry","ruleInvocationStateUpdate","invokeRuleCatch","ruleFinallyStateUpdate","resyncEnabledConfig","isFirstInvokedRule","reSyncEnabled","recogError","partialCstResult","recoveredNode","optionInternal","actionORMethodDef","optionInternalLogic","orgLookaheadFunction","atLeastOneInternal","laKey","atLeastOneInternalLogic","raiseEarlyExitException","ERR_MSG","doSingleRepetition","atLeastOneSepFirstInternal","atLeastOneSepFirstInternalLogic","separatorLookAheadFunc","CONSUME","repetitionSepSecondInternal","manyInternal","manyInternalLogic","lookaheadFunction","manySepFirstInternal","manySepFirstInternalLogic","nextTerminalAfterWalker","beforeIteration","orInternal","altsOrOpts","altIdxToTake","raiseNoAltException","isAtEndOfInput","firstRedundantTok","subruleInternal","ruleToCall","subruleInternalError","consumeInternal","consumeInternalError","eFromConsumption","consumeInternalRecovery","eFromInRuleRecovery","saveRecogState","savedErrors","savedRuleStack","lexerState","reloadRecogState","fullName","ACTION","CONSUME1","CONSUME2","CONSUME3","CONSUME4","CONSUME5","CONSUME6","CONSUME7","CONSUME8","CONSUME9","SUBRULE","SUBRULE1","SUBRULE2","SUBRULE3","SUBRULE4","SUBRULE5","SUBRULE6","SUBRULE7","SUBRULE8","SUBRULE9","OPTION1","OPTION2","OPTION3","OPTION4","OPTION5","OPTION6","OPTION7","OPTION8","OPTION9","OR","OR1","OR2","OR3","OR4","OR5","OR6","OR7","OR8","OR9","MANY","MANY1","MANY2","MANY3","MANY4","MANY5","MANY6","MANY7","MANY8","MANY9","MANY_SEP","MANY_SEP1","MANY_SEP2","MANY_SEP3","MANY_SEP4","MANY_SEP5","MANY_SEP6","MANY_SEP7","MANY_SEP8","MANY_SEP9","AT_LEAST_ONE","AT_LEAST_ONE1","AT_LEAST_ONE2","AT_LEAST_ONE3","AT_LEAST_ONE4","AT_LEAST_ONE5","AT_LEAST_ONE6","AT_LEAST_ONE7","AT_LEAST_ONE8","AT_LEAST_ONE9","AT_LEAST_ONE_SEP","AT_LEAST_ONE_SEP1","AT_LEAST_ONE_SEP2","AT_LEAST_ONE_SEP3","AT_LEAST_ONE_SEP4","AT_LEAST_ONE_SEP5","AT_LEAST_ONE_SEP6","AT_LEAST_ONE_SEP7","AT_LEAST_ONE_SEP8","AT_LEAST_ONE_SEP9","ruleImplementation","OVERRIDE_RULE","ruleErrors","INVALID_RULE_OVERRIDE","validateRuleIsOverridden","BACKTRACK","orgState","getSerializedGastProductions","topRules","_errors","ruleOccurrenceStack","newErrors","userDefinedErrMsg","insideProdPaths","actualTokens","errMsgTypes","lookAheadPathsPerAlternative","computeContentAssist","startRuleName","precedingInput","startRuleGast","topRuleName","topProduction","arg1","arg2","consumeInternalRecord","subruleInternalRecord","optionInternalRecord","orInternalRecord","manyInternalRecord","manySepFirstInternalRecord","atLeastOneInternalRecord","atLeastOneSepFirstInternalRecord","ACTION_RECORD","BACKTRACK_RECORD","LA_RECORD","newTopLevelRule","originalError","mutabilityError","newNoneTerminal","userTraceInitPerf","traceIsNumber","baseCtor","baseProto","propName","basePropDescriptor","configClone","PieTokenBuilder","PieValueConverter","PieModule","createPieServices","Pie","PieGeneratedModule","cc","insertToSet","subItem","addFlag","flagObj","flagKey","ASSERT_EXISTS","ASSERT_NEVER_REACH_HERE","isCharacter","digitsCharCodes","wordCharCodes","whitespaceCodes","hexDigitPattern","decimalPattern","decimalPatternNoZero","saveState","restoreState","consumeChar","disjunction","multiLine","isRegExpFlag","popChar","peekChar","isTerm","isAssertion","assertion","isBacktracking","atMost","integerIncludingZero","isDigit","greedy","dotAll","atomEscape","characterClass","isPatternCharacter","patternCharacter","isQuantifier","decimalEscapeAtom","characterClassEscape","controlEscapeAtom","controlLetterEscapeAtom","nulCharacterAtom","hexEscapeSequenceAtom","regExpUnicodeEscapeSequenceAtom","identityEscapeAtom","positiveInteger","escapeCode","parseHexDigits","classPatternCharacterAtom","isClassAtom","classAtom","isRangeDash","classEscape","capturing","groupAst","nextChar","isAtom","prevState","howMany","hexString","hexChar","subChild","visitPattern","visitFlags","visitDisjunction","visitWordBoundary","visitNonWordBoundary","visitGroupBackReference","visitQuantifier","RangeComparison","comparison","Before","After","startInside","endInside","Inside","OverlapBack","OverlapFront","Outside","compareRange","commentNames","getPreviousNode","isCommentNode","findIndex","toFinite","remainder","reachableRules","terminalTokens","buildTerminalTokens","buildKeywordTokens","terminalToken","popDiagnostics","buildTerminalToken","requiresCustomPattern","regexPatternFunction","stickyRegex","distinct","sort","buildKeywordToken","keywordPattern","buildKeywordPattern","findLongerAlt","longerAlts","PacketTokenBuilder","PacketModule","createPacketServices","Packet","PacketGeneratedModule","findIndexFunc","iterable","createFind","baseFindIndex","EmptyFileSystemProvider","stringArray","elem","events_1","Cancelled","shortcutEvent","MutableToken","_isCancelled","_emitter","_token","GitGraphTokenBuilder","GitGraphModule","createGitGraphServices","GitGraph","GitGraphGeneratedModule","minimalGrammarModule","minimalSharedGrammarModule","loadGrammarFromJson","json","createMinimalGrammarServices","__defProp","Statement","Architecture","Axis","Branch","Checkout","CherryPicking","ClassDefStatement","Commit","Curve","Edge","Entry","Item","Junction","Merge","PacketBlock","PieSection","Service","loadedInfoGrammar","loadedPacketGrammar","loadedPieGrammar","loadedArchitectureGrammar","loadedGitGraphGrammar","loadedRadarGrammar","loadedTreemapGrammar","TreemapRow","Direction","Leaf","Section","MermaidAstReflection","InfoGrammar","PacketGrammar","PieGrammar","ArchitectureGrammar","GitGraphGrammar","RadarGrammar","TreemapGrammar","InfoLanguageMetaData","PacketLanguageMetaData","PieLanguageMetaData","ArchitectureLanguageMetaData","GitGraphLanguageMetaData","RadarLanguageMetaData","TreemapLanguageMetaData","ArchitectureGeneratedModule","rulesRegexes","ACC_DESCR","ACC_TITLE","TITLE","runConverter","runCommonConverter","_rule","_input","_Class4","keywords","_Class5","baseMap","startFn","nextFn","toMap","keyFn","valueFn","entryStream","firstDone","addSeparator","searchElement","initialValue","reduceRight","recursiveReduce","mapped","isIterable","depth","head","tail","skipCount","limit","maxSize","by","internalState","exclude","otherKeySet","ownKey","EMPTY_STREAM","collections","collIndex","arrIndex","iterators","pruned","prune","product","allTerminals","entryRule","getEntryRule","topMostRules","getHiddenRules","ruleDfs","visitedSet","refRule","getCrossReferenceTerminal","nameAssigment","findNodesForPropertyInternal","nodeFeature","findNodesForKeywordInternal","treeIterator","keywordNodes","childNode","startNode","findNameAssignmentInternal","go","refType","childAssignment","typeRef","isDataTypeRuleInternal","visited","inferredType","dataType","returnType","getActionType","getRuleType","abstractElementToRegex","flagText","WILDCARD","withCardinality","keywordToRegex","characterRangeToRegex","until","lastSlash","regexFlags","parsers","initializers","createInfoServices2","packet","createPacketServices2","pie","createPieServices2","architecture","createArchitectureServices","createArchitectureServices2","gitGraph","createGitGraphServices2","radar","createRadarServices2","treemap","createTreemapServices2","diagramType","MermaidParseError","ArchitectureTokenBuilder","ArchitectureValueConverter","ArchitectureModule","convertInt","convertString","convertID","convertNumber","convertBoolean","convertBigint","convertDate","convertEscapeCharacter","BigInt"],"sourceRoot":""}